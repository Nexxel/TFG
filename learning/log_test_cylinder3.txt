=======================================
Simulation: 1
Iteration: 1
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -10
New value of Visit matrix: 1
New value of Q matrix: -0.2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 0.2
New value of Value function: 0.2
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 8
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 9
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -10
New value of Visit matrix: 3
New value of Q matrix: -0.1964
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0036
New value of Value function: 0.2
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0036
New value of Value function: 0.2
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.007128
New value of Value function: 0.2
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.1996
New value of Value function: 0.1996
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.199201
New value of Value function: 0.199201
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.198802
New value of Value function: 0.198802
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0105639
New value of Value function: 0.198802
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.198405
New value of Value function: 0.198405
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.198008
New value of Value function: 0.198008
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00356414
New value of Value function: 0.198008
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.197612
New value of Value function: 0.197612
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.197217
New value of Value function: 0.197217
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00704276
New value of Value function: 0.197217
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.196822
New value of Value function: 0.196822
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.196429
New value of Value function: 0.196429
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 10
New value of Visit matrix: 11
New value of Q matrix: 0.3925
New value of Value function: 0.3925
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 26
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 27
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 28
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 29
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 30
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 31
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -10
New value of Visit matrix: 6
New value of Q matrix: -0.2
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 32
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -10
New value of Visit matrix: 1
New value of Q matrix: -0.192935
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.391715
New value of Value function: 0.391715
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 10
New value of Visit matrix: 13
New value of Q matrix: 0.583881
New value of Value function: 0.583881
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 35
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 0.2
New value of Value function: 0.2
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 36
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 0.1
New value of Value function: 0.1
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 37
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 38
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 39
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 40
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 41
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.196
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 42
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 43
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 44
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 45
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 46
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 47
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 48
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 49
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 50
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 51
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.19208
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 52
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.188238
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 53
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -10
New value of Visit matrix: 1
New value of Q matrix: -0.2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 55
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 0.2
New value of Value function: 0.2
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 56
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 57
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 60
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 61
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.196
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 63
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 65
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 66
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 67
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -10
New value of Visit matrix: 1
New value of Q matrix: -0.1964
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 69
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 0.2
New value of Value function: 0.2
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 70
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -10
New value of Visit matrix: 2
New value of Q matrix: -0.2
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 71
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 72
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 0.2
New value of Value function: 0.2
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 73
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 74
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 76
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 77
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.192472
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 78
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 79
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 80
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 81
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 82
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -10
New value of Visit matrix: 3
New value of Q matrix: -0.3924
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 83
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 0.2
New value of Value function: 0.2
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 84
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -10
New value of Visit matrix: 6
New value of Q matrix: -0.1964
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 85
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 0.2
New value of Value function: 0.2
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 86
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 87
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -10
New value of Visit matrix: 2
New value of Q matrix: -0.1964
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 0.2
New value of Value function: 0.2
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 89
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 95
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

