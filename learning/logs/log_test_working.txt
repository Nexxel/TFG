=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.333333
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 43
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.335
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0366667
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0235714
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0366667
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.066
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.11
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.141429
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.165
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.183333
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.198
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.21
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.22
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.228462
New value of Value function: 0.333333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.333
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.235691
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.241956
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.247438
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.252275
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.256575
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.260422
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.263884
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.267017
New value of Value function: 0.333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.332697
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.269851
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.272439
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.274811
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.276994
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.065937
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.279008
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.280873
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.282605
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.284218
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.285723
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.287131
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.065937
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.288451
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0898855
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.289691
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.290858
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.291958
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.292998
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.043958
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.293981
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0898855
New value of Value function: 0.332697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.33242
New value of Value function: 0.33242
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.332164
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.294898
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0617633
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.295768
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.296595
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.297382
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.298131
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.298845
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.299527
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.300178
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.300801
New value of Value function: 0.332164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.331927
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.301393
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.30196
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.302504
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.303026
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.07746
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.303528
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.30401
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.109779
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.126612
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.304474
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.304921
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.305352
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.305767
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.14104
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.306168
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.306555
New value of Value function: 0.331927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.331706
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.306925
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.15353
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.307282
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.307628
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.307963
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.308287
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.308601
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.308906
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.309201
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.309487
New value of Value function: 0.331706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.331498
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.309762
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.310029
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.310289
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.310541
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.310786
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.311024
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.311256
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0913891
New value of Value function: 0.331498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.331303
New value of Value function: 0.331303
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.311479
New value of Value function: 0.331303
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.164434
New value of Value function: 0.331303
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.311696
New value of Value function: 0.331303
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.311908
New value of Value function: 0.331303
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.312114
New value of Value function: 0.331303
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.331119
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.312313
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.312507
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.312695
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.31288
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.31306
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.313235
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.313407
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.313574
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.313738
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.109712
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.313898
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.314054
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.314207
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.314356
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.314502
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.314645
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.174044
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.314786
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.314923
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.315057
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.315188
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.315317
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.315443
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.182587
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.315567
New value of Value function: 0.331119
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 101
New value of Q matrix: 0.342145
New value of Value function: 0.342145
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 170
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 171
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 172
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 173
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 174
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 176
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 178
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 179
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 180
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 181
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.505
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.49167
New value of Value function: 2.49167
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 185
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.48544
New value of Value function: 2.48544
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 186
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.48047
New value of Value function: 2.48047
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 187
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.47633
New value of Value function: 2.47633
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 188
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.47279
New value of Value function: 2.47279
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 189
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 190
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.420833
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 191
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.360714
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 192
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.315625
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.280556
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 194
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: -0.2575
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 195
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 196
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 197
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 198
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.475
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 199
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 200
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 201
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 202
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 203
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 204
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.2835
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 205
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 206
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.9801
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 207
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 208
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.45025
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 209
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.9005
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 210
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 211
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.92525
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 212
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.25883
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 213
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.657
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 214
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.88825
New value of Value function: 4.88825
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 215
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.90883
New value of Value function: 4.90883
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 216
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.91912
New value of Value function: 4.91912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 217
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.68011
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 218
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.89959
New value of Value function: 4.91912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 219
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.88522
New value of Value function: 4.91912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 220
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.90929
New value of Value function: 4.90929
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 221
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.05969
New value of Value function: 4.90929
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 222
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.17107
New value of Value function: 4.90929
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 223
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.8789
New value of Value function: 4.8789
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 224
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.25345
New value of Value function: 4.90929
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 225
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.87422
New value of Value function: 4.87422
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 226
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.9011
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 227
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.31997
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 228
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.37052
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 229
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.8698
New value of Value function: 4.8698
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 230
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.41148
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 231
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.86684
New value of Value function: 4.86684
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 232
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.44537
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 233
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.86474
New value of Value function: 4.86474
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 234
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.47389
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 235
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.86316
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 236
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.62543
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 237
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.49822
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 238
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.81453
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 239
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.81453
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 240
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.40726
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 241
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 242
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 243
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 244
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 245
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 246
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 247
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 248
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 249
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 250
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 251
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 252
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 253
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 254
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 255
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 256
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 257
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 258
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 259
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 260
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 261
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 262
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 263
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 264
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 265
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 266
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 267
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 268
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 269
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 270
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 271
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 272
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 273
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 274
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 275
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 276
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 277
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 278
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 279
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 280
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 281
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 282
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.33064
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.342112
New value of Value function: 0.342112
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.190803
New value of Value function: 0.342112
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.342079
New value of Value function: 0.342079
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.342046
New value of Value function: 0.342046
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.342013
New value of Value function: 0.342013
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.127319
New value of Value function: 0.342013
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.341981
New value of Value function: 0.341981
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.142407
New value of Value function: 0.341981
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.341949
New value of Value function: 0.341949
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.341917
New value of Value function: 0.341917
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.341886
New value of Value function: 0.341886
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.341855
New value of Value function: 0.341855
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.341824
New value of Value function: 0.341824
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.341794
New value of Value function: 0.341794
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.155472
New value of Value function: 0.341794
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.341763
New value of Value function: 0.341763
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.166902
New value of Value function: 0.341763
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.341733
New value of Value function: 0.341733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.341704
New value of Value function: 0.341704
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.341674
New value of Value function: 0.341674
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.104382
New value of Value function: 0.341674
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.341645
New value of Value function: 0.341645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.341616
New value of Value function: 0.341616
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.341587
New value of Value function: 0.341587
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.341559
New value of Value function: 0.341559
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.341531
New value of Value function: 0.341531
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.341503
New value of Value function: 0.341503
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.331486
New value of Value function: 0.341503
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.341475
New value of Value function: 0.341475
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.17697
New value of Value function: 0.341475
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.341447
New value of Value function: 0.341447
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.116065
New value of Value function: 0.341447
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.34142
New value of Value function: 0.34142
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.126633
New value of Value function: 0.34142
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.341393
New value of Value function: 0.341393
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.341366
New value of Value function: 0.341366
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.341339
New value of Value function: 0.341339
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.341313
New value of Value function: 0.341313
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.341287
New value of Value function: 0.341287
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.136235
New value of Value function: 0.341287
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.341261
New value of Value function: 0.341261
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.145001
New value of Value function: 0.341261
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0.341235
New value of Value function: 0.341235
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.341209
New value of Value function: 0.341209
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0.341184
New value of Value function: 0.341184
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.185903
New value of Value function: 0.341184
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.193896
New value of Value function: 0.341184
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.20109
New value of Value function: 0.341184
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0.341158
New value of Value function: 0.341158
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.341133
New value of Value function: 0.341133
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.341108
New value of Value function: 0.341108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.341084
New value of Value function: 0.341084
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.341059
New value of Value function: 0.341059
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.341035
New value of Value function: 0.341035
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.331793
New value of Value function: 0.341035
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.341011
New value of Value function: 0.341011
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.340987
New value of Value function: 0.340987
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.332068
New value of Value function: 0.340987
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.340963
New value of Value function: 0.340963
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.340939
New value of Value function: 0.340939
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.340915
New value of Value function: 0.340915
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.332316
New value of Value function: 0.340915
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.332541
New value of Value function: 0.340915
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.340892
New value of Value function: 0.340892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.332747
New value of Value function: 0.340892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0.340869
New value of Value function: 0.340869
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.340846
New value of Value function: 0.340846
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.340823
New value of Value function: 0.340823
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0.3408
New value of Value function: 0.3408
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.153017
New value of Value function: 0.3408
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.340778
New value of Value function: 0.340778
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.207579
New value of Value function: 0.340778
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0.340755
New value of Value function: 0.340755
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.213478
New value of Value function: 0.340755
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.16039
New value of Value function: 0.340755
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.340733
New value of Value function: 0.340733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.218863
New value of Value function: 0.340733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.167196
New value of Value function: 0.340733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0.340711
New value of Value function: 0.340711
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.340689
New value of Value function: 0.340689
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0.340667
New value of Value function: 0.340667
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0.340645
New value of Value function: 0.340645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0.340624
New value of Value function: 0.340624
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0.340602
New value of Value function: 0.340602
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0.340581
New value of Value function: 0.340581
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0.34056
New value of Value function: 0.34056
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0.340539
New value of Value function: 0.340539
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0.340518
New value of Value function: 0.340518
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0.340497
New value of Value function: 0.340497
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0.340477
New value of Value function: 0.340477
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.340456
New value of Value function: 0.340456
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.340436
New value of Value function: 0.340436
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.340415
New value of Value function: 0.340415
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0.340395
New value of Value function: 0.340395
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0.340375
New value of Value function: 0.340375
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0.340355
New value of Value function: 0.340355
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0.340336
New value of Value function: 0.340336
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0.340316
New value of Value function: 0.340316
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.332914
New value of Value function: 0.340316
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0.340296
New value of Value function: 0.340296
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.333067
New value of Value function: 0.340296
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.198107
New value of Value function: 0.340296
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0.340277
New value of Value function: 0.340277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.204715
New value of Value function: 0.340277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.17348
New value of Value function: 0.340277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0.340258
New value of Value function: 0.340258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0.340238
New value of Value function: 0.340238
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0.340219
New value of Value function: 0.340219
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0.3402
New value of Value function: 0.3402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0.340181
New value of Value function: 0.340181
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.210718
New value of Value function: 0.340181
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.179312
New value of Value function: 0.340181
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0.340163
New value of Value function: 0.340163
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0.340144
New value of Value function: 0.340144
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0.340125
New value of Value function: 0.340125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0.340107
New value of Value function: 0.340107
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0.340088
New value of Value function: 0.340088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0.34007
New value of Value function: 0.34007
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0.340052
New value of Value function: 0.340052
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0.340034
New value of Value function: 0.340034
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0.340016
New value of Value function: 0.340016
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0.339998
New value of Value function: 0.339998
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0.33998
New value of Value function: 0.33998
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.333197
New value of Value function: 0.33998
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0.339962
New value of Value function: 0.339962
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0.339945
New value of Value function: 0.339945
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 194
New value of Q matrix: 0.353656
New value of Value function: 0.353656
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 410
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 411
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 412
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 413
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 414
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 415
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 416
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 417
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 418
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 419
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 420
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 421
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 422
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 423
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 424
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 425
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 426
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 427
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 428
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 429
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 430
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 431
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 432
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 433
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 434
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 435
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.64988
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 195
New value of Q matrix: 0.367227
New value of Value function: 0.367227
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 437
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 438
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: -0.125545
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 196
New value of Q matrix: 0.38066
New value of Value function: 0.38066
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 440
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: -0.119838
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 441
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 442
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 443
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 444
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 445
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 446
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 447
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.234091
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 448
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: -0.63125
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 449
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 450
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.93409
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 451
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.08709
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 452
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.52181
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 453
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.5401
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 454
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.20968
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 455
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.40726
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 456
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 457
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 458
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 459
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 460
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.81453
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 461
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.87909
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 462
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.953276
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 463
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.794397
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 464
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.38319
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 465
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 466
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 467
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 468
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.2375
New value of Value function: 1.2375
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 469
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 470
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 471
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.22513
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 472
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.98
New value of Value function: 1.98
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 473
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 474
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 475
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 476
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.475
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 477
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.48342
New value of Value function: 2.48342
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 478
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.22513
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 479
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.45025
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 480
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.45025
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 481
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 482
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 483
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.22513
New value of Value function: 1.22513
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 484
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.83156
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 485
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.45025
New value of Value function: 2.45025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 486
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.438
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 487
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.42575
New value of Value function: 2.45025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 488
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.42575
New value of Value function: 2.45025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 489
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.0986996
New value of Value function: 2.45025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0.380641
New value of Value function: 0.380641
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.334756
New value of Value function: 0.380641
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0.380621
New value of Value function: 0.380621
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0.380602
New value of Value function: 0.380602
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0.380583
New value of Value function: 0.380583
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.225443
New value of Value function: 0.380583
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0.380564
New value of Value function: 0.380564
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0.380546
New value of Value function: 0.380546
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0.380527
New value of Value function: 0.380527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0.380508
New value of Value function: 0.380508
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.231493
New value of Value function: 0.380508
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0.38049
New value of Value function: 0.38049
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.237077
New value of Value function: 0.38049
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0.380471
New value of Value function: 0.380471
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.242247
New value of Value function: 0.380471
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.186118
New value of Value function: 0.380471
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0.380453
New value of Value function: 0.380453
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0.380434
New value of Value function: 0.380434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.217932
New value of Value function: 0.380434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0.380416
New value of Value function: 0.380416
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0.380398
New value of Value function: 0.380398
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0.38038
New value of Value function: 0.38038
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0.380362
New value of Value function: 0.380362
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.224541
New value of Value function: 0.380362
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0.380344
New value of Value function: 0.380344
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0.380326
New value of Value function: 0.380326
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0.380309
New value of Value function: 0.380309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0.380291
New value of Value function: 0.380291
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0.380274
New value of Value function: 0.380274
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0.380256
New value of Value function: 0.380256
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0.380239
New value of Value function: 0.380239
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0.380222
New value of Value function: 0.380222
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0.380204
New value of Value function: 0.380204
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0.380187
New value of Value function: 0.380187
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.19246
New value of Value function: 0.380187
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.247038
New value of Value function: 0.380187
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0.38017
New value of Value function: 0.38017
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0.380153
New value of Value function: 0.380153
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.198392
New value of Value function: 0.380153
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 0.380136
New value of Value function: 0.380136
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0.38012
New value of Value function: 0.38012
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0.380103
New value of Value function: 0.380103
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 0.380086
New value of Value function: 0.380086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.336188
New value of Value function: 0.380086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.230611
New value of Value function: 0.380086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.251495
New value of Value function: 0.380086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0.38007
New value of Value function: 0.38007
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0.380053
New value of Value function: 0.380053
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 0.380037
New value of Value function: 0.380037
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 0.38002
New value of Value function: 0.38002
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0.380004
New value of Value function: 0.380004
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0.379988
New value of Value function: 0.379988
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.379971
New value of Value function: 0.379971
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0.379955
New value of Value function: 0.379955
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.203947
New value of Value function: 0.379955
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.379939
New value of Value function: 0.379939
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0.379923
New value of Value function: 0.379923
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0.379907
New value of Value function: 0.379907
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.337518
New value of Value function: 0.379907
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.255648
New value of Value function: 0.379907
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.338763
New value of Value function: 0.379907
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.236207
New value of Value function: 0.379907
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 0.379892
New value of Value function: 0.379892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 0.379876
New value of Value function: 0.379876
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0.37986
New value of Value function: 0.37986
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.379845
New value of Value function: 0.379845
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 0.379829
New value of Value function: 0.379829
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 0.379813
New value of Value function: 0.379813
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.259531
New value of Value function: 0.379813
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.209161
New value of Value function: 0.379813
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0.379798
New value of Value function: 0.379798
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.241384
New value of Value function: 0.379798
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0.379783
New value of Value function: 0.379783
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 0.379767
New value of Value function: 0.379767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 0.379752
New value of Value function: 0.379752
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 0.379737
New value of Value function: 0.379737
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.214066
New value of Value function: 0.379737
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.263169
New value of Value function: 0.379737
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 0.379722
New value of Value function: 0.379722
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 0.379707
New value of Value function: 0.379707
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 0.379692
New value of Value function: 0.379692
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 0.379677
New value of Value function: 0.379677
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 0.379662
New value of Value function: 0.379662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 0.379647
New value of Value function: 0.379647
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 0.379632
New value of Value function: 0.379632
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 0.379618
New value of Value function: 0.379618
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 0.379603
New value of Value function: 0.379603
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 0.379588
New value of Value function: 0.379588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.246185
New value of Value function: 0.379588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 0.379574
New value of Value function: 0.379574
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 0.379559
New value of Value function: 0.379559
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 0.379545
New value of Value function: 0.379545
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 0.37953
New value of Value function: 0.37953
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 0.379516
New value of Value function: 0.379516
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 0.379502
New value of Value function: 0.379502
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.339918
New value of Value function: 0.379502
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 0.379488
New value of Value function: 0.379488
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 0.379473
New value of Value function: 0.379473
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 0.379459
New value of Value function: 0.379459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 0.379445
New value of Value function: 0.379445
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 0.379431
New value of Value function: 0.379431
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 0.379417
New value of Value function: 0.379417
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 0.379403
New value of Value function: 0.379403
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 0.37939
New value of Value function: 0.37939
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.218681
New value of Value function: 0.37939
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 0.379376
New value of Value function: 0.379376
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 0.379362
New value of Value function: 0.379362
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.223039
New value of Value function: 0.379362
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 0.379348
New value of Value function: 0.379348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.250646
New value of Value function: 0.379348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 0.379335
New value of Value function: 0.379335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 0.379321
New value of Value function: 0.379321
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 0.379308
New value of Value function: 0.379308
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 0.379294
New value of Value function: 0.379294
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 0.379281
New value of Value function: 0.379281
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 0.379267
New value of Value function: 0.379267
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 606
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 0.379254
New value of Value function: 0.379254
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 0.379241
New value of Value function: 0.379241
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 0.379227
New value of Value function: 0.379227
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 287
New value of Q matrix: 0.388359
New value of Value function: 0.388359
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 610
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: -0.114628
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 611
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 612
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: -0.218832
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 288
New value of Q matrix: 0.397427
New value of Value function: 0.397427
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 614
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 615
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 616
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 617
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: -0.590346
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 618
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.92525
New value of Value function: 4.92525
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 619
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.9335
New value of Value function: 4.9335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 620
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.19637
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 621
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.55846
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 622
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.8763
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 623
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.57268
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 624
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.20166
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 625
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.42519
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 626
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.1916
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 627
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.34532
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 628
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.9767
New value of Value function: 1.9767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 629
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.391387
New value of Value function: 1.9767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 630
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.95693
New value of Value function: 1.9767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 631
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.97388
New value of Value function: 1.97388
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 632
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.34589
New value of Value function: 2.34589
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 633
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.31667
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 634
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 635
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 636
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 637
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.71263
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 638
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.45025
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 639
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.45025
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 640
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.44208
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 641
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.6335
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 642
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.44412
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 643
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.573488
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 0.397413
New value of Value function: 0.397413
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 0.3974
New value of Value function: 0.3974
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.341539
New value of Value function: 0.3974
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 0.397386
New value of Value function: 0.397386
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 0.397372
New value of Value function: 0.397372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 0.397359
New value of Value function: 0.397359
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 0.397345
New value of Value function: 0.397345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 0.397332
New value of Value function: 0.397332
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 0.397318
New value of Value function: 0.397318
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.267114
New value of Value function: 0.397318
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 0.397305
New value of Value function: 0.397305
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.255402
New value of Value function: 0.397305
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 0.397292
New value of Value function: 0.397292
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 0.397278
New value of Value function: 0.397278
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 0.397265
New value of Value function: 0.397265
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 0.397252
New value of Value function: 0.397252
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 0.397239
New value of Value function: 0.397239
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 0.397226
New value of Value function: 0.397226
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 0.397213
New value of Value function: 0.397213
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.34306
New value of Value function: 0.397213
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 0.3972
New value of Value function: 0.3972
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 0.397187
New value of Value function: 0.397187
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 0.397174
New value of Value function: 0.397174
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 0.397161
New value of Value function: 0.397161
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 0.397148
New value of Value function: 0.397148
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.270821
New value of Value function: 0.397148
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 0.397135
New value of Value function: 0.397135
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 0.397122
New value of Value function: 0.397122
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 0.39711
New value of Value function: 0.39711
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 0.397097
New value of Value function: 0.397097
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 0.397084
New value of Value function: 0.397084
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 0.397072
New value of Value function: 0.397072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 0.397059
New value of Value function: 0.397059
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 0.397047
New value of Value function: 0.397047
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 678
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 0.397034
New value of Value function: 0.397034
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 0.397022
New value of Value function: 0.397022
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 0.397009
New value of Value function: 0.397009
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 0.396997
New value of Value function: 0.396997
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 682
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.227634
New value of Value function: 0.396997
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.259841
New value of Value function: 0.396997
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 0.396985
New value of Value function: 0.396985
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 0.396972
New value of Value function: 0.396972
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 0.39696
New value of Value function: 0.39696
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 0.396948
New value of Value function: 0.396948
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 0.396936
New value of Value function: 0.396936
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 0.396924
New value of Value function: 0.396924
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 0.396911
New value of Value function: 0.396911
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 0.396899
New value of Value function: 0.396899
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 0.396887
New value of Value function: 0.396887
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 0.396875
New value of Value function: 0.396875
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 694
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 0.396863
New value of Value function: 0.396863
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 695
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 0.396851
New value of Value function: 0.396851
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 696
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 0.39684
New value of Value function: 0.39684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 0.396828
New value of Value function: 0.396828
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 0.396816
New value of Value function: 0.396816
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 0.396804
New value of Value function: 0.396804
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 0.396792
New value of Value function: 0.396792
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 0.396781
New value of Value function: 0.396781
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.263997
New value of Value function: 0.396781
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 703
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 0.396769
New value of Value function: 0.396769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 0.396757
New value of Value function: 0.396757
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 0.396746
New value of Value function: 0.396746
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 0.396734
New value of Value function: 0.396734
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 0.396723
New value of Value function: 0.396723
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.231979
New value of Value function: 0.396723
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 0.396711
New value of Value function: 0.396711
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 0.3967
New value of Value function: 0.3967
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 0.396688
New value of Value function: 0.396688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 712
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.236101
New value of Value function: 0.396688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.267898
New value of Value function: 0.396688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 0.396677
New value of Value function: 0.396677
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 715
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.240016
New value of Value function: 0.396677
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 716
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.271569
New value of Value function: 0.396677
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 0.396666
New value of Value function: 0.396666
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.344478
New value of Value function: 0.396666
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.345817
New value of Value function: 0.396666
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.274304
New value of Value function: 0.396666
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.277592
New value of Value function: 0.396666
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.24374
New value of Value function: 0.396666
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 0.396654
New value of Value function: 0.396654
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.247286
New value of Value function: 0.396654
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 0.396643
New value of Value function: 0.396643
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 0.396632
New value of Value function: 0.396632
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 0.39662
New value of Value function: 0.39662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 0.396609
New value of Value function: 0.396609
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 0.396598
New value of Value function: 0.396598
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 0.396587
New value of Value function: 0.396587
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 0.396576
New value of Value function: 0.396576
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 0.396565
New value of Value function: 0.396565
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 0.396554
New value of Value function: 0.396554
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 0.396543
New value of Value function: 0.396543
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 735
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.275026
New value of Value function: 0.396543
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.278291
New value of Value function: 0.396543
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 0.396532
New value of Value function: 0.396532
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.347081
New value of Value function: 0.396532
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.250665
New value of Value function: 0.396532
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 0.396521
New value of Value function: 0.396521
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 0.39651
New value of Value function: 0.39651
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 0.396499
New value of Value function: 0.396499
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 0.396488
New value of Value function: 0.396488
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 0.396477
New value of Value function: 0.396477
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 0.396466
New value of Value function: 0.396466
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.280698
New value of Value function: 0.396466
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 0.396456
New value of Value function: 0.396456
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 0.396445
New value of Value function: 0.396445
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 0.396434
New value of Value function: 0.396434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 0.396423
New value of Value function: 0.396423
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 0.396413
New value of Value function: 0.396413
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 752
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 0.396402
New value of Value function: 0.396402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 0.396392
New value of Value function: 0.396392
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 0.396381
New value of Value function: 0.396381
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 0.39637
New value of Value function: 0.39637
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 0.39636
New value of Value function: 0.39636
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.283638
New value of Value function: 0.39636
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 0.396349
New value of Value function: 0.396349
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 0.396339
New value of Value function: 0.396339
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 760
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.286426
New value of Value function: 0.396339
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 0.396329
New value of Value function: 0.396329
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.253885
New value of Value function: 0.396329
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 0.396318
New value of Value function: 0.396318
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 764
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 382
New value of Q matrix: 0.403134
New value of Value function: 0.403134
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 765
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 766
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -0.520179
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 383
New value of Q matrix: 0.409914
New value of Value function: 0.409914
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 768
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.32494
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 769
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 770
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.74802
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 771
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 384
New value of Q matrix: 0.416659
New value of Value function: 0.416659
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 772
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 773
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: -0.313579
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 385
New value of Q matrix: 0.423369
New value of Value function: 0.423369
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 775
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 776
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.548179
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 777
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.511633
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 778
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: -0.486896
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 779
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.92117
New value of Value function: 4.92117
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 780
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.92693
New value of Value function: 4.92693
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 781
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.27834
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 782
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.58739
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 783
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.59875
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 784
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.59886
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 785
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.72858
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 786
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.91549
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 787
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.97363
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 788
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.34329
New value of Value function: 2.34329
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 789
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.60396
New value of Value function: 2.60396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 790
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.46015
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 791
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.01296
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 792
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.45025
New value of Value function: 7.45025
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 793
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.44535
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 794
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.60765
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 0.423358
New value of Value function: 0.423358
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 0.423347
New value of Value function: 0.423347
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.282097
New value of Value function: 0.423347
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 0.423337
New value of Value function: 0.423337
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 0.423326
New value of Value function: 0.423326
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 0.423315
New value of Value function: 0.423315
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 0.423304
New value of Value function: 0.423304
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.289742
New value of Value function: 0.423304
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 0.423293
New value of Value function: 0.423293
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.292896
New value of Value function: 0.423293
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 0.423282
New value of Value function: 0.423282
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 0.423272
New value of Value function: 0.423272
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 0.423261
New value of Value function: 0.423261
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.257555
New value of Value function: 0.423261
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 0.42325
New value of Value function: 0.42325
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.2857
New value of Value function: 0.42325
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 0.42324
New value of Value function: 0.42324
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.348974
New value of Value function: 0.42324
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 0.423229
New value of Value function: 0.423229
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 0.423218
New value of Value function: 0.423218
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 0.423208
New value of Value function: 0.423208
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 0.423197
New value of Value function: 0.423197
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 0.423187
New value of Value function: 0.423187
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 0.423176
New value of Value function: 0.423176
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.350768
New value of Value function: 0.423176
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.352472
New value of Value function: 0.423176
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 0.423166
New value of Value function: 0.423166
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.289117
New value of Value function: 0.423166
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 0.423155
New value of Value function: 0.423155
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 0.423145
New value of Value function: 0.423145
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 0.423134
New value of Value function: 0.423134
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 0.423124
New value of Value function: 0.423124
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 0.423114
New value of Value function: 0.423114
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.292361
New value of Value function: 0.423114
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 0.423103
New value of Value function: 0.423103
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 0.423093
New value of Value function: 0.423093
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.295895
New value of Value function: 0.423093
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 0.423083
New value of Value function: 0.423083
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 0.423073
New value of Value function: 0.423073
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 0.423062
New value of Value function: 0.423062
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 0.423052
New value of Value function: 0.423052
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 0.423042
New value of Value function: 0.423042
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 0.423032
New value of Value function: 0.423032
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 0.423022
New value of Value function: 0.423022
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.35409
New value of Value function: 0.423022
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.35563
New value of Value function: 0.423022
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 0.423012
New value of Value function: 0.423012
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 0.423002
New value of Value function: 0.423002
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 0.422992
New value of Value function: 0.422992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 0.422982
New value of Value function: 0.422982
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 0.422972
New value of Value function: 0.422972
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.357098
New value of Value function: 0.422972
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.261059
New value of Value function: 0.422972
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 0.422962
New value of Value function: 0.422962
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 0.422952
New value of Value function: 0.422952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 0.422942
New value of Value function: 0.422942
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 0.422932
New value of Value function: 0.422932
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 0.422922
New value of Value function: 0.422922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 0.422912
New value of Value function: 0.422912
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.264413
New value of Value function: 0.422912
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 0.422902
New value of Value function: 0.422902
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 0.422892
New value of Value function: 0.422892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.29875
New value of Value function: 0.422892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 0.422883
New value of Value function: 0.422883
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 0.422873
New value of Value function: 0.422873
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 0.422863
New value of Value function: 0.422863
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 0.422853
New value of Value function: 0.422853
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 0.422844
New value of Value function: 0.422844
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.267625
New value of Value function: 0.422844
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 0.422834
New value of Value function: 0.422834
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.29544
New value of Value function: 0.422834
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.301474
New value of Value function: 0.422834
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 0.422824
New value of Value function: 0.422824
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 0.422815
New value of Value function: 0.422815
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 0.422805
New value of Value function: 0.422805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 0.422796
New value of Value function: 0.422796
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 0.422786
New value of Value function: 0.422786
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.304076
New value of Value function: 0.422786
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 0.422776
New value of Value function: 0.422776
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 0.422767
New value of Value function: 0.422767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 0.422757
New value of Value function: 0.422757
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 0.422748
New value of Value function: 0.422748
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 0.422738
New value of Value function: 0.422738
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.29837
New value of Value function: 0.422738
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 0.422729
New value of Value function: 0.422729
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 0.42272
New value of Value function: 0.42272
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 0.42271
New value of Value function: 0.42271
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 0.422701
New value of Value function: 0.422701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 0.422692
New value of Value function: 0.422692
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 0.422682
New value of Value function: 0.422682
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.358493
New value of Value function: 0.422682
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 0.422673
New value of Value function: 0.422673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.306562
New value of Value function: 0.422673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 0.422664
New value of Value function: 0.422664
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 0.422654
New value of Value function: 0.422654
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 0.422645
New value of Value function: 0.422645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.301162
New value of Value function: 0.422645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.359824
New value of Value function: 0.422645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 458
New value of Q matrix: 0.422636
New value of Value function: 0.422636
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 894
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 459
New value of Q matrix: 0.422627
New value of Value function: 0.422627
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 460
New value of Q matrix: 0.422617
New value of Value function: 0.422617
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 0.422608
New value of Value function: 0.422608
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 897
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.361097
New value of Value function: 0.422608
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.303826
New value of Value function: 0.422608
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 462
New value of Q matrix: 0.422599
New value of Value function: 0.422599
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 900
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 0.42259
New value of Value function: 0.42259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 901
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 0.422581
New value of Value function: 0.422581
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 902
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 0.422572
New value of Value function: 0.422572
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 903
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 0.422563
New value of Value function: 0.422563
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 904
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.306371
New value of Value function: 0.422563
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 905
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 467
New value of Q matrix: 0.422554
New value of Value function: 0.422554
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 906
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.308805
New value of Value function: 0.422554
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 907
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 468
New value of Q matrix: 0.422545
New value of Value function: 0.422545
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 908
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 0.422536
New value of Value function: 0.422536
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 909
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 470
New value of Q matrix: 0.422527
New value of Value function: 0.422527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 910
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 471
New value of Q matrix: 0.422518
New value of Value function: 0.422518
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 911
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 472
New value of Q matrix: 0.422509
New value of Value function: 0.422509
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 912
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 473
New value of Q matrix: 0.4225
New value of Value function: 0.4225
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 913
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 474
New value of Q matrix: 0.422491
New value of Value function: 0.422491
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 475
New value of Q matrix: 0.422482
New value of Value function: 0.422482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 915
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 476
New value of Q matrix: 0.422473
New value of Value function: 0.422473
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 916
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 477
New value of Q matrix: 0.422464
New value of Value function: 0.422464
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.270699
New value of Value function: 0.422464
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.308938
New value of Value function: 0.422464
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 478
New value of Q matrix: 0.422455
New value of Value function: 0.422455
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 479
New value of Q matrix: 0.422447
New value of Value function: 0.422447
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 921
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.311133
New value of Value function: 0.422447
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 922
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.313364
New value of Value function: 0.422447
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 480
New value of Q matrix: 0.422438
New value of Value function: 0.422438
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 924
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 481
New value of Q matrix: 0.427797
New value of Value function: 0.427797
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 925
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 926
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 927
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 928
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 929
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 930
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 931
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.87766
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 932
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.87766
New value of Value function: 4.92693
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 933
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.91872
New value of Value function: 4.91872
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 934
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.86953
New value of Value function: 4.91872
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 935
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.86953
New value of Value function: 4.91872
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 936
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.0611682
New value of Value function: 4.91872
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 937
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 938
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 939
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 940
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.31667
New value of Value function: 3.31667
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 941
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 3.61225
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 942
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.30837
New value of Value function: 3.30837
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 943
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.30176
New value of Value function: 3.30176
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 944
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.75147
New value of Value function: 2.75147
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 945
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 946
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.91383
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 947
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 948
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.60922
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 949
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.93477
New value of Value function: 4.93477
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 950
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 4.19968
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 951
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.72395
New value of Value function: 4.93477
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 952
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.05632
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 953
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.88542
New value of Value function: 4.93477
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 954
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.87485
New value of Value function: 4.93477
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 955
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 956
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 957
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 958
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 959
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 960
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 961
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 962
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 963
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.02575
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 964
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.51288
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 965
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 966
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 967
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 968
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 969
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 970
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 971
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 972
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 973
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 974
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 975
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 976
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 1.96291
New value of Value function: 1.96291
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 977
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.83718
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 978
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.81453
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 979
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.92165
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 980
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.10192
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 981
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 982
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 983
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.54179
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 984
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.95729
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 985
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.72452
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 986
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.742783
New value of Value function: 2.45025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 987
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.0870333
New value of Value function: 2.45025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 482
New value of Q matrix: 0.427788
New value of Value function: 0.427788
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 483
New value of Q matrix: 0.427779
New value of Value function: 0.427779
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 484
New value of Q matrix: 0.42777
New value of Value function: 0.42777
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 485
New value of Q matrix: 0.427761
New value of Value function: 0.427761
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 486
New value of Q matrix: 0.427752
New value of Value function: 0.427752
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.362424
New value of Value function: 0.427752
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 487
New value of Q matrix: 0.427744
New value of Value function: 0.427744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 488
New value of Q matrix: 0.427735
New value of Value function: 0.427735
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 489
New value of Q matrix: 0.427726
New value of Value function: 0.427726
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 490
New value of Q matrix: 0.427717
New value of Value function: 0.427717
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 491
New value of Q matrix: 0.427709
New value of Value function: 0.427709
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 492
New value of Q matrix: 0.4277
New value of Value function: 0.4277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 493
New value of Q matrix: 0.427691
New value of Value function: 0.427691
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 494
New value of Q matrix: 0.427683
New value of Value function: 0.427683
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.273753
New value of Value function: 0.427683
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 495
New value of Q matrix: 0.427674
New value of Value function: 0.427674
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 496
New value of Q matrix: 0.427665
New value of Value function: 0.427665
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.315609
New value of Value function: 0.427665
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 497
New value of Q matrix: 0.427657
New value of Value function: 0.427657
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 498
New value of Q matrix: 0.427648
New value of Value function: 0.427648
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 499
New value of Q matrix: 0.42764
New value of Value function: 0.42764
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 500
New value of Q matrix: 0.427631
New value of Value function: 0.427631
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 501
New value of Q matrix: 0.427622
New value of Value function: 0.427622
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.317764
New value of Value function: 0.427622
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.363694
New value of Value function: 0.427622
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 502
New value of Q matrix: 0.427614
New value of Value function: 0.427614
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 503
New value of Q matrix: 0.427605
New value of Value function: 0.427605
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 504
New value of Q matrix: 0.427597
New value of Value function: 0.427597
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 505
New value of Q matrix: 0.427589
New value of Value function: 0.427589
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 506
New value of Q matrix: 0.42758
New value of Value function: 0.42758
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 507
New value of Q matrix: 0.427572
New value of Value function: 0.427572
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 508
New value of Q matrix: 0.427563
New value of Value function: 0.427563
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 0.427555
New value of Value function: 0.427555
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.319833
New value of Value function: 0.427555
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.321822
New value of Value function: 0.427555
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 510
New value of Q matrix: 0.427546
New value of Value function: 0.427546
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.364909
New value of Value function: 0.427546
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 511
New value of Q matrix: 0.427538
New value of Value function: 0.427538
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.323736
New value of Value function: 0.427538
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 512
New value of Q matrix: 0.42753
New value of Value function: 0.42753
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 513
New value of Q matrix: 0.427521
New value of Value function: 0.427521
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 0.427513
New value of Value function: 0.427513
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 515
New value of Q matrix: 0.427505
New value of Value function: 0.427505
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 516
New value of Q matrix: 0.427496
New value of Value function: 0.427496
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 517
New value of Q matrix: 0.427488
New value of Value function: 0.427488
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 0.42748
New value of Value function: 0.42748
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 519
New value of Q matrix: 0.427472
New value of Value function: 0.427472
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 0.427463
New value of Value function: 0.427463
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.276683
New value of Value function: 0.427463
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.279501
New value of Value function: 0.427463
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 521
New value of Q matrix: 0.427455
New value of Value function: 0.427455
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 522
New value of Q matrix: 0.427447
New value of Value function: 0.427447
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 0.427439
New value of Value function: 0.427439
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 0.427431
New value of Value function: 0.427431
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 0.427423
New value of Value function: 0.427423
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 0.427415
New value of Value function: 0.427415
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.325577
New value of Value function: 0.427415
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.327351
New value of Value function: 0.427415
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 0.427406
New value of Value function: 0.427406
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.311318
New value of Value function: 0.427406
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.366074
New value of Value function: 0.427406
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 0.427398
New value of Value function: 0.427398
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 0.42739
New value of Value function: 0.42739
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 0.427382
New value of Value function: 0.427382
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 531
New value of Q matrix: 0.427374
New value of Value function: 0.427374
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 0.427366
New value of Value function: 0.427366
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 0.427358
New value of Value function: 0.427358
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 534
New value of Q matrix: 0.42735
New value of Value function: 0.42735
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.367192
New value of Value function: 0.42735
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 535
New value of Q matrix: 0.427342
New value of Value function: 0.427342
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 536
New value of Q matrix: 0.427334
New value of Value function: 0.427334
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 537
New value of Q matrix: 0.427326
New value of Value function: 0.427326
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.32906
New value of Value function: 0.427326
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 538
New value of Q matrix: 0.427318
New value of Value function: 0.427318
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 539
New value of Q matrix: 0.42731
New value of Value function: 0.42731
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 0.427302
New value of Value function: 0.427302
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.313597
New value of Value function: 0.427302
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.282209
New value of Value function: 0.427302
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 541
New value of Q matrix: 0.427294
New value of Value function: 0.427294
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 0.427287
New value of Value function: 0.427287
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 543
New value of Q matrix: 0.427279
New value of Value function: 0.427279
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.368265
New value of Value function: 0.427279
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.330708
New value of Value function: 0.427279
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 544
New value of Q matrix: 0.427271
New value of Value function: 0.427271
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 545
New value of Q matrix: 0.427263
New value of Value function: 0.427263
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 546
New value of Q matrix: 0.427255
New value of Value function: 0.427255
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 547
New value of Q matrix: 0.427247
New value of Value function: 0.427247
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.284816
New value of Value function: 0.427247
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.332299
New value of Value function: 0.427247
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 548
New value of Q matrix: 0.42724
New value of Value function: 0.42724
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 549
New value of Q matrix: 0.427232
New value of Value function: 0.427232
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.287327
New value of Value function: 0.427232
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 550
New value of Q matrix: 0.427224
New value of Value function: 0.427224
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 551
New value of Q matrix: 0.427216
New value of Value function: 0.427216
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.315784
New value of Value function: 0.427216
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.317885
New value of Value function: 0.427216
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 552
New value of Q matrix: 0.427209
New value of Value function: 0.427209
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 553
New value of Q matrix: 0.427201
New value of Value function: 0.427201
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 554
New value of Q matrix: 0.427193
New value of Value function: 0.427193
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 555
New value of Q matrix: 0.427185
New value of Value function: 0.427185
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 556
New value of Q matrix: 0.427178
New value of Value function: 0.427178
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 557
New value of Q matrix: 0.42717
New value of Value function: 0.42717
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 558
New value of Q matrix: 0.427162
New value of Value function: 0.427162
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 559
New value of Q matrix: 0.427155
New value of Value function: 0.427155
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 560
New value of Q matrix: 0.427147
New value of Value function: 0.427147
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 561
New value of Q matrix: 0.42714
New value of Value function: 0.42714
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 562
New value of Q matrix: 0.427132
New value of Value function: 0.427132
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 563
New value of Q matrix: 0.427124
New value of Value function: 0.427124
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 564
New value of Q matrix: 0.427117
New value of Value function: 0.427117
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 565
New value of Q matrix: 0.427109
New value of Value function: 0.427109
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 566
New value of Q matrix: 0.427102
New value of Value function: 0.427102
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 567
New value of Q matrix: 0.427094
New value of Value function: 0.427094
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 568
New value of Q matrix: 0.427087
New value of Value function: 0.427087
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 569
New value of Q matrix: 0.427079
New value of Value function: 0.427079
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 570
New value of Q matrix: 0.427072
New value of Value function: 0.427072
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.369294
New value of Value function: 0.427072
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 571
New value of Q matrix: 0.427064
New value of Value function: 0.427064
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 572
New value of Q matrix: 0.427057
New value of Value function: 0.427057
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 573
New value of Q matrix: 0.427049
New value of Value function: 0.427049
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 574
New value of Q matrix: 0.427042
New value of Value function: 0.427042
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 575
New value of Q matrix: 0.427034
New value of Value function: 0.427034
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.333832
New value of Value function: 0.427034
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 576
New value of Q matrix: 0.427027
New value of Value function: 0.427027
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.289746
New value of Value function: 0.427027
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.292079
New value of Value function: 0.427027
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.294332
New value of Value function: 0.427027
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 577
New value of Q matrix: 0.42702
New value of Value function: 0.42702
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 578
New value of Q matrix: 0.427012
New value of Value function: 0.427012
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 579
New value of Q matrix: 0.427005
New value of Value function: 0.427005
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 580
New value of Q matrix: 0.426997
New value of Value function: 0.426997
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 581
New value of Q matrix: 0.42699
New value of Value function: 0.42699
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 582
New value of Q matrix: 0.426983
New value of Value function: 0.426983
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 583
New value of Q matrix: 0.426975
New value of Value function: 0.426975
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.296508
New value of Value function: 0.426975
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 584
New value of Q matrix: 0.426968
New value of Value function: 0.426968
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 585
New value of Q matrix: 0.426961
New value of Value function: 0.426961
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.319901
New value of Value function: 0.426961
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 586
New value of Q matrix: 0.426953
New value of Value function: 0.426953
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 587
New value of Q matrix: 0.426946
New value of Value function: 0.426946
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 588
New value of Q matrix: 0.431322
New value of Value function: 0.431322
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 128
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 129
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 130
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 131
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4773
	Distance: 8
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 132
----------
State: 4773
	Distance: 8
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 133
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 134
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 135
----------
State: 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 136
----------
State: 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 137
----------
State: 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 138
----------
State: 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 139
----------
State: 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 140
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 141
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 142
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 143
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 144
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 145
----------
State: 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 146
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -4.175
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 147
----------
State: 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 148
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 149
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 150
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 151
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 152
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 153
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 154
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 155
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 156
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 157
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 158
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 159
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.505
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 160
----------
State: 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 161
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 162
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -2.78333
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 163
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.35
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 164
----------
State: 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.6625
New value of Value function: 1.6625
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 165
----------
State: 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 2.33
New value of Value function: 2.33
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 166
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.675
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 167
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 168
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 169
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 170
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 171
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 172
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 173
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 174
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 175
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 176
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 177
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 178
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 179
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 180
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 181
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 182
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 183
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 184
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 0.833333
New value of Value function: 0.833333
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 185
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.175
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 186
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.832143
New value of Value function: 0.832143
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 187
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.831103
New value of Value function: 0.831103
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 188
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.830179
New value of Value function: 0.830179
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 189
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.829349
New value of Value function: 0.829349
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 190
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.821056
New value of Value function: 0.829349
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 191
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.829349
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 192
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 0.833333
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 193
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 194
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.0875
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 195
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 196
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -4.17697
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 197
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 198
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -2.78465
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 199
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -2.08849
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 200
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1.67079
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 201
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -1.39232
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 202
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -1.19342
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 203
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 204
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 205
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.35
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 206
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 207
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 208
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 209
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 210
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 211
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 212
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 213
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 214
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 215
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -1.04424
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 216
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 217
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 218
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 219
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 220
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 221
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 222
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 223
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 224
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 225
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 226
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 227
----------
State: 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 228
----------
State: 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.2865
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.298683
New value of Value function: 0.431322
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 589
New value of Q matrix: 0.431315
New value of Value function: 0.431315
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 590
New value of Q matrix: 0.431308
New value of Value function: 0.431308
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 591
New value of Q matrix: 0.4313
New value of Value function: 0.4313
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 592
New value of Q matrix: 0.431293
New value of Value function: 0.431293
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 593
New value of Q matrix: 0.431286
New value of Value function: 0.431286
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.335384
New value of Value function: 0.431286
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.321921
New value of Value function: 0.431286
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.323867
New value of Value function: 0.431286
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 594
New value of Q matrix: 0.431278
New value of Value function: 0.431278
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 595
New value of Q matrix: 0.431271
New value of Value function: 0.431271
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 596
New value of Q matrix: 0.431264
New value of Value function: 0.431264
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.336886
New value of Value function: 0.431264
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 597
New value of Q matrix: 0.431257
New value of Value function: 0.431257
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 598
New value of Q matrix: 0.431249
New value of Value function: 0.431249
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 599
New value of Q matrix: 0.431242
New value of Value function: 0.431242
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 600
New value of Q matrix: 0.431235
New value of Value function: 0.431235
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 601
New value of Q matrix: 0.431228
New value of Value function: 0.431228
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 602
New value of Q matrix: 0.431221
New value of Value function: 0.431221
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 603
New value of Q matrix: 0.431214
New value of Value function: 0.431214
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 604
New value of Q matrix: 0.431206
New value of Value function: 0.431206
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 605
New value of Q matrix: 0.431199
New value of Value function: 0.431199
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.37036
New value of Value function: 0.431199
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 606
New value of Q matrix: 0.431192
New value of Value function: 0.431192
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 607
New value of Q matrix: 0.431185
New value of Value function: 0.431185
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 608
New value of Q matrix: 0.431178
New value of Value function: 0.431178
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 609
New value of Q matrix: 0.431171
New value of Value function: 0.431171
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 610
New value of Q matrix: 0.431164
New value of Value function: 0.431164
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.325739
New value of Value function: 0.431164
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 611
New value of Q matrix: 0.431157
New value of Value function: 0.431157
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 612
New value of Q matrix: 0.43115
New value of Value function: 0.43115
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 613
New value of Q matrix: 0.431143
New value of Value function: 0.431143
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 614
New value of Q matrix: 0.431136
New value of Value function: 0.431136
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 615
New value of Q matrix: 0.431129
New value of Value function: 0.431129
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 616
New value of Q matrix: 0.431122
New value of Value function: 0.431122
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 617
New value of Q matrix: 0.431115
New value of Value function: 0.431115
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 618
New value of Q matrix: 0.431108
New value of Value function: 0.431108
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 619
New value of Q matrix: 0.431101
New value of Value function: 0.431101
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 620
New value of Q matrix: 0.431094
New value of Value function: 0.431094
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 621
New value of Q matrix: 0.431087
New value of Value function: 0.431087
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 622
New value of Q matrix: 0.43108
New value of Value function: 0.43108
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 623
New value of Q matrix: 0.431073
New value of Value function: 0.431073
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.300783
New value of Value function: 0.431073
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 624
New value of Q matrix: 0.431066
New value of Value function: 0.431066
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 625
New value of Q matrix: 0.431059
New value of Value function: 0.431059
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.327543
New value of Value function: 0.431059
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 626
New value of Q matrix: 0.431052
New value of Value function: 0.431052
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 627
New value of Q matrix: 0.431045
New value of Value function: 0.431045
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.338335
New value of Value function: 0.431045
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 628
New value of Q matrix: 0.431039
New value of Value function: 0.431039
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 629
New value of Q matrix: 0.431032
New value of Value function: 0.431032
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 630
New value of Q matrix: 0.431025
New value of Value function: 0.431025
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.371385
New value of Value function: 0.431025
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.329283
New value of Value function: 0.431025
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 631
New value of Q matrix: 0.431018
New value of Value function: 0.431018
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 632
New value of Q matrix: 0.431011
New value of Value function: 0.431011
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.330962
New value of Value function: 0.431011
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 633
New value of Q matrix: 0.431004
New value of Value function: 0.431004
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 634
New value of Q matrix: 0.430998
New value of Value function: 0.430998
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 635
New value of Q matrix: 0.430991
New value of Value function: 0.430991
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 636
New value of Q matrix: 0.430984
New value of Value function: 0.430984
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 637
New value of Q matrix: 0.430977
New value of Value function: 0.430977
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.332584
New value of Value function: 0.430977
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 638
New value of Q matrix: 0.430971
New value of Value function: 0.430971
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 639
New value of Q matrix: 0.430964
New value of Value function: 0.430964
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.302813
New value of Value function: 0.430964
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 640
New value of Q matrix: 0.430957
New value of Value function: 0.430957
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 641
New value of Q matrix: 0.43095
New value of Value function: 0.43095
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.304779
New value of Value function: 0.43095
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 642
New value of Q matrix: 0.430944
New value of Value function: 0.430944
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 643
New value of Q matrix: 0.430937
New value of Value function: 0.430937
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 644
New value of Q matrix: 0.43093
New value of Value function: 0.43093
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 645
New value of Q matrix: 0.430924
New value of Value function: 0.430924
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 646
New value of Q matrix: 0.430917
New value of Value function: 0.430917
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 647
New value of Q matrix: 0.43091
New value of Value function: 0.43091
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 648
New value of Q matrix: 0.430904
New value of Value function: 0.430904
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 649
New value of Q matrix: 0.430897
New value of Value function: 0.430897
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 650
New value of Q matrix: 0.43089
New value of Value function: 0.43089
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 651
New value of Q matrix: 0.430884
New value of Value function: 0.430884
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 652
New value of Q matrix: 0.430877
New value of Value function: 0.430877
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 653
New value of Q matrix: 0.430871
New value of Value function: 0.430871
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 654
New value of Q matrix: 0.430864
New value of Value function: 0.430864
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 655
New value of Q matrix: 0.430857
New value of Value function: 0.430857
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.306681
New value of Value function: 0.430857
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 656
New value of Q matrix: 0.430851
New value of Value function: 0.430851
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.37237
New value of Value function: 0.430851
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.339735
New value of Value function: 0.430851
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 657
New value of Q matrix: 0.430844
New value of Value function: 0.430844
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 658
New value of Q matrix: 0.430838
New value of Value function: 0.430838
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 659
New value of Q matrix: 0.430831
New value of Value function: 0.430831
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 660
New value of Q matrix: 0.430825
New value of Value function: 0.430825
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 661
New value of Q matrix: 0.430818
New value of Value function: 0.430818
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 662
New value of Q matrix: 0.430812
New value of Value function: 0.430812
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 663
New value of Q matrix: 0.430805
New value of Value function: 0.430805
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 664
New value of Q matrix: 0.430799
New value of Value function: 0.430799
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 665
New value of Q matrix: 0.430792
New value of Value function: 0.430792
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 666
New value of Q matrix: 0.430786
New value of Value function: 0.430786
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 667
New value of Q matrix: 0.430779
New value of Value function: 0.430779
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 668
New value of Q matrix: 0.430773
New value of Value function: 0.430773
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.334149
New value of Value function: 0.430773
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 669
New value of Q matrix: 0.430766
New value of Value function: 0.430766
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 670
New value of Q matrix: 0.43076
New value of Value function: 0.43076
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.34109
New value of Value function: 0.43076
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.308524
New value of Value function: 0.43076
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 671
New value of Q matrix: 0.430753
New value of Value function: 0.430753
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.335662
New value of Value function: 0.430753
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 672
New value of Q matrix: 0.430747
New value of Value function: 0.430747
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.373319
New value of Value function: 0.430747
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 673
New value of Q matrix: 0.430741
New value of Value function: 0.430741
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.31031
New value of Value function: 0.430741
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 674
New value of Q matrix: 0.430734
New value of Value function: 0.430734
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 675
New value of Q matrix: 0.430728
New value of Value function: 0.430728
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 676
New value of Q matrix: 0.430721
New value of Value function: 0.430721
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 677
New value of Q matrix: 0.430715
New value of Value function: 0.430715
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 678
New value of Q matrix: 0.430709
New value of Value function: 0.430709
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 679
New value of Q matrix: 0.430702
New value of Value function: 0.430702
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.312043
New value of Value function: 0.430702
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 680
New value of Q matrix: 0.434481
New value of Value function: 0.434481
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 347
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 348
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 349
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 350
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 351
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 352
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 353
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 354
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 355
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 356
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 357
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 358
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 359
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 360
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 361
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.45025
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 362
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 363
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.45025
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 364
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 365
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 366
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 367
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.9005
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 368
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.25067
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 369
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.85149
New value of Value function: 4.9005
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 370
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.42575
New value of Value function: 4.9005
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 371
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.85149
New value of Value function: 4.9005
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 372
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.876
New value of Value function: 4.876
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 373
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.83937
New value of Value function: 4.876
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 374
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.88417
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 375
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.64683
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 376
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.84341
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 377
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.56227
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 378
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 379
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 380
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 381
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 382
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 383
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 384
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 0.833333
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 385
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 386
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 387
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.0823383
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 388
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.4217
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 389
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.0823383
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 390
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 2.93736
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 391
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.109784
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 392
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 3.28114
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 393
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.123507
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 394
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.83802
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 395
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.93026
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 396
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.832143
New value of Value function: 0.832143
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 397
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 398
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0548922
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 399
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.0823383
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 400
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.18273
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 401
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 402
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 403
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.8
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 404
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 405
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.31667
New value of Value function: 3.31667
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 406
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.928216
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 407
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 408
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.65
New value of Value function: 1.65
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 409
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 410
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 411
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 412
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 413
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.56986
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 0.418606
New value of Value function: 0.434481
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 415
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 416
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 417
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -0.513973
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 681
New value of Q matrix: 0.434474
New value of Value function: 0.434474
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 682
New value of Q matrix: 0.434468
New value of Value function: 0.434468
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 683
New value of Q matrix: 0.434462
New value of Value function: 0.434462
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 684
New value of Q matrix: 0.434455
New value of Value function: 0.434455
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 685
New value of Q matrix: 0.434449
New value of Value function: 0.434449
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 686
New value of Q matrix: 0.434443
New value of Value function: 0.434443
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 687
New value of Q matrix: 0.434436
New value of Value function: 0.434436
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 688
New value of Q matrix: 0.43443
New value of Value function: 0.43443
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.342459
New value of Value function: 0.43443
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 689
New value of Q matrix: 0.434424
New value of Value function: 0.434424
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 690
New value of Q matrix: 0.434417
New value of Value function: 0.434417
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 691
New value of Q matrix: 0.434411
New value of Value function: 0.434411
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.4188
New value of Value function: 0.434411
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 692
New value of Q matrix: 0.434405
New value of Value function: 0.434405
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 693
New value of Q matrix: 0.434399
New value of Value function: 0.434399
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 694
New value of Q matrix: 0.434392
New value of Value function: 0.434392
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 695
New value of Q matrix: 0.434386
New value of Value function: 0.434386
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 696
New value of Q matrix: 0.43438
New value of Value function: 0.43438
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.343786
New value of Value function: 0.43438
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 697
New value of Q matrix: 0.434374
New value of Value function: 0.434374
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 698
New value of Q matrix: 0.434367
New value of Value function: 0.434367
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 699
New value of Q matrix: 0.434361
New value of Value function: 0.434361
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.337184
New value of Value function: 0.434361
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.338658
New value of Value function: 0.434361
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 700
New value of Q matrix: 0.434355
New value of Value function: 0.434355
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 701
New value of Q matrix: 0.434349
New value of Value function: 0.434349
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 702
New value of Q matrix: 0.434343
New value of Value function: 0.434343
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 703
New value of Q matrix: 0.434336
New value of Value function: 0.434336
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 704
New value of Q matrix: 0.43433
New value of Value function: 0.43433
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 705
New value of Q matrix: 0.434324
New value of Value function: 0.434324
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 706
New value of Q matrix: 0.434318
New value of Value function: 0.434318
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 707
New value of Q matrix: 0.434312
New value of Value function: 0.434312
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 708
New value of Q matrix: 0.434306
New value of Value function: 0.434306
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 709
New value of Q matrix: 0.4343
New value of Value function: 0.4343
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.345072
New value of Value function: 0.4343
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.313777
New value of Value function: 0.4343
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.315461
New value of Value function: 0.4343
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.340084
New value of Value function: 0.4343
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.341467
New value of Value function: 0.4343
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 710
New value of Q matrix: 0.434293
New value of Value function: 0.434293
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 711
New value of Q matrix: 0.434287
New value of Value function: 0.434287
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 712
New value of Q matrix: 0.434281
New value of Value function: 0.434281
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.342807
New value of Value function: 0.434281
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 713
New value of Q matrix: 0.434275
New value of Value function: 0.434275
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 714
New value of Q matrix: 0.434269
New value of Value function: 0.434269
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 715
New value of Q matrix: 0.434263
New value of Value function: 0.434263
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 716
New value of Q matrix: 0.434257
New value of Value function: 0.434257
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 717
New value of Q matrix: 0.434251
New value of Value function: 0.434251
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 718
New value of Q matrix: 0.434245
New value of Value function: 0.434245
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.344107
New value of Value function: 0.434245
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 719
New value of Q matrix: 0.434239
New value of Value function: 0.434239
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 720
New value of Q matrix: 0.434233
New value of Value function: 0.434233
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 721
New value of Q matrix: 0.434227
New value of Value function: 0.434227
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.346319
New value of Value function: 0.434227
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 722
New value of Q matrix: 0.434221
New value of Value function: 0.434221
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.345368
New value of Value function: 0.434221
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 723
New value of Q matrix: 0.434215
New value of Value function: 0.434215
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 724
New value of Q matrix: 0.434209
New value of Value function: 0.434209
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 725
New value of Q matrix: 0.434203
New value of Value function: 0.434203
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 726
New value of Q matrix: 0.434197
New value of Value function: 0.434197
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 727
New value of Q matrix: 0.434191
New value of Value function: 0.434191
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.418985
New value of Value function: 0.434191
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 728
New value of Q matrix: 0.434185
New value of Value function: 0.434185
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.346593
New value of Value function: 0.434185
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 729
New value of Q matrix: 0.434179
New value of Value function: 0.434179
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 730
New value of Q matrix: 0.434173
New value of Value function: 0.434173
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.34753
New value of Value function: 0.434173
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 731
New value of Q matrix: 0.434167
New value of Value function: 0.434167
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 732
New value of Q matrix: 0.434161
New value of Value function: 0.434161
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 733
New value of Q matrix: 0.434155
New value of Value function: 0.434155
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 734
New value of Q matrix: 0.434149
New value of Value function: 0.434149
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.419162
New value of Value function: 0.434149
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 735
New value of Q matrix: 0.434143
New value of Value function: 0.434143
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 736
New value of Q matrix: 0.434137
New value of Value function: 0.434137
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 737
New value of Q matrix: 0.434131
New value of Value function: 0.434131
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 738
New value of Q matrix: 0.434126
New value of Value function: 0.434126
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 739
New value of Q matrix: 0.43412
New value of Value function: 0.43412
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.348705
New value of Value function: 0.43412
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 740
New value of Q matrix: 0.434114
New value of Value function: 0.434114
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.419333
New value of Value function: 0.434114
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 741
New value of Q matrix: 0.434108
New value of Value function: 0.434108
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 742
New value of Q matrix: 0.434102
New value of Value function: 0.434102
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 743
New value of Q matrix: 0.434096
New value of Value function: 0.434096
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.347781
New value of Value function: 0.434096
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 744
New value of Q matrix: 0.43409
New value of Value function: 0.43409
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.349846
New value of Value function: 0.43409
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 745
New value of Q matrix: 0.434085
New value of Value function: 0.434085
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 746
New value of Q matrix: 0.434079
New value of Value function: 0.434079
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 747
New value of Q matrix: 0.434073
New value of Value function: 0.434073
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 748
New value of Q matrix: 0.434067
New value of Value function: 0.434067
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 749
New value of Q matrix: 0.434061
New value of Value function: 0.434061
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.348935
New value of Value function: 0.434061
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.350955
New value of Value function: 0.434061
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 750
New value of Q matrix: 0.434056
New value of Value function: 0.434056
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.350057
New value of Value function: 0.434056
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.352034
New value of Value function: 0.434056
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 751
New value of Q matrix: 0.43405
New value of Value function: 0.43405
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 752
New value of Q matrix: 0.434044
New value of Value function: 0.434044
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 753
New value of Q matrix: 0.434038
New value of Value function: 0.434038
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.353084
New value of Value function: 0.434038
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.354105
New value of Value function: 0.434038
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 754
New value of Q matrix: 0.434033
New value of Value function: 0.434033
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.3551
New value of Value function: 0.434033
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 755
New value of Q matrix: 0.434027
New value of Value function: 0.434027
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 756
New value of Q matrix: 0.434021
New value of Value function: 0.434021
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 757
New value of Q matrix: 0.434015
New value of Value function: 0.434015
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 758
New value of Q matrix: 0.43401
New value of Value function: 0.43401
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 759
New value of Q matrix: 0.434004
New value of Value function: 0.434004
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 760
New value of Q matrix: 0.433998
New value of Value function: 0.433998
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 761
New value of Q matrix: 0.433992
New value of Value function: 0.433992
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.317092
New value of Value function: 0.433992
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.419497
New value of Value function: 0.433992
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 762
New value of Q matrix: 0.433987
New value of Value function: 0.433987
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 763
New value of Q matrix: 0.433981
New value of Value function: 0.433981
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 764
New value of Q matrix: 0.433975
New value of Value function: 0.433975
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 765
New value of Q matrix: 0.43397
New value of Value function: 0.43397
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 766
New value of Q matrix: 0.433964
New value of Value function: 0.433964
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 767
New value of Q matrix: 0.433958
New value of Value function: 0.433958
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 768
New value of Q matrix: 0.433953
New value of Value function: 0.433953
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.419655
New value of Value function: 0.433953
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 769
New value of Q matrix: 0.433947
New value of Value function: 0.433947
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.419808
New value of Value function: 0.433947
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.318677
New value of Value function: 0.433947
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.419957
New value of Value function: 0.433947
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 770
New value of Q matrix: 0.433941
New value of Value function: 0.433941
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 771
New value of Q matrix: 0.433936
New value of Value function: 0.433936
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 772
New value of Q matrix: 0.43726
New value of Value function: 0.43726
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 545
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 546
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 547
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 548
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 549
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 550
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.267
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 551
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 552
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 553
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.89756
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 554
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.05386
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 555
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.36635
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 556
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.52471
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 557
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 558
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.9625
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 559
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.7165
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 560
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.7375
New value of Value function: 3.7375
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 561
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.85825
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 562
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.572167
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 563
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 564
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 565
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 566
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 567
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.025
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 568
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.71003
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 569
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3.99
New value of Value function: 3.99
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 570
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 571
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 572
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.349967
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 573
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.15833
New value of Value function: 4.15833
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 574
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.88325
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 575
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.27857
New value of Value function: 4.27857
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 576
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 577
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 578
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 579
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 1.25
New value of Value function: 1.25
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 580
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 581
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 582
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 583
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 584
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 585
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 586
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2849
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 587
----------
State: 2849
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2849
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 588
----------
State: 2849
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.28356
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.320263
New value of Value function: 0.43726
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 773
New value of Q matrix: 0.437254
New value of Value function: 0.437254
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 774
New value of Q matrix: 0.437248
New value of Value function: 0.437248
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 775
New value of Q matrix: 0.437243
New value of Value function: 0.437243
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 776
New value of Q matrix: 0.437237
New value of Value function: 0.437237
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.420149
New value of Value function: 0.437237
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 777
New value of Q matrix: 0.437232
New value of Value function: 0.437232
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 778
New value of Q matrix: 0.437226
New value of Value function: 0.437226
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 779
New value of Q matrix: 0.43722
New value of Value function: 0.43722
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 780
New value of Q matrix: 0.437215
New value of Value function: 0.437215
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 781
New value of Q matrix: 0.437209
New value of Value function: 0.437209
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.321805
New value of Value function: 0.437209
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 782
New value of Q matrix: 0.437204
New value of Value function: 0.437204
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 783
New value of Q matrix: 0.437198
New value of Value function: 0.437198
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 784
New value of Q matrix: 0.437192
New value of Value function: 0.437192
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 785
New value of Q matrix: 0.437187
New value of Value function: 0.437187
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 786
New value of Q matrix: 0.437181
New value of Value function: 0.437181
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 606
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 787
New value of Q matrix: 0.437176
New value of Value function: 0.437176
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.35119
New value of Value function: 0.437176
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 788
New value of Q matrix: 0.43717
New value of Value function: 0.43717
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 789
New value of Q matrix: 0.437165
New value of Value function: 0.437165
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 790
New value of Q matrix: 0.437159
New value of Value function: 0.437159
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.356109
New value of Value function: 0.437159
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 791
New value of Q matrix: 0.437154
New value of Value function: 0.437154
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 792
New value of Q matrix: 0.437148
New value of Value function: 0.437148
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 793
New value of Q matrix: 0.437142
New value of Value function: 0.437142
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 794
New value of Q matrix: 0.437137
New value of Value function: 0.437137
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 795
New value of Q matrix: 0.437131
New value of Value function: 0.437131
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.352293
New value of Value function: 0.437131
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 796
New value of Q matrix: 0.437126
New value of Value function: 0.437126
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 619
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 797
New value of Q matrix: 0.437121
New value of Value function: 0.437121
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.420335
New value of Value function: 0.437121
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 798
New value of Q matrix: 0.437115
New value of Value function: 0.437115
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.353365
New value of Value function: 0.437115
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 799
New value of Q matrix: 0.43711
New value of Value function: 0.43711
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.35441
New value of Value function: 0.43711
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 800
New value of Q matrix: 0.437104
New value of Value function: 0.437104
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 801
New value of Q matrix: 0.437099
New value of Value function: 0.437099
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 627
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 802
New value of Q matrix: 0.437093
New value of Value function: 0.437093
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 803
New value of Q matrix: 0.437088
New value of Value function: 0.437088
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 804
New value of Q matrix: 0.437082
New value of Value function: 0.437082
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 805
New value of Q matrix: 0.437077
New value of Value function: 0.437077
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 806
New value of Q matrix: 0.437071
New value of Value function: 0.437071
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 807
New value of Q matrix: 0.437066
New value of Value function: 0.437066
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.357091
New value of Value function: 0.437066
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 808
New value of Q matrix: 0.437061
New value of Value function: 0.437061
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 809
New value of Q matrix: 0.437055
New value of Value function: 0.437055
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 810
New value of Q matrix: 0.43705
New value of Value function: 0.43705
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 811
New value of Q matrix: 0.437044
New value of Value function: 0.437044
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 812
New value of Q matrix: 0.437039
New value of Value function: 0.437039
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 813
New value of Q matrix: 0.437034
New value of Value function: 0.437034
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.323303
New value of Value function: 0.437034
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.355426
New value of Value function: 0.437034
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 814
New value of Q matrix: 0.437028
New value of Value function: 0.437028
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 815
New value of Q matrix: 0.437023
New value of Value function: 0.437023
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 816
New value of Q matrix: 0.437018
New value of Value function: 0.437018
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 817
New value of Q matrix: 0.437012
New value of Value function: 0.437012
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 818
New value of Q matrix: 0.437007
New value of Value function: 0.437007
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.356416
New value of Value function: 0.437007
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 819
New value of Q matrix: 0.437002
New value of Value function: 0.437002
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 820
New value of Q matrix: 0.436996
New value of Value function: 0.436996
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 821
New value of Q matrix: 0.436991
New value of Value function: 0.436991
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 822
New value of Q matrix: 0.436986
New value of Value function: 0.436986
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 823
New value of Q matrix: 0.43698
New value of Value function: 0.43698
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 824
New value of Q matrix: 0.436975
New value of Value function: 0.436975
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 825
New value of Q matrix: 0.43697
New value of Value function: 0.43697
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 826
New value of Q matrix: 0.436964
New value of Value function: 0.436964
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 827
New value of Q matrix: 0.436959
New value of Value function: 0.436959
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 828
New value of Q matrix: 0.436954
New value of Value function: 0.436954
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 829
New value of Q matrix: 0.436949
New value of Value function: 0.436949
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 830
New value of Q matrix: 0.436943
New value of Value function: 0.436943
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 831
New value of Q matrix: 0.436938
New value of Value function: 0.436938
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.420512
New value of Value function: 0.436938
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.358046
New value of Value function: 0.436938
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 832
New value of Q matrix: 0.436933
New value of Value function: 0.436933
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 833
New value of Q matrix: 0.436928
New value of Value function: 0.436928
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 834
New value of Q matrix: 0.436922
New value of Value function: 0.436922
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.32476
New value of Value function: 0.436922
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 835
New value of Q matrix: 0.436917
New value of Value function: 0.436917
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 836
New value of Q matrix: 0.436912
New value of Value function: 0.436912
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 837
New value of Q matrix: 0.436907
New value of Value function: 0.436907
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 838
New value of Q matrix: 0.436901
New value of Value function: 0.436901
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 839
New value of Q matrix: 0.436896
New value of Value function: 0.436896
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.420684
New value of Value function: 0.436896
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 840
New value of Q matrix: 0.436891
New value of Value function: 0.436891
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 841
New value of Q matrix: 0.436886
New value of Value function: 0.436886
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 842
New value of Q matrix: 0.436881
New value of Value function: 0.436881
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.42085
New value of Value function: 0.436881
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 843
New value of Q matrix: 0.436875
New value of Value function: 0.436875
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 678
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 844
New value of Q matrix: 0.43687
New value of Value function: 0.43687
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 845
New value of Q matrix: 0.436865
New value of Value function: 0.436865
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 846
New value of Q matrix: 0.43686
New value of Value function: 0.43686
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 847
New value of Q matrix: 0.436855
New value of Value function: 0.436855
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 682
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.357379
New value of Value function: 0.436855
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 848
New value of Q matrix: 0.43685
New value of Value function: 0.43685
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 849
New value of Q matrix: 0.436844
New value of Value function: 0.436844
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 850
New value of Q matrix: 0.436839
New value of Value function: 0.436839
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 851
New value of Q matrix: 0.436834
New value of Value function: 0.436834
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 852
New value of Q matrix: 0.436829
New value of Value function: 0.436829
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 853
New value of Q matrix: 0.436824
New value of Value function: 0.436824
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.421011
New value of Value function: 0.436824
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 854
New value of Q matrix: 0.436819
New value of Value function: 0.436819
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 855
New value of Q matrix: 0.436814
New value of Value function: 0.436814
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.358317
New value of Value function: 0.436814
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 856
New value of Q matrix: 0.436809
New value of Value function: 0.436809
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 694
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 857
New value of Q matrix: 0.436804
New value of Value function: 0.436804
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 695
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 858
New value of Q matrix: 0.436798
New value of Value function: 0.436798
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 696
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.358976
New value of Value function: 0.436798
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 859
New value of Q matrix: 0.436793
New value of Value function: 0.436793
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 860
New value of Q matrix: 0.436788
New value of Value function: 0.436788
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 861
New value of Q matrix: 0.436783
New value of Value function: 0.436783
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 862
New value of Q matrix: 0.436778
New value of Value function: 0.436778
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 863
New value of Q matrix: 0.436773
New value of Value function: 0.436773
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 864
New value of Q matrix: 0.43974
New value of Value function: 0.43974
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 703
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 704
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 705
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 706
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0333333
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 707
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 708
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 709
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.0331667
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 710
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.1655
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 711
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.64386
New value of Value function: 4.88417
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 712
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.87195
New value of Value function: 4.87195
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 713
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.83432
New value of Value function: 4.87195
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 714
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.74214
New value of Value function: 4.87195
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 715
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.22491
New value of Value function: 4.87195
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 716
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.83505
New value of Value function: 4.87195
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 717
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 718
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.75002
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 719
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.67656
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 720
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.27322
New value of Value function: 4.27322
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 721
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.41016
New value of Value function: 4.27322
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 722
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.97992
New value of Value function: 3.97992
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 723
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.6335
New value of Value function: 1.65
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 724
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.64587
New value of Value function: 1.64587
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 725
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 2.5642
New value of Value function: 2.5642
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 726
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.2375
New value of Value function: 1.25
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 727
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1
New value of Value function: 1.2375
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 728
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.428311
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 729
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.367123
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 730
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: -0.641815
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 865
New value of Q matrix: 0.439735
New value of Value function: 0.439735
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 866
New value of Q matrix: 0.43973
New value of Value function: 0.43973
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 867
New value of Q matrix: 0.439725
New value of Value function: 0.439725
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 868
New value of Q matrix: 0.439719
New value of Value function: 0.439719
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 735
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 869
New value of Q matrix: 0.439714
New value of Value function: 0.439714
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 870
New value of Q matrix: 0.439709
New value of Value function: 0.439709
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.359268
New value of Value function: 0.439709
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 871
New value of Q matrix: 0.439704
New value of Value function: 0.439704
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 872
New value of Q matrix: 0.439699
New value of Value function: 0.439699
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 873
New value of Q matrix: 0.439694
New value of Value function: 0.439694
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.421207
New value of Value function: 0.439694
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 874
New value of Q matrix: 0.439689
New value of Value function: 0.439689
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 875
New value of Q matrix: 0.439684
New value of Value function: 0.439684
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 876
New value of Q matrix: 0.439679
New value of Value function: 0.439679
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 877
New value of Q matrix: 0.439674
New value of Value function: 0.439674
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 878
New value of Q matrix: 0.439669
New value of Value function: 0.439669
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 879
New value of Q matrix: 0.439664
New value of Value function: 0.439664
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 880
New value of Q matrix: 0.439659
New value of Value function: 0.439659
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 881
New value of Q matrix: 0.439654
New value of Value function: 0.439654
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 882
New value of Q matrix: 0.439649
New value of Value function: 0.439649
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 883
New value of Q matrix: 0.439644
New value of Value function: 0.439644
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 752
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 884
New value of Q matrix: 0.439639
New value of Value function: 0.439639
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 885
New value of Q matrix: 0.439634
New value of Value function: 0.439634
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 886
New value of Q matrix: 0.439629
New value of Value function: 0.439629
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.359917
New value of Value function: 0.439629
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 887
New value of Q matrix: 0.439624
New value of Value function: 0.439624
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 888
New value of Q matrix: 0.439619
New value of Value function: 0.439619
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 889
New value of Q matrix: 0.439614
New value of Value function: 0.439614
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 890
New value of Q matrix: 0.439609
New value of Value function: 0.439609
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 760
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 891
New value of Q matrix: 0.439605
New value of Value function: 0.439605
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.326213
New value of Value function: 0.439605
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 892
New value of Q matrix: 0.4396
New value of Value function: 0.4396
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 893
New value of Q matrix: 0.439595
New value of Value function: 0.439595
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 764
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 894
New value of Q matrix: 0.43959
New value of Value function: 0.43959
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 895
New value of Q matrix: 0.439585
New value of Value function: 0.439585
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 896
New value of Q matrix: 0.43958
New value of Value function: 0.43958
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.360835
New value of Value function: 0.43958
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 768
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 897
New value of Q matrix: 0.439575
New value of Value function: 0.439575
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 769
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 898
New value of Q matrix: 0.43957
New value of Value function: 0.43957
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 770
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.421396
New value of Value function: 0.43957
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 771
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 899
New value of Q matrix: 0.439565
New value of Value function: 0.439565
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 772
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 900
New value of Q matrix: 0.43956
New value of Value function: 0.43956
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 773
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.361731
New value of Value function: 0.43956
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 901
New value of Q matrix: 0.439556
New value of Value function: 0.439556
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 775
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 902
New value of Q matrix: 0.439551
New value of Value function: 0.439551
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 903
New value of Q matrix: 0.439546
New value of Value function: 0.439546
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.327628
New value of Value function: 0.439546
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.421579
New value of Value function: 0.439546
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.329006
New value of Value function: 0.439546
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.360193
New value of Value function: 0.439546
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 904
New value of Q matrix: 0.439541
New value of Value function: 0.439541
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 905
New value of Q matrix: 0.439536
New value of Value function: 0.439536
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.362605
New value of Value function: 0.439536
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 784
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 906
New value of Q matrix: 0.439531
New value of Value function: 0.439531
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 907
New value of Q matrix: 0.439526
New value of Value function: 0.439526
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 908
New value of Q matrix: 0.439522
New value of Value function: 0.439522
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 909
New value of Q matrix: 0.439517
New value of Value function: 0.439517
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 910
New value of Q matrix: 0.439512
New value of Value function: 0.439512
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 911
New value of Q matrix: 0.439507
New value of Value function: 0.439507
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 912
New value of Q matrix: 0.439502
New value of Value function: 0.439502
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 913
New value of Q matrix: 0.439497
New value of Value function: 0.439497
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 914
New value of Q matrix: 0.439493
New value of Value function: 0.439493
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 915
New value of Q matrix: 0.439488
New value of Value function: 0.439488
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 794
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 916
New value of Q matrix: 0.439483
New value of Value function: 0.439483
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 917
New value of Q matrix: 0.439478
New value of Value function: 0.439478
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 918
New value of Q matrix: 0.439473
New value of Value function: 0.439473
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 919
New value of Q matrix: 0.439469
New value of Value function: 0.439469
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.363457
New value of Value function: 0.439469
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.421757
New value of Value function: 0.439469
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 920
New value of Q matrix: 0.439464
New value of Value function: 0.439464
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 921
New value of Q matrix: 0.439459
New value of Value function: 0.439459
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.330349
New value of Value function: 0.439459
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 922
New value of Q matrix: 0.439454
New value of Value function: 0.439454
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 923
New value of Q matrix: 0.43945
New value of Value function: 0.43945
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 924
New value of Q matrix: 0.439445
New value of Value function: 0.439445
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 925
New value of Q matrix: 0.43944
New value of Value function: 0.43944
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 926
New value of Q matrix: 0.439435
New value of Value function: 0.439435
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 927
New value of Q matrix: 0.439431
New value of Value function: 0.439431
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 928
New value of Q matrix: 0.439426
New value of Value function: 0.439426
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 929
New value of Q matrix: 0.439421
New value of Value function: 0.439421
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 930
New value of Q matrix: 0.439416
New value of Value function: 0.439416
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.331657
New value of Value function: 0.439416
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 931
New value of Q matrix: 0.439412
New value of Value function: 0.439412
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 932
New value of Q matrix: 0.439407
New value of Value function: 0.439407
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 933
New value of Q matrix: 0.439402
New value of Value function: 0.439402
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 934
New value of Q matrix: 0.439398
New value of Value function: 0.439398
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 935
New value of Q matrix: 0.439393
New value of Value function: 0.439393
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.421929
New value of Value function: 0.439393
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.332933
New value of Value function: 0.439393
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 936
New value of Q matrix: 0.439388
New value of Value function: 0.439388
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 937
New value of Q matrix: 0.439383
New value of Value function: 0.439383
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 938
New value of Q matrix: 0.439379
New value of Value function: 0.439379
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.361094
New value of Value function: 0.439379
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 939
New value of Q matrix: 0.439374
New value of Value function: 0.439374
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 940
New value of Q matrix: 0.439369
New value of Value function: 0.439369
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 941
New value of Q matrix: 0.439365
New value of Value function: 0.439365
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 942
New value of Q matrix: 0.43936
New value of Value function: 0.43936
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 943
New value of Q matrix: 0.439355
New value of Value function: 0.439355
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.422096
New value of Value function: 0.439355
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 944
New value of Q matrix: 0.439351
New value of Value function: 0.439351
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 945
New value of Q matrix: 0.439346
New value of Value function: 0.439346
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.361973
New value of Value function: 0.439346
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 946
New value of Q matrix: 0.439341
New value of Value function: 0.439341
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 947
New value of Q matrix: 0.439337
New value of Value function: 0.439337
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.422258
New value of Value function: 0.439337
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 948
New value of Q matrix: 0.439332
New value of Value function: 0.439332
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 949
New value of Q matrix: 0.439328
New value of Value function: 0.439328
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.362832
New value of Value function: 0.439328
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 950
New value of Q matrix: 0.439323
New value of Value function: 0.439323
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 951
New value of Q matrix: 0.439318
New value of Value function: 0.439318
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 952
New value of Q matrix: 0.439314
New value of Value function: 0.439314
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.364288
New value of Value function: 0.439314
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 953
New value of Q matrix: 0.439309
New value of Value function: 0.439309
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 954
New value of Q matrix: 0.439304
New value of Value function: 0.439304
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.3651
New value of Value function: 0.439304
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 955
New value of Q matrix: 0.4393
New value of Value function: 0.4393
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.365893
New value of Value function: 0.4393
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 956
New value of Q matrix: 0.439295
New value of Value function: 0.439295
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 957
New value of Q matrix: 0.439291
New value of Value function: 0.439291
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.36367
New value of Value function: 0.439291
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 958
New value of Q matrix: 0.439286
New value of Value function: 0.439286
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 959
New value of Q matrix: 0.439282
New value of Value function: 0.439282
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 960
New value of Q matrix: 0.441949
New value of Value function: 0.441949
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 854
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.833333
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 855
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.025
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 856
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 857
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.024875
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 858
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.0398
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 859
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.93762
New value of Value function: 4.93762
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 860
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.67231
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 861
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.25584
New value of Value function: 4.93762
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 862
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.31888
New value of Value function: 4.93762
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 863
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.91469
New value of Value function: 4.87195
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 864
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.71074
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 865
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.62511
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 866
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.97594
New value of Value function: 3.97594
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 867
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.84527
New value of Value function: 3.84527
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 868
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.55993
New value of Value function: 2.55993
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 869
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.08353
New value of Value function: 3.08353
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 870
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.03752
New value of Value function: 1.2375
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 871
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.889304
New value of Value function: 1.2375
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 872
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.22513
New value of Value function: 1.22513
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 873
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.22513
New value of Value function: 1.2375
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 874
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.931281
New value of Value function: 1.2375
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 875
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.962569
New value of Value function: 1.2375
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 876
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.435739
New value of Value function: 1.22513
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 877
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -0.512494
New value of Value function: 1.22513
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 961
New value of Q matrix: 0.441944
New value of Value function: 0.441944
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 962
New value of Q matrix: 0.44194
New value of Value function: 0.44194
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 963
New value of Q matrix: 0.441935
New value of Value function: 0.441935
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 964
New value of Q matrix: 0.441931
New value of Value function: 0.441931
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.364519
New value of Value function: 0.441931
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 965
New value of Q matrix: 0.441926
New value of Value function: 0.441926
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 966
New value of Q matrix: 0.441921
New value of Value function: 0.441921
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 967
New value of Q matrix: 0.441917
New value of Value function: 0.441917
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 968
New value of Q matrix: 0.441912
New value of Value function: 0.441912
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 969
New value of Q matrix: 0.441908
New value of Value function: 0.441908
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.365348
New value of Value function: 0.441908
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 970
New value of Q matrix: 0.441903
New value of Value function: 0.441903
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 971
New value of Q matrix: 0.441899
New value of Value function: 0.441899
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 972
New value of Q matrix: 0.441894
New value of Value function: 0.441894
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 973
New value of Q matrix: 0.44189
New value of Value function: 0.44189
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 974
New value of Q matrix: 0.441885
New value of Value function: 0.441885
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 894
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 975
New value of Q matrix: 0.44188
New value of Value function: 0.44188
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 976
New value of Q matrix: 0.441876
New value of Value function: 0.441876
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.366697
New value of Value function: 0.441876
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 897
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.422448
New value of Value function: 0.441876
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 977
New value of Q matrix: 0.441871
New value of Value function: 0.441871
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 978
New value of Q matrix: 0.441867
New value of Value function: 0.441867
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 900
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 979
New value of Q matrix: 0.441862
New value of Value function: 0.441862
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 901
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 980
New value of Q matrix: 0.441858
New value of Value function: 0.441858
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 902
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.367483
New value of Value function: 0.441858
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 903
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 981
New value of Q matrix: 0.441853
New value of Value function: 0.441853
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 904
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 982
New value of Q matrix: 0.441849
New value of Value function: 0.441849
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 905
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 983
New value of Q matrix: 0.441844
New value of Value function: 0.441844
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 906
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 984
New value of Q matrix: 0.44184
New value of Value function: 0.44184
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 907
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.334207
New value of Value function: 0.44184
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 908
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.422633
New value of Value function: 0.44184
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 909
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 985
New value of Q matrix: 0.441835
New value of Value function: 0.441835
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 910
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 986
New value of Q matrix: 0.441831
New value of Value function: 0.441831
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 911
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.368252
New value of Value function: 0.441831
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 912
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 987
New value of Q matrix: 0.441826
New value of Value function: 0.441826
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 913
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 988
New value of Q matrix: 0.441822
New value of Value function: 0.441822
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 989
New value of Q matrix: 0.441818
New value of Value function: 0.441818
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 915
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 990
New value of Q matrix: 0.441813
New value of Value function: 0.441813
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 916
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 991
New value of Q matrix: 0.441809
New value of Value function: 0.441809
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 992
New value of Q matrix: 0.441804
New value of Value function: 0.441804
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 993
New value of Q matrix: 0.4418
New value of Value function: 0.4418
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 994
New value of Q matrix: 0.441795
New value of Value function: 0.441795
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 995
New value of Q matrix: 0.441791
New value of Value function: 0.441791
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 921
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 996
New value of Q matrix: 0.441786
New value of Value function: 0.441786
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 922
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 997
New value of Q matrix: 0.441782
New value of Value function: 0.441782
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 998
New value of Q matrix: 0.441778
New value of Value function: 0.441778
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 924
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 999
New value of Q matrix: 0.441773
New value of Value function: 0.441773
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 925
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1000
New value of Q matrix: 0.441769
New value of Value function: 0.441769
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 926
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1001
New value of Q matrix: 0.441764
New value of Value function: 0.441764
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1002
New value of Q matrix: 0.44176
New value of Value function: 0.44176
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1003
New value of Q matrix: 0.441755
New value of Value function: 0.441755
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 929
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1004
New value of Q matrix: 0.441751
New value of Value function: 0.441751
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 930
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.369003
New value of Value function: 0.441751
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 931
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1005
New value of Q matrix: 0.441747
New value of Value function: 0.441747
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 932
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1006
New value of Q matrix: 0.441742
New value of Value function: 0.441742
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 933
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.369737
New value of Value function: 0.441742
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 934
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1007
New value of Q matrix: 0.441738
New value of Value function: 0.441738
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1008
New value of Q matrix: 0.441733
New value of Value function: 0.441733
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 936
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.422812
New value of Value function: 0.441733
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 937
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1009
New value of Q matrix: 0.441729
New value of Value function: 0.441729
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 938
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1010
New value of Q matrix: 0.441725
New value of Value function: 0.441725
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.366156
New value of Value function: 0.441725
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1011
New value of Q matrix: 0.44172
New value of Value function: 0.44172
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1012
New value of Q matrix: 0.441716
New value of Value function: 0.441716
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 942
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1013
New value of Q matrix: 0.441712
New value of Value function: 0.441712
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 943
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1014
New value of Q matrix: 0.441707
New value of Value function: 0.441707
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 944
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1015
New value of Q matrix: 0.441703
New value of Value function: 0.441703
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 945
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.422987
New value of Value function: 0.441703
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1016
New value of Q matrix: 0.441699
New value of Value function: 0.441699
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1017
New value of Q matrix: 0.441694
New value of Value function: 0.441694
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1018
New value of Q matrix: 0.44169
New value of Value function: 0.44169
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1019
New value of Q matrix: 0.441686
New value of Value function: 0.441686
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1020
New value of Q matrix: 0.441681
New value of Value function: 0.441681
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1021
New value of Q matrix: 0.441677
New value of Value function: 0.441677
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1022
New value of Q matrix: 0.441673
New value of Value function: 0.441673
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1023
New value of Q matrix: 0.441668
New value of Value function: 0.441668
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1024
New value of Q matrix: 0.441664
New value of Value function: 0.441664
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1025
New value of Q matrix: 0.44166
New value of Value function: 0.44166
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1026
New value of Q matrix: 0.441655
New value of Value function: 0.441655
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1027
New value of Q matrix: 0.441651
New value of Value function: 0.441651
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1028
New value of Q matrix: 0.441647
New value of Value function: 0.441647
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 959
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1029
New value of Q matrix: 0.441642
New value of Value function: 0.441642
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 960
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1030
New value of Q matrix: 0.441638
New value of Value function: 0.441638
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 961
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1031
New value of Q matrix: 0.441634
New value of Value function: 0.441634
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.366946
New value of Value function: 0.441634
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 963
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1032
New value of Q matrix: 0.44163
New value of Value function: 0.44163
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 964
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.423156
New value of Value function: 0.44163
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 965
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.370455
New value of Value function: 0.44163
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.335448
New value of Value function: 0.44163
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1033
New value of Q matrix: 0.441625
New value of Value function: 0.441625
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1034
New value of Q matrix: 0.441621
New value of Value function: 0.441621
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 969
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1035
New value of Q matrix: 0.441617
New value of Value function: 0.441617
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1036
New value of Q matrix: 0.441613
New value of Value function: 0.441613
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1037
New value of Q matrix: 0.441608
New value of Value function: 0.441608
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.367718
New value of Value function: 0.441608
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 973
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1038
New value of Q matrix: 0.441604
New value of Value function: 0.441604
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1039
New value of Q matrix: 0.4416
New value of Value function: 0.4416
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.423321
New value of Value function: 0.4416
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1040
New value of Q matrix: 0.441596
New value of Value function: 0.441596
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1041
New value of Q matrix: 0.441591
New value of Value function: 0.441591
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 978
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.423482
New value of Value function: 0.441591
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1042
New value of Q matrix: 0.441587
New value of Value function: 0.441587
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1043
New value of Q matrix: 0.441583
New value of Value function: 0.441583
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1044
New value of Q matrix: 0.441579
New value of Value function: 0.441579
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1045
New value of Q matrix: 0.441574
New value of Value function: 0.441574
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1046
New value of Q matrix: 0.44157
New value of Value function: 0.44157
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1047
New value of Q matrix: 0.441566
New value of Value function: 0.441566
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.423639
New value of Value function: 0.441566
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 986
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.423793
New value of Value function: 0.441566
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 987
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1048
New value of Q matrix: 0.441562
New value of Value function: 0.441562
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1049
New value of Q matrix: 0.441557
New value of Value function: 0.441557
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1050
New value of Q matrix: 0.441553
New value of Value function: 0.441553
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.423943
New value of Value function: 0.441553
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.336659
New value of Value function: 0.441553
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1051
New value of Q matrix: 0.441549
New value of Value function: 0.441549
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1052
New value of Q matrix: 0.441545
New value of Value function: 0.441545
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1053
New value of Q matrix: 0.441541
New value of Value function: 0.441541
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1054
New value of Q matrix: 0.441537
New value of Value function: 0.441537
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.337841
New value of Value function: 0.441537
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1055
New value of Q matrix: 0.441532
New value of Value function: 0.441532
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.368472
New value of Value function: 0.441532
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1056
New value of Q matrix: 0.441528
New value of Value function: 0.441528
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.36921
New value of Value function: 0.441528
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1057
New value of Q matrix: 0.441524
New value of Value function: 0.441524
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1058
New value of Q matrix: 0.44152
New value of Value function: 0.44152
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1059
New value of Q matrix: 0.441516
New value of Value function: 0.441516
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1060
New value of Q matrix: 0.441511
New value of Value function: 0.441511
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1061
New value of Q matrix: 0.441507
New value of Value function: 0.441507
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1062
New value of Q matrix: 0.441503
New value of Value function: 0.441503
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1063
New value of Q matrix: 0.441499
New value of Value function: 0.441499
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1064
New value of Q matrix: 0.441495
New value of Value function: 0.441495
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1065
New value of Q matrix: 0.441491
New value of Value function: 0.441491
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1066
New value of Q matrix: 0.441487
New value of Value function: 0.441487
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1067
New value of Q matrix: 0.441482
New value of Value function: 0.441482
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1068
New value of Q matrix: 0.441478
New value of Value function: 0.441478
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1069
New value of Q matrix: 0.441474
New value of Value function: 0.441474
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1070
New value of Q matrix: 0.44147
New value of Value function: 0.44147
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1071
New value of Q matrix: 0.441466
New value of Value function: 0.441466
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1072
New value of Q matrix: 0.441462
New value of Value function: 0.441462
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1073
New value of Q matrix: 0.441458
New value of Value function: 0.441458
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1074
New value of Q matrix: 0.441454
New value of Value function: 0.441454
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1075
New value of Q matrix: 0.441449
New value of Value function: 0.441449
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1076
New value of Q matrix: 0.441445
New value of Value function: 0.441445
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.424088
New value of Value function: 0.441445
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1077
New value of Q matrix: 0.441441
New value of Value function: 0.441441
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1078
New value of Q matrix: 0.441437
New value of Value function: 0.441437
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1079
New value of Q matrix: 0.441433
New value of Value function: 0.441433
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1080
New value of Q matrix: 0.441429
New value of Value function: 0.441429
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1081
New value of Q matrix: 0.441425
New value of Value function: 0.441425
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1082
New value of Q matrix: 0.441421
New value of Value function: 0.441421
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1083
New value of Q matrix: 0.441417
New value of Value function: 0.441417
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1084
New value of Q matrix: 0.441413
New value of Value function: 0.441413
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1085
New value of Q matrix: 0.441409
New value of Value function: 0.441409
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1086
New value of Q matrix: 0.441405
New value of Value function: 0.441405
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1087
New value of Q matrix: 0.4414
New value of Value function: 0.4414
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1088
New value of Q matrix: 0.441396
New value of Value function: 0.441396
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1089
New value of Q matrix: 0.441392
New value of Value function: 0.441392
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1090
New value of Q matrix: 0.441388
New value of Value function: 0.441388
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1091
New value of Q matrix: 0.441384
New value of Value function: 0.441384
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1092
New value of Q matrix: 0.44138
New value of Value function: 0.44138
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.338994
New value of Value function: 0.44138
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.34012
New value of Value function: 0.44138
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.369931
New value of Value function: 0.44138
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.42423
New value of Value function: 0.44138
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1093
New value of Q matrix: 0.441376
New value of Value function: 0.441376
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.370637
New value of Value function: 0.441376
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1094
New value of Q matrix: 0.441372
New value of Value function: 0.441372
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.371327
New value of Value function: 0.441372
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1095
New value of Q matrix: 0.441368
New value of Value function: 0.441368
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1096
New value of Q matrix: 0.441364
New value of Value function: 0.441364
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.34122
New value of Value function: 0.441364
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.424368
New value of Value function: 0.441364
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1097
New value of Q matrix: 0.44136
New value of Value function: 0.44136
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1098
New value of Q matrix: 0.441356
New value of Value function: 0.441356
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1099
New value of Q matrix: 0.441352
New value of Value function: 0.441352
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1100
New value of Q matrix: 0.441348
New value of Value function: 0.441348
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.342295
New value of Value function: 0.441348
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1101
New value of Q matrix: 0.441344
New value of Value function: 0.441344
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1102
New value of Q matrix: 0.44134
New value of Value function: 0.44134
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1103
New value of Q matrix: 0.441336
New value of Value function: 0.441336
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.371155
New value of Value function: 0.441336
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1104
New value of Q matrix: 0.441332
New value of Value function: 0.441332
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1105
New value of Q matrix: 0.441328
New value of Value function: 0.441328
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1106
New value of Q matrix: 0.441324
New value of Value function: 0.441324
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.372004
New value of Value function: 0.441324
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1107
New value of Q matrix: 0.44132
New value of Value function: 0.44132
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1108
New value of Q matrix: 0.441316
New value of Value function: 0.441316
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1109
New value of Q matrix: 0.441312
New value of Value function: 0.441312
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1110
New value of Q matrix: 0.441308
New value of Value function: 0.441308
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1111
New value of Q matrix: 0.441304
New value of Value function: 0.441304
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1112
New value of Q matrix: 0.4413
New value of Value function: 0.4413
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1113
New value of Q matrix: 0.441296
New value of Value function: 0.441296
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1114
New value of Q matrix: 0.441292
New value of Value function: 0.441292
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1115
New value of Q matrix: 0.441288
New value of Value function: 0.441288
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1116
New value of Q matrix: 0.441284
New value of Value function: 0.441284
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1117
New value of Q matrix: 0.44128
New value of Value function: 0.44128
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1118
New value of Q matrix: 0.441276
New value of Value function: 0.441276
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.372665
New value of Value function: 0.441276
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1119
New value of Q matrix: 0.441272
New value of Value function: 0.441272
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.373314
New value of Value function: 0.441272
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1120
New value of Q matrix: 0.441269
New value of Value function: 0.441269
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1121
New value of Q matrix: 0.441265
New value of Value function: 0.441265
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1122
New value of Q matrix: 0.441261
New value of Value function: 0.441261
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.343346
New value of Value function: 0.441261
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.424502
New value of Value function: 0.441261
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1123
New value of Q matrix: 0.441257
New value of Value function: 0.441257
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1124
New value of Q matrix: 0.441253
New value of Value function: 0.441253
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.424633
New value of Value function: 0.441253
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1125
New value of Q matrix: 0.441249
New value of Value function: 0.441249
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1126
New value of Q matrix: 0.441245
New value of Value function: 0.441245
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1127
New value of Q matrix: 0.441241
New value of Value function: 0.441241
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1128
New value of Q matrix: 0.441237
New value of Value function: 0.441237
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1129
New value of Q matrix: 0.441233
New value of Value function: 0.441233
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1130
New value of Q matrix: 0.441229
New value of Value function: 0.441229
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1131
New value of Q matrix: 0.441225
New value of Value function: 0.441225
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1132
New value of Q matrix: 0.441222
New value of Value function: 0.441222
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1133
New value of Q matrix: 0.441218
New value of Value function: 0.441218
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1134
New value of Q matrix: 0.441214
New value of Value function: 0.441214
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.344373
New value of Value function: 0.441214
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1135
New value of Q matrix: 0.44121
New value of Value function: 0.44121
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.373949
New value of Value function: 0.44121
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1136
New value of Q matrix: 0.441206
New value of Value function: 0.441206
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1137
New value of Q matrix: 0.441202
New value of Value function: 0.441202
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1138
New value of Q matrix: 0.441198
New value of Value function: 0.441198
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1139
New value of Q matrix: 0.441194
New value of Value function: 0.441194
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1140
New value of Q matrix: 0.44119
New value of Value function: 0.44119
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.424761
New value of Value function: 0.44119
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1141
New value of Q matrix: 0.441187
New value of Value function: 0.441187
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1142
New value of Q matrix: 0.441183
New value of Value function: 0.441183
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1143
New value of Q matrix: 0.441179
New value of Value function: 0.441179
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1144
New value of Q matrix: 0.441175
New value of Value function: 0.441175
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1145
New value of Q matrix: 0.441171
New value of Value function: 0.441171
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1146
New value of Q matrix: 0.443404
New value of Value function: 0.443404
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 111
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 112
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 113
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 114
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 115
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -0.0199068
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 116
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.29972
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 117
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: -0.461196
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 118
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.74602
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 119
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.84657
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 120
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.61081
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 121
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.86823
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 122
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.62007
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 123
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.99606
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 124
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.05531
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 125
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.58879
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 126
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.50909
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 127
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.61597
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 128
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 3.04529
New value of Value function: 3.04529
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 129
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 1.85006
New value of Value function: 1.85006
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 130
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.26891
New value of Value function: 5.26891
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 131
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.81524
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 132
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.88579
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 133
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 1.44111
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1147
New value of Q matrix: 0.4434
New value of Value function: 0.4434
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1148
New value of Q matrix: 0.443396
New value of Value function: 0.443396
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1149
New value of Q matrix: 0.443392
New value of Value function: 0.443392
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1150
New value of Q matrix: 0.443389
New value of Value function: 0.443389
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1151
New value of Q matrix: 0.443385
New value of Value function: 0.443385
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1152
New value of Q matrix: 0.443381
New value of Value function: 0.443381
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.374592
New value of Value function: 0.443381
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1153
New value of Q matrix: 0.443377
New value of Value function: 0.443377
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1154
New value of Q matrix: 0.443373
New value of Value function: 0.443373
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1155
New value of Q matrix: 0.443369
New value of Value function: 0.443369
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1156
New value of Q matrix: 0.443366
New value of Value function: 0.443366
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1157
New value of Q matrix: 0.443362
New value of Value function: 0.443362
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.345401
New value of Value function: 0.443362
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1158
New value of Q matrix: 0.443358
New value of Value function: 0.443358
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1159
New value of Q matrix: 0.443354
New value of Value function: 0.443354
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1160
New value of Q matrix: 0.44335
New value of Value function: 0.44335
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1161
New value of Q matrix: 0.443346
New value of Value function: 0.443346
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1162
New value of Q matrix: 0.443343
New value of Value function: 0.443343
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1163
New value of Q matrix: 0.443339
New value of Value function: 0.443339
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1164
New value of Q matrix: 0.443335
New value of Value function: 0.443335
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1165
New value of Q matrix: 0.443331
New value of Value function: 0.443331
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.371861
New value of Value function: 0.443331
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1166
New value of Q matrix: 0.443327
New value of Value function: 0.443327
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1167
New value of Q matrix: 0.443324
New value of Value function: 0.443324
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.375223
New value of Value function: 0.443324
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1168
New value of Q matrix: 0.44332
New value of Value function: 0.44332
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.375841
New value of Value function: 0.44332
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1169
New value of Q matrix: 0.443316
New value of Value function: 0.443316
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1170
New value of Q matrix: 0.443312
New value of Value function: 0.443312
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1171
New value of Q matrix: 0.443308
New value of Value function: 0.443308
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1172
New value of Q matrix: 0.443305
New value of Value function: 0.443305
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1173
New value of Q matrix: 0.443301
New value of Value function: 0.443301
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1174
New value of Q matrix: 0.443297
New value of Value function: 0.443297
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1175
New value of Q matrix: 0.443293
New value of Value function: 0.443293
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1176
New value of Q matrix: 0.443289
New value of Value function: 0.443289
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1177
New value of Q matrix: 0.443286
New value of Value function: 0.443286
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1178
New value of Q matrix: 0.443282
New value of Value function: 0.443282
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1179
New value of Q matrix: 0.443278
New value of Value function: 0.443278
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1180
New value of Q matrix: 0.443274
New value of Value function: 0.443274
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1181
New value of Q matrix: 0.443271
New value of Value function: 0.443271
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1182
New value of Q matrix: 0.443267
New value of Value function: 0.443267
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1183
New value of Q matrix: 0.443263
New value of Value function: 0.443263
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1184
New value of Q matrix: 0.443259
New value of Value function: 0.443259
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1185
New value of Q matrix: 0.443256
New value of Value function: 0.443256
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1186
New value of Q matrix: 0.443252
New value of Value function: 0.443252
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1187
New value of Q matrix: 0.443248
New value of Value function: 0.443248
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1188
New value of Q matrix: 0.443245
New value of Value function: 0.443245
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.372551
New value of Value function: 0.443245
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1189
New value of Q matrix: 0.443241
New value of Value function: 0.443241
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1190
New value of Q matrix: 0.443237
New value of Value function: 0.443237
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1191
New value of Q matrix: 0.443233
New value of Value function: 0.443233
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1192
New value of Q matrix: 0.44323
New value of Value function: 0.44323
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1193
New value of Q matrix: 0.443226
New value of Value function: 0.443226
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.376446
New value of Value function: 0.443226
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.346405
New value of Value function: 0.443226
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1194
New value of Q matrix: 0.443222
New value of Value function: 0.443222
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1195
New value of Q matrix: 0.443218
New value of Value function: 0.443218
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1196
New value of Q matrix: 0.443215
New value of Value function: 0.443215
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.373227
New value of Value function: 0.443215
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.373889
New value of Value function: 0.443215
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1197
New value of Q matrix: 0.443211
New value of Value function: 0.443211
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.424907
New value of Value function: 0.443211
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1198
New value of Q matrix: 0.443207
New value of Value function: 0.443207
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1199
New value of Q matrix: 0.443204
New value of Value function: 0.443204
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.347388
New value of Value function: 0.443204
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1200
New value of Q matrix: 0.4432
New value of Value function: 0.4432
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.34835
New value of Value function: 0.4432
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1201
New value of Q matrix: 0.443196
New value of Value function: 0.443196
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.37704
New value of Value function: 0.443196
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1202
New value of Q matrix: 0.443193
New value of Value function: 0.443193
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1203
New value of Q matrix: 0.443189
New value of Value function: 0.443189
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1204
New value of Q matrix: 0.443185
New value of Value function: 0.443185
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1205
New value of Q matrix: 0.443182
New value of Value function: 0.443182
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1206
New value of Q matrix: 0.443178
New value of Value function: 0.443178
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.377622
New value of Value function: 0.443178
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1207
New value of Q matrix: 0.443174
New value of Value function: 0.443174
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1208
New value of Q matrix: 0.443171
New value of Value function: 0.443171
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.378193
New value of Value function: 0.443171
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1209
New value of Q matrix: 0.443167
New value of Value function: 0.443167
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1210
New value of Q matrix: 0.443163
New value of Value function: 0.443163
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1211
New value of Q matrix: 0.44316
New value of Value function: 0.44316
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1212
New value of Q matrix: 0.443156
New value of Value function: 0.443156
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.42505
New value of Value function: 0.443156
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1213
New value of Q matrix: 0.443152
New value of Value function: 0.443152
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.374537
New value of Value function: 0.443152
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.378753
New value of Value function: 0.443152
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.349291
New value of Value function: 0.443152
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1214
New value of Q matrix: 0.443149
New value of Value function: 0.443149
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1215
New value of Q matrix: 0.443145
New value of Value function: 0.443145
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.379303
New value of Value function: 0.443145
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1216
New value of Q matrix: 0.443141
New value of Value function: 0.443141
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1217
New value of Q matrix: 0.443138
New value of Value function: 0.443138
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.425189
New value of Value function: 0.443138
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1218
New value of Q matrix: 0.443134
New value of Value function: 0.443134
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.425326
New value of Value function: 0.443134
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1219
New value of Q matrix: 0.44313
New value of Value function: 0.44313
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.350213
New value of Value function: 0.44313
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1220
New value of Q matrix: 0.443127
New value of Value function: 0.443127
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1221
New value of Q matrix: 0.443123
New value of Value function: 0.443123
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.375172
New value of Value function: 0.443123
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1222
New value of Q matrix: 0.44312
New value of Value function: 0.44312
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1223
New value of Q matrix: 0.443116
New value of Value function: 0.443116
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1224
New value of Q matrix: 0.443112
New value of Value function: 0.443112
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1225
New value of Q matrix: 0.443109
New value of Value function: 0.443109
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1226
New value of Q matrix: 0.443105
New value of Value function: 0.443105
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1227
New value of Q matrix: 0.443101
New value of Value function: 0.443101
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.351115
New value of Value function: 0.443101
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.425459
New value of Value function: 0.443101
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1228
New value of Q matrix: 0.443098
New value of Value function: 0.443098
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1229
New value of Q matrix: 0.443094
New value of Value function: 0.443094
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1230
New value of Q matrix: 0.443091
New value of Value function: 0.443091
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.42559
New value of Value function: 0.443091
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1231
New value of Q matrix: 0.443087
New value of Value function: 0.443087
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1232
New value of Q matrix: 0.443083
New value of Value function: 0.443083
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1233
New value of Q matrix: 0.44308
New value of Value function: 0.44308
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1234
New value of Q matrix: 0.443076
New value of Value function: 0.443076
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1235
New value of Q matrix: 0.443073
New value of Value function: 0.443073
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.351999
New value of Value function: 0.443073
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1236
New value of Q matrix: 0.443069
New value of Value function: 0.443069
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.379843
New value of Value function: 0.443069
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1237
New value of Q matrix: 0.443065
New value of Value function: 0.443065
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1238
New value of Q matrix: 0.443062
New value of Value function: 0.443062
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1239
New value of Q matrix: 0.443058
New value of Value function: 0.443058
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1240
New value of Q matrix: 0.44512
New value of Value function: 0.44512
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 258
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0179161
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 259
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0162874
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 260
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 261
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0149301
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 262
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 263
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 264
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 265
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 266
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 267
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.0137816
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 268
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: -0.445528
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 269
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.60922
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 270
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.93853
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 271
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.0088
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 272
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.63016
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 273
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.63784
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 274
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.76638
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 275
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 1.91002
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 276
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.2162
New value of Value function: 10.2162
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 277
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5.44253
New value of Value function: 5.44253
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 278
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.9701
New value of Value function: 1.9701
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 279
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.53285
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 280
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 1.19183
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1241
New value of Q matrix: 0.445117
New value of Value function: 0.445117
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1242
New value of Q matrix: 0.445113
New value of Value function: 0.445113
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1243
New value of Q matrix: 0.44511
New value of Value function: 0.44511
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1244
New value of Q matrix: 0.445106
New value of Value function: 0.445106
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.380391
New value of Value function: 0.445106
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1245
New value of Q matrix: 0.445102
New value of Value function: 0.445102
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.375814
New value of Value function: 0.445102
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1246
New value of Q matrix: 0.445099
New value of Value function: 0.445099
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1247
New value of Q matrix: 0.445095
New value of Value function: 0.445095
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1248
New value of Q matrix: 0.445092
New value of Value function: 0.445092
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1249
New value of Q matrix: 0.445088
New value of Value function: 0.445088
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1250
New value of Q matrix: 0.445085
New value of Value function: 0.445085
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1251
New value of Q matrix: 0.445081
New value of Value function: 0.445081
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.380929
New value of Value function: 0.445081
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1252
New value of Q matrix: 0.445078
New value of Value function: 0.445078
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1253
New value of Q matrix: 0.445074
New value of Value function: 0.445074
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1254
New value of Q matrix: 0.44507
New value of Value function: 0.44507
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.376443
New value of Value function: 0.44507
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1255
New value of Q matrix: 0.445067
New value of Value function: 0.445067
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1256
New value of Q matrix: 0.445063
New value of Value function: 0.445063
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1257
New value of Q matrix: 0.44506
New value of Value function: 0.44506
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1258
New value of Q matrix: 0.445056
New value of Value function: 0.445056
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.425737
New value of Value function: 0.445056
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1259
New value of Q matrix: 0.445053
New value of Value function: 0.445053
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1260
New value of Q matrix: 0.445049
New value of Value function: 0.445049
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1261
New value of Q matrix: 0.445046
New value of Value function: 0.445046
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.425881
New value of Value function: 0.445046
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1262
New value of Q matrix: 0.445042
New value of Value function: 0.445042
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.352885
New value of Value function: 0.445042
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.353754
New value of Value function: 0.445042
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.426023
New value of Value function: 0.445042
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1263
New value of Q matrix: 0.445039
New value of Value function: 0.445039
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1264
New value of Q matrix: 0.445035
New value of Value function: 0.445035
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1265
New value of Q matrix: 0.445032
New value of Value function: 0.445032
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1266
New value of Q matrix: 0.445028
New value of Value function: 0.445028
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1267
New value of Q matrix: 0.445025
New value of Value function: 0.445025
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1268
New value of Q matrix: 0.445021
New value of Value function: 0.445021
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.37706
New value of Value function: 0.445021
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.426161
New value of Value function: 0.445021
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1269
New value of Q matrix: 0.445018
New value of Value function: 0.445018
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1270
New value of Q matrix: 0.445014
New value of Value function: 0.445014
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.426297
New value of Value function: 0.445014
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.42643
New value of Value function: 0.445014
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.381456
New value of Value function: 0.445014
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.377665
New value of Value function: 0.445014
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1271
New value of Q matrix: 0.445011
New value of Value function: 0.445011
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1272
New value of Q matrix: 0.445007
New value of Value function: 0.445007
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1273
New value of Q matrix: 0.445004
New value of Value function: 0.445004
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1274
New value of Q matrix: 0.445
New value of Value function: 0.445
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1275
New value of Q matrix: 0.444997
New value of Value function: 0.444997
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.378258
New value of Value function: 0.444997
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.354605
New value of Value function: 0.444997
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1276
New value of Q matrix: 0.444993
New value of Value function: 0.444993
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1277
New value of Q matrix: 0.44499
New value of Value function: 0.44499
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1278
New value of Q matrix: 0.444986
New value of Value function: 0.444986
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1279
New value of Q matrix: 0.444983
New value of Value function: 0.444983
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1280
New value of Q matrix: 0.444979
New value of Value function: 0.444979
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1281
New value of Q matrix: 0.444976
New value of Value function: 0.444976
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1282
New value of Q matrix: 0.444972
New value of Value function: 0.444972
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1283
New value of Q matrix: 0.444969
New value of Value function: 0.444969
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.37884
New value of Value function: 0.444969
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.379411
New value of Value function: 0.444969
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1284
New value of Q matrix: 0.444965
New value of Value function: 0.444965
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1285
New value of Q matrix: 0.444962
New value of Value function: 0.444962
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1286
New value of Q matrix: 0.444958
New value of Value function: 0.444958
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1287
New value of Q matrix: 0.444955
New value of Value function: 0.444955
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.426561
New value of Value function: 0.444955
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.426689
New value of Value function: 0.444955
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1288
New value of Q matrix: 0.444951
New value of Value function: 0.444951
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1289
New value of Q matrix: 0.444948
New value of Value function: 0.444948
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.426814
New value of Value function: 0.444948
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1290
New value of Q matrix: 0.444945
New value of Value function: 0.444945
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1291
New value of Q matrix: 0.444941
New value of Value function: 0.444941
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.426937
New value of Value function: 0.444941
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.379971
New value of Value function: 0.444941
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1292
New value of Q matrix: 0.444938
New value of Value function: 0.444938
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1293
New value of Q matrix: 0.444934
New value of Value function: 0.444934
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1294
New value of Q matrix: 0.444931
New value of Value function: 0.444931
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.381974
New value of Value function: 0.444931
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1295
New value of Q matrix: 0.444927
New value of Value function: 0.444927
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.427058
New value of Value function: 0.444927
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1296
New value of Q matrix: 0.444924
New value of Value function: 0.444924
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1297
New value of Q matrix: 0.44492
New value of Value function: 0.44492
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.380521
New value of Value function: 0.44492
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.427177
New value of Value function: 0.44492
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1298
New value of Q matrix: 0.444917
New value of Value function: 0.444917
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1299
New value of Q matrix: 0.444914
New value of Value function: 0.444914
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1300
New value of Q matrix: 0.44491
New value of Value function: 0.44491
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1301
New value of Q matrix: 0.444907
New value of Value function: 0.444907
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1302
New value of Q matrix: 0.444903
New value of Value function: 0.444903
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1303
New value of Q matrix: 0.4449
New value of Value function: 0.4449
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.427293
New value of Value function: 0.4449
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1304
New value of Q matrix: 0.444897
New value of Value function: 0.444897
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1305
New value of Q matrix: 0.444893
New value of Value function: 0.444893
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1306
New value of Q matrix: 0.44489
New value of Value function: 0.44489
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1307
New value of Q matrix: 0.444886
New value of Value function: 0.444886
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.355438
New value of Value function: 0.444886
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1308
New value of Q matrix: 0.444883
New value of Value function: 0.444883
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.382482
New value of Value function: 0.444883
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1309
New value of Q matrix: 0.444879
New value of Value function: 0.444879
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1310
New value of Q matrix: 0.444876
New value of Value function: 0.444876
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.382982
New value of Value function: 0.444876
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1311
New value of Q matrix: 0.444873
New value of Value function: 0.444873
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1312
New value of Q matrix: 0.444869
New value of Value function: 0.444869
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1313
New value of Q matrix: 0.444866
New value of Value function: 0.444866
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1314
New value of Q matrix: 0.444863
New value of Value function: 0.444863
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1315
New value of Q matrix: 0.444859
New value of Value function: 0.444859
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1316
New value of Q matrix: 0.444856
New value of Value function: 0.444856
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1317
New value of Q matrix: 0.444852
New value of Value function: 0.444852
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1318
New value of Q matrix: 0.444849
New value of Value function: 0.444849
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.383473
New value of Value function: 0.444849
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1319
New value of Q matrix: 0.444846
New value of Value function: 0.444846
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1320
New value of Q matrix: 0.444842
New value of Value function: 0.444842
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1321
New value of Q matrix: 0.444839
New value of Value function: 0.444839
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1322
New value of Q matrix: 0.444836
New value of Value function: 0.444836
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1323
New value of Q matrix: 0.444832
New value of Value function: 0.444832
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.356255
New value of Value function: 0.444832
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1324
New value of Q matrix: 0.444829
New value of Value function: 0.444829
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1325
New value of Q matrix: 0.444825
New value of Value function: 0.444825
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.383955
New value of Value function: 0.444825
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1326
New value of Q matrix: 0.444822
New value of Value function: 0.444822
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1327
New value of Q matrix: 0.444819
New value of Value function: 0.444819
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1328
New value of Q matrix: 0.444815
New value of Value function: 0.444815
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.384429
New value of Value function: 0.444815
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1329
New value of Q matrix: 0.444812
New value of Value function: 0.444812
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.427407
New value of Value function: 0.444812
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1330
New value of Q matrix: 0.444809
New value of Value function: 0.444809
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.384895
New value of Value function: 0.444809
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1331
New value of Q matrix: 0.444805
New value of Value function: 0.444805
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1332
New value of Q matrix: 0.444802
New value of Value function: 0.444802
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1333
New value of Q matrix: 0.444799
New value of Value function: 0.444799
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1334
New value of Q matrix: 0.444795
New value of Value function: 0.444795
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1335
New value of Q matrix: 0.444792
New value of Value function: 0.444792
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.38106
New value of Value function: 0.444792
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1336
New value of Q matrix: 0.444789
New value of Value function: 0.444789
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1337
New value of Q matrix: 0.444785
New value of Value function: 0.444785
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1338
New value of Q matrix: 0.444782
New value of Value function: 0.444782
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.427519
New value of Value function: 0.444782
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1339
New value of Q matrix: 0.444779
New value of Value function: 0.444779
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.385353
New value of Value function: 0.444779
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1340
New value of Q matrix: 0.444775
New value of Value function: 0.444775
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.357055
New value of Value function: 0.444775
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1341
New value of Q matrix: 0.444772
New value of Value function: 0.444772
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.357841
New value of Value function: 0.444772
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1342
New value of Q matrix: 0.444769
New value of Value function: 0.444769
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1343
New value of Q matrix: 0.444765
New value of Value function: 0.444765
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1344
New value of Q matrix: 0.444762
New value of Value function: 0.444762
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1345
New value of Q matrix: 0.444759
New value of Value function: 0.444759
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1346
New value of Q matrix: 0.444756
New value of Value function: 0.444756
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1347
New value of Q matrix: 0.444752
New value of Value function: 0.444752
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1348
New value of Q matrix: 0.444749
New value of Value function: 0.444749
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1349
New value of Q matrix: 0.444746
New value of Value function: 0.444746
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1350
New value of Q matrix: 0.444742
New value of Value function: 0.444742
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1351
New value of Q matrix: 0.444739
New value of Value function: 0.444739
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1352
New value of Q matrix: 0.444736
New value of Value function: 0.444736
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1353
New value of Q matrix: 0.444732
New value of Value function: 0.444732
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.381589
New value of Value function: 0.444732
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1354
New value of Q matrix: 0.444729
New value of Value function: 0.444729
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1355
New value of Q matrix: 0.446615
New value of Value function: 0.446615
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 440
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.0127972
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 441
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: -0.0238881
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 442
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.35762
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 443
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.41686
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 444
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.78245
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 445
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.02328
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 446
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.06904
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 447
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 25
New value of Q matrix: 4.25233
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 448
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.92605
New value of Value function: 4.92605
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 449
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.27395
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 450
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.10954
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 451
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.15333
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 452
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.14805
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 453
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.21472
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 454
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.04275
New value of Value function: 3.04275
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 455
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 1.48456
New value of Value function: 3.04275
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 456
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 1.70643
New value of Value function: 1.70643
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 457
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.52979
New value of Value function: 5.52979
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 458
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.81269
New value of Value function: 1.81269
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 459
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.13478
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 460
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.85029
New value of Value function: 1.85029
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 461
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.28675
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 462
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.28184
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 463
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.36638
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 464
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.410671
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 465
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: -0.0840824
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1356
New value of Q matrix: 0.446612
New value of Value function: 0.446612
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1357
New value of Q matrix: 0.446608
New value of Value function: 0.446608
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.427644
New value of Value function: 0.446608
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.358629
New value of Value function: 0.446608
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1358
New value of Q matrix: 0.446605
New value of Value function: 0.446605
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.385819
New value of Value function: 0.446605
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1359
New value of Q matrix: 0.446602
New value of Value function: 0.446602
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1360
New value of Q matrix: 0.446599
New value of Value function: 0.446599
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.386276
New value of Value function: 0.446599
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.386727
New value of Value function: 0.446599
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1361
New value of Q matrix: 0.446595
New value of Value function: 0.446595
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1362
New value of Q matrix: 0.446592
New value of Value function: 0.446592
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1363
New value of Q matrix: 0.446589
New value of Value function: 0.446589
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.427766
New value of Value function: 0.446589
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1364
New value of Q matrix: 0.446585
New value of Value function: 0.446585
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1365
New value of Q matrix: 0.446582
New value of Value function: 0.446582
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1366
New value of Q matrix: 0.446579
New value of Value function: 0.446579
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.427887
New value of Value function: 0.446579
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1367
New value of Q matrix: 0.446576
New value of Value function: 0.446576
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1368
New value of Q matrix: 0.446572
New value of Value function: 0.446572
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1369
New value of Q matrix: 0.446569
New value of Value function: 0.446569
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1370
New value of Q matrix: 0.446566
New value of Value function: 0.446566
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1371
New value of Q matrix: 0.446563
New value of Value function: 0.446563
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1372
New value of Q matrix: 0.446559
New value of Value function: 0.446559
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1373
New value of Q matrix: 0.446556
New value of Value function: 0.446556
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1374
New value of Q matrix: 0.446553
New value of Value function: 0.446553
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1375
New value of Q matrix: 0.44655
New value of Value function: 0.44655
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.38717
New value of Value function: 0.44655
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.387606
New value of Value function: 0.44655
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1376
New value of Q matrix: 0.446546
New value of Value function: 0.446546
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1377
New value of Q matrix: 0.446543
New value of Value function: 0.446543
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1378
New value of Q matrix: 0.44654
New value of Value function: 0.44654
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1379
New value of Q matrix: 0.446537
New value of Value function: 0.446537
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1380
New value of Q matrix: 0.446533
New value of Value function: 0.446533
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1381
New value of Q matrix: 0.44653
New value of Value function: 0.44653
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.382124
New value of Value function: 0.44653
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1382
New value of Q matrix: 0.446527
New value of Value function: 0.446527
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1383
New value of Q matrix: 0.446524
New value of Value function: 0.446524
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1384
New value of Q matrix: 0.44652
New value of Value function: 0.44652
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.428005
New value of Value function: 0.44652
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1385
New value of Q matrix: 0.446517
New value of Value function: 0.446517
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.359401
New value of Value function: 0.446517
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1386
New value of Q matrix: 0.446514
New value of Value function: 0.446514
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1387
New value of Q matrix: 0.446511
New value of Value function: 0.446511
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1388
New value of Q matrix: 0.446508
New value of Value function: 0.446508
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1389
New value of Q matrix: 0.446504
New value of Value function: 0.446504
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.388034
New value of Value function: 0.446504
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.38265
New value of Value function: 0.446504
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1390
New value of Q matrix: 0.446501
New value of Value function: 0.446501
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1391
New value of Q matrix: 0.446498
New value of Value function: 0.446498
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.388456
New value of Value function: 0.446498
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1392
New value of Q matrix: 0.446495
New value of Value function: 0.446495
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.383166
New value of Value function: 0.446495
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1393
New value of Q matrix: 0.446492
New value of Value function: 0.446492
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1394
New value of Q matrix: 0.446488
New value of Value function: 0.446488
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.428121
New value of Value function: 0.446488
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.383674
New value of Value function: 0.446488
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1395
New value of Q matrix: 0.446485
New value of Value function: 0.446485
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1396
New value of Q matrix: 0.446482
New value of Value function: 0.446482
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1397
New value of Q matrix: 0.446479
New value of Value function: 0.446479
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.388871
New value of Value function: 0.446479
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1398
New value of Q matrix: 0.446476
New value of Value function: 0.446476
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1399
New value of Q matrix: 0.446472
New value of Value function: 0.446472
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.428235
New value of Value function: 0.446472
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.428347
New value of Value function: 0.446472
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1400
New value of Q matrix: 0.446469
New value of Value function: 0.446469
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1401
New value of Q matrix: 0.446466
New value of Value function: 0.446466
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.384172
New value of Value function: 0.446466
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1402
New value of Q matrix: 0.446463
New value of Value function: 0.446463
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.428457
New value of Value function: 0.446463
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1403
New value of Q matrix: 0.44646
New value of Value function: 0.44646
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.38928
New value of Value function: 0.44646
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.384662
New value of Value function: 0.44646
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1404
New value of Q matrix: 0.446456
New value of Value function: 0.446456
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1405
New value of Q matrix: 0.446453
New value of Value function: 0.446453
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.385144
New value of Value function: 0.446453
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1406
New value of Q matrix: 0.44645
New value of Value function: 0.44645
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.428565
New value of Value function: 0.44645
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.360159
New value of Value function: 0.44645
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1407
New value of Q matrix: 0.446447
New value of Value function: 0.446447
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.389682
New value of Value function: 0.446447
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1408
New value of Q matrix: 0.446444
New value of Value function: 0.446444
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1409
New value of Q matrix: 0.446441
New value of Value function: 0.446441
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1410
New value of Q matrix: 0.446437
New value of Value function: 0.446437
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1411
New value of Q matrix: 0.446434
New value of Value function: 0.446434
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1412
New value of Q matrix: 0.446431
New value of Value function: 0.446431
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.360903
New value of Value function: 0.446431
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1413
New value of Q matrix: 0.446428
New value of Value function: 0.446428
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1414
New value of Q matrix: 0.446425
New value of Value function: 0.446425
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1415
New value of Q matrix: 0.446422
New value of Value function: 0.446422
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1416
New value of Q matrix: 0.446418
New value of Value function: 0.446418
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1417
New value of Q matrix: 0.446415
New value of Value function: 0.446415
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1418
New value of Q matrix: 0.446412
New value of Value function: 0.446412
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1419
New value of Q matrix: 0.446409
New value of Value function: 0.446409
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1420
New value of Q matrix: 0.446406
New value of Value function: 0.446406
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.361633
New value of Value function: 0.446406
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1421
New value of Q matrix: 0.446403
New value of Value function: 0.446403
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1422
New value of Q matrix: 0.4464
New value of Value function: 0.4464
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1423
New value of Q matrix: 0.446396
New value of Value function: 0.446396
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.385617
New value of Value function: 0.446396
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1424
New value of Q matrix: 0.446393
New value of Value function: 0.446393
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1425
New value of Q matrix: 0.44639
New value of Value function: 0.44639
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1426
New value of Q matrix: 0.446387
New value of Value function: 0.446387
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1427
New value of Q matrix: 0.446384
New value of Value function: 0.446384
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.36235
New value of Value function: 0.446384
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1428
New value of Q matrix: 0.446381
New value of Value function: 0.446381
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1429
New value of Q matrix: 0.446378
New value of Value function: 0.446378
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1430
New value of Q matrix: 0.446375
New value of Value function: 0.446375
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1431
New value of Q matrix: 0.446371
New value of Value function: 0.446371
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1432
New value of Q matrix: 0.446368
New value of Value function: 0.446368
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0.390078
New value of Value function: 0.446368
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1433
New value of Q matrix: 0.446365
New value of Value function: 0.446365
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1434
New value of Q matrix: 0.446362
New value of Value function: 0.446362
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1435
New value of Q matrix: 0.446359
New value of Value function: 0.446359
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.428671
New value of Value function: 0.446359
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1436
New value of Q matrix: 0.446356
New value of Value function: 0.446356
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.363054
New value of Value function: 0.446356
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1437
New value of Q matrix: 0.446353
New value of Value function: 0.446353
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1438
New value of Q matrix: 0.44635
New value of Value function: 0.44635
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1439
New value of Q matrix: 0.446347
New value of Value function: 0.446347
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1440
New value of Q matrix: 0.446343
New value of Value function: 0.446343
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1441
New value of Q matrix: 0.44634
New value of Value function: 0.44634
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.428775
New value of Value function: 0.44634
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1442
New value of Q matrix: 0.446337
New value of Value function: 0.446337
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1443
New value of Q matrix: 0.446334
New value of Value function: 0.446334
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1444
New value of Q matrix: 0.446331
New value of Value function: 0.446331
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.363745
New value of Value function: 0.446331
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1445
New value of Q matrix: 0.446328
New value of Value function: 0.446328
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1446
New value of Q matrix: 0.446325
New value of Value function: 0.446325
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1447
New value of Q matrix: 0.446322
New value of Value function: 0.446322
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1448
New value of Q matrix: 0.446319
New value of Value function: 0.446319
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1449
New value of Q matrix: 0.446316
New value of Value function: 0.446316
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.386082
New value of Value function: 0.446316
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1450
New value of Q matrix: 0.446313
New value of Value function: 0.446313
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1451
New value of Q matrix: 0.44631
New value of Value function: 0.44631
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1452
New value of Q matrix: 0.446306
New value of Value function: 0.446306
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1453
New value of Q matrix: 0.448064
New value of Value function: 0.448064
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 603
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.0223951
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 604
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: -0.301518
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 605
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -0.0210778
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 606
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 607
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: -0.290351
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 608
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: -0.0199068
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 609
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 610
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 611
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 612
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 613
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 614
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.12777
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 615
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.17304
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 616
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.29536
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 617
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.3139
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 618
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.19466
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 619
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.22829
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 620
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.36182
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 621
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.81453
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 622
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.25818
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 623
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.78739
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 624
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 2.27169
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 625
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.04041
New value of Value function: 3.04041
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 626
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.21427
New value of Value function: 3.21427
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 627
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.44573
New value of Value function: 5.52979
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 628
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 5.59734
New value of Value function: 5.59734
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 629
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.704479
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 630
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.41618
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 631
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.45976
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 632
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 1.22351
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1454
New value of Q matrix: 0.448061
New value of Value function: 0.448061
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1455
New value of Q matrix: 0.448058
New value of Value function: 0.448058
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1456
New value of Q matrix: 0.448055
New value of Value function: 0.448055
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1457
New value of Q matrix: 0.448052
New value of Value function: 0.448052
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1458
New value of Q matrix: 0.448049
New value of Value function: 0.448049
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1459
New value of Q matrix: 0.448046
New value of Value function: 0.448046
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1460
New value of Q matrix: 0.448042
New value of Value function: 0.448042
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1461
New value of Q matrix: 0.448039
New value of Value function: 0.448039
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1462
New value of Q matrix: 0.448036
New value of Value function: 0.448036
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1463
New value of Q matrix: 0.448033
New value of Value function: 0.448033
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1464
New value of Q matrix: 0.44803
New value of Value function: 0.44803
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1465
New value of Q matrix: 0.448027
New value of Value function: 0.448027
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1466
New value of Q matrix: 0.448024
New value of Value function: 0.448024
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1467
New value of Q matrix: 0.448021
New value of Value function: 0.448021
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1468
New value of Q matrix: 0.448018
New value of Value function: 0.448018
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1469
New value of Q matrix: 0.448015
New value of Value function: 0.448015
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1470
New value of Q matrix: 0.448012
New value of Value function: 0.448012
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1471
New value of Q matrix: 0.448009
New value of Value function: 0.448009
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1472
New value of Q matrix: 0.448006
New value of Value function: 0.448006
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1473
New value of Q matrix: 0.448003
New value of Value function: 0.448003
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.42889
New value of Value function: 0.448003
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1474
New value of Q matrix: 0.448
New value of Value function: 0.448
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.364439
New value of Value function: 0.448
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.386553
New value of Value function: 0.448
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.387016
New value of Value function: 0.448
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1475
New value of Q matrix: 0.447997
New value of Value function: 0.447997
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1476
New value of Q matrix: 0.447994
New value of Value function: 0.447994
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.36512
New value of Value function: 0.447994
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1477
New value of Q matrix: 0.447991
New value of Value function: 0.447991
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1478
New value of Q matrix: 0.447988
New value of Value function: 0.447988
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1479
New value of Q matrix: 0.447985
New value of Value function: 0.447985
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1480
New value of Q matrix: 0.447981
New value of Value function: 0.447981
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.429003
New value of Value function: 0.447981
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.39048
New value of Value function: 0.447981
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1481
New value of Q matrix: 0.447978
New value of Value function: 0.447978
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1482
New value of Q matrix: 0.447975
New value of Value function: 0.447975
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1483
New value of Q matrix: 0.447972
New value of Value function: 0.447972
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.429115
New value of Value function: 0.447972
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1484
New value of Q matrix: 0.447969
New value of Value function: 0.447969
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1485
New value of Q matrix: 0.447966
New value of Value function: 0.447966
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1486
New value of Q matrix: 0.447963
New value of Value function: 0.447963
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1487
New value of Q matrix: 0.44796
New value of Value function: 0.44796
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1488
New value of Q matrix: 0.447957
New value of Value function: 0.447957
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1489
New value of Q matrix: 0.447954
New value of Value function: 0.447954
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1490
New value of Q matrix: 0.447951
New value of Value function: 0.447951
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 678
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1491
New value of Q matrix: 0.447948
New value of Value function: 0.447948
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0.390875
New value of Value function: 0.447948
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1492
New value of Q matrix: 0.447945
New value of Value function: 0.447945
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.387471
New value of Value function: 0.447945
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 682
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1493
New value of Q matrix: 0.447942
New value of Value function: 0.447942
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1494
New value of Q matrix: 0.447939
New value of Value function: 0.447939
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0.391264
New value of Value function: 0.447939
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1495
New value of Q matrix: 0.447936
New value of Value function: 0.447936
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.391648
New value of Value function: 0.447936
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1496
New value of Q matrix: 0.447933
New value of Value function: 0.447933
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.387919
New value of Value function: 0.447933
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1497
New value of Q matrix: 0.44793
New value of Value function: 0.44793
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1498
New value of Q matrix: 0.447927
New value of Value function: 0.447927
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1499
New value of Q matrix: 0.447924
New value of Value function: 0.447924
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1500
New value of Q matrix: 0.447921
New value of Value function: 0.447921
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1501
New value of Q matrix: 0.447918
New value of Value function: 0.447918
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 694
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1502
New value of Q matrix: 0.447915
New value of Value function: 0.447915
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 695
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1503
New value of Q matrix: 0.447912
New value of Value function: 0.447912
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 696
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1504
New value of Q matrix: 0.447909
New value of Value function: 0.447909
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1505
New value of Q matrix: 0.447906
New value of Value function: 0.447906
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1506
New value of Q matrix: 0.447904
New value of Value function: 0.447904
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1507
New value of Q matrix: 0.447901
New value of Value function: 0.447901
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.388359
New value of Value function: 0.447901
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1508
New value of Q matrix: 0.447898
New value of Value function: 0.447898
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1509
New value of Q matrix: 0.447895
New value of Value function: 0.447895
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 703
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1510
New value of Q matrix: 0.447892
New value of Value function: 0.447892
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1511
New value of Q matrix: 0.447889
New value of Value function: 0.447889
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1512
New value of Q matrix: 0.447886
New value of Value function: 0.447886
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1513
New value of Q matrix: 0.447883
New value of Value function: 0.447883
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.429224
New value of Value function: 0.447883
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1514
New value of Q matrix: 0.44788
New value of Value function: 0.44788
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.365789
New value of Value function: 0.44788
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1515
New value of Q matrix: 0.447877
New value of Value function: 0.447877
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1516
New value of Q matrix: 0.447874
New value of Value function: 0.447874
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 712
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1517
New value of Q matrix: 0.447871
New value of Value function: 0.447871
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.366447
New value of Value function: 0.447871
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1518
New value of Q matrix: 0.447868
New value of Value function: 0.447868
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 715
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1519
New value of Q matrix: 0.447865
New value of Value function: 0.447865
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 716
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1520
New value of Q matrix: 0.447862
New value of Value function: 0.447862
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1521
New value of Q matrix: 0.447859
New value of Value function: 0.447859
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1522
New value of Q matrix: 0.447856
New value of Value function: 0.447856
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1523
New value of Q matrix: 0.447853
New value of Value function: 0.447853
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1524
New value of Q matrix: 0.44785
New value of Value function: 0.44785
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0.429331
New value of Value function: 0.44785
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1525
New value of Q matrix: 0.447847
New value of Value function: 0.447847
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.367093
New value of Value function: 0.447847
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1526
New value of Q matrix: 0.447844
New value of Value function: 0.447844
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1527
New value of Q matrix: 0.447842
New value of Value function: 0.447842
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1528
New value of Q matrix: 0.447839
New value of Value function: 0.447839
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1529
New value of Q matrix: 0.447836
New value of Value function: 0.447836
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1530
New value of Q matrix: 0.447833
New value of Value function: 0.447833
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1531
New value of Q matrix: 0.44783
New value of Value function: 0.44783
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1532
New value of Q matrix: 0.447827
New value of Value function: 0.447827
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1533
New value of Q matrix: 0.447824
New value of Value function: 0.447824
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.367729
New value of Value function: 0.447824
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1534
New value of Q matrix: 0.447821
New value of Value function: 0.447821
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1535
New value of Q matrix: 0.447818
New value of Value function: 0.447818
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 735
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.388792
New value of Value function: 0.447818
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.389219
New value of Value function: 0.447818
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1536
New value of Q matrix: 0.447815
New value of Value function: 0.447815
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.389638
New value of Value function: 0.447815
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1537
New value of Q matrix: 0.447812
New value of Value function: 0.447812
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1538
New value of Q matrix: 0.447809
New value of Value function: 0.447809
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1539
New value of Q matrix: 0.447806
New value of Value function: 0.447806
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.368354
New value of Value function: 0.447806
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.390051
New value of Value function: 0.447806
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1540
New value of Q matrix: 0.447804
New value of Value function: 0.447804
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1541
New value of Q matrix: 0.447801
New value of Value function: 0.447801
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1542
New value of Q matrix: 0.447798
New value of Value function: 0.447798
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1543
New value of Q matrix: 0.447795
New value of Value function: 0.447795
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.429436
New value of Value function: 0.447795
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1544
New value of Q matrix: 0.447792
New value of Value function: 0.447792
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1545
New value of Q matrix: 0.449444
New value of Value function: 0.449444
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 751
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: -0.0188591
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 752
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: -0.0179161
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 753
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.114581
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 754
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.41213
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 755
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.46533
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 756
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.21298
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 757
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.33246
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 758
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.34853
New value of Value function: 4.9011
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 759
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.28746
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 760
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.31141
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 761
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.43801
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 762
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.48451
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 763
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.36166
New value of Value function: 3.36166
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 764
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 2.53413
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 765
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.36941
New value of Value function: 3.36941
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 766
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 5.59268
New value of Value function: 5.59268
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 767
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 5.70966
New value of Value function: 5.70966
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 768
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.03808
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 769
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.05315
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 770
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.28896
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 771
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.22571
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 772
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.881478
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 773
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.34751
New value of Value function: 2.13478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 774
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.270999
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 775
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: -0.0822568
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.39047
New value of Value function: 0.449444
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1546
New value of Q matrix: 0.449441
New value of Value function: 0.449441
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1547
New value of Q matrix: 0.449438
New value of Value function: 0.449438
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1548
New value of Q matrix: 0.449435
New value of Value function: 0.449435
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1549
New value of Q matrix: 0.449432
New value of Value function: 0.449432
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1550
New value of Q matrix: 0.449429
New value of Value function: 0.449429
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1551
New value of Q matrix: 0.449426
New value of Value function: 0.449426
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1552
New value of Q matrix: 0.449424
New value of Value function: 0.449424
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 784
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1553
New value of Q matrix: 0.449421
New value of Value function: 0.449421
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0.390883
New value of Value function: 0.449421
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1554
New value of Q matrix: 0.449418
New value of Value function: 0.449418
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1555
New value of Q matrix: 0.449415
New value of Value function: 0.449415
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1556
New value of Q matrix: 0.449412
New value of Value function: 0.449412
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1557
New value of Q matrix: 0.449409
New value of Value function: 0.449409
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1558
New value of Q matrix: 0.449406
New value of Value function: 0.449406
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0.429552
New value of Value function: 0.449406
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1559
New value of Q matrix: 0.449403
New value of Value function: 0.449403
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1560
New value of Q matrix: 0.4494
New value of Value function: 0.4494
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 794
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1561
New value of Q matrix: 0.449398
New value of Value function: 0.449398
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1562
New value of Q matrix: 0.449395
New value of Value function: 0.449395
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1563
New value of Q matrix: 0.449392
New value of Value function: 0.449392
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.391289
New value of Value function: 0.449392
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1564
New value of Q matrix: 0.449389
New value of Value function: 0.449389
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0.391689
New value of Value function: 0.449389
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1565
New value of Q matrix: 0.449386
New value of Value function: 0.449386
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1566
New value of Q matrix: 0.449383
New value of Value function: 0.449383
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1567
New value of Q matrix: 0.44938
New value of Value function: 0.44938
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1568
New value of Q matrix: 0.449377
New value of Value function: 0.449377
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0.392083
New value of Value function: 0.449377
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1569
New value of Q matrix: 0.449375
New value of Value function: 0.449375
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.392471
New value of Value function: 0.449375
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1570
New value of Q matrix: 0.449372
New value of Value function: 0.449372
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1571
New value of Q matrix: 0.449369
New value of Value function: 0.449369
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.392037
New value of Value function: 0.449369
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1572
New value of Q matrix: 0.449366
New value of Value function: 0.449366
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1573
New value of Q matrix: 0.449363
New value of Value function: 0.449363
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.39242
New value of Value function: 0.449363
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.368981
New value of Value function: 0.449363
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1574
New value of Q matrix: 0.44936
New value of Value function: 0.44936
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1575
New value of Q matrix: 0.449357
New value of Value function: 0.449357
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.392854
New value of Value function: 0.449357
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1576
New value of Q matrix: 0.449355
New value of Value function: 0.449355
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1577
New value of Q matrix: 0.449352
New value of Value function: 0.449352
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.39323
New value of Value function: 0.449352
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0.429665
New value of Value function: 0.449352
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1578
New value of Q matrix: 0.449349
New value of Value function: 0.449349
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1579
New value of Q matrix: 0.449346
New value of Value function: 0.449346
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.393602
New value of Value function: 0.449346
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.393968
New value of Value function: 0.449346
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.369598
New value of Value function: 0.449346
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.392797
New value of Value function: 0.449346
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1580
New value of Q matrix: 0.449343
New value of Value function: 0.449343
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1581
New value of Q matrix: 0.44934
New value of Value function: 0.44934
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1582
New value of Q matrix: 0.449338
New value of Value function: 0.449338
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1583
New value of Q matrix: 0.449335
New value of Value function: 0.449335
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1584
New value of Q matrix: 0.449332
New value of Value function: 0.449332
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1585
New value of Q matrix: 0.449329
New value of Value function: 0.449329
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.394329
New value of Value function: 0.449329
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1586
New value of Q matrix: 0.449326
New value of Value function: 0.449326
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1587
New value of Q matrix: 0.449323
New value of Value function: 0.449323
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1588
New value of Q matrix: 0.449321
New value of Value function: 0.449321
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1589
New value of Q matrix: 0.449318
New value of Value function: 0.449318
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1590
New value of Q matrix: 0.449315
New value of Value function: 0.449315
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1591
New value of Q matrix: 0.449312
New value of Value function: 0.449312
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1592
New value of Q matrix: 0.449309
New value of Value function: 0.449309
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1593
New value of Q matrix: 0.449306
New value of Value function: 0.449306
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.429776
New value of Value function: 0.449306
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1594
New value of Q matrix: 0.449304
New value of Value function: 0.449304
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.370204
New value of Value function: 0.449304
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1595
New value of Q matrix: 0.449301
New value of Value function: 0.449301
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.429886
New value of Value function: 0.449301
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1596
New value of Q matrix: 0.449298
New value of Value function: 0.449298
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1597
New value of Q matrix: 0.449295
New value of Value function: 0.449295
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1598
New value of Q matrix: 0.449292
New value of Value function: 0.449292
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1599
New value of Q matrix: 0.44929
New value of Value function: 0.44929
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1600
New value of Q matrix: 0.449287
New value of Value function: 0.449287
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.370801
New value of Value function: 0.449287
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.394684
New value of Value function: 0.449287
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1601
New value of Q matrix: 0.449284
New value of Value function: 0.449284
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1602
New value of Q matrix: 0.449281
New value of Value function: 0.449281
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1603
New value of Q matrix: 0.449278
New value of Value function: 0.449278
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1604
New value of Q matrix: 0.449276
New value of Value function: 0.449276
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1605
New value of Q matrix: 0.449273
New value of Value function: 0.449273
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1606
New value of Q matrix: 0.44927
New value of Value function: 0.44927
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1607
New value of Q matrix: 0.449267
New value of Value function: 0.449267
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1608
New value of Q matrix: 0.449264
New value of Value function: 0.449264
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1609
New value of Q matrix: 0.449262
New value of Value function: 0.449262
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1610
New value of Q matrix: 0.449259
New value of Value function: 0.449259
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1611
New value of Q matrix: 0.449256
New value of Value function: 0.449256
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1612
New value of Q matrix: 0.449253
New value of Value function: 0.449253
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1613
New value of Q matrix: 0.44925
New value of Value function: 0.44925
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1614
New value of Q matrix: 0.449248
New value of Value function: 0.449248
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1615
New value of Q matrix: 0.449245
New value of Value function: 0.449245
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1616
New value of Q matrix: 0.449242
New value of Value function: 0.449242
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1617
New value of Q matrix: 0.449239
New value of Value function: 0.449239
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1618
New value of Q matrix: 0.449236
New value of Value function: 0.449236
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1619
New value of Q matrix: 0.449234
New value of Value function: 0.449234
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.429994
New value of Value function: 0.449234
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1620
New value of Q matrix: 0.449231
New value of Value function: 0.449231
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.371388
New value of Value function: 0.449231
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1621
New value of Q matrix: 0.449228
New value of Value function: 0.449228
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1622
New value of Q matrix: 0.449225
New value of Value function: 0.449225
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1623
New value of Q matrix: 0.449223
New value of Value function: 0.449223
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1624
New value of Q matrix: 0.44922
New value of Value function: 0.44922
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1625
New value of Q matrix: 0.449217
New value of Value function: 0.449217
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1626
New value of Q matrix: 0.449214
New value of Value function: 0.449214
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1627
New value of Q matrix: 0.449212
New value of Value function: 0.449212
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1628
New value of Q matrix: 0.449209
New value of Value function: 0.449209
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.4301
New value of Value function: 0.449209
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.371965
New value of Value function: 0.449209
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1629
New value of Q matrix: 0.449206
New value of Value function: 0.449206
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.395034
New value of Value function: 0.449206
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.430204
New value of Value function: 0.449206
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1630
New value of Q matrix: 0.449203
New value of Value function: 0.449203
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1631
New value of Q matrix: 0.449201
New value of Value function: 0.449201
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1632
New value of Q matrix: 0.449198
New value of Value function: 0.449198
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1633
New value of Q matrix: 0.449195
New value of Value function: 0.449195
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.393168
New value of Value function: 0.449195
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 894
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1634
New value of Q matrix: 0.449192
New value of Value function: 0.449192
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1635
New value of Q matrix: 0.44919
New value of Value function: 0.44919
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1636
New value of Q matrix: 0.449187
New value of Value function: 0.449187
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 897
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.395379
New value of Value function: 0.449187
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1637
New value of Q matrix: 0.449184
New value of Value function: 0.449184
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1638
New value of Q matrix: 0.449181
New value of Value function: 0.449181
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 900
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1639
New value of Q matrix: 0.449179
New value of Value function: 0.449179
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 901
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1640
New value of Q matrix: 0.449176
New value of Value function: 0.449176
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 902
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1641
New value of Q matrix: 0.45073
New value of Value function: 0.45073
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 903
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: -0.017063
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 904
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.433483
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 905
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: -0.0162874
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 906
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.076387
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 907
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.0697903
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 908
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.25393
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 909
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.28541
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 910
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.90809
New value of Value function: 4.90809
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 911
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.91967
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 912
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.365
New value of Value function: 4.90809
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 913
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.37905
New value of Value function: 4.90809
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 914
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.33537
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 915
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.35496
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 916
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 2.65815
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 917
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.04273
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 918
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.38319
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 919
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 2.69381
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 920
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.3673
New value of Value function: 3.3673
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 921
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.33363
New value of Value function: 3.3673
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 922
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 3.5711
New value of Value function: 3.5711
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 923
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.915892
New value of Value function: 1.85029
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 924
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.84823
New value of Value function: 1.84823
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 925
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.87475
New value of Value function: 1.87475
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 926
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.2151
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 927
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.3216
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 928
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.10006
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 929
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.38978
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 930
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 0.578081
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 931
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1642
New value of Q matrix: 0.450728
New value of Value function: 0.450728
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 932
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1643
New value of Q matrix: 0.450725
New value of Value function: 0.450725
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 933
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1644
New value of Q matrix: 0.450722
New value of Value function: 0.450722
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 934
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.395729
New value of Value function: 0.450722
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1645
New value of Q matrix: 0.450719
New value of Value function: 0.450719
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 936
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1646
New value of Q matrix: 0.450717
New value of Value function: 0.450717
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 937
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1647
New value of Q matrix: 0.450714
New value of Value function: 0.450714
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 938
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1648
New value of Q matrix: 0.450711
New value of Value function: 0.450711
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1649
New value of Q matrix: 0.450708
New value of Value function: 0.450708
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.396075
New value of Value function: 0.450708
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1650
New value of Q matrix: 0.450706
New value of Value function: 0.450706
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 942
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1651
New value of Q matrix: 0.450703
New value of Value function: 0.450703
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 943
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1652
New value of Q matrix: 0.4507
New value of Value function: 0.4507
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 944
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1653
New value of Q matrix: 0.450697
New value of Value function: 0.450697
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 945
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.372545
New value of Value function: 0.450697
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1654
New value of Q matrix: 0.450695
New value of Value function: 0.450695
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.373116
New value of Value function: 0.450695
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1655
New value of Q matrix: 0.450692
New value of Value function: 0.450692
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1656
New value of Q matrix: 0.450689
New value of Value function: 0.450689
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1657
New value of Q matrix: 0.450687
New value of Value function: 0.450687
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1658
New value of Q matrix: 0.450684
New value of Value function: 0.450684
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1659
New value of Q matrix: 0.450681
New value of Value function: 0.450681
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.393544
New value of Value function: 0.450681
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1660
New value of Q matrix: 0.450678
New value of Value function: 0.450678
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1661
New value of Q matrix: 0.450676
New value of Value function: 0.450676
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1662
New value of Q matrix: 0.450673
New value of Value function: 0.450673
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0.396416
New value of Value function: 0.450673
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1663
New value of Q matrix: 0.45067
New value of Value function: 0.45067
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 959
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.396752
New value of Value function: 0.45067
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 960
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.373678
New value of Value function: 0.45067
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 961
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1664
New value of Q matrix: 0.450668
New value of Value function: 0.450668
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1665
New value of Q matrix: 0.450665
New value of Value function: 0.450665
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 963
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1666
New value of Q matrix: 0.450662
New value of Value function: 0.450662
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 964
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.374231
New value of Value function: 0.450662
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 965
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1667
New value of Q matrix: 0.450659
New value of Value function: 0.450659
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1668
New value of Q matrix: 0.450657
New value of Value function: 0.450657
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1669
New value of Q matrix: 0.450654
New value of Value function: 0.450654
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0.374776
New value of Value function: 0.450654
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 969
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.393914
New value of Value function: 0.450654
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1670
New value of Q matrix: 0.450651
New value of Value function: 0.450651
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1671
New value of Q matrix: 0.450649
New value of Value function: 0.450649
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.394279
New value of Value function: 0.450649
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 973
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1672
New value of Q matrix: 0.450646
New value of Value function: 0.450646
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1673
New value of Q matrix: 0.450643
New value of Value function: 0.450643
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1674
New value of Q matrix: 0.450641
New value of Value function: 0.450641
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1675
New value of Q matrix: 0.450638
New value of Value function: 0.450638
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1676
New value of Q matrix: 0.450635
New value of Value function: 0.450635
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 978
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1677
New value of Q matrix: 0.450632
New value of Value function: 0.450632
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1678
New value of Q matrix: 0.45063
New value of Value function: 0.45063
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1679
New value of Q matrix: 0.450627
New value of Value function: 0.450627
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1680
New value of Q matrix: 0.450624
New value of Value function: 0.450624
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1681
New value of Q matrix: 0.450622
New value of Value function: 0.450622
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1682
New value of Q matrix: 0.450619
New value of Value function: 0.450619
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1683
New value of Q matrix: 0.450616
New value of Value function: 0.450616
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.430317
New value of Value function: 0.450616
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 986
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1684
New value of Q matrix: 0.450614
New value of Value function: 0.450614
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 987
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1685
New value of Q matrix: 0.450611
New value of Value function: 0.450611
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1686
New value of Q matrix: 0.450608
New value of Value function: 0.450608
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1687
New value of Q matrix: 0.450606
New value of Value function: 0.450606
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.394639
New value of Value function: 0.450606
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1688
New value of Q matrix: 0.450603
New value of Value function: 0.450603
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1689
New value of Q matrix: 0.4506
New value of Value function: 0.4506
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.394994
New value of Value function: 0.4506
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1690
New value of Q matrix: 0.450598
New value of Value function: 0.450598
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1691
New value of Q matrix: 0.450595
New value of Value function: 0.450595
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1692
New value of Q matrix: 0.450592
New value of Value function: 0.450592
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1693
New value of Q matrix: 0.45059
New value of Value function: 0.45059
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1694
New value of Q matrix: 0.450587
New value of Value function: 0.450587
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1695
New value of Q matrix: 0.450584
New value of Value function: 0.450584
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.375312
New value of Value function: 0.450584
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 1
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.887092
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 2
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -1.3038
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1696
New value of Q matrix: 0.450582
New value of Value function: 0.450582
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.397083
New value of Value function: 0.450582
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1697
New value of Q matrix: 0.450579
New value of Value function: 0.450579
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1698
New value of Q matrix: 0.450576
New value of Value function: 0.450576
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1699
New value of Q matrix: 0.450574
New value of Value function: 0.450574
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.430428
New value of Value function: 0.450574
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1700
New value of Q matrix: 0.450571
New value of Value function: 0.450571
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0.37584
New value of Value function: 0.450571
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1701
New value of Q matrix: 0.450568
New value of Value function: 0.450568
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0.37636
New value of Value function: 0.450568
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1702
New value of Q matrix: 0.450566
New value of Value function: 0.450566
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1703
New value of Q matrix: 0.450563
New value of Value function: 0.450563
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.376873
New value of Value function: 0.450563
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1704
New value of Q matrix: 0.450561
New value of Value function: 0.450561
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0.397409
New value of Value function: 0.450561
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1705
New value of Q matrix: 0.450558
New value of Value function: 0.450558
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1706
New value of Q matrix: 0.450555
New value of Value function: 0.450555
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1707
New value of Q matrix: 0.450553
New value of Value function: 0.450553
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1708
New value of Q matrix: 0.45055
New value of Value function: 0.45055
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1709
New value of Q matrix: 0.450547
New value of Value function: 0.450547
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.430537
New value of Value function: 0.450547
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1710
New value of Q matrix: 0.450545
New value of Value function: 0.450545
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.377377
New value of Value function: 0.450545
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1711
New value of Q matrix: 0.450542
New value of Value function: 0.450542
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1712
New value of Q matrix: 0.450539
New value of Value function: 0.450539
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.395344
New value of Value function: 0.450539
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1713
New value of Q matrix: 0.450537
New value of Value function: 0.450537
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1714
New value of Q matrix: 0.450534
New value of Value function: 0.450534
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.397731
New value of Value function: 0.450534
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.430644
New value of Value function: 0.450534
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1715
New value of Q matrix: 0.450532
New value of Value function: 0.450532
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1716
New value of Q matrix: 0.450529
New value of Value function: 0.450529
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0.398049
New value of Value function: 0.450529
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1717
New value of Q matrix: 0.450526
New value of Value function: 0.450526
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1718
New value of Q matrix: 0.450524
New value of Value function: 0.450524
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1719
New value of Q matrix: 0.450521
New value of Value function: 0.450521
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1720
New value of Q matrix: 0.450518
New value of Value function: 0.450518
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1721
New value of Q matrix: 0.450516
New value of Value function: 0.450516
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1722
New value of Q matrix: 0.450513
New value of Value function: 0.450513
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1723
New value of Q matrix: 0.450511
New value of Value function: 0.450511
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.398363
New value of Value function: 0.450511
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0.395688
New value of Value function: 0.450511
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1724
New value of Q matrix: 0.450508
New value of Value function: 0.450508
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1725
New value of Q matrix: 0.450505
New value of Value function: 0.450505
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.396028
New value of Value function: 0.450505
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1726
New value of Q matrix: 0.450503
New value of Value function: 0.450503
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1727
New value of Q matrix: 0.4505
New value of Value function: 0.4505
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1728
New value of Q matrix: 0.450498
New value of Value function: 0.450498
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1729
New value of Q matrix: 0.450495
New value of Value function: 0.450495
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1730
New value of Q matrix: 0.450492
New value of Value function: 0.450492
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.43075
New value of Value function: 0.450492
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1731
New value of Q matrix: 0.45049
New value of Value function: 0.45049
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1732
New value of Q matrix: 0.450487
New value of Value function: 0.450487
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1733
New value of Q matrix: 0.450485
New value of Value function: 0.450485
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1734
New value of Q matrix: 0.450482
New value of Value function: 0.450482
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1735
New value of Q matrix: 0.450479
New value of Value function: 0.450479
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1736
New value of Q matrix: 0.450477
New value of Value function: 0.450477
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1737
New value of Q matrix: 0.450474
New value of Value function: 0.450474
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1738
New value of Q matrix: 0.450472
New value of Value function: 0.450472
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1739
New value of Q matrix: 0.450469
New value of Value function: 0.450469
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.430855
New value of Value function: 0.450469
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0.430957
New value of Value function: 0.450469
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.377874
New value of Value function: 0.450469
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1740
New value of Q matrix: 0.450466
New value of Value function: 0.450466
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1741
New value of Q matrix: 0.450464
New value of Value function: 0.450464
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0.398672
New value of Value function: 0.450464
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1742
New value of Q matrix: 0.450461
New value of Value function: 0.450461
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.431059
New value of Value function: 0.450461
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1743
New value of Q matrix: 0.450459
New value of Value function: 0.450459
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.431159
New value of Value function: 0.450459
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.396363
New value of Value function: 0.450459
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.378364
New value of Value function: 0.450459
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1744
New value of Q matrix: 0.450456
New value of Value function: 0.450456
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1745
New value of Q matrix: 0.450453
New value of Value function: 0.450453
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.378847
New value of Value function: 0.450453
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0.396694
New value of Value function: 0.450453
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1746
New value of Q matrix: 0.450451
New value of Value function: 0.450451
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1747
New value of Q matrix: 0.450448
New value of Value function: 0.450448
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1748
New value of Q matrix: 0.450446
New value of Value function: 0.450446
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1749
New value of Q matrix: 0.450443
New value of Value function: 0.450443
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1750
New value of Q matrix: 0.450441
New value of Value function: 0.450441
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1751
New value of Q matrix: 0.450438
New value of Value function: 0.450438
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1752
New value of Q matrix: 0.450435
New value of Value function: 0.450435
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1753
New value of Q matrix: 0.450433
New value of Value function: 0.450433
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1754
New value of Q matrix: 0.45043
New value of Value function: 0.45043
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.379323
New value of Value function: 0.45043
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1755
New value of Q matrix: 0.450428
New value of Value function: 0.450428
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1756
New value of Q matrix: 0.450425
New value of Value function: 0.450425
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1757
New value of Q matrix: 0.450423
New value of Value function: 0.450423
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.398976
New value of Value function: 0.450423
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1758
New value of Q matrix: 0.45042
New value of Value function: 0.45042
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1759
New value of Q matrix: 0.450417
New value of Value function: 0.450417
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0.431257
New value of Value function: 0.450417
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.431354
New value of Value function: 0.450417
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1760
New value of Q matrix: 0.450415
New value of Value function: 0.450415
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.39702
New value of Value function: 0.450415
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0.43145
New value of Value function: 0.450415
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.431544
New value of Value function: 0.450415
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1761
New value of Q matrix: 0.450412
New value of Value function: 0.450412
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1762
New value of Q matrix: 0.45041
New value of Value function: 0.45041
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1763
New value of Q matrix: 0.450407
New value of Value function: 0.450407
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1764
New value of Q matrix: 0.450405
New value of Value function: 0.450405
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1765
New value of Q matrix: 0.450402
New value of Value function: 0.450402
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.379792
New value of Value function: 0.450402
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1766
New value of Q matrix: 0.4504
New value of Value function: 0.4504
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1767
New value of Q matrix: 0.450397
New value of Value function: 0.450397
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1768
New value of Q matrix: 0.450395
New value of Value function: 0.450395
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1769
New value of Q matrix: 0.450392
New value of Value function: 0.450392
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1770
New value of Q matrix: 0.450389
New value of Value function: 0.450389
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1771
New value of Q matrix: 0.450387
New value of Value function: 0.450387
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.380254
New value of Value function: 0.450387
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1772
New value of Q matrix: 0.450384
New value of Value function: 0.450384
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1773
New value of Q matrix: 0.450382
New value of Value function: 0.450382
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0.399277
New value of Value function: 0.450382
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1774
New value of Q matrix: 0.450379
New value of Value function: 0.450379
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1775
New value of Q matrix: 0.450377
New value of Value function: 0.450377
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0.399574
New value of Value function: 0.450377
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1776
New value of Q matrix: 0.450374
New value of Value function: 0.450374
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1777
New value of Q matrix: 0.450372
New value of Value function: 0.450372
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1778
New value of Q matrix: 0.450369
New value of Value function: 0.450369
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1779
New value of Q matrix: 0.450367
New value of Value function: 0.450367
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0.431637
New value of Value function: 0.450367
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.431729
New value of Value function: 0.450367
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0.43182
New value of Value function: 0.450367
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1780
New value of Q matrix: 0.450364
New value of Value function: 0.450364
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1781
New value of Q matrix: 0.450362
New value of Value function: 0.450362
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1782
New value of Q matrix: 0.450359
New value of Value function: 0.450359
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1783
New value of Q matrix: 0.450356
New value of Value function: 0.450356
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1784
New value of Q matrix: 0.450354
New value of Value function: 0.450354
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0.431909
New value of Value function: 0.450354
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1785
New value of Q matrix: 0.450351
New value of Value function: 0.450351
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1786
New value of Q matrix: 0.450349
New value of Value function: 0.450349
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1787
New value of Q matrix: 0.450346
New value of Value function: 0.450346
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1788
New value of Q matrix: 0.450344
New value of Value function: 0.450344
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.380709
New value of Value function: 0.450344
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1789
New value of Q matrix: 0.450341
New value of Value function: 0.450341
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1790
New value of Q matrix: 0.450339
New value of Value function: 0.450339
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1791
New value of Q matrix: 0.450336
New value of Value function: 0.450336
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1792
New value of Q matrix: 0.450334
New value of Value function: 0.450334
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0.399867
New value of Value function: 0.450334
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1793
New value of Q matrix: 0.450331
New value of Value function: 0.450331
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1794
New value of Q matrix: 0.450329
New value of Value function: 0.450329
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1795
New value of Q matrix: 0.450326
New value of Value function: 0.450326
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1796
New value of Q matrix: 0.450324
New value of Value function: 0.450324
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1797
New value of Q matrix: 0.450321
New value of Value function: 0.450321
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1798
New value of Q matrix: 0.451739
New value of Value function: 0.451739
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 149
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 150
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 151
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 152
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 153
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 154
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.55278
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.381168
New value of Value function: 0.451739
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0.39735
New value of Value function: 0.451739
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.397676
New value of Value function: 0.451739
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1799
New value of Q matrix: 0.451737
New value of Value function: 0.451737
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1800
New value of Q matrix: 0.453153
New value of Value function: 0.453153
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 160
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 161
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 162
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.27569
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1801
New value of Q matrix: 0.45315
New value of Value function: 0.45315
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0.432015
New value of Value function: 0.45315
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1802
New value of Q matrix: 0.453147
New value of Value function: 0.453147
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0.432119
New value of Value function: 0.453147
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1803
New value of Q matrix: 0.453145
New value of Value function: 0.453145
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1804
New value of Q matrix: 0.454557
New value of Value function: 0.454557
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 169
----------
State: 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 170
----------
State: 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.27499
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1805
New value of Q matrix: 0.454554
New value of Value function: 0.454554
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1806
New value of Q matrix: 0.455964
New value of Value function: 0.455964
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 173
----------
State: 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.849996
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 174
----------
State: 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.5486
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1807
New value of Q matrix: 0.457372
New value of Value function: 0.457372
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 176
----------
State: 2425
	Distance: 4
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 177
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 178
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 179
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 180
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 181
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 182
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.525
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 183
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 184
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 185
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 186
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 187
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 188
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 189
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 190
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 191
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 192
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 193
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 194
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 195
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 196
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 197
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 198
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 199
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 200
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 201
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 202
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 203
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.04975
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 204
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 205
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 206
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.45025
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 207
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.45025
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 208
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 209
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.928002
New value of Value function: 0.928002
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 210
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.459361
New value of Value function: 1.87475
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 211
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.23734
New value of Value function: 1.23734
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 212
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 2.15886
New value of Value function: 2.15886
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 213
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.86272
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 214
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 2.39563
New value of Value function: 2.39563
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 215
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1.04304
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 216
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.8692
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 217
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.5472
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0.398034
New value of Value function: 0.457372
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1808
New value of Q matrix: 0.457369
New value of Value function: 0.457369
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.381659
New value of Value function: 0.457369
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1809
New value of Q matrix: 0.457366
New value of Value function: 0.457366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0.4002
New value of Value function: 0.457366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1810
New value of Q matrix: 0.457364
New value of Value function: 0.457364
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0.400528
New value of Value function: 0.457364
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1811
New value of Q matrix: 0.457361
New value of Value function: 0.457361
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.398387
New value of Value function: 0.457361
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1812
New value of Q matrix: 0.457359
New value of Value function: 0.457359
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0.432248
New value of Value function: 0.457359
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1813
New value of Q matrix: 0.457356
New value of Value function: 0.457356
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0.398736
New value of Value function: 0.457356
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1814
New value of Q matrix: 0.457354
New value of Value function: 0.457354
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1815
New value of Q matrix: 0.457351
New value of Value function: 0.457351
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1816
New value of Q matrix: 0.457349
New value of Value function: 0.457349
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1817
New value of Q matrix: 0.457346
New value of Value function: 0.457346
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1818
New value of Q matrix: 0.457344
New value of Value function: 0.457344
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1819
New value of Q matrix: 0.457341
New value of Value function: 0.457341
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0.400853
New value of Value function: 0.457341
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1820
New value of Q matrix: 0.457339
New value of Value function: 0.457339
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0.432376
New value of Value function: 0.457339
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1821
New value of Q matrix: 0.457336
New value of Value function: 0.457336
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1822
New value of Q matrix: 0.457334
New value of Value function: 0.457334
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1823
New value of Q matrix: 0.457331
New value of Value function: 0.457331
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1824
New value of Q matrix: 0.457329
New value of Value function: 0.457329
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1825
New value of Q matrix: 0.457326
New value of Value function: 0.457326
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0.432502
New value of Value function: 0.457326
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1826
New value of Q matrix: 0.457324
New value of Value function: 0.457324
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1827
New value of Q matrix: 0.457321
New value of Value function: 0.457321
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1828
New value of Q matrix: 0.457319
New value of Value function: 0.457319
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0.401173
New value of Value function: 0.457319
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1829
New value of Q matrix: 0.457316
New value of Value function: 0.457316
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1830
New value of Q matrix: 0.457314
New value of Value function: 0.457314
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1831
New value of Q matrix: 0.457311
New value of Value function: 0.457311
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0.401489
New value of Value function: 0.457311
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1832
New value of Q matrix: 0.457309
New value of Value function: 0.457309
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1833
New value of Q matrix: 0.457306
New value of Value function: 0.457306
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1834
New value of Q matrix: 0.457304
New value of Value function: 0.457304
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0.432626
New value of Value function: 0.457304
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1835
New value of Q matrix: 0.457301
New value of Value function: 0.457301
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1836
New value of Q matrix: 0.457299
New value of Value function: 0.457299
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1837
New value of Q matrix: 0.457296
New value of Value function: 0.457296
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1838
New value of Q matrix: 0.457294
New value of Value function: 0.457294
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1839
New value of Q matrix: 0.457291
New value of Value function: 0.457291
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1840
New value of Q matrix: 0.457289
New value of Value function: 0.457289
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1841
New value of Q matrix: 0.457286
New value of Value function: 0.457286
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0.382142
New value of Value function: 0.457286
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1842
New value of Q matrix: 0.457284
New value of Value function: 0.457284
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1843
New value of Q matrix: 0.457281
New value of Value function: 0.457281
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.382619
New value of Value function: 0.457281
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1844
New value of Q matrix: 0.457279
New value of Value function: 0.457279
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1845
New value of Q matrix: 0.457276
New value of Value function: 0.457276
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1846
New value of Q matrix: 0.457274
New value of Value function: 0.457274
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0.39908
New value of Value function: 0.457274
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.383089
New value of Value function: 0.457274
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0.432748
New value of Value function: 0.457274
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1847
New value of Q matrix: 0.457271
New value of Value function: 0.457271
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0.399419
New value of Value function: 0.457271
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1848
New value of Q matrix: 0.457269
New value of Value function: 0.457269
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1849
New value of Q matrix: 0.457266
New value of Value function: 0.457266
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1850
New value of Q matrix: 0.457264
New value of Value function: 0.457264
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1851
New value of Q matrix: 0.457262
New value of Value function: 0.457262
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1852
New value of Q matrix: 0.457259
New value of Value function: 0.457259
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1853
New value of Q matrix: 0.457257
New value of Value function: 0.457257
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0.432869
New value of Value function: 0.457257
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1854
New value of Q matrix: 0.457254
New value of Value function: 0.457254
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1855
New value of Q matrix: 0.457252
New value of Value function: 0.457252
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1856
New value of Q matrix: 0.457249
New value of Value function: 0.457249
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0.383553
New value of Value function: 0.457249
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1857
New value of Q matrix: 0.457247
New value of Value function: 0.457247
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1858
New value of Q matrix: 0.457244
New value of Value function: 0.457244
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1859
New value of Q matrix: 0.457242
New value of Value function: 0.457242
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1860
New value of Q matrix: 0.457239
New value of Value function: 0.457239
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1861
New value of Q matrix: 0.457237
New value of Value function: 0.457237
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1862
New value of Q matrix: 0.457234
New value of Value function: 0.457234
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.384011
New value of Value function: 0.457234
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1863
New value of Q matrix: 0.457232
New value of Value function: 0.457232
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1864
New value of Q matrix: 0.45723
New value of Value function: 0.45723
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0.384462
New value of Value function: 0.45723
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1865
New value of Q matrix: 0.457227
New value of Value function: 0.457227
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.384908
New value of Value function: 0.457227
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1866
New value of Q matrix: 0.457225
New value of Value function: 0.457225
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1867
New value of Q matrix: 0.457222
New value of Value function: 0.457222
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1868
New value of Q matrix: 0.45722
New value of Value function: 0.45722
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1869
New value of Q matrix: 0.457217
New value of Value function: 0.457217
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0.399754
New value of Value function: 0.457217
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1870
New value of Q matrix: 0.457215
New value of Value function: 0.457215
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1871
New value of Q matrix: 0.457212
New value of Value function: 0.457212
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0.385348
New value of Value function: 0.457212
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1872
New value of Q matrix: 0.45721
New value of Value function: 0.45721
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.385782
New value of Value function: 0.45721
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1873
New value of Q matrix: 0.457208
New value of Value function: 0.457208
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1874
New value of Q matrix: 0.457205
New value of Value function: 0.457205
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0.400084
New value of Value function: 0.457205
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1875
New value of Q matrix: 0.457203
New value of Value function: 0.457203
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1876
New value of Q matrix: 0.4572
New value of Value function: 0.4572
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1877
New value of Q matrix: 0.457198
New value of Value function: 0.457198
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1878
New value of Q matrix: 0.457195
New value of Value function: 0.457195
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1879
New value of Q matrix: 0.457193
New value of Value function: 0.457193
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1880
New value of Q matrix: 0.45719
New value of Value function: 0.45719
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1881
New value of Q matrix: 0.457188
New value of Value function: 0.457188
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1882
New value of Q matrix: 0.457186
New value of Value function: 0.457186
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1883
New value of Q matrix: 0.457183
New value of Value function: 0.457183
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.432988
New value of Value function: 0.457183
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0.401801
New value of Value function: 0.457183
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1884
New value of Q matrix: 0.457181
New value of Value function: 0.457181
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0.40041
New value of Value function: 0.457181
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1885
New value of Q matrix: 0.457178
New value of Value function: 0.457178
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1886
New value of Q matrix: 0.457176
New value of Value function: 0.457176
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1887
New value of Q matrix: 0.457174
New value of Value function: 0.457174
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1888
New value of Q matrix: 0.457171
New value of Value function: 0.457171
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1889
New value of Q matrix: 0.457169
New value of Value function: 0.457169
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1890
New value of Q matrix: 0.457166
New value of Value function: 0.457166
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1891
New value of Q matrix: 0.457164
New value of Value function: 0.457164
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1892
New value of Q matrix: 0.457161
New value of Value function: 0.457161
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1893
New value of Q matrix: 0.457159
New value of Value function: 0.457159
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0.38621
New value of Value function: 0.457159
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1894
New value of Q matrix: 0.457157
New value of Value function: 0.457157
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0.402109
New value of Value function: 0.457157
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1895
New value of Q matrix: 0.457154
New value of Value function: 0.457154
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1896
New value of Q matrix: 0.457152
New value of Value function: 0.457152
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1897
New value of Q matrix: 0.457149
New value of Value function: 0.457149
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1898
New value of Q matrix: 0.457147
New value of Value function: 0.457147
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1899
New value of Q matrix: 0.457145
New value of Value function: 0.457145
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1900
New value of Q matrix: 0.457142
New value of Value function: 0.457142
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1901
New value of Q matrix: 0.45714
New value of Value function: 0.45714
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0.400732
New value of Value function: 0.45714
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1902
New value of Q matrix: 0.457137
New value of Value function: 0.457137
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1903
New value of Q matrix: 0.457135
New value of Value function: 0.457135
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1904
New value of Q matrix: 0.45847
New value of Value function: 0.45847
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 349
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 350
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.85046
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 351
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 352
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.439168
New value of Value function: 0.439168
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 353
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 354
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 355
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 356
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 357
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 358
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 359
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 360
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 361
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 362
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 363
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 364
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.35
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 365
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.33
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 366
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 1.10833
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 367
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.525
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 368
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.97513
New value of Value function: 4.97513
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 369
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.267
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 370
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.04182
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 371
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.178
New value of Value function: 2.178
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 372
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 373
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.04975
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 374
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.78137
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 375
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.0663333
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 376
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3.22509
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 377
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.84378
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 378
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.21674
New value of Value function: 2.21674
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 379
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 2.59596
New value of Value function: 2.59596
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 380
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 381
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 382
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 383
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.404291
New value of Value function: 0.404291
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 384
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 0.107835
New value of Value function: 1.22513
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 385
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 386
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: -0.0307425
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 387
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.54611
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1905
New value of Q matrix: 0.458468
New value of Value function: 0.458468
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0.401058
New value of Value function: 0.458468
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0.386641
New value of Value function: 0.458468
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1906
New value of Q matrix: 0.458466
New value of Value function: 0.458466
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1907
New value of Q matrix: 0.458463
New value of Value function: 0.458463
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1908
New value of Q matrix: 0.458461
New value of Value function: 0.458461
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1909
New value of Q matrix: 0.458458
New value of Value function: 0.458458
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1910
New value of Q matrix: 0.458456
New value of Value function: 0.458456
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1911
New value of Q matrix: 0.458454
New value of Value function: 0.458454
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1912
New value of Q matrix: 0.458451
New value of Value function: 0.458451
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1913
New value of Q matrix: 0.458449
New value of Value function: 0.458449
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1914
New value of Q matrix: 0.458446
New value of Value function: 0.458446
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.433113
New value of Value function: 0.458446
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1915
New value of Q matrix: 0.458444
New value of Value function: 0.458444
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0.387067
New value of Value function: 0.458444
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1916
New value of Q matrix: 0.458442
New value of Value function: 0.458442
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1917
New value of Q matrix: 0.458439
New value of Value function: 0.458439
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1918
New value of Q matrix: 0.458437
New value of Value function: 0.458437
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1919
New value of Q matrix: 0.458434
New value of Value function: 0.458434
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1920
New value of Q matrix: 0.458432
New value of Value function: 0.458432
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1921
New value of Q matrix: 0.45843
New value of Value function: 0.45843
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1922
New value of Q matrix: 0.458427
New value of Value function: 0.458427
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1923
New value of Q matrix: 0.458425
New value of Value function: 0.458425
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1924
New value of Q matrix: 0.458423
New value of Value function: 0.458423
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.433236
New value of Value function: 0.458423
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0.40138
New value of Value function: 0.458423
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1925
New value of Q matrix: 0.45842
New value of Value function: 0.45842
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1926
New value of Q matrix: 0.458418
New value of Value function: 0.458418
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0.387487
New value of Value function: 0.458418
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1927
New value of Q matrix: 0.458415
New value of Value function: 0.458415
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1928
New value of Q matrix: 0.458413
New value of Value function: 0.458413
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1929
New value of Q matrix: 0.458411
New value of Value function: 0.458411
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0.433358
New value of Value function: 0.458411
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1930
New value of Q matrix: 0.458408
New value of Value function: 0.458408
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1931
New value of Q matrix: 0.458406
New value of Value function: 0.458406
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1932
New value of Q matrix: 0.458404
New value of Value function: 0.458404
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1933
New value of Q matrix: 0.458401
New value of Value function: 0.458401
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0.387901
New value of Value function: 0.458401
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0.433478
New value of Value function: 0.458401
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0.388311
New value of Value function: 0.458401
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.40242
New value of Value function: 0.458401
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1934
New value of Q matrix: 0.458399
New value of Value function: 0.458399
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1935
New value of Q matrix: 0.458396
New value of Value function: 0.458396
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1936
New value of Q matrix: 0.458394
New value of Value function: 0.458394
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1937
New value of Q matrix: 0.458392
New value of Value function: 0.458392
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1938
New value of Q matrix: 0.458389
New value of Value function: 0.458389
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1939
New value of Q matrix: 0.458387
New value of Value function: 0.458387
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1940
New value of Q matrix: 0.458385
New value of Value function: 0.458385
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.402728
New value of Value function: 0.458385
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.403032
New value of Value function: 0.458385
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1941
New value of Q matrix: 0.458382
New value of Value function: 0.458382
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1942
New value of Q matrix: 0.45838
New value of Value function: 0.45838
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1943
New value of Q matrix: 0.458378
New value of Value function: 0.458378
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1944
New value of Q matrix: 0.458375
New value of Value function: 0.458375
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0.388715
New value of Value function: 0.458375
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1945
New value of Q matrix: 0.458373
New value of Value function: 0.458373
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0.401698
New value of Value function: 0.458373
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1946
New value of Q matrix: 0.45837
New value of Value function: 0.45837
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1947
New value of Q matrix: 0.458368
New value of Value function: 0.458368
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0.389114
New value of Value function: 0.458368
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1948
New value of Q matrix: 0.458366
New value of Value function: 0.458366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0.389508
New value of Value function: 0.458366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0.389898
New value of Value function: 0.458366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1949
New value of Q matrix: 0.458363
New value of Value function: 0.458363
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.402012
New value of Value function: 0.458363
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1950
New value of Q matrix: 0.458361
New value of Value function: 0.458361
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1951
New value of Q matrix: 0.458359
New value of Value function: 0.458359
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1952
New value of Q matrix: 0.458356
New value of Value function: 0.458356
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0.403332
New value of Value function: 0.458356
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1953
New value of Q matrix: 0.458354
New value of Value function: 0.458354
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1954
New value of Q matrix: 0.458352
New value of Value function: 0.458352
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1955
New value of Q matrix: 0.458349
New value of Value function: 0.458349
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.402322
New value of Value function: 0.458349
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1956
New value of Q matrix: 0.458347
New value of Value function: 0.458347
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1957
New value of Q matrix: 0.458345
New value of Value function: 0.458345
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1958
New value of Q matrix: 0.458342
New value of Value function: 0.458342
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1959
New value of Q matrix: 0.45834
New value of Value function: 0.45834
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0.403629
New value of Value function: 0.45834
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.402628
New value of Value function: 0.45834
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1960
New value of Q matrix: 0.458338
New value of Value function: 0.458338
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1961
New value of Q matrix: 0.458335
New value of Value function: 0.458335
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1962
New value of Q matrix: 0.458333
New value of Value function: 0.458333
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0.403922
New value of Value function: 0.458333
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.390282
New value of Value function: 0.458333
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0.433597
New value of Value function: 0.458333
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1963
New value of Q matrix: 0.458331
New value of Value function: 0.458331
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1964
New value of Q matrix: 0.458328
New value of Value function: 0.458328
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1965
New value of Q matrix: 0.458326
New value of Value function: 0.458326
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1966
New value of Q matrix: 0.458324
New value of Value function: 0.458324
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1967
New value of Q matrix: 0.458321
New value of Value function: 0.458321
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1968
New value of Q matrix: 0.458319
New value of Value function: 0.458319
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1969
New value of Q matrix: 0.458317
New value of Value function: 0.458317
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1970
New value of Q matrix: 0.458314
New value of Value function: 0.458314
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1971
New value of Q matrix: 0.458312
New value of Value function: 0.458312
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0.433714
New value of Value function: 0.458312
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0.43383
New value of Value function: 0.458312
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1972
New value of Q matrix: 0.45831
New value of Value function: 0.45831
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1973
New value of Q matrix: 0.458307
New value of Value function: 0.458307
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0.404212
New value of Value function: 0.458307
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1974
New value of Q matrix: 0.458305
New value of Value function: 0.458305
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1975
New value of Q matrix: 0.458303
New value of Value function: 0.458303
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1976
New value of Q matrix: 0.4583
New value of Value function: 0.4583
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1977
New value of Q matrix: 0.458298
New value of Value function: 0.458298
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1978
New value of Q matrix: 0.458296
New value of Value function: 0.458296
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1979
New value of Q matrix: 0.458293
New value of Value function: 0.458293
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1980
New value of Q matrix: 0.458291
New value of Value function: 0.458291
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1981
New value of Q matrix: 0.458289
New value of Value function: 0.458289
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0.433944
New value of Value function: 0.458289
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1982
New value of Q matrix: 0.458286
New value of Value function: 0.458286
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1983
New value of Q matrix: 0.458284
New value of Value function: 0.458284
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0.434057
New value of Value function: 0.458284
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1984
New value of Q matrix: 0.458282
New value of Value function: 0.458282
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1985
New value of Q matrix: 0.45828
New value of Value function: 0.45828
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.390662
New value of Value function: 0.45828
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1986
New value of Q matrix: 0.458277
New value of Value function: 0.458277
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1987
New value of Q matrix: 0.458275
New value of Value function: 0.458275
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1988
New value of Q matrix: 0.458273
New value of Value function: 0.458273
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1989
New value of Q matrix: 0.45827
New value of Value function: 0.45827
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1990
New value of Q matrix: 0.458268
New value of Value function: 0.458268
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0.434168
New value of Value function: 0.458268
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1991
New value of Q matrix: 0.458266
New value of Value function: 0.458266
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1992
New value of Q matrix: 0.458263
New value of Value function: 0.458263
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1993
New value of Q matrix: 0.458261
New value of Value function: 0.458261
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1994
New value of Q matrix: 0.458259
New value of Value function: 0.458259
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1995
New value of Q matrix: 0.458257
New value of Value function: 0.458257
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1996
New value of Q matrix: 0.458254
New value of Value function: 0.458254
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1997
New value of Q matrix: 0.458252
New value of Value function: 0.458252
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1998
New value of Q matrix: 0.45825
New value of Value function: 0.45825
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1999
New value of Q matrix: 0.458247
New value of Value function: 0.458247
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0.404497
New value of Value function: 0.458247
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0.40478
New value of Value function: 0.458247
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0.40293
New value of Value function: 0.458247
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2000
New value of Q matrix: 0.458245
New value of Value function: 0.458245
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2001
New value of Q matrix: 0.459515
New value of Value function: 0.459515
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 522
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 523
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0166667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 524
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 525
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 526
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.68333
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 527
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 528
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 529
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 530
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0142857
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 531
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 532
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 533
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 534
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0658707
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 535
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0548922
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 536
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 537
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 538
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 539
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 540
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.675
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 541
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.65362
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 542
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.46269
New value of Value function: 4.97513
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 543
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.64179
New value of Value function: 4.97513
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 544
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.96517
New value of Value function: 4.96517
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 545
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.9544
New value of Value function: 4.9544
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 546
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.50433
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 547
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.31722
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 548
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 2.74732
New value of Value function: 2.74732
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 549
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.200124
New value of Value function: 0.404291
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 550
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.400248
New value of Value function: 0.404291
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 551
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.403281
New value of Value function: 0.403281
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 552
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.200124
New value of Value function: 0.403281
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 553
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 0.5981
New value of Value function: 0.5981
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 554
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.40788
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 555
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.531645
New value of Value function: 0.531645
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 556
----------
State: 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.857664
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 557
----------
State: 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -1.27952
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2002
New value of Q matrix: 0.459513
New value of Value function: 0.459513
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2003
New value of Q matrix: 0.459511
New value of Value function: 0.459511
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0.405066
New value of Value function: 0.459511
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2004
New value of Q matrix: 0.459508
New value of Value function: 0.459508
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2005
New value of Q matrix: 0.459506
New value of Value function: 0.459506
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2006
New value of Q matrix: 0.459504
New value of Value function: 0.459504
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0.403235
New value of Value function: 0.459504
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0.403538
New value of Value function: 0.459504
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2007
New value of Q matrix: 0.459502
New value of Value function: 0.459502
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2008
New value of Q matrix: 0.459499
New value of Value function: 0.459499
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2009
New value of Q matrix: 0.459497
New value of Value function: 0.459497
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2010
New value of Q matrix: 0.459495
New value of Value function: 0.459495
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.391045
New value of Value function: 0.459495
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2011
New value of Q matrix: 0.459492
New value of Value function: 0.459492
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2012
New value of Q matrix: 0.45949
New value of Value function: 0.45949
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0.391422
New value of Value function: 0.45949
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0.40535
New value of Value function: 0.45949
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2013
New value of Q matrix: 0.459488
New value of Value function: 0.459488
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0.403836
New value of Value function: 0.459488
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2014
New value of Q matrix: 0.459486
New value of Value function: 0.459486
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0.404131
New value of Value function: 0.459486
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2015
New value of Q matrix: 0.459483
New value of Value function: 0.459483
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2016
New value of Q matrix: 0.459481
New value of Value function: 0.459481
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0.404423
New value of Value function: 0.459481
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2017
New value of Q matrix: 0.459479
New value of Value function: 0.459479
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2018
New value of Q matrix: 0.459476
New value of Value function: 0.459476
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0.391796
New value of Value function: 0.459476
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2019
New value of Q matrix: 0.459474
New value of Value function: 0.459474
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2020
New value of Q matrix: 0.459472
New value of Value function: 0.459472
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2021
New value of Q matrix: 0.45947
New value of Value function: 0.45947
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2022
New value of Q matrix: 0.459467
New value of Value function: 0.459467
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2023
New value of Q matrix: 0.459465
New value of Value function: 0.459465
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2024
New value of Q matrix: 0.459463
New value of Value function: 0.459463
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2025
New value of Q matrix: 0.459461
New value of Value function: 0.459461
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2026
New value of Q matrix: 0.459458
New value of Value function: 0.459458
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2027
New value of Q matrix: 0.459456
New value of Value function: 0.459456
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2028
New value of Q matrix: 0.459454
New value of Value function: 0.459454
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0.404711
New value of Value function: 0.459454
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2029
New value of Q matrix: 0.459451
New value of Value function: 0.459451
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0.405629
New value of Value function: 0.459451
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2030
New value of Q matrix: 0.459449
New value of Value function: 0.459449
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2031
New value of Q matrix: 0.459447
New value of Value function: 0.459447
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2032
New value of Q matrix: 0.459445
New value of Value function: 0.459445
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2033
New value of Q matrix: 0.459442
New value of Value function: 0.459442
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2034
New value of Q matrix: 0.45944
New value of Value function: 0.45944
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2035
New value of Q matrix: 0.459438
New value of Value function: 0.459438
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2036
New value of Q matrix: 0.459436
New value of Value function: 0.459436
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2037
New value of Q matrix: 0.459433
New value of Value function: 0.459433
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 606
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2038
New value of Q matrix: 0.459431
New value of Value function: 0.459431
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2039
New value of Q matrix: 0.459429
New value of Value function: 0.459429
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2040
New value of Q matrix: 0.459427
New value of Value function: 0.459427
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2041
New value of Q matrix: 0.459424
New value of Value function: 0.459424
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2042
New value of Q matrix: 0.459422
New value of Value function: 0.459422
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2043
New value of Q matrix: 0.45942
New value of Value function: 0.45942
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2044
New value of Q matrix: 0.459418
New value of Value function: 0.459418
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0.392164
New value of Value function: 0.459418
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2045
New value of Q matrix: 0.459415
New value of Value function: 0.459415
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0.404996
New value of Value function: 0.459415
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2046
New value of Q matrix: 0.459413
New value of Value function: 0.459413
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0.405277
New value of Value function: 0.459413
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2047
New value of Q matrix: 0.459411
New value of Value function: 0.459411
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 619
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2048
New value of Q matrix: 0.459409
New value of Value function: 0.459409
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0.434285
New value of Value function: 0.459409
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2049
New value of Q matrix: 0.459406
New value of Value function: 0.459406
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0.4344
New value of Value function: 0.459406
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2050
New value of Q matrix: 0.459404
New value of Value function: 0.459404
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2051
New value of Q matrix: 0.459402
New value of Value function: 0.459402
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2052
New value of Q matrix: 0.4594
New value of Value function: 0.4594
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2053
New value of Q matrix: 0.459397
New value of Value function: 0.459397
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 627
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2054
New value of Q matrix: 0.459395
New value of Value function: 0.459395
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2055
New value of Q matrix: 0.459393
New value of Value function: 0.459393
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0.434514
New value of Value function: 0.459393
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0.405906
New value of Value function: 0.459393
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0.434627
New value of Value function: 0.459393
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2056
New value of Q matrix: 0.459391
New value of Value function: 0.459391
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2057
New value of Q matrix: 0.459389
New value of Value function: 0.459389
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0.434738
New value of Value function: 0.459389
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2058
New value of Q matrix: 0.459386
New value of Value function: 0.459386
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2059
New value of Q matrix: 0.459384
New value of Value function: 0.459384
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2060
New value of Q matrix: 0.459382
New value of Value function: 0.459382
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2061
New value of Q matrix: 0.45938
New value of Value function: 0.45938
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2062
New value of Q matrix: 0.459377
New value of Value function: 0.459377
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2063
New value of Q matrix: 0.459375
New value of Value function: 0.459375
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2064
New value of Q matrix: 0.459373
New value of Value function: 0.459373
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2065
New value of Q matrix: 0.459371
New value of Value function: 0.459371
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2066
New value of Q matrix: 0.459368
New value of Value function: 0.459368
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2067
New value of Q matrix: 0.459366
New value of Value function: 0.459366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0.392528
New value of Value function: 0.459366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2068
New value of Q matrix: 0.459364
New value of Value function: 0.459364
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2069
New value of Q matrix: 0.459362
New value of Value function: 0.459362
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2070
New value of Q matrix: 0.45936
New value of Value function: 0.45936
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2071
New value of Q matrix: 0.459357
New value of Value function: 0.459357
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2072
New value of Q matrix: 0.459355
New value of Value function: 0.459355
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2073
New value of Q matrix: 0.459353
New value of Value function: 0.459353
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2074
New value of Q matrix: 0.459351
New value of Value function: 0.459351
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2075
New value of Q matrix: 0.459348
New value of Value function: 0.459348
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2076
New value of Q matrix: 0.459346
New value of Value function: 0.459346
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2077
New value of Q matrix: 0.459344
New value of Value function: 0.459344
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2078
New value of Q matrix: 0.459342
New value of Value function: 0.459342
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2079
New value of Q matrix: 0.45934
New value of Value function: 0.45934
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2080
New value of Q matrix: 0.459337
New value of Value function: 0.459337
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0.405555
New value of Value function: 0.459337
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2081
New value of Q matrix: 0.459335
New value of Value function: 0.459335
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2082
New value of Q matrix: 0.459333
New value of Value function: 0.459333
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2083
New value of Q matrix: 0.459331
New value of Value function: 0.459331
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2084
New value of Q matrix: 0.459329
New value of Value function: 0.459329
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0.406178
New value of Value function: 0.459329
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2085
New value of Q matrix: 0.459326
New value of Value function: 0.459326
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2086
New value of Q matrix: 0.459324
New value of Value function: 0.459324
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2087
New value of Q matrix: 0.459322
New value of Value function: 0.459322
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2088
New value of Q matrix: 0.45932
New value of Value function: 0.45932
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2089
New value of Q matrix: 0.459318
New value of Value function: 0.459318
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2090
New value of Q matrix: 0.459315
New value of Value function: 0.459315
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2091
New value of Q matrix: 0.459313
New value of Value function: 0.459313
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2092
New value of Q matrix: 0.460528
New value of Value function: 0.460528
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 673
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 674
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 675
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 676
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 677
----------
State: 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 678
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 679
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 680
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0125
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 681
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 682
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 683
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 684
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 685
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 686
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.833333
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 687
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 688
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 689
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 690
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 691
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 692
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 693
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 694
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 695
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 696
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 697
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 698
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 699
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 700
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 701
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 702
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 703
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 704
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0470505
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 705
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0411692
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 706
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0365948
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 707
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.675
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 708
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0329353
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 709
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0299412
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 710
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 711
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 712
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 713
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 714
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 715
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 716
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.68333
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 717
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.2625
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 718
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 719
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 720
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 721
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.42189
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 722
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 723
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 724
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 725
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 726
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 727
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 728
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 729
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 730
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 731
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 732
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 733
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.408375
New value of Value function: 0.408375
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 734
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.11875
New value of Value function: 3.11875
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 735
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 736
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.59571
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 737
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.07817
New value of Value function: 1.07817
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 738
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.17507
New value of Value function: 3.11875
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 739
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 1.52279
New value of Value function: 3.11875
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 740
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 741
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 742
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.956219
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 743
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 1.81256
New value of Value function: 3.11875
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 744
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.91244
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 745
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 2.05775
New value of Value function: 3.11875
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 746
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 747
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.20394
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 748
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 749
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 750
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.956219
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 751
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 2.26791
New value of Value function: 3.11875
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 752
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 753
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 754
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.27496
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 755
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 2.45005
New value of Value function: 3.11875
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 756
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 757
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 758
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 759
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 760
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 761
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.46929
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 762
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 763
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 764
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.10197
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 765
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.881576
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 766
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.956219
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 767
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 768
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 769
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 770
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 771
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 0.5
New value of Value function: 0.5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 772
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.505
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 773
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0825
New value of Value function: 0.5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 774
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.764975
New value of Value function: 0.5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 775
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.495
New value of Value function: 0.495
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 776
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 777
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.9275
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 778
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.6625
New value of Value function: 1.6625
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 779
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.821184
New value of Value function: 0.821184
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2093
New value of Q matrix: 0.460525
New value of Value function: 0.460525
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2094
New value of Q matrix: 0.460523
New value of Value function: 0.460523
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2095
New value of Q matrix: 0.460521
New value of Value function: 0.460521
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0.392895
New value of Value function: 0.460521
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 784
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2096
New value of Q matrix: 0.460519
New value of Value function: 0.460519
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2097
New value of Q matrix: 0.460517
New value of Value function: 0.460517
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2098
New value of Q matrix: 0.460515
New value of Value function: 0.460515
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2099
New value of Q matrix: 0.460512
New value of Value function: 0.460512
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2100
New value of Q matrix: 0.46051
New value of Value function: 0.46051
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2101
New value of Q matrix: 0.460508
New value of Value function: 0.460508
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0.405837
New value of Value function: 0.460508
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2102
New value of Q matrix: 0.460506
New value of Value function: 0.460506
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0.393257
New value of Value function: 0.460506
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2103
New value of Q matrix: 0.460504
New value of Value function: 0.460504
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 794
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2104
New value of Q matrix: 0.460501
New value of Value function: 0.460501
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2105
New value of Q matrix: 0.460499
New value of Value function: 0.460499
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2106
New value of Q matrix: 0.460497
New value of Value function: 0.460497
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2107
New value of Q matrix: 0.460495
New value of Value function: 0.460495
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2108
New value of Q matrix: 0.460493
New value of Value function: 0.460493
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2109
New value of Q matrix: 0.46049
New value of Value function: 0.46049
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0.393615
New value of Value function: 0.46049
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2110
New value of Q matrix: 0.460488
New value of Value function: 0.460488
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2111
New value of Q matrix: 0.460486
New value of Value function: 0.460486
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0.406115
New value of Value function: 0.460486
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2112
New value of Q matrix: 0.460484
New value of Value function: 0.460484
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0.40639
New value of Value function: 0.460484
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2113
New value of Q matrix: 0.460482
New value of Value function: 0.460482
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2114
New value of Q matrix: 0.46048
New value of Value function: 0.46048
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2115
New value of Q matrix: 0.460477
New value of Value function: 0.460477
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2116
New value of Q matrix: 0.460475
New value of Value function: 0.460475
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2117
New value of Q matrix: 0.460473
New value of Value function: 0.460473
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2118
New value of Q matrix: 0.460471
New value of Value function: 0.460471
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2119
New value of Q matrix: 0.460469
New value of Value function: 0.460469
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0.406454
New value of Value function: 0.460469
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0.406727
New value of Value function: 0.460469
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2120
New value of Q matrix: 0.460466
New value of Value function: 0.460466
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2121
New value of Q matrix: 0.460464
New value of Value function: 0.460464
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2122
New value of Q matrix: 0.460462
New value of Value function: 0.460462
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2123
New value of Q matrix: 0.46046
New value of Value function: 0.46046
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2124
New value of Q matrix: 0.460458
New value of Value function: 0.460458
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0.393968
New value of Value function: 0.460458
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2125
New value of Q matrix: 0.460456
New value of Value function: 0.460456
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2126
New value of Q matrix: 0.460453
New value of Value function: 0.460453
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0.394318
New value of Value function: 0.460453
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0.394664
New value of Value function: 0.460453
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0.434854
New value of Value function: 0.460453
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0.434969
New value of Value function: 0.460453
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2127
New value of Q matrix: 0.460451
New value of Value function: 0.460451
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2128
New value of Q matrix: 0.460449
New value of Value function: 0.460449
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0.435083
New value of Value function: 0.460449
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2129
New value of Q matrix: 0.460447
New value of Value function: 0.460447
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0.406997
New value of Value function: 0.460447
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2130
New value of Q matrix: 0.460445
New value of Value function: 0.460445
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2131
New value of Q matrix: 0.460443
New value of Value function: 0.460443
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0.395005
New value of Value function: 0.460443
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2132
New value of Q matrix: 0.46044
New value of Value function: 0.46044
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2133
New value of Q matrix: 0.460438
New value of Value function: 0.460438
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2134
New value of Q matrix: 0.460436
New value of Value function: 0.460436
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2135
New value of Q matrix: 0.460434
New value of Value function: 0.460434
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2136
New value of Q matrix: 0.460432
New value of Value function: 0.460432
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0.406661
New value of Value function: 0.460432
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0.395343
New value of Value function: 0.460432
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0.407264
New value of Value function: 0.460432
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2137
New value of Q matrix: 0.46043
New value of Value function: 0.46043
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2138
New value of Q matrix: 0.460428
New value of Value function: 0.460428
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0.395677
New value of Value function: 0.460428
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2139
New value of Q matrix: 0.460425
New value of Value function: 0.460425
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0.396008
New value of Value function: 0.460425
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0.396335
New value of Value function: 0.460425
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2140
New value of Q matrix: 0.460423
New value of Value function: 0.460423
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2141
New value of Q matrix: 0.460421
New value of Value function: 0.460421
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0.435195
New value of Value function: 0.460421
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2142
New value of Q matrix: 0.460419
New value of Value function: 0.460419
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2143
New value of Q matrix: 0.460417
New value of Value function: 0.460417
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2144
New value of Q matrix: 0.460415
New value of Value function: 0.460415
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2145
New value of Q matrix: 0.460413
New value of Value function: 0.460413
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2146
New value of Q matrix: 0.46041
New value of Value function: 0.46041
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2147
New value of Q matrix: 0.460408
New value of Value function: 0.460408
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0.435305
New value of Value function: 0.460408
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2148
New value of Q matrix: 0.460406
New value of Value function: 0.460406
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2149
New value of Q matrix: 0.460404
New value of Value function: 0.460404
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2150
New value of Q matrix: 0.460402
New value of Value function: 0.460402
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2151
New value of Q matrix: 0.4604
New value of Value function: 0.4604
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0.396658
New value of Value function: 0.4604
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2152
New value of Q matrix: 0.460398
New value of Value function: 0.460398
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2153
New value of Q matrix: 0.460395
New value of Value function: 0.460395
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2154
New value of Q matrix: 0.460393
New value of Value function: 0.460393
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2155
New value of Q matrix: 0.460391
New value of Value function: 0.460391
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2156
New value of Q matrix: 0.460389
New value of Value function: 0.460389
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2157
New value of Q matrix: 0.460387
New value of Value function: 0.460387
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2158
New value of Q matrix: 0.460385
New value of Value function: 0.460385
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2159
New value of Q matrix: 0.460383
New value of Value function: 0.460383
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2160
New value of Q matrix: 0.46038
New value of Value function: 0.46038
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2161
New value of Q matrix: 0.460378
New value of Value function: 0.460378
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2162
New value of Q matrix: 0.460376
New value of Value function: 0.460376
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2163
New value of Q matrix: 0.460374
New value of Value function: 0.460374
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2164
New value of Q matrix: 0.460372
New value of Value function: 0.460372
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2165
New value of Q matrix: 0.46037
New value of Value function: 0.46037
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2166
New value of Q matrix: 0.460368
New value of Value function: 0.460368
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2167
New value of Q matrix: 0.460366
New value of Value function: 0.460366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0.40693
New value of Value function: 0.460366
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2168
New value of Q matrix: 0.460363
New value of Value function: 0.460363
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2169
New value of Q matrix: 0.460361
New value of Value function: 0.460361
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0.407528
New value of Value function: 0.460361
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2170
New value of Q matrix: 0.460359
New value of Value function: 0.460359
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2171
New value of Q matrix: 0.460357
New value of Value function: 0.460357
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2172
New value of Q matrix: 0.460355
New value of Value function: 0.460355
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2173
New value of Q matrix: 0.460353
New value of Value function: 0.460353
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2174
New value of Q matrix: 0.460351
New value of Value function: 0.460351
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2175
New value of Q matrix: 0.460349
New value of Value function: 0.460349
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2176
New value of Q matrix: 0.460346
New value of Value function: 0.460346
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2177
New value of Q matrix: 0.460344
New value of Value function: 0.460344
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2178
New value of Q matrix: 0.460342
New value of Value function: 0.460342
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2179
New value of Q matrix: 0.46034
New value of Value function: 0.46034
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 894
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0.396977
New value of Value function: 0.46034
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2180
New value of Q matrix: 0.460338
New value of Value function: 0.460338
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2181
New value of Q matrix: 0.460336
New value of Value function: 0.460336
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 897
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2182
New value of Q matrix: 0.460334
New value of Value function: 0.460334
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2183
New value of Q matrix: 0.461497
New value of Value function: 0.461497
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 899
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 900
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 901
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 902
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 903
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 904
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 905
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 906
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 907
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 908
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0274461
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 909
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.0253349
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 910
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 911
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.11667
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 912
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 913
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 914
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.8375
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 915
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 916
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 917
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 918
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 919
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 920
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 921
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 922
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.714286
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 923
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.625
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 924
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 925
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 926
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 927
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 928
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 929
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 930
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 931
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 932
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 933
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 934
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 935
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 936
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 937
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 938
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 939
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0331667
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 940
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0284286
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 941
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 942
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 943
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 944
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.11667
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 945
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.0235252
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 946
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.8375
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 947
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.0219569
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 948
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 949
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 950
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 951
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 952
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 953
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 954
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 955
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 956
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 957
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 958
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 959
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.266848
New value of Value function: 0.266848
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 960
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.533695
New value of Value function: 1.07817
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 961
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 1.25
New value of Value function: 1.25
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 962
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -4.1791
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 963
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.11004
New value of Value function: 1.25
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 964
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.43962
New value of Value function: 1.43962
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 965
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 2.64005
New value of Value function: 3.11875
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 966
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.653986
New value of Value function: 0.653986
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 967
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.68432
New value of Value function: 0.68432
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 968
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 969
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.734647
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 970
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.532915
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 971
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.58656
New value of Value function: 0.58656
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 972
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 973
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.27156
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2184
New value of Q matrix: 0.461495
New value of Value function: 0.461495
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2185
New value of Q matrix: 0.461493
New value of Value function: 0.461493
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2186
New value of Q matrix: 0.461491
New value of Value function: 0.461491
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2187
New value of Q matrix: 0.461489
New value of Value function: 0.461489
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 978
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2188
New value of Q matrix: 0.461487
New value of Value function: 0.461487
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2189
New value of Q matrix: 0.461485
New value of Value function: 0.461485
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2190
New value of Q matrix: 0.461482
New value of Value function: 0.461482
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2191
New value of Q matrix: 0.46148
New value of Value function: 0.46148
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2192
New value of Q matrix: 0.461478
New value of Value function: 0.461478
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0.435421
New value of Value function: 0.461478
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2193
New value of Q matrix: 0.461476
New value of Value function: 0.461476
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2194
New value of Q matrix: 0.461474
New value of Value function: 0.461474
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 986
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2195
New value of Q matrix: 0.461472
New value of Value function: 0.461472
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 987
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0.435535
New value of Value function: 0.461472
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0.397299
New value of Value function: 0.461472
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0.407201
New value of Value function: 0.461472
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2196
New value of Q matrix: 0.46147
New value of Value function: 0.46147
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2197
New value of Q matrix: 0.461468
New value of Value function: 0.461468
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2198
New value of Q matrix: 0.461466
New value of Value function: 0.461466
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2199
New value of Q matrix: 0.461463
New value of Value function: 0.461463
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2200
New value of Q matrix: 0.461461
New value of Value function: 0.461461
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0.397618
New value of Value function: 0.461461
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0.397933
New value of Value function: 0.461461
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2201
New value of Q matrix: 0.461459
New value of Value function: 0.461459
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2202
New value of Q matrix: 0.461457
New value of Value function: 0.461457
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2203
New value of Q matrix: 0.461455
New value of Value function: 0.461455
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2204
New value of Q matrix: 0.461453
New value of Value function: 0.461453
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2205
New value of Q matrix: 0.461451
New value of Value function: 0.461451
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0.435647
New value of Value function: 0.461451
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2206
New value of Q matrix: 0.461449
New value of Value function: 0.461449
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2207
New value of Q matrix: 0.461447
New value of Value function: 0.461447
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2208
New value of Q matrix: 0.461445
New value of Value function: 0.461445
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0.407794
New value of Value function: 0.461445
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0.398244
New value of Value function: 0.461445
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0.435759
New value of Value function: 0.461445
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2209
New value of Q matrix: 0.461443
New value of Value function: 0.461443
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2210
New value of Q matrix: 0.46144
New value of Value function: 0.46144
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2211
New value of Q matrix: 0.461438
New value of Value function: 0.461438
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2212
New value of Q matrix: 0.461436
New value of Value function: 0.461436
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2213
New value of Q matrix: 0.461434
New value of Value function: 0.461434
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0.407469
New value of Value function: 0.461434
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2214
New value of Q matrix: 0.461432
New value of Value function: 0.461432
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2215
New value of Q matrix: 0.46143
New value of Value function: 0.46143
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2216
New value of Q matrix: 0.461428
New value of Value function: 0.461428
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2217
New value of Q matrix: 0.461426
New value of Value function: 0.461426
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2218
New value of Q matrix: 0.461424
New value of Value function: 0.461424
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2219
New value of Q matrix: 0.461422
New value of Value function: 0.461422
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2220
New value of Q matrix: 0.46142
New value of Value function: 0.46142
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2221
New value of Q matrix: 0.461418
New value of Value function: 0.461418
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0.407734
New value of Value function: 0.461418
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2222
New value of Q matrix: 0.461415
New value of Value function: 0.461415
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2223
New value of Q matrix: 0.461413
New value of Value function: 0.461413
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2224
New value of Q matrix: 0.461411
New value of Value function: 0.461411
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2225
New value of Q matrix: 0.461409
New value of Value function: 0.461409
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0.435869
New value of Value function: 0.461409
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2226
New value of Q matrix: 0.461407
New value of Value function: 0.461407
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2227
New value of Q matrix: 0.461405
New value of Value function: 0.461405
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2228
New value of Q matrix: 0.461403
New value of Value function: 0.461403
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0.398552
New value of Value function: 0.461403
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2229
New value of Q matrix: 0.461401
New value of Value function: 0.461401
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2230
New value of Q matrix: 0.461399
New value of Value function: 0.461399
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2231
New value of Q matrix: 0.461397
New value of Value function: 0.461397
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2232
New value of Q matrix: 0.461395
New value of Value function: 0.461395
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2233
New value of Q matrix: 0.461393
New value of Value function: 0.461393
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0.408057
New value of Value function: 0.461393
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2234
New value of Q matrix: 0.461391
New value of Value function: 0.461391
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2235
New value of Q matrix: 0.461389
New value of Value function: 0.461389
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2236
New value of Q matrix: 0.461387
New value of Value function: 0.461387
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0.435978
New value of Value function: 0.461387
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2237
New value of Q matrix: 0.461384
New value of Value function: 0.461384
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2238
New value of Q matrix: 0.461382
New value of Value function: 0.461382
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0.398857
New value of Value function: 0.461382
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2239
New value of Q matrix: 0.46138
New value of Value function: 0.46138
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2240
New value of Q matrix: 0.461378
New value of Value function: 0.461378
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2241
New value of Q matrix: 0.461376
New value of Value function: 0.461376
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2242
New value of Q matrix: 0.461374
New value of Value function: 0.461374
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2243
New value of Q matrix: 0.461372
New value of Value function: 0.461372
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0.436086
New value of Value function: 0.461372
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2244
New value of Q matrix: 0.46137
New value of Value function: 0.46137
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0.399159
New value of Value function: 0.46137
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0.399457
New value of Value function: 0.46137
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2245
New value of Q matrix: 0.461368
New value of Value function: 0.461368
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2246
New value of Q matrix: 0.461366
New value of Value function: 0.461366
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2247
New value of Q matrix: 0.461364
New value of Value function: 0.461364
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0.408318
New value of Value function: 0.461364
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2248
New value of Q matrix: 0.461362
New value of Value function: 0.461362
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2249
New value of Q matrix: 0.46136
New value of Value function: 0.46136
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0.399752
New value of Value function: 0.46136
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2250
New value of Q matrix: 0.461358
New value of Value function: 0.461358
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0.400045
New value of Value function: 0.461358
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0.407996
New value of Value function: 0.461358
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2251
New value of Q matrix: 0.461356
New value of Value function: 0.461356
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2252
New value of Q matrix: 0.461354
New value of Value function: 0.461354
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2253
New value of Q matrix: 0.461352
New value of Value function: 0.461352
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2254
New value of Q matrix: 0.46135
New value of Value function: 0.46135
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2255
New value of Q matrix: 0.461347
New value of Value function: 0.461347
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2256
New value of Q matrix: 0.461345
New value of Value function: 0.461345
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2257
New value of Q matrix: 0.461343
New value of Value function: 0.461343
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2258
New value of Q matrix: 0.461341
New value of Value function: 0.461341
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2259
New value of Q matrix: 0.461339
New value of Value function: 0.461339
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2260
New value of Q matrix: 0.461337
New value of Value function: 0.461337
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2261
New value of Q matrix: 0.461335
New value of Value function: 0.461335
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2262
New value of Q matrix: 0.461333
New value of Value function: 0.461333
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0.408575
New value of Value function: 0.461333
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2263
New value of Q matrix: 0.461331
New value of Value function: 0.461331
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2264
New value of Q matrix: 0.461329
New value of Value function: 0.461329
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2265
New value of Q matrix: 0.461327
New value of Value function: 0.461327
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2266
New value of Q matrix: 0.461325
New value of Value function: 0.461325
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0.400334
New value of Value function: 0.461325
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2267
New value of Q matrix: 0.461323
New value of Value function: 0.461323
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2268
New value of Q matrix: 0.461321
New value of Value function: 0.461321
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2269
New value of Q matrix: 0.461319
New value of Value function: 0.461319
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2270
New value of Q matrix: 0.461317
New value of Value function: 0.461317
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0.408255
New value of Value function: 0.461317
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2271
New value of Q matrix: 0.461315
New value of Value function: 0.461315
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2272
New value of Q matrix: 0.461313
New value of Value function: 0.461313
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2273
New value of Q matrix: 0.461311
New value of Value function: 0.461311
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2274
New value of Q matrix: 0.461309
New value of Value function: 0.461309
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2275
New value of Q matrix: 0.461307
New value of Value function: 0.461307
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2276
New value of Q matrix: 0.461305
New value of Value function: 0.461305
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0.40883
New value of Value function: 0.461305
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2277
New value of Q matrix: 0.461303
New value of Value function: 0.461303
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2278
New value of Q matrix: 0.461301
New value of Value function: 0.461301
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2279
New value of Q matrix: 0.461299
New value of Value function: 0.461299
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0.408512
New value of Value function: 0.461299
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0.436192
New value of Value function: 0.461299
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0.40062
New value of Value function: 0.461299
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2280
New value of Q matrix: 0.461297
New value of Value function: 0.461297
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2281
New value of Q matrix: 0.461295
New value of Value function: 0.461295
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2282
New value of Q matrix: 0.461293
New value of Value function: 0.461293
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2283
New value of Q matrix: 0.461291
New value of Value function: 0.461291
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2284
New value of Q matrix: 0.461289
New value of Value function: 0.461289
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2285
New value of Q matrix: 0.461287
New value of Value function: 0.461287
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2286
New value of Q matrix: 0.461285
New value of Value function: 0.461285
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2287
New value of Q matrix: 0.461282
New value of Value function: 0.461282
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2288
New value of Q matrix: 0.46128
New value of Value function: 0.46128
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2289
New value of Q matrix: 0.461278
New value of Value function: 0.461278
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2290
New value of Q matrix: 0.461276
New value of Value function: 0.461276
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0.409082
New value of Value function: 0.461276
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2291
New value of Q matrix: 0.461274
New value of Value function: 0.461274
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2292
New value of Q matrix: 0.461272
New value of Value function: 0.461272
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0.400903
New value of Value function: 0.461272
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2293
New value of Q matrix: 0.46127
New value of Value function: 0.46127
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2294
New value of Q matrix: 0.461268
New value of Value function: 0.461268
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2295
New value of Q matrix: 0.462375
New value of Value function: 0.462375
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 119
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 120
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 121
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 122
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 123
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 124
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 125
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -2.34333
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 126
----------
State: 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 3.33333
New value of Value function: 3.33333
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 127
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.11667
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 128
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.420833
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 129
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.4
New value of Value function: 0.4
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 130
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.258333
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 131
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.8125
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 132
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 133
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 134
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5.99
New value of Value function: 5.99
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 135
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.998333
New value of Value function: 0.998333
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 136
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 0.141429
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 137
----------
State: 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.9301
New value of Value function: 5.9301
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 138
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.9125
New value of Value function: 5.99
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 139
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.825
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 140
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.226875
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 141
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.832143
New value of Value function: 0.832143
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 142
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.831103
New value of Value function: 0.831103
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 143
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.751667
New value of Value function: 0.831103
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 144
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.88553
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 145
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.411396
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 146
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.1715
New value of Value function: 1.1715
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 147
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 148
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.45
New value of Value function: 7.45
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 149
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 150
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 151
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 152
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 153
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 154
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 155
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 156
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -2.51408
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2296
New value of Q matrix: 0.462373
New value of Value function: 0.462373
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2297
New value of Q matrix: 0.462371
New value of Value function: 0.462371
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2298
New value of Q matrix: 0.462369
New value of Value function: 0.462369
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2299
New value of Q matrix: 0.462367
New value of Value function: 0.462367
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2300
New value of Q matrix: 0.462365
New value of Value function: 0.462365
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2301
New value of Q matrix: 0.462363
New value of Value function: 0.462363
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2302
New value of Q matrix: 0.462361
New value of Value function: 0.462361
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2303
New value of Q matrix: 0.462359
New value of Value function: 0.462359
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2304
New value of Q matrix: 0.462357
New value of Value function: 0.462357
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2305
New value of Q matrix: 0.462355
New value of Value function: 0.462355
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2306
New value of Q matrix: 0.462352
New value of Value function: 0.462352
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2307
New value of Q matrix: 0.46235
New value of Value function: 0.46235
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2308
New value of Q matrix: 0.462348
New value of Value function: 0.462348
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2309
New value of Q matrix: 0.462346
New value of Value function: 0.462346
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2310
New value of Q matrix: 0.462344
New value of Value function: 0.462344
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0.436302
New value of Value function: 0.462344
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2311
New value of Q matrix: 0.462342
New value of Value function: 0.462342
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2312
New value of Q matrix: 0.46234
New value of Value function: 0.46234
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2313
New value of Q matrix: 0.462338
New value of Value function: 0.462338
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0.401188
New value of Value function: 0.462338
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0.408771
New value of Value function: 0.462338
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2314
New value of Q matrix: 0.462336
New value of Value function: 0.462336
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2315
New value of Q matrix: 0.462334
New value of Value function: 0.462334
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2316
New value of Q matrix: 0.462332
New value of Value function: 0.462332
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0.409027
New value of Value function: 0.462332
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2317
New value of Q matrix: 0.46233
New value of Value function: 0.46233
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2318
New value of Q matrix: 0.462329
New value of Value function: 0.462329
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2319
New value of Q matrix: 0.462327
New value of Value function: 0.462327
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2320
New value of Q matrix: 0.462325
New value of Value function: 0.462325
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0.409336
New value of Value function: 0.462325
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0.409588
New value of Value function: 0.462325
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2321
New value of Q matrix: 0.462323
New value of Value function: 0.462323
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2322
New value of Q matrix: 0.462321
New value of Value function: 0.462321
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2323
New value of Q matrix: 0.462319
New value of Value function: 0.462319
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0.436411
New value of Value function: 0.462319
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0.401471
New value of Value function: 0.462319
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2324
New value of Q matrix: 0.462317
New value of Value function: 0.462317
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2325
New value of Q matrix: 0.462315
New value of Value function: 0.462315
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2326
New value of Q matrix: 0.462313
New value of Value function: 0.462313
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0.401751
New value of Value function: 0.462313
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2327
New value of Q matrix: 0.462311
New value of Value function: 0.462311
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0.402028
New value of Value function: 0.462311
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2328
New value of Q matrix: 0.462309
New value of Value function: 0.462309
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2329
New value of Q matrix: 0.462307
New value of Value function: 0.462307
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2330
New value of Q matrix: 0.462305
New value of Value function: 0.462305
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2331
New value of Q matrix: 0.462303
New value of Value function: 0.462303
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2332
New value of Q matrix: 0.462301
New value of Value function: 0.462301
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2333
New value of Q matrix: 0.462299
New value of Value function: 0.462299
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2334
New value of Q matrix: 0.462297
New value of Value function: 0.462297
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2335
New value of Q matrix: 0.462295
New value of Value function: 0.462295
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2336
New value of Q matrix: 0.462293
New value of Value function: 0.462293
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2337
New value of Q matrix: 0.462291
New value of Value function: 0.462291
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2338
New value of Q matrix: 0.462289
New value of Value function: 0.462289
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2339
New value of Q matrix: 0.462287
New value of Value function: 0.462287
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2340
New value of Q matrix: 0.462285
New value of Value function: 0.462285
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0.40928
New value of Value function: 0.462285
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2341
New value of Q matrix: 0.462283
New value of Value function: 0.462283
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2342
New value of Q matrix: 0.462281
New value of Value function: 0.462281
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2343
New value of Q matrix: 0.462279
New value of Value function: 0.462279
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2344
New value of Q matrix: 0.462277
New value of Value function: 0.462277
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2345
New value of Q matrix: 0.462275
New value of Value function: 0.462275
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2346
New value of Q matrix: 0.462273
New value of Value function: 0.462273
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2347
New value of Q matrix: 0.462271
New value of Value function: 0.462271
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0.409837
New value of Value function: 0.462271
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0.402302
New value of Value function: 0.462271
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2348
New value of Q matrix: 0.462269
New value of Value function: 0.462269
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0.436519
New value of Value function: 0.462269
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2349
New value of Q matrix: 0.462267
New value of Value function: 0.462267
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2350
New value of Q matrix: 0.462265
New value of Value function: 0.462265
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2351
New value of Q matrix: 0.462263
New value of Value function: 0.462263
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2352
New value of Q matrix: 0.462261
New value of Value function: 0.462261
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2353
New value of Q matrix: 0.462259
New value of Value function: 0.462259
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2354
New value of Q matrix: 0.462257
New value of Value function: 0.462257
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2355
New value of Q matrix: 0.462255
New value of Value function: 0.462255
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2356
New value of Q matrix: 0.462253
New value of Value function: 0.462253
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0.402573
New value of Value function: 0.462253
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2357
New value of Q matrix: 0.462251
New value of Value function: 0.462251
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2358
New value of Q matrix: 0.462249
New value of Value function: 0.462249
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0.402841
New value of Value function: 0.462249
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0.409531
New value of Value function: 0.462249
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2359
New value of Q matrix: 0.462247
New value of Value function: 0.462247
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0.409779
New value of Value function: 0.462247
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0.410083
New value of Value function: 0.462247
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0.436626
New value of Value function: 0.462247
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2360
New value of Q matrix: 0.462246
New value of Value function: 0.462246
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2361
New value of Q matrix: 0.462244
New value of Value function: 0.462244
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0.410327
New value of Value function: 0.462244
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0.410024
New value of Value function: 0.462244
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2362
New value of Q matrix: 0.462242
New value of Value function: 0.462242
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2363
New value of Q matrix: 0.46224
New value of Value function: 0.46224
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2364
New value of Q matrix: 0.462238
New value of Value function: 0.462238
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2365
New value of Q matrix: 0.462236
New value of Value function: 0.462236
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2366
New value of Q matrix: 0.462234
New value of Value function: 0.462234
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0.410568
New value of Value function: 0.462234
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0.410807
New value of Value function: 0.462234
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2367
New value of Q matrix: 0.462232
New value of Value function: 0.462232
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2368
New value of Q matrix: 0.46223
New value of Value function: 0.46223
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0.403107
New value of Value function: 0.46223
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2369
New value of Q matrix: 0.462228
New value of Value function: 0.462228
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2370
New value of Q matrix: 0.462226
New value of Value function: 0.462226
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2371
New value of Q matrix: 0.462224
New value of Value function: 0.462224
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2372
New value of Q matrix: 0.462222
New value of Value function: 0.462222
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0.411044
New value of Value function: 0.462222
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0.436731
New value of Value function: 0.462222
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2373
New value of Q matrix: 0.46222
New value of Value function: 0.46222
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2374
New value of Q matrix: 0.462218
New value of Value function: 0.462218
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2375
New value of Q matrix: 0.462216
New value of Value function: 0.462216
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2376
New value of Q matrix: 0.462214
New value of Value function: 0.462214
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2377
New value of Q matrix: 0.462212
New value of Value function: 0.462212
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2378
New value of Q matrix: 0.46221
New value of Value function: 0.46221
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2379
New value of Q matrix: 0.462208
New value of Value function: 0.462208
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2380
New value of Q matrix: 0.462207
New value of Value function: 0.462207
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2381
New value of Q matrix: 0.462205
New value of Value function: 0.462205
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2382
New value of Q matrix: 0.462203
New value of Value function: 0.462203
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2383
New value of Q matrix: 0.462201
New value of Value function: 0.462201
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0.410267
New value of Value function: 0.462201
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2384
New value of Q matrix: 0.462199
New value of Value function: 0.462199
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2385
New value of Q matrix: 0.462197
New value of Value function: 0.462197
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2386
New value of Q matrix: 0.462195
New value of Value function: 0.462195
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2387
New value of Q matrix: 0.463258
New value of Value function: 0.463258
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 277
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.43762
New value of Value function: 2.43762
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 278
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.9229
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 279
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 280
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 2.43575
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 281
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 282
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 283
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.198
New value of Value function: 0.198
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 284
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.3992
New value of Value function: 0.3992
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 285
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.131736
New value of Value function: 0.3992
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 286
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.15767
New value of Value function: 1.15767
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 287
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.881957
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 288
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.867623
New value of Value function: 1.1715
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 289
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.17044
New value of Value function: 1.17044
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 290
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.68752
New value of Value function: 1.68752
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 291
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.42517
New value of Value function: 7.42517
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 292
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.80637
New value of Value function: 6.80637
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 293
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.475
New value of Value function: 7.475
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 294
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.33333
New value of Value function: 3.33333
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 295
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.88556
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 296
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -2.01672
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2388
New value of Q matrix: 0.463256
New value of Value function: 0.463256
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2389
New value of Q matrix: 0.463254
New value of Value function: 0.463254
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2390
New value of Q matrix: 0.463252
New value of Value function: 0.463252
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2391
New value of Q matrix: 0.46325
New value of Value function: 0.46325
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2392
New value of Q matrix: 0.463248
New value of Value function: 0.463248
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2393
New value of Q matrix: 0.463246
New value of Value function: 0.463246
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2394
New value of Q matrix: 0.463244
New value of Value function: 0.463244
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2395
New value of Q matrix: 0.463243
New value of Value function: 0.463243
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2396
New value of Q matrix: 0.463241
New value of Value function: 0.463241
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2397
New value of Q matrix: 0.463239
New value of Value function: 0.463239
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2398
New value of Q matrix: 0.463237
New value of Value function: 0.463237
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2399
New value of Q matrix: 0.463235
New value of Value function: 0.463235
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2400
New value of Q matrix: 0.463233
New value of Value function: 0.463233
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2401
New value of Q matrix: 0.463231
New value of Value function: 0.463231
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2402
New value of Q matrix: 0.463229
New value of Value function: 0.463229
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2403
New value of Q matrix: 0.463227
New value of Value function: 0.463227
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2404
New value of Q matrix: 0.463225
New value of Value function: 0.463225
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2405
New value of Q matrix: 0.463223
New value of Value function: 0.463223
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0.411283
New value of Value function: 0.463223
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0.43684
New value of Value function: 0.463223
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2406
New value of Q matrix: 0.463221
New value of Value function: 0.463221
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2407
New value of Q matrix: 0.463219
New value of Value function: 0.463219
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2408
New value of Q matrix: 0.463217
New value of Value function: 0.463217
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2409
New value of Q matrix: 0.463216
New value of Value function: 0.463216
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2410
New value of Q matrix: 0.463214
New value of Value function: 0.463214
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2411
New value of Q matrix: 0.463212
New value of Value function: 0.463212
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0.436949
New value of Value function: 0.463212
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0.411519
New value of Value function: 0.463212
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0.410512
New value of Value function: 0.463212
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2412
New value of Q matrix: 0.46321
New value of Value function: 0.46321
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2413
New value of Q matrix: 0.463208
New value of Value function: 0.463208
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2414
New value of Q matrix: 0.463206
New value of Value function: 0.463206
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2415
New value of Q matrix: 0.463204
New value of Value function: 0.463204
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2416
New value of Q matrix: 0.463202
New value of Value function: 0.463202
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2417
New value of Q matrix: 0.4632
New value of Value function: 0.4632
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2418
New value of Q matrix: 0.463198
New value of Value function: 0.463198
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0.403375
New value of Value function: 0.463198
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0.410755
New value of Value function: 0.463198
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2419
New value of Q matrix: 0.463196
New value of Value function: 0.463196
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2420
New value of Q matrix: 0.463194
New value of Value function: 0.463194
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0.411753
New value of Value function: 0.463194
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2421
New value of Q matrix: 0.463193
New value of Value function: 0.463193
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2422
New value of Q matrix: 0.463191
New value of Value function: 0.463191
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2423
New value of Q matrix: 0.463189
New value of Value function: 0.463189
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2424
New value of Q matrix: 0.463187
New value of Value function: 0.463187
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2425
New value of Q matrix: 0.463185
New value of Value function: 0.463185
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2426
New value of Q matrix: 0.463183
New value of Value function: 0.463183
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2427
New value of Q matrix: 0.463181
New value of Value function: 0.463181
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2428
New value of Q matrix: 0.463179
New value of Value function: 0.463179
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2429
New value of Q matrix: 0.463177
New value of Value function: 0.463177
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2430
New value of Q matrix: 0.463175
New value of Value function: 0.463175
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2431
New value of Q matrix: 0.463173
New value of Value function: 0.463173
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2432
New value of Q matrix: 0.463172
New value of Value function: 0.463172
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2433
New value of Q matrix: 0.46317
New value of Value function: 0.46317
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2434
New value of Q matrix: 0.463168
New value of Value function: 0.463168
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2435
New value of Q matrix: 0.463166
New value of Value function: 0.463166
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0.411985
New value of Value function: 0.463166
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2436
New value of Q matrix: 0.463164
New value of Value function: 0.463164
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2437
New value of Q matrix: 0.463162
New value of Value function: 0.463162
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2438
New value of Q matrix: 0.46316
New value of Value function: 0.46316
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2439
New value of Q matrix: 0.463158
New value of Value function: 0.463158
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2440
New value of Q matrix: 0.463156
New value of Value function: 0.463156
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2441
New value of Q matrix: 0.463154
New value of Value function: 0.463154
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0.437055
New value of Value function: 0.463154
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2442
New value of Q matrix: 0.463153
New value of Value function: 0.463153
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2443
New value of Q matrix: 0.463151
New value of Value function: 0.463151
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0.410995
New value of Value function: 0.463151
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2444
New value of Q matrix: 0.463149
New value of Value function: 0.463149
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2445
New value of Q matrix: 0.463147
New value of Value function: 0.463147
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2446
New value of Q matrix: 0.463145
New value of Value function: 0.463145
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0.40364
New value of Value function: 0.463145
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2447
New value of Q matrix: 0.463143
New value of Value function: 0.463143
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2448
New value of Q matrix: 0.463141
New value of Value function: 0.463141
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2449
New value of Q matrix: 0.463139
New value of Value function: 0.463139
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2450
New value of Q matrix: 0.463137
New value of Value function: 0.463137
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2451
New value of Q matrix: 0.463136
New value of Value function: 0.463136
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2452
New value of Q matrix: 0.463134
New value of Value function: 0.463134
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0.412214
New value of Value function: 0.463134
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2453
New value of Q matrix: 0.463132
New value of Value function: 0.463132
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2454
New value of Q matrix: 0.46313
New value of Value function: 0.46313
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2455
New value of Q matrix: 0.463128
New value of Value function: 0.463128
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2456
New value of Q matrix: 0.463126
New value of Value function: 0.463126
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2457
New value of Q matrix: 0.463124
New value of Value function: 0.463124
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2458
New value of Q matrix: 0.463122
New value of Value function: 0.463122
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2459
New value of Q matrix: 0.46312
New value of Value function: 0.46312
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2460
New value of Q matrix: 0.463119
New value of Value function: 0.463119
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2461
New value of Q matrix: 0.463117
New value of Value function: 0.463117
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2462
New value of Q matrix: 0.463115
New value of Value function: 0.463115
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0.403903
New value of Value function: 0.463115
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2463
New value of Q matrix: 0.463113
New value of Value function: 0.463113
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2464
New value of Q matrix: 0.463111
New value of Value function: 0.463111
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0.412441
New value of Value function: 0.463111
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2465
New value of Q matrix: 0.463109
New value of Value function: 0.463109
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2466
New value of Q matrix: 0.463107
New value of Value function: 0.463107
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0.437161
New value of Value function: 0.463107
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2467
New value of Q matrix: 0.463105
New value of Value function: 0.463105
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0.437265
New value of Value function: 0.463105
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2468
New value of Q matrix: 0.463104
New value of Value function: 0.463104
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2469
New value of Q matrix: 0.463102
New value of Value function: 0.463102
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2470
New value of Q matrix: 0.4631
New value of Value function: 0.4631
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0.404162
New value of Value function: 0.4631
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0.411232
New value of Value function: 0.4631
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0.437369
New value of Value function: 0.4631
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0.437471
New value of Value function: 0.4631
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0.437573
New value of Value function: 0.4631
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0.437673
New value of Value function: 0.4631
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2471
New value of Q matrix: 0.463098
New value of Value function: 0.463098
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2472
New value of Q matrix: 0.463096
New value of Value function: 0.463096
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2473
New value of Q matrix: 0.463094
New value of Value function: 0.463094
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2474
New value of Q matrix: 0.463092
New value of Value function: 0.463092
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2475
New value of Q matrix: 0.46309
New value of Value function: 0.46309
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2476
New value of Q matrix: 0.463089
New value of Value function: 0.463089
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2477
New value of Q matrix: 0.463087
New value of Value function: 0.463087
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0.412665
New value of Value function: 0.463087
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2478
New value of Q matrix: 0.463085
New value of Value function: 0.463085
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2479
New value of Q matrix: 0.463083
New value of Value function: 0.463083
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2480
New value of Q matrix: 0.463081
New value of Value function: 0.463081
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2481
New value of Q matrix: 0.463079
New value of Value function: 0.463079
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2482
New value of Q matrix: 0.463077
New value of Value function: 0.463077
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2483
New value of Q matrix: 0.463075
New value of Value function: 0.463075
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0.411467
New value of Value function: 0.463075
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0.437773
New value of Value function: 0.463075
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2484
New value of Q matrix: 0.463074
New value of Value function: 0.463074
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2485
New value of Q matrix: 0.465066
New value of Value function: 0.465066
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 421
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.4295
New value of Value function: 2.4295
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 422
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.05344
New value of Value function: 3.05344
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 423
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.79139
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 424
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.84197
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 425
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.92525
New value of Value function: 9.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 426
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 2.17353
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 427
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.51403
New value of Value function: 9.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 428
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.15601
New value of Value function: 1.15601
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 429
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.63026
New value of Value function: 1.63026
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 430
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.55996
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 431
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.57578
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 432
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.68623
New value of Value function: 1.68623
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 433
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.24718
New value of Value function: 1.68623
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 434
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.66936
New value of Value function: 1.68623
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 435
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.68502
New value of Value function: 1.68502
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 436
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.02191
New value of Value function: 2.02191
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 437
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.79276
New value of Value function: 6.79276
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 438
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.04397
New value of Value function: 7.04397
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 439
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 440
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -1.6806
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 441
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 442
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 443
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -1.44052
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 444
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 445
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -1.26045
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 446
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: -1.40258
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2486
New value of Q matrix: 0.465064
New value of Value function: 0.465064
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0.412897
New value of Value function: 0.465064
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2487
New value of Q matrix: 0.465062
New value of Value function: 0.465062
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2488
New value of Q matrix: 0.46506
New value of Value function: 0.46506
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0.404429
New value of Value function: 0.46506
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0.413126
New value of Value function: 0.46506
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0.413354
New value of Value function: 0.46506
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2489
New value of Q matrix: 0.465058
New value of Value function: 0.465058
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0.43788
New value of Value function: 0.465058
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0.411709
New value of Value function: 0.465058
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0.413579
New value of Value function: 0.465058
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2490
New value of Q matrix: 0.465056
New value of Value function: 0.465056
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2491
New value of Q matrix: 0.465054
New value of Value function: 0.465054
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2492
New value of Q matrix: 0.465053
New value of Value function: 0.465053
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2493
New value of Q matrix: 0.465051
New value of Value function: 0.465051
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2494
New value of Q matrix: 0.465049
New value of Value function: 0.465049
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0.411949
New value of Value function: 0.465049
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2495
New value of Q matrix: 0.465047
New value of Value function: 0.465047
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2496
New value of Q matrix: 0.465045
New value of Value function: 0.465045
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2497
New value of Q matrix: 0.465043
New value of Value function: 0.465043
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2498
New value of Q matrix: 0.465041
New value of Value function: 0.465041
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0.412186
New value of Value function: 0.465041
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0.404693
New value of Value function: 0.465041
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2499
New value of Q matrix: 0.46504
New value of Value function: 0.46504
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2500
New value of Q matrix: 0.465038
New value of Value function: 0.465038
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2501
New value of Q matrix: 0.465036
New value of Value function: 0.465036
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2502
New value of Q matrix: 0.465034
New value of Value function: 0.465034
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2503
New value of Q matrix: 0.465032
New value of Value function: 0.465032
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0.404954
New value of Value function: 0.465032
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0.437987
New value of Value function: 0.465032
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2504
New value of Q matrix: 0.46503
New value of Value function: 0.46503
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0.405213
New value of Value function: 0.46503
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2505
New value of Q matrix: 0.465028
New value of Value function: 0.465028
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2506
New value of Q matrix: 0.465026
New value of Value function: 0.465026
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2507
New value of Q matrix: 0.465025
New value of Value function: 0.465025
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2508
New value of Q matrix: 0.465023
New value of Value function: 0.465023
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2509
New value of Q matrix: 0.465021
New value of Value function: 0.465021
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2510
New value of Q matrix: 0.465019
New value of Value function: 0.465019
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2511
New value of Q matrix: 0.465017
New value of Value function: 0.465017
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2512
New value of Q matrix: 0.465015
New value of Value function: 0.465015
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0.40547
New value of Value function: 0.465015
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2513
New value of Q matrix: 0.465014
New value of Value function: 0.465014
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2514
New value of Q matrix: 0.465012
New value of Value function: 0.465012
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2515
New value of Q matrix: 0.46501
New value of Value function: 0.46501
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2516
New value of Q matrix: 0.465008
New value of Value function: 0.465008
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2517
New value of Q matrix: 0.465006
New value of Value function: 0.465006
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0.405724
New value of Value function: 0.465006
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2518
New value of Q matrix: 0.465004
New value of Value function: 0.465004
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2519
New value of Q matrix: 0.465002
New value of Value function: 0.465002
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0.405976
New value of Value function: 0.465002
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2520
New value of Q matrix: 0.465001
New value of Value function: 0.465001
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2521
New value of Q matrix: 0.464999
New value of Value function: 0.464999
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0.413802
New value of Value function: 0.464999
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0.406225
New value of Value function: 0.464999
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2522
New value of Q matrix: 0.464997
New value of Value function: 0.464997
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2523
New value of Q matrix: 0.464995
New value of Value function: 0.464995
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0.438092
New value of Value function: 0.464995
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2524
New value of Q matrix: 0.464993
New value of Value function: 0.464993
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2525
New value of Q matrix: 0.464991
New value of Value function: 0.464991
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2526
New value of Q matrix: 0.46499
New value of Value function: 0.46499
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2527
New value of Q matrix: 0.464988
New value of Value function: 0.464988
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2528
New value of Q matrix: 0.464986
New value of Value function: 0.464986
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2529
New value of Q matrix: 0.464984
New value of Value function: 0.464984
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2530
New value of Q matrix: 0.464982
New value of Value function: 0.464982
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0.412421
New value of Value function: 0.464982
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2531
New value of Q matrix: 0.46498
New value of Value function: 0.46498
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0.412654
New value of Value function: 0.46498
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2532
New value of Q matrix: 0.464979
New value of Value function: 0.464979
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2533
New value of Q matrix: 0.464977
New value of Value function: 0.464977
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2534
New value of Q matrix: 0.464975
New value of Value function: 0.464975
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2535
New value of Q matrix: 0.464973
New value of Value function: 0.464973
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2536
New value of Q matrix: 0.464971
New value of Value function: 0.464971
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2537
New value of Q matrix: 0.464969
New value of Value function: 0.464969
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2538
New value of Q matrix: 0.464968
New value of Value function: 0.464968
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2539
New value of Q matrix: 0.464966
New value of Value function: 0.464966
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2540
New value of Q matrix: 0.464964
New value of Value function: 0.464964
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0.406472
New value of Value function: 0.464964
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2541
New value of Q matrix: 0.464962
New value of Value function: 0.464962
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2542
New value of Q matrix: 0.46496
New value of Value function: 0.46496
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2543
New value of Q matrix: 0.464958
New value of Value function: 0.464958
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0.414022
New value of Value function: 0.464958
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2544
New value of Q matrix: 0.464957
New value of Value function: 0.464957
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2545
New value of Q matrix: 0.464955
New value of Value function: 0.464955
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2546
New value of Q matrix: 0.464953
New value of Value function: 0.464953
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0.41424
New value of Value function: 0.464953
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2547
New value of Q matrix: 0.464951
New value of Value function: 0.464951
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2548
New value of Q matrix: 0.464949
New value of Value function: 0.464949
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2549
New value of Q matrix: 0.464947
New value of Value function: 0.464947
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2550
New value of Q matrix: 0.464946
New value of Value function: 0.464946
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0.414456
New value of Value function: 0.464946
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2551
New value of Q matrix: 0.464944
New value of Value function: 0.464944
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2552
New value of Q matrix: 0.464942
New value of Value function: 0.464942
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0.406717
New value of Value function: 0.464942
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2553
New value of Q matrix: 0.46494
New value of Value function: 0.46494
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2554
New value of Q matrix: 0.464938
New value of Value function: 0.464938
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0.406959
New value of Value function: 0.464938
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2555
New value of Q matrix: 0.464936
New value of Value function: 0.464936
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2556
New value of Q matrix: 0.464935
New value of Value function: 0.464935
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0.438197
New value of Value function: 0.464935
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0.412884
New value of Value function: 0.464935
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0.413112
New value of Value function: 0.464935
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2557
New value of Q matrix: 0.464933
New value of Value function: 0.464933
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0.413338
New value of Value function: 0.464933
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2558
New value of Q matrix: 0.464931
New value of Value function: 0.464931
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2559
New value of Q matrix: 0.464929
New value of Value function: 0.464929
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2560
New value of Q matrix: 0.464927
New value of Value function: 0.464927
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2561
New value of Q matrix: 0.464926
New value of Value function: 0.464926
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2562
New value of Q matrix: 0.464924
New value of Value function: 0.464924
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2563
New value of Q matrix: 0.464922
New value of Value function: 0.464922
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0.413561
New value of Value function: 0.464922
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2564
New value of Q matrix: 0.46492
New value of Value function: 0.46492
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2565
New value of Q matrix: 0.464918
New value of Value function: 0.464918
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2566
New value of Q matrix: 0.464917
New value of Value function: 0.464917
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0.414671
New value of Value function: 0.464917
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2567
New value of Q matrix: 0.464915
New value of Value function: 0.464915
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2568
New value of Q matrix: 0.464913
New value of Value function: 0.464913
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2569
New value of Q matrix: 0.464911
New value of Value function: 0.464911
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2570
New value of Q matrix: 0.464909
New value of Value function: 0.464909
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2571
New value of Q matrix: 0.464907
New value of Value function: 0.464907
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2572
New value of Q matrix: 0.464906
New value of Value function: 0.464906
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2573
New value of Q matrix: 0.464904
New value of Value function: 0.464904
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2574
New value of Q matrix: 0.464902
New value of Value function: 0.464902
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2575
New value of Q matrix: 0.4649
New value of Value function: 0.4649
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2576
New value of Q matrix: 0.464898
New value of Value function: 0.464898
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2577
New value of Q matrix: 0.465882
New value of Value function: 0.465882
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 572
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.0229
New value of Value function: 3.0229
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 573
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 1.44275
New value of Value function: 1.44275
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 574
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.92525
New value of Value function: 9.92525
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 575
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 2.43878
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 576
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.826
New value of Value function: 9.92525
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 577
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.698999
New value of Value function: 9.92525
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 578
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.826
New value of Value function: 9.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 579
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.789012
New value of Value function: 9.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 580
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.146724
New value of Value function: 1.63026
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 581
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.62845
New value of Value function: 1.62845
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 582
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.9606
New value of Value function: 1.9606
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 583
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.99755
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 584
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 585
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.45
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 586
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.00084
New value of Value function: 6.00084
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 587
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.14507
New value of Value function: 2.02191
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 588
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.33446
New value of Value function: 6.33446
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 589
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 1.95367
New value of Value function: 1.95367
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 590
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.46207
New value of Value function: 6.46207
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 591
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.974274
New value of Value function: 1.95367
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 592
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.95252
New value of Value function: 1.95252
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 593
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.06143
New value of Value function: 1.95252
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 594
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 2.23146
New value of Value function: 2.23146
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 595
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.03391
New value of Value function: 7.03391
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 596
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.08904
New value of Value function: 7.08904
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 597
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 598
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -1.26232
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 599
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -1.14756
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 600
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: -1.2635
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2578
New value of Q matrix: 0.46588
New value of Value function: 0.46588
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2579
New value of Q matrix: 0.465879
New value of Value function: 0.465879
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2580
New value of Q matrix: 0.465877
New value of Value function: 0.465877
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0.438304
New value of Value function: 0.465877
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2581
New value of Q matrix: 0.465875
New value of Value function: 0.465875
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 606
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2582
New value of Q matrix: 0.465873
New value of Value function: 0.465873
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2583
New value of Q matrix: 0.465871
New value of Value function: 0.465871
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2584
New value of Q matrix: 0.46587
New value of Value function: 0.46587
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0.407204
New value of Value function: 0.46587
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2585
New value of Q matrix: 0.465868
New value of Value function: 0.465868
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2586
New value of Q matrix: 0.465866
New value of Value function: 0.465866
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2587
New value of Q matrix: 0.465864
New value of Value function: 0.465864
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2588
New value of Q matrix: 0.465862
New value of Value function: 0.465862
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0.414887
New value of Value function: 0.465862
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0.438411
New value of Value function: 0.465862
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2589
New value of Q matrix: 0.465861
New value of Value function: 0.465861
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0.407446
New value of Value function: 0.465861
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2590
New value of Q matrix: 0.465859
New value of Value function: 0.465859
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 619
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0.413787
New value of Value function: 0.465859
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0.407686
New value of Value function: 0.465859
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2591
New value of Q matrix: 0.465857
New value of Value function: 0.465857
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 0.407924
New value of Value function: 0.465857
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2592
New value of Q matrix: 0.465855
New value of Value function: 0.465855
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0.41401
New value of Value function: 0.465855
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0.414232
New value of Value function: 0.465855
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2593
New value of Q matrix: 0.465853
New value of Value function: 0.465853
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 627
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0.438516
New value of Value function: 0.465853
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2594
New value of Q matrix: 0.465852
New value of Value function: 0.465852
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2595
New value of Q matrix: 0.46585
New value of Value function: 0.46585
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0.438621
New value of Value function: 0.46585
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2596
New value of Q matrix: 0.465848
New value of Value function: 0.465848
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0.438724
New value of Value function: 0.465848
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2597
New value of Q matrix: 0.465846
New value of Value function: 0.465846
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0.408159
New value of Value function: 0.465846
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2598
New value of Q matrix: 0.465844
New value of Value function: 0.465844
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2599
New value of Q matrix: 0.465843
New value of Value function: 0.465843
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2600
New value of Q matrix: 0.465841
New value of Value function: 0.465841
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2601
New value of Q matrix: 0.465839
New value of Value function: 0.465839
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0.438827
New value of Value function: 0.465839
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2602
New value of Q matrix: 0.465837
New value of Value function: 0.465837
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2603
New value of Q matrix: 0.465835
New value of Value function: 0.465835
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2604
New value of Q matrix: 0.465834
New value of Value function: 0.465834
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2605
New value of Q matrix: 0.465832
New value of Value function: 0.465832
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0.438928
New value of Value function: 0.465832
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2606
New value of Q matrix: 0.46583
New value of Value function: 0.46583
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2607
New value of Q matrix: 0.465828
New value of Value function: 0.465828
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2608
New value of Q matrix: 0.465826
New value of Value function: 0.465826
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0.439029
New value of Value function: 0.465826
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2609
New value of Q matrix: 0.465825
New value of Value function: 0.465825
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2610
New value of Q matrix: 0.465823
New value of Value function: 0.465823
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2611
New value of Q matrix: 0.465821
New value of Value function: 0.465821
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2612
New value of Q matrix: 0.465819
New value of Value function: 0.465819
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2613
New value of Q matrix: 0.465818
New value of Value function: 0.465818
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2614
New value of Q matrix: 0.465816
New value of Value function: 0.465816
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0.439129
New value of Value function: 0.465816
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2615
New value of Q matrix: 0.465814
New value of Value function: 0.465814
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2616
New value of Q matrix: 0.465812
New value of Value function: 0.465812
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0.414451
New value of Value function: 0.465812
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2617
New value of Q matrix: 0.46581
New value of Value function: 0.46581
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2618
New value of Q matrix: 0.465809
New value of Value function: 0.465809
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2619
New value of Q matrix: 0.465807
New value of Value function: 0.465807
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2620
New value of Q matrix: 0.465805
New value of Value function: 0.465805
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2621
New value of Q matrix: 0.465803
New value of Value function: 0.465803
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2622
New value of Q matrix: 0.465802
New value of Value function: 0.465802
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0.414668
New value of Value function: 0.465802
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0.414884
New value of Value function: 0.465802
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2623
New value of Q matrix: 0.4658
New value of Value function: 0.4658
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2624
New value of Q matrix: 0.465798
New value of Value function: 0.465798
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0.439227
New value of Value function: 0.465798
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2625
New value of Q matrix: 0.465796
New value of Value function: 0.465796
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2626
New value of Q matrix: 0.465794
New value of Value function: 0.465794
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0.415097
New value of Value function: 0.465794
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2627
New value of Q matrix: 0.465793
New value of Value function: 0.465793
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2628
New value of Q matrix: 0.465791
New value of Value function: 0.465791
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2629
New value of Q matrix: 0.465789
New value of Value function: 0.465789
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2630
New value of Q matrix: 0.465787
New value of Value function: 0.465787
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2631
New value of Q matrix: 0.465786
New value of Value function: 0.465786
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 678
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2632
New value of Q matrix: 0.465784
New value of Value function: 0.465784
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2633
New value of Q matrix: 0.465782
New value of Value function: 0.465782
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2634
New value of Q matrix: 0.46578
New value of Value function: 0.46578
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0.439325
New value of Value function: 0.46578
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 682
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2635
New value of Q matrix: 0.465779
New value of Value function: 0.465779
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 0.439422
New value of Value function: 0.465779
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2636
New value of Q matrix: 0.465777
New value of Value function: 0.465777
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2637
New value of Q matrix: 0.465775
New value of Value function: 0.465775
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0.408393
New value of Value function: 0.465775
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2638
New value of Q matrix: 0.465773
New value of Value function: 0.465773
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0.415101
New value of Value function: 0.465773
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0.415313
New value of Value function: 0.465773
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0.415523
New value of Value function: 0.465773
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2639
New value of Q matrix: 0.465771
New value of Value function: 0.465771
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2640
New value of Q matrix: 0.46577
New value of Value function: 0.46577
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2641
New value of Q matrix: 0.465768
New value of Value function: 0.465768
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 694
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2642
New value of Q matrix: 0.465766
New value of Value function: 0.465766
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 695
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2643
New value of Q matrix: 0.465764
New value of Value function: 0.465764
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 696
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2644
New value of Q matrix: 0.465763
New value of Value function: 0.465763
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2645
New value of Q matrix: 0.465761
New value of Value function: 0.465761
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2646
New value of Q matrix: 0.465759
New value of Value function: 0.465759
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0.415308
New value of Value function: 0.465759
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0.415731
New value of Value function: 0.465759
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2647
New value of Q matrix: 0.465757
New value of Value function: 0.465757
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2648
New value of Q matrix: 0.465756
New value of Value function: 0.465756
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 703
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2649
New value of Q matrix: 0.465754
New value of Value function: 0.465754
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2650
New value of Q matrix: 0.465752
New value of Value function: 0.465752
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0.439518
New value of Value function: 0.465752
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2651
New value of Q matrix: 0.46575
New value of Value function: 0.46575
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2652
New value of Q matrix: 0.465749
New value of Value function: 0.465749
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2653
New value of Q matrix: 0.465747
New value of Value function: 0.465747
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0.439613
New value of Value function: 0.465747
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2654
New value of Q matrix: 0.465745
New value of Value function: 0.465745
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0.415517
New value of Value function: 0.465745
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 712
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2655
New value of Q matrix: 0.465743
New value of Value function: 0.465743
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2656
New value of Q matrix: 0.465742
New value of Value function: 0.465742
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2657
New value of Q matrix: 0.46574
New value of Value function: 0.46574
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 715
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2658
New value of Q matrix: 0.465738
New value of Value function: 0.465738
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 716
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2659
New value of Q matrix: 0.465736
New value of Value function: 0.465736
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0.415937
New value of Value function: 0.465736
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2660
New value of Q matrix: 0.465735
New value of Value function: 0.465735
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0.416142
New value of Value function: 0.465735
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2661
New value of Q matrix: 0.465733
New value of Value function: 0.465733
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0.415724
New value of Value function: 0.465733
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2662
New value of Q matrix: 0.465731
New value of Value function: 0.465731
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2663
New value of Q matrix: 0.465729
New value of Value function: 0.465729
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2664
New value of Q matrix: 0.465728
New value of Value function: 0.465728
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2665
New value of Q matrix: 0.465726
New value of Value function: 0.465726
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2666
New value of Q matrix: 0.465724
New value of Value function: 0.465724
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2667
New value of Q matrix: 0.465722
New value of Value function: 0.465722
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0.415929
New value of Value function: 0.465722
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2668
New value of Q matrix: 0.465721
New value of Value function: 0.465721
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2669
New value of Q matrix: 0.465719
New value of Value function: 0.465719
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2670
New value of Q matrix: 0.465717
New value of Value function: 0.465717
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0.416132
New value of Value function: 0.465717
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2671
New value of Q matrix: 0.465715
New value of Value function: 0.465715
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2672
New value of Q matrix: 0.465714
New value of Value function: 0.465714
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 735
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2673
New value of Q matrix: 0.465712
New value of Value function: 0.465712
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 0.439707
New value of Value function: 0.465712
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2674
New value of Q matrix: 0.46571
New value of Value function: 0.46571
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 0.408623
New value of Value function: 0.46571
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2675
New value of Q matrix: 0.465708
New value of Value function: 0.465708
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0.416334
New value of Value function: 0.465708
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2676
New value of Q matrix: 0.465707
New value of Value function: 0.465707
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2677
New value of Q matrix: 0.465705
New value of Value function: 0.465705
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2678
New value of Q matrix: 0.465703
New value of Value function: 0.465703
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2679
New value of Q matrix: 0.467182
New value of Value function: 0.467182
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 745
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.02317
New value of Value function: 2.02317
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 746
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.66482
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 747
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 2.84492
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 748
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.826
New value of Value function: 9.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 749
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.27533
New value of Value function: 9.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 750
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.59641
New value of Value function: 9.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 751
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.87562
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 752
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.79315
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 753
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.52856
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 754
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.95882
New value of Value function: 1.95882
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 755
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.296099
New value of Value function: 1.95882
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 756
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.20809
New value of Value function: 2.20809
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 757
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.3256
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 758
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.31396
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 759
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 2.4834
New value of Value function: 2.4834
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 760
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.09378
New value of Value function: 7.08904
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 761
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.06396
New value of Value function: 2.4834
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 762
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 2.71013
New value of Value function: 2.71013
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 763
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 7.08117
New value of Value function: 7.08117
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 764
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.39126
New value of Value function: 7.08117
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 765
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.00518
New value of Value function: 7.08117
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 766
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 7.07105
New value of Value function: 7.07105
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 767
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.99667
New value of Value function: 1.99667
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 768
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.9767
New value of Value function: 1.99667
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 769
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.71143
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 770
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4005
	Distance: 6
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -1.16631
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 771
----------
State: 4005
	Distance: 6
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 772
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -1.083
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 773
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: -1.17996
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2680
New value of Q matrix: 0.467181
New value of Value function: 0.467181
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 775
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2681
New value of Q matrix: 0.467179
New value of Value function: 0.467179
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2682
New value of Q matrix: 0.467177
New value of Value function: 0.467177
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2683
New value of Q matrix: 0.467175
New value of Value function: 0.467175
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2684
New value of Q matrix: 0.467174
New value of Value function: 0.467174
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2685
New value of Q matrix: 0.467172
New value of Value function: 0.467172
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2686
New value of Q matrix: 0.46717
New value of Value function: 0.46717
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2687
New value of Q matrix: 0.467168
New value of Value function: 0.467168
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2688
New value of Q matrix: 0.467167
New value of Value function: 0.467167
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2689
New value of Q matrix: 0.467165
New value of Value function: 0.467165
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 784
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2690
New value of Q matrix: 0.467163
New value of Value function: 0.467163
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0.41635
New value of Value function: 0.467163
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2691
New value of Q matrix: 0.467161
New value of Value function: 0.467161
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2692
New value of Q matrix: 0.46716
New value of Value function: 0.46716
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2693
New value of Q matrix: 0.467158
New value of Value function: 0.467158
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2694
New value of Q matrix: 0.467156
New value of Value function: 0.467156
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2695
New value of Q matrix: 0.467154
New value of Value function: 0.467154
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2696
New value of Q matrix: 0.467153
New value of Value function: 0.467153
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2697
New value of Q matrix: 0.467151
New value of Value function: 0.467151
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2698
New value of Q matrix: 0.467149
New value of Value function: 0.467149
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 794
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2699
New value of Q matrix: 0.467148
New value of Value function: 0.467148
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2700
New value of Q matrix: 0.467146
New value of Value function: 0.467146
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2701
New value of Q matrix: 0.467144
New value of Value function: 0.467144
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2702
New value of Q matrix: 0.467142
New value of Value function: 0.467142
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2703
New value of Q matrix: 0.467141
New value of Value function: 0.467141
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2704
New value of Q matrix: 0.467139
New value of Value function: 0.467139
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2705
New value of Q matrix: 0.467137
New value of Value function: 0.467137
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2706
New value of Q matrix: 0.467135
New value of Value function: 0.467135
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2707
New value of Q matrix: 0.467134
New value of Value function: 0.467134
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2708
New value of Q matrix: 0.467132
New value of Value function: 0.467132
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0.416557
New value of Value function: 0.467132
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2709
New value of Q matrix: 0.46713
New value of Value function: 0.46713
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2710
New value of Q matrix: 0.467129
New value of Value function: 0.467129
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0.408859
New value of Value function: 0.467129
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2711
New value of Q matrix: 0.467127
New value of Value function: 0.467127
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2712
New value of Q matrix: 0.467125
New value of Value function: 0.467125
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2713
New value of Q matrix: 0.467123
New value of Value function: 0.467123
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0.416762
New value of Value function: 0.467123
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2714
New value of Q matrix: 0.467122
New value of Value function: 0.467122
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2715
New value of Q matrix: 0.46712
New value of Value function: 0.46712
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2716
New value of Q matrix: 0.467118
New value of Value function: 0.467118
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2717
New value of Q matrix: 0.467116
New value of Value function: 0.467116
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2718
New value of Q matrix: 0.467115
New value of Value function: 0.467115
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2719
New value of Q matrix: 0.467113
New value of Value function: 0.467113
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2720
New value of Q matrix: 0.467111
New value of Value function: 0.467111
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2721
New value of Q matrix: 0.46711
New value of Value function: 0.46711
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2722
New value of Q matrix: 0.467108
New value of Value function: 0.467108
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2723
New value of Q matrix: 0.467106
New value of Value function: 0.467106
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0.41654
New value of Value function: 0.467106
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2724
New value of Q matrix: 0.467104
New value of Value function: 0.467104
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2725
New value of Q matrix: 0.467103
New value of Value function: 0.467103
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2726
New value of Q matrix: 0.467101
New value of Value function: 0.467101
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2727
New value of Q matrix: 0.467099
New value of Value function: 0.467099
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2728
New value of Q matrix: 0.467098
New value of Value function: 0.467098
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2729
New value of Q matrix: 0.467096
New value of Value function: 0.467096
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2730
New value of Q matrix: 0.467094
New value of Value function: 0.467094
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2731
New value of Q matrix: 0.467092
New value of Value function: 0.467092
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2732
New value of Q matrix: 0.467091
New value of Value function: 0.467091
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2733
New value of Q matrix: 0.467089
New value of Value function: 0.467089
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2734
New value of Q matrix: 0.467087
New value of Value function: 0.467087
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0.409091
New value of Value function: 0.467087
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2735
New value of Q matrix: 0.467086
New value of Value function: 0.467086
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2736
New value of Q matrix: 0.467084
New value of Value function: 0.467084
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 0.409322
New value of Value function: 0.467084
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2737
New value of Q matrix: 0.467082
New value of Value function: 0.467082
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2738
New value of Q matrix: 0.467081
New value of Value function: 0.467081
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2739
New value of Q matrix: 0.467079
New value of Value function: 0.467079
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 0.416965
New value of Value function: 0.467079
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2740
New value of Q matrix: 0.467077
New value of Value function: 0.467077
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 0.409551
New value of Value function: 0.467077
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2741
New value of Q matrix: 0.467075
New value of Value function: 0.467075
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2742
New value of Q matrix: 0.467074
New value of Value function: 0.467074
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2743
New value of Q matrix: 0.467072
New value of Value function: 0.467072
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0.439806
New value of Value function: 0.467072
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 0.416743
New value of Value function: 0.467072
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0.439904
New value of Value function: 0.467072
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2744
New value of Q matrix: 0.46707
New value of Value function: 0.46707
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2745
New value of Q matrix: 0.467069
New value of Value function: 0.467069
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2746
New value of Q matrix: 0.467067
New value of Value function: 0.467067
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0.409778
New value of Value function: 0.467067
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2747
New value of Q matrix: 0.467065
New value of Value function: 0.467065
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 0.440002
New value of Value function: 0.467065
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2748
New value of Q matrix: 0.467064
New value of Value function: 0.467064
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2749
New value of Q matrix: 0.467062
New value of Value function: 0.467062
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0.417166
New value of Value function: 0.467062
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2750
New value of Q matrix: 0.46706
New value of Value function: 0.46706
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0.417365
New value of Value function: 0.46706
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2751
New value of Q matrix: 0.467058
New value of Value function: 0.467058
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2752
New value of Q matrix: 0.467057
New value of Value function: 0.467057
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 0.440098
New value of Value function: 0.467057
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2753
New value of Q matrix: 0.467055
New value of Value function: 0.467055
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2754
New value of Q matrix: 0.467053
New value of Value function: 0.467053
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2755
New value of Q matrix: 0.467052
New value of Value function: 0.467052
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2756
New value of Q matrix: 0.46705
New value of Value function: 0.46705
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2757
New value of Q matrix: 0.467048
New value of Value function: 0.467048
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2758
New value of Q matrix: 0.467047
New value of Value function: 0.467047
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2759
New value of Q matrix: 0.467045
New value of Value function: 0.467045
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2760
New value of Q matrix: 0.467043
New value of Value function: 0.467043
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2761
New value of Q matrix: 0.467041
New value of Value function: 0.467041
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2762
New value of Q matrix: 0.46704
New value of Value function: 0.46704
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2763
New value of Q matrix: 0.467038
New value of Value function: 0.467038
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0.440194
New value of Value function: 0.467038
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0.410003
New value of Value function: 0.467038
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2764
New value of Q matrix: 0.467036
New value of Value function: 0.467036
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2765
New value of Q matrix: 0.467035
New value of Value function: 0.467035
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2766
New value of Q matrix: 0.467033
New value of Value function: 0.467033
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2767
New value of Q matrix: 0.467031
New value of Value function: 0.467031
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2768
New value of Q matrix: 0.46703
New value of Value function: 0.46703
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0.416945
New value of Value function: 0.46703
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0.417145
New value of Value function: 0.46703
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 0.417344
New value of Value function: 0.46703
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2769
New value of Q matrix: 0.467028
New value of Value function: 0.467028
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2770
New value of Q matrix: 0.467026
New value of Value function: 0.467026
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0.440288
New value of Value function: 0.467026
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.410225
New value of Value function: 0.467026
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2771
New value of Q matrix: 0.467025
New value of Value function: 0.467025
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2772
New value of Q matrix: 0.467023
New value of Value function: 0.467023
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2773
New value of Q matrix: 0.468659
New value of Value function: 0.468659
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 892
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.02028
New value of Value function: 2.02028
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 893
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.3834
New value of Value function: 2.3834
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 894
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.00494
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 895
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 3.13151
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 896
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.36074
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 897
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.20639
New value of Value function: 2.20639
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 898
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 2.40236
New value of Value function: 2.40236
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 899
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.5536
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 900
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.56438
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 901
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 2.70884
New value of Value function: 2.70884
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 902
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 2.90391
New value of Value function: 2.90391
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 903
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 7.06462
New value of Value function: 7.06462
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 904
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.56883
New value of Value function: 7.06462
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 905
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 7.05873
New value of Value function: 7.05873
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 906
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 7.0509
New value of Value function: 7.0509
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 907
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.4975
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 908
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -1.10622
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 909
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -1.04115
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 910
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.634007
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 911
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2774
New value of Q matrix: 0.468657
New value of Value function: 0.468657
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 912
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2775
New value of Q matrix: 0.468655
New value of Value function: 0.468655
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 913
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2776
New value of Q matrix: 0.468654
New value of Value function: 0.468654
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2777
New value of Q matrix: 0.468652
New value of Value function: 0.468652
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 915
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2778
New value of Q matrix: 0.46865
New value of Value function: 0.46865
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 916
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0.417547
New value of Value function: 0.46865
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.440389
New value of Value function: 0.46865
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 0.41757
New value of Value function: 0.46865
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2779
New value of Q matrix: 0.468649
New value of Value function: 0.468649
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2780
New value of Q matrix: 0.468647
New value of Value function: 0.468647
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 921
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2781
New value of Q matrix: 0.468645
New value of Value function: 0.468645
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 922
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0.417749
New value of Value function: 0.468645
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2782
New value of Q matrix: 0.468643
New value of Value function: 0.468643
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 924
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2783
New value of Q matrix: 0.468642
New value of Value function: 0.468642
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 925
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2784
New value of Q matrix: 0.46864
New value of Value function: 0.46864
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 926
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2785
New value of Q matrix: 0.468638
New value of Value function: 0.468638
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2786
New value of Q matrix: 0.468637
New value of Value function: 0.468637
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2787
New value of Q matrix: 0.468635
New value of Value function: 0.468635
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 929
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0.417772
New value of Value function: 0.468635
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 930
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2788
New value of Q matrix: 0.468633
New value of Value function: 0.468633
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 931
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2789
New value of Q matrix: 0.468632
New value of Value function: 0.468632
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 932
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2790
New value of Q matrix: 0.46863
New value of Value function: 0.46863
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 933
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2791
New value of Q matrix: 0.468628
New value of Value function: 0.468628
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 934
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2792
New value of Q matrix: 0.468627
New value of Value function: 0.468627
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0.410453
New value of Value function: 0.468627
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 936
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2793
New value of Q matrix: 0.468625
New value of Value function: 0.468625
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 937
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2794
New value of Q matrix: 0.468623
New value of Value function: 0.468623
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 938
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2795
New value of Q matrix: 0.468622
New value of Value function: 0.468622
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2796
New value of Q matrix: 0.46862
New value of Value function: 0.46862
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2797
New value of Q matrix: 0.468618
New value of Value function: 0.468618
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2798
New value of Q matrix: 0.468617
New value of Value function: 0.468617
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 942
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2799
New value of Q matrix: 0.468615
New value of Value function: 0.468615
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 943
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2800
New value of Q matrix: 0.468613
New value of Value function: 0.468613
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 944
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2801
New value of Q matrix: 0.468612
New value of Value function: 0.468612
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 945
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0.440489
New value of Value function: 0.468612
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.440588
New value of Value function: 0.468612
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2802
New value of Q matrix: 0.46861
New value of Value function: 0.46861
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0.417973
New value of Value function: 0.46861
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2803
New value of Q matrix: 0.468608
New value of Value function: 0.468608
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2804
New value of Q matrix: 0.468607
New value of Value function: 0.468607
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2805
New value of Q matrix: 0.468605
New value of Value function: 0.468605
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2806
New value of Q matrix: 0.468603
New value of Value function: 0.468603
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2807
New value of Q matrix: 0.468602
New value of Value function: 0.468602
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0.440686
New value of Value function: 0.468602
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2808
New value of Q matrix: 0.4686
New value of Value function: 0.4686
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0.440783
New value of Value function: 0.4686
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2809
New value of Q matrix: 0.468598
New value of Value function: 0.468598
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2810
New value of Q matrix: 0.468597
New value of Value function: 0.468597
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 959
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2811
New value of Q matrix: 0.468595
New value of Value function: 0.468595
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 960
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2812
New value of Q matrix: 0.468593
New value of Value function: 0.468593
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 961
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2813
New value of Q matrix: 0.468592
New value of Value function: 0.468592
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2814
New value of Q matrix: 0.46859
New value of Value function: 0.46859
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 963
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2815
New value of Q matrix: 0.468588
New value of Value function: 0.468588
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 964
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2816
New value of Q matrix: 0.468587
New value of Value function: 0.468587
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 965
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 0.418172
New value of Value function: 0.468587
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2817
New value of Q matrix: 0.468585
New value of Value function: 0.468585
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2818
New value of Q matrix: 0.468583
New value of Value function: 0.468583
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2819
New value of Q matrix: 0.468582
New value of Value function: 0.468582
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 969
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2820
New value of Q matrix: 0.46858
New value of Value function: 0.46858
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 0.440879
New value of Value function: 0.46858
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 0.418369
New value of Value function: 0.46858
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2821
New value of Q matrix: 0.468578
New value of Value function: 0.468578
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 973
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 0.417949
New value of Value function: 0.468578
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2822
New value of Q matrix: 0.468577
New value of Value function: 0.468577
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.410678
New value of Value function: 0.468577
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 0.418147
New value of Value function: 0.468577
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2823
New value of Q matrix: 0.468575
New value of Value function: 0.468575
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 978
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0.418343
New value of Value function: 0.468575
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2824
New value of Q matrix: 0.468573
New value of Value function: 0.468573
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2825
New value of Q matrix: 0.468572
New value of Value function: 0.468572
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2826
New value of Q matrix: 0.46857
New value of Value function: 0.46857
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2827
New value of Q matrix: 0.468568
New value of Value function: 0.468568
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2828
New value of Q matrix: 0.468567
New value of Value function: 0.468567
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0.418564
New value of Value function: 0.468567
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0.418758
New value of Value function: 0.468567
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 986
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2829
New value of Q matrix: 0.468565
New value of Value function: 0.468565
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 987
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2830
New value of Q matrix: 0.468563
New value of Value function: 0.468563
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2831
New value of Q matrix: 0.468562
New value of Value function: 0.468562
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2832
New value of Q matrix: 0.46856
New value of Value function: 0.46856
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2833
New value of Q matrix: 0.468558
New value of Value function: 0.468558
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2834
New value of Q matrix: 0.468557
New value of Value function: 0.468557
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0.418538
New value of Value function: 0.468557
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.418731
New value of Value function: 0.468557
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2835
New value of Q matrix: 0.468555
New value of Value function: 0.468555
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2836
New value of Q matrix: 0.468553
New value of Value function: 0.468553
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2837
New value of Q matrix: 0.468552
New value of Value function: 0.468552
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2838
New value of Q matrix: 0.46855
New value of Value function: 0.46855
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2839
New value of Q matrix: 0.468548
New value of Value function: 0.468548
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2840
New value of Q matrix: 0.468547
New value of Value function: 0.468547
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2841
New value of Q matrix: 0.468545
New value of Value function: 0.468545
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 1
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 2.4649
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 2
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.35021
New value of Value function: 6.35021
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 3
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.39745
New value of Value function: 6.46207
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 4
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.39745
New value of Value function: 6.46207
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 5
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.39745
New value of Value function: 6.46207
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 6
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.07415
New value of Value function: 6.46207
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 7
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.13616
New value of Value function: 7.13616
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 8
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.06424
New value of Value function: 2.90391
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 9
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.73112
New value of Value function: 7.13616
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 10
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.13412
New value of Value function: 7.13616
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 11
----------
State: 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.49745
New value of Value function: 6.49745
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 12
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.3824
New value of Value function: 7.3824
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 13
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.12532
New value of Value function: 2.90391
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 14
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.23357
New value of Value function: 7.3824
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 15
----------
State: 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.76782
New value of Value function: 6.76782
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 16
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.35022
New value of Value function: 7.3824
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 17
----------
State: 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.4002
New value of Value function: 12.4002
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 18
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.45008
New value of Value function: 7.45008
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 19
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.82506
New value of Value function: 6.82506
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 20
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 21
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 22
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: -1.1242
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0.410902
New value of Value function: 0.468545
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 0.440975
New value of Value function: 0.468545
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2842
New value of Q matrix: 0.468543
New value of Value function: 0.468543
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2843
New value of Q matrix: 0.468542
New value of Value function: 0.468542
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2844
New value of Q matrix: 0.46854
New value of Value function: 0.46854
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2845
New value of Q matrix: 0.468539
New value of Value function: 0.468539
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2846
New value of Q matrix: 0.468537
New value of Value function: 0.468537
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2847
New value of Q matrix: 0.468535
New value of Value function: 0.468535
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2848
New value of Q matrix: 0.468534
New value of Value function: 0.468534
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2849
New value of Q matrix: 0.468532
New value of Value function: 0.468532
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2850
New value of Q matrix: 0.46853
New value of Value function: 0.46853
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2851
New value of Q matrix: 0.468529
New value of Value function: 0.468529
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2852
New value of Q matrix: 0.468527
New value of Value function: 0.468527
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2853
New value of Q matrix: 0.468525
New value of Value function: 0.468525
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2854
New value of Q matrix: 0.468524
New value of Value function: 0.468524
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2855
New value of Q matrix: 0.468522
New value of Value function: 0.468522
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0.441069
New value of Value function: 0.468522
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0.411123
New value of Value function: 0.468522
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2856
New value of Q matrix: 0.46852
New value of Value function: 0.46852
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2857
New value of Q matrix: 0.468519
New value of Value function: 0.468519
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.418949
New value of Value function: 0.468519
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2858
New value of Q matrix: 0.468517
New value of Value function: 0.468517
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2859
New value of Q matrix: 0.468516
New value of Value function: 0.468516
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2860
New value of Q matrix: 0.468514
New value of Value function: 0.468514
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2861
New value of Q matrix: 0.468512
New value of Value function: 0.468512
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2862
New value of Q matrix: 0.468511
New value of Value function: 0.468511
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2863
New value of Q matrix: 0.468509
New value of Value function: 0.468509
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2864
New value of Q matrix: 0.468507
New value of Value function: 0.468507
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2865
New value of Q matrix: 0.468506
New value of Value function: 0.468506
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2866
New value of Q matrix: 0.468504
New value of Value function: 0.468504
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2867
New value of Q matrix: 0.468502
New value of Value function: 0.468502
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2868
New value of Q matrix: 0.468501
New value of Value function: 0.468501
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 0.411343
New value of Value function: 0.468501
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0.418922
New value of Value function: 0.468501
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2869
New value of Q matrix: 0.468499
New value of Value function: 0.468499
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2870
New value of Q matrix: 0.468498
New value of Value function: 0.468498
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2871
New value of Q matrix: 0.468496
New value of Value function: 0.468496
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2872
New value of Q matrix: 0.468494
New value of Value function: 0.468494
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2873
New value of Q matrix: 0.468493
New value of Value function: 0.468493
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2874
New value of Q matrix: 0.468491
New value of Value function: 0.468491
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2875
New value of Q matrix: 0.468489
New value of Value function: 0.468489
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2876
New value of Q matrix: 0.468488
New value of Value function: 0.468488
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2877
New value of Q matrix: 0.468486
New value of Value function: 0.468486
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2878
New value of Q matrix: 0.468485
New value of Value function: 0.468485
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2879
New value of Q matrix: 0.468483
New value of Value function: 0.468483
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2880
New value of Q matrix: 0.468481
New value of Value function: 0.468481
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2881
New value of Q matrix: 0.46848
New value of Value function: 0.46848
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2882
New value of Q matrix: 0.468478
New value of Value function: 0.468478
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0.419139
New value of Value function: 0.468478
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2883
New value of Q matrix: 0.468476
New value of Value function: 0.468476
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2884
New value of Q matrix: 0.468475
New value of Value function: 0.468475
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2885
New value of Q matrix: 0.468473
New value of Value function: 0.468473
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2886
New value of Q matrix: 0.468472
New value of Value function: 0.468472
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.419111
New value of Value function: 0.468472
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2887
New value of Q matrix: 0.46847
New value of Value function: 0.46847
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2888
New value of Q matrix: 0.468468
New value of Value function: 0.468468
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.419328
New value of Value function: 0.468468
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2889
New value of Q matrix: 0.468467
New value of Value function: 0.468467
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.441163
New value of Value function: 0.468467
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2890
New value of Q matrix: 0.468465
New value of Value function: 0.468465
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2891
New value of Q matrix: 0.468463
New value of Value function: 0.468463
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2892
New value of Q matrix: 0.468462
New value of Value function: 0.468462
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2893
New value of Q matrix: 0.46846
New value of Value function: 0.46846
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2894
New value of Q matrix: 0.468459
New value of Value function: 0.468459
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2895
New value of Q matrix: 0.468457
New value of Value function: 0.468457
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2896
New value of Q matrix: 0.468455
New value of Value function: 0.468455
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2897
New value of Q matrix: 0.468454
New value of Value function: 0.468454
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2898
New value of Q matrix: 0.468452
New value of Value function: 0.468452
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 0.41156
New value of Value function: 0.468452
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2899
New value of Q matrix: 0.46845
New value of Value function: 0.46845
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0.419515
New value of Value function: 0.46845
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2900
New value of Q matrix: 0.468449
New value of Value function: 0.468449
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2901
New value of Q matrix: 0.468447
New value of Value function: 0.468447
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2902
New value of Q matrix: 0.468446
New value of Value function: 0.468446
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 0.441255
New value of Value function: 0.468446
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2903
New value of Q matrix: 0.468444
New value of Value function: 0.468444
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2904
New value of Q matrix: 0.468442
New value of Value function: 0.468442
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2905
New value of Q matrix: 0.468441
New value of Value function: 0.468441
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 0.441347
New value of Value function: 0.468441
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2906
New value of Q matrix: 0.468439
New value of Value function: 0.468439
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2907
New value of Q matrix: 0.468438
New value of Value function: 0.468438
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2908
New value of Q matrix: 0.468436
New value of Value function: 0.468436
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0.441438
New value of Value function: 0.468436
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2909
New value of Q matrix: 0.468434
New value of Value function: 0.468434
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2910
New value of Q matrix: 0.468433
New value of Value function: 0.468433
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2911
New value of Q matrix: 0.468431
New value of Value function: 0.468431
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2912
New value of Q matrix: 0.46843
New value of Value function: 0.46843
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2913
New value of Q matrix: 0.468428
New value of Value function: 0.468428
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2914
New value of Q matrix: 0.468426
New value of Value function: 0.468426
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0.411776
New value of Value function: 0.468426
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0.4197
New value of Value function: 0.468426
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2915
New value of Q matrix: 0.468425
New value of Value function: 0.468425
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 0.419883
New value of Value function: 0.468425
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2916
New value of Q matrix: 0.468423
New value of Value function: 0.468423
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2917
New value of Q matrix: 0.468421
New value of Value function: 0.468421
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 0.420065
New value of Value function: 0.468421
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.41199
New value of Value function: 0.468421
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2918
New value of Q matrix: 0.46842
New value of Value function: 0.46842
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2919
New value of Q matrix: 0.468418
New value of Value function: 0.468418
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0.420246
New value of Value function: 0.468418
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0.441528
New value of Value function: 0.468418
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 0.441618
New value of Value function: 0.468418
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2920
New value of Q matrix: 0.468417
New value of Value function: 0.468417
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0.419298
New value of Value function: 0.468417
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2921
New value of Q matrix: 0.468415
New value of Value function: 0.468415
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2922
New value of Q matrix: 0.468413
New value of Value function: 0.468413
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2923
New value of Q matrix: 0.468412
New value of Value function: 0.468412
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2924
New value of Q matrix: 0.46841
New value of Value function: 0.46841
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2925
New value of Q matrix: 0.468409
New value of Value function: 0.468409
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2926
New value of Q matrix: 0.468407
New value of Value function: 0.468407
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2927
New value of Q matrix: 0.468405
New value of Value function: 0.468405
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2928
New value of Q matrix: 0.468404
New value of Value function: 0.468404
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2929
New value of Q matrix: 0.468402
New value of Value function: 0.468402
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0.419484
New value of Value function: 0.468402
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2930
New value of Q matrix: 0.468401
New value of Value function: 0.468401
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 0.419669
New value of Value function: 0.468401
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2931
New value of Q matrix: 0.468399
New value of Value function: 0.468399
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2932
New value of Q matrix: 0.468397
New value of Value function: 0.468397
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 0.419851
New value of Value function: 0.468397
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2933
New value of Q matrix: 0.468396
New value of Value function: 0.468396
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2934
New value of Q matrix: 0.468394
New value of Value function: 0.468394
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2935
New value of Q matrix: 0.468393
New value of Value function: 0.468393
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2936
New value of Q matrix: 0.470059
New value of Value function: 0.470059
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 146
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.38075
New value of Value function: 2.38075
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 147
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 2.62527
New value of Value function: 2.62527
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 148
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.51457
New value of Value function: 9.92525
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 149
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.07364
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 150
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 3.39695
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 151
----------
State: 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.32612
New value of Value function: 2.32612
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 152
----------
State: 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.04786
New value of Value function: 3.04786
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 153
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.456272
New value of Value function: 2.40236
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 154
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.40076
New value of Value function: 2.40076
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 155
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.56009
New value of Value function: 2.56009
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 156
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 2.64241
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 157
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 2.62015
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 158
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.54189
New value of Value function: 7.3824
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 159
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.74424
New value of Value function: 7.3824
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 160
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.66967
New value of Value function: 7.3824
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 161
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.42834
New value of Value function: 7.42834
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 162
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 7.0299
New value of Value function: 7.0299
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 163
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.81141
New value of Value function: 6.81141
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 164
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.7433
New value of Value function: 6.81141
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 165
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.50951
New value of Value function: 6.7433
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 166
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: -1.06503
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 167
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: -1.01178
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 168
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: -1.0843
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2937
New value of Q matrix: 0.470057
New value of Value function: 0.470057
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2938
New value of Q matrix: 0.470055
New value of Value function: 0.470055
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2939
New value of Q matrix: 0.470054
New value of Value function: 0.470054
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2940
New value of Q matrix: 0.470052
New value of Value function: 0.470052
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2941
New value of Q matrix: 0.470051
New value of Value function: 0.470051
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 0.412209
New value of Value function: 0.470051
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2942
New value of Q matrix: 0.470049
New value of Value function: 0.470049
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2943
New value of Q matrix: 0.470047
New value of Value function: 0.470047
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.420431
New value of Value function: 0.470047
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 0.420615
New value of Value function: 0.470047
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2944
New value of Q matrix: 0.470046
New value of Value function: 0.470046
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 0.420798
New value of Value function: 0.470046
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2945
New value of Q matrix: 0.470044
New value of Value function: 0.470044
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 0.441713
New value of Value function: 0.470044
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2946
New value of Q matrix: 0.470043
New value of Value function: 0.470043
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 0.441808
New value of Value function: 0.470043
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2947
New value of Q matrix: 0.470041
New value of Value function: 0.470041
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2948
New value of Q matrix: 0.470039
New value of Value function: 0.470039
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2949
New value of Q matrix: 0.470038
New value of Value function: 0.470038
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0.420979
New value of Value function: 0.470038
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0.421158
New value of Value function: 0.470038
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2950
New value of Q matrix: 0.470036
New value of Value function: 0.470036
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2951
New value of Q matrix: 0.470035
New value of Value function: 0.470035
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2952
New value of Q matrix: 0.470033
New value of Value function: 0.470033
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 0.441901
New value of Value function: 0.470033
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 0.421337
New value of Value function: 0.470033
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2953
New value of Q matrix: 0.470031
New value of Value function: 0.470031
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2954
New value of Q matrix: 0.47003
New value of Value function: 0.47003
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2955
New value of Q matrix: 0.470028
New value of Value function: 0.470028
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0.420039
New value of Value function: 0.470028
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 0.441994
New value of Value function: 0.470028
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2956
New value of Q matrix: 0.470027
New value of Value function: 0.470027
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 0.412425
New value of Value function: 0.470027
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2957
New value of Q matrix: 0.470025
New value of Value function: 0.470025
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0.41264
New value of Value function: 0.470025
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2958
New value of Q matrix: 0.470024
New value of Value function: 0.470024
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2959
New value of Q matrix: 0.470022
New value of Value function: 0.470022
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2960
New value of Q matrix: 0.47002
New value of Value function: 0.47002
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2961
New value of Q matrix: 0.470019
New value of Value function: 0.470019
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2962
New value of Q matrix: 0.470017
New value of Value function: 0.470017
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.420226
New value of Value function: 0.470017
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2963
New value of Q matrix: 0.470016
New value of Value function: 0.470016
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0.412854
New value of Value function: 0.470016
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 0.442087
New value of Value function: 0.470016
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2964
New value of Q matrix: 0.470014
New value of Value function: 0.470014
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2965
New value of Q matrix: 0.470012
New value of Value function: 0.470012
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2966
New value of Q matrix: 0.470011
New value of Value function: 0.470011
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2967
New value of Q matrix: 0.470009
New value of Value function: 0.470009
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2968
New value of Q matrix: 0.470008
New value of Value function: 0.470008
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2969
New value of Q matrix: 0.470006
New value of Value function: 0.470006
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2970
New value of Q matrix: 0.470004
New value of Value function: 0.470004
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 0.442178
New value of Value function: 0.470004
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2971
New value of Q matrix: 0.470003
New value of Value function: 0.470003
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2972
New value of Q matrix: 0.470001
New value of Value function: 0.470001
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2973
New value of Q matrix: 0.47
New value of Value function: 0.47
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 0.413065
New value of Value function: 0.47
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2974
New value of Q matrix: 0.469998
New value of Value function: 0.469998
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2975
New value of Q matrix: 0.469997
New value of Value function: 0.469997
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2976
New value of Q matrix: 0.469995
New value of Value function: 0.469995
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2977
New value of Q matrix: 0.469993
New value of Value function: 0.469993
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2978
New value of Q matrix: 0.469992
New value of Value function: 0.469992
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2979
New value of Q matrix: 0.46999
New value of Value function: 0.46999
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2980
New value of Q matrix: 0.469989
New value of Value function: 0.469989
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2981
New value of Q matrix: 0.469987
New value of Value function: 0.469987
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 0.442269
New value of Value function: 0.469987
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2982
New value of Q matrix: 0.469986
New value of Value function: 0.469986
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2983
New value of Q matrix: 0.469984
New value of Value function: 0.469984
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2984
New value of Q matrix: 0.469982
New value of Value function: 0.469982
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2985
New value of Q matrix: 0.469981
New value of Value function: 0.469981
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2986
New value of Q matrix: 0.469979
New value of Value function: 0.469979
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2987
New value of Q matrix: 0.469978
New value of Value function: 0.469978
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 0.442358
New value of Value function: 0.469978
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 0.413275
New value of Value function: 0.469978
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2988
New value of Q matrix: 0.469976
New value of Value function: 0.469976
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 0.413483
New value of Value function: 0.469976
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2989
New value of Q matrix: 0.469975
New value of Value function: 0.469975
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 0.413689
New value of Value function: 0.469975
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 0.421513
New value of Value function: 0.469975
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2990
New value of Q matrix: 0.469973
New value of Value function: 0.469973
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2991
New value of Q matrix: 0.469971
New value of Value function: 0.469971
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2992
New value of Q matrix: 0.46997
New value of Value function: 0.46997
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2993
New value of Q matrix: 0.469968
New value of Value function: 0.469968
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 0.413894
New value of Value function: 0.469968
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2994
New value of Q matrix: 0.469967
New value of Value function: 0.469967
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2995
New value of Q matrix: 0.469965
New value of Value function: 0.469965
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2996
New value of Q matrix: 0.469964
New value of Value function: 0.469964
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 0.442448
New value of Value function: 0.469964
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2997
New value of Q matrix: 0.469962
New value of Value function: 0.469962
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2998
New value of Q matrix: 0.46996
New value of Value function: 0.46996
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 0.414097
New value of Value function: 0.46996
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 0.42041
New value of Value function: 0.46996
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2999
New value of Q matrix: 0.469959
New value of Value function: 0.469959
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3000
New value of Q matrix: 0.469957
New value of Value function: 0.469957
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3001
New value of Q matrix: 0.469956
New value of Value function: 0.469956
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3002
New value of Q matrix: 0.469954
New value of Value function: 0.469954
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3003
New value of Q matrix: 0.469953
New value of Value function: 0.469953
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3004
New value of Q matrix: 0.469951
New value of Value function: 0.469951
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3005
New value of Q matrix: 0.469949
New value of Value function: 0.469949
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3006
New value of Q matrix: 0.469948
New value of Value function: 0.469948
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3007
New value of Q matrix: 0.469946
New value of Value function: 0.469946
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 0.414298
New value of Value function: 0.469946
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3008
New value of Q matrix: 0.469945
New value of Value function: 0.469945
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3009
New value of Q matrix: 0.469943
New value of Value function: 0.469943
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3010
New value of Q matrix: 0.469942
New value of Value function: 0.469942
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3011
New value of Q matrix: 0.46994
New value of Value function: 0.46994
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 0.420593
New value of Value function: 0.46994
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 0.421688
New value of Value function: 0.46994
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3012
New value of Q matrix: 0.469939
New value of Value function: 0.469939
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3013
New value of Q matrix: 0.469937
New value of Value function: 0.469937
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 0.442536
New value of Value function: 0.469937
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3014
New value of Q matrix: 0.469935
New value of Value function: 0.469935
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3015
New value of Q matrix: 0.469934
New value of Value function: 0.469934
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 0.414498
New value of Value function: 0.469934
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3016
New value of Q matrix: 0.469932
New value of Value function: 0.469932
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3017
New value of Q matrix: 0.469931
New value of Value function: 0.469931
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3018
New value of Q matrix: 0.469929
New value of Value function: 0.469929
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0.420775
New value of Value function: 0.469929
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3019
New value of Q matrix: 0.469928
New value of Value function: 0.469928
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 0.421861
New value of Value function: 0.469928
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3020
New value of Q matrix: 0.469926
New value of Value function: 0.469926
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 0.422033
New value of Value function: 0.469926
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 0.442624
New value of Value function: 0.469926
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 0.442711
New value of Value function: 0.469926
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3021
New value of Q matrix: 0.469924
New value of Value function: 0.469924
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3022
New value of Q matrix: 0.469923
New value of Value function: 0.469923
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 0.442797
New value of Value function: 0.469923
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 0.442882
New value of Value function: 0.469923
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3023
New value of Q matrix: 0.469921
New value of Value function: 0.469921
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 0.422204
New value of Value function: 0.469921
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3024
New value of Q matrix: 0.46992
New value of Value function: 0.46992
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3025
New value of Q matrix: 0.469918
New value of Value function: 0.469918
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3026
New value of Q matrix: 0.469917
New value of Value function: 0.469917
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3027
New value of Q matrix: 0.469915
New value of Value function: 0.469915
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3028
New value of Q matrix: 0.469914
New value of Value function: 0.469914
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3029
New value of Q matrix: 0.469912
New value of Value function: 0.469912
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3030
New value of Q matrix: 0.469911
New value of Value function: 0.469911
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3031
New value of Q matrix: 0.469909
New value of Value function: 0.469909
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3032
New value of Q matrix: 0.469907
New value of Value function: 0.469907
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3033
New value of Q matrix: 0.469906
New value of Value function: 0.469906
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 0.422373
New value of Value function: 0.469906
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3034
New value of Q matrix: 0.469904
New value of Value function: 0.469904
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 0.442967
New value of Value function: 0.469904
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3035
New value of Q matrix: 0.469903
New value of Value function: 0.469903
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3036
New value of Q matrix: 0.469901
New value of Value function: 0.469901
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3037
New value of Q matrix: 0.4699
New value of Value function: 0.4699
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3038
New value of Q matrix: 0.469898
New value of Value function: 0.469898
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3039
New value of Q matrix: 0.471586
New value of Value function: 0.471586
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 316
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 2.38207
New value of Value function: 2.38207
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 317
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 318
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.35825
New value of Value function: 7.35825
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 319
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.28466
New value of Value function: 2.38207
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 320
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.45275
New value of Value function: 7.35825
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 321
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.28466
New value of Value function: 2.38207
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 322
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.67912
New value of Value function: 7.35825
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 323
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 2.58573
New value of Value function: 2.58573
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 324
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.72496
New value of Value function: 9.92525
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 325
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 2.93359
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 326
----------
State: 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.9335
New value of Value function: 3.9335
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 327
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 2.55858
New value of Value function: 2.55858
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 328
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 2.69144
New value of Value function: 2.69144
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 329
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 330
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 2.53681
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 331
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.55098
New value of Value function: 6.55098
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 332
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.48416
New value of Value function: 7.48416
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 333
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.08025
New value of Value function: 3.08025
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 334
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 7.00629
New value of Value function: 7.00629
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 335
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.67587
New value of Value function: 6.7433
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 336
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.57343
New value of Value function: 6.7433
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 337
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.33111
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 338
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: -0.752608
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 339
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.208293
New value of Value function: 1.22513
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 340
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.88744
New value of Value function: 0.208293
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 341
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 342
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: -0.719886
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 343
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: -0.689891
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 344
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: -0.763621
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3040
New value of Q matrix: 0.471584
New value of Value function: 0.471584
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3041
New value of Q matrix: 0.471583
New value of Value function: 0.471583
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3042
New value of Q matrix: 0.471581
New value of Value function: 0.471581
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3043
New value of Q matrix: 0.47158
New value of Value function: 0.47158
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3044
New value of Q matrix: 0.471578
New value of Value function: 0.471578
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 0.443058
New value of Value function: 0.471578
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3045
New value of Q matrix: 0.471577
New value of Value function: 0.471577
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3046
New value of Q matrix: 0.471575
New value of Value function: 0.471575
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3047
New value of Q matrix: 0.471573
New value of Value function: 0.471573
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3048
New value of Q matrix: 0.471572
New value of Value function: 0.471572
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3049
New value of Q matrix: 0.47157
New value of Value function: 0.47157
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3050
New value of Q matrix: 0.471569
New value of Value function: 0.471569
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3051
New value of Q matrix: 0.471567
New value of Value function: 0.471567
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3052
New value of Q matrix: 0.471566
New value of Value function: 0.471566
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3053
New value of Q matrix: 0.471564
New value of Value function: 0.471564
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3054
New value of Q matrix: 0.471563
New value of Value function: 0.471563
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3055
New value of Q matrix: 0.471561
New value of Value function: 0.471561
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3056
New value of Q matrix: 0.47156
New value of Value function: 0.47156
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3057
New value of Q matrix: 0.471558
New value of Value function: 0.471558
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3058
New value of Q matrix: 0.471556
New value of Value function: 0.471556
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3059
New value of Q matrix: 0.471555
New value of Value function: 0.471555
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3060
New value of Q matrix: 0.471553
New value of Value function: 0.471553
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3061
New value of Q matrix: 0.471552
New value of Value function: 0.471552
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3062
New value of Q matrix: 0.47155
New value of Value function: 0.47155
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3063
New value of Q matrix: 0.471549
New value of Value function: 0.471549
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3064
New value of Q matrix: 0.471547
New value of Value function: 0.471547
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 0.414703
New value of Value function: 0.471547
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0.420961
New value of Value function: 0.471547
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3065
New value of Q matrix: 0.471546
New value of Value function: 0.471546
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3066
New value of Q matrix: 0.471544
New value of Value function: 0.471544
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3067
New value of Q matrix: 0.471543
New value of Value function: 0.471543
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3068
New value of Q matrix: 0.471541
New value of Value function: 0.471541
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3069
New value of Q matrix: 0.47154
New value of Value function: 0.47154
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3070
New value of Q matrix: 0.471538
New value of Value function: 0.471538
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3071
New value of Q matrix: 0.471536
New value of Value function: 0.471536
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3072
New value of Q matrix: 0.471535
New value of Value function: 0.471535
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 0.414905
New value of Value function: 0.471535
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3073
New value of Q matrix: 0.471533
New value of Value function: 0.471533
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 0.415107
New value of Value function: 0.471533
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 0.415306
New value of Value function: 0.471533
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3074
New value of Q matrix: 0.471532
New value of Value function: 0.471532
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3075
New value of Q matrix: 0.47153
New value of Value function: 0.47153
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3076
New value of Q matrix: 0.471529
New value of Value function: 0.471529
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3077
New value of Q matrix: 0.471527
New value of Value function: 0.471527
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 0.422548
New value of Value function: 0.471527
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3078
New value of Q matrix: 0.471526
New value of Value function: 0.471526
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 0.443147
New value of Value function: 0.471526
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3079
New value of Q matrix: 0.471524
New value of Value function: 0.471524
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 0.415504
New value of Value function: 0.471524
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3080
New value of Q matrix: 0.471523
New value of Value function: 0.471523
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3081
New value of Q matrix: 0.471521
New value of Value function: 0.471521
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 0.421146
New value of Value function: 0.471521
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3082
New value of Q matrix: 0.47152
New value of Value function: 0.47152
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3083
New value of Q matrix: 0.471518
New value of Value function: 0.471518
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 0.422721
New value of Value function: 0.471518
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3084
New value of Q matrix: 0.471517
New value of Value function: 0.471517
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3085
New value of Q matrix: 0.471515
New value of Value function: 0.471515
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 0.415701
New value of Value function: 0.471515
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3086
New value of Q matrix: 0.471514
New value of Value function: 0.471514
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3087
New value of Q matrix: 0.471512
New value of Value function: 0.471512
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3088
New value of Q matrix: 0.47151
New value of Value function: 0.47151
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3089
New value of Q matrix: 0.471509
New value of Value function: 0.471509
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3090
New value of Q matrix: 0.471507
New value of Value function: 0.471507
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3091
New value of Q matrix: 0.471506
New value of Value function: 0.471506
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 0.415896
New value of Value function: 0.471506
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3092
New value of Q matrix: 0.471504
New value of Value function: 0.471504
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 0.416089
New value of Value function: 0.471504
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3093
New value of Q matrix: 0.471503
New value of Value function: 0.471503
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3094
New value of Q matrix: 0.471501
New value of Value function: 0.471501
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3095
New value of Q matrix: 0.4715
New value of Value function: 0.4715
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 0.421329
New value of Value function: 0.4715
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3096
New value of Q matrix: 0.471498
New value of Value function: 0.471498
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3097
New value of Q matrix: 0.471497
New value of Value function: 0.471497
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3098
New value of Q matrix: 0.471495
New value of Value function: 0.471495
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 0.422892
New value of Value function: 0.471495
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3099
New value of Q matrix: 0.471494
New value of Value function: 0.471494
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 0.443236
New value of Value function: 0.471494
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 0.443324
New value of Value function: 0.471494
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 0.423062
New value of Value function: 0.471494
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3100
New value of Q matrix: 0.471492
New value of Value function: 0.471492
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3101
New value of Q matrix: 0.471491
New value of Value function: 0.471491
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 0.416281
New value of Value function: 0.471491
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3102
New value of Q matrix: 0.471489
New value of Value function: 0.471489
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 0.443412
New value of Value function: 0.471489
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3103
New value of Q matrix: 0.471488
New value of Value function: 0.471488
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 0.443499
New value of Value function: 0.471488
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3104
New value of Q matrix: 0.471486
New value of Value function: 0.471486
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3105
New value of Q matrix: 0.471485
New value of Value function: 0.471485
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3106
New value of Q matrix: 0.471483
New value of Value function: 0.471483
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3107
New value of Q matrix: 0.471482
New value of Value function: 0.471482
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3108
New value of Q matrix: 0.47148
New value of Value function: 0.47148
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3109
New value of Q matrix: 0.471479
New value of Value function: 0.471479
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3110
New value of Q matrix: 0.471477
New value of Value function: 0.471477
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3111
New value of Q matrix: 0.471475
New value of Value function: 0.471475
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3112
New value of Q matrix: 0.471474
New value of Value function: 0.471474
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3113
New value of Q matrix: 0.471472
New value of Value function: 0.471472
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3114
New value of Q matrix: 0.471471
New value of Value function: 0.471471
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3115
New value of Q matrix: 0.471469
New value of Value function: 0.471469
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 0.421511
New value of Value function: 0.471469
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3116
New value of Q matrix: 0.471468
New value of Value function: 0.471468
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3117
New value of Q matrix: 0.471466
New value of Value function: 0.471466
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 0.421691
New value of Value function: 0.471466
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3118
New value of Q matrix: 0.471465
New value of Value function: 0.471465
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3119
New value of Q matrix: 0.471463
New value of Value function: 0.471463
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3120
New value of Q matrix: 0.471462
New value of Value function: 0.471462
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3121
New value of Q matrix: 0.47146
New value of Value function: 0.47146
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 0.42187
New value of Value function: 0.47146
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 0.416472
New value of Value function: 0.47146
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3122
New value of Q matrix: 0.471459
New value of Value function: 0.471459
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 0.422047
New value of Value function: 0.471459
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3123
New value of Q matrix: 0.471457
New value of Value function: 0.471457
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3124
New value of Q matrix: 0.471456
New value of Value function: 0.471456
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3125
New value of Q matrix: 0.471454
New value of Value function: 0.471454
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3126
New value of Q matrix: 0.471453
New value of Value function: 0.471453
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3127
New value of Q matrix: 0.471451
New value of Value function: 0.471451
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3128
New value of Q matrix: 0.47145
New value of Value function: 0.47145
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3129
New value of Q matrix: 0.471448
New value of Value function: 0.471448
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3130
New value of Q matrix: 0.471447
New value of Value function: 0.471447
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3131
New value of Q matrix: 0.471445
New value of Value function: 0.471445
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3132
New value of Q matrix: 0.471444
New value of Value function: 0.471444
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3133
New value of Q matrix: 0.471442
New value of Value function: 0.471442
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3134
New value of Q matrix: 0.472249
New value of Value function: 0.472249
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 467
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -0.0248575
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 468
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.61071
New value of Value function: 9.92525
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 469
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 3.2412
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 470
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.50386
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 471
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.4393
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 472
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 2.69002
New value of Value function: 2.69002
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 473
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 2.80178
New value of Value function: 2.80178
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 474
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 2.56697
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 475
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.2271
New value of Value function: 3.08025
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 476
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.07896
New value of Value function: 3.07896
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 477
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.23325
New value of Value function: 3.23325
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 478
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.31553
New value of Value function: 7.00629
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 479
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.85334
New value of Value function: 7.00629
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 480
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.24433
New value of Value function: 7.00629
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 481
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 7.07169
New value of Value function: 7.07169
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 482
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.9427
New value of Value function: 2.9427
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 483
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.39369
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 484
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.26699
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 485
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: -0.734251
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 486
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 27
New value of Q matrix: -0.800851
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3135
New value of Q matrix: 0.472248
New value of Value function: 0.472248
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3136
New value of Q matrix: 0.472246
New value of Value function: 0.472246
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3137
New value of Q matrix: 0.472245
New value of Value function: 0.472245
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3138
New value of Q matrix: 0.472243
New value of Value function: 0.472243
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3139
New value of Q matrix: 0.472242
New value of Value function: 0.472242
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3140
New value of Q matrix: 0.47224
New value of Value function: 0.47224
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3141
New value of Q matrix: 0.472239
New value of Value function: 0.472239
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3142
New value of Q matrix: 0.472237
New value of Value function: 0.472237
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3143
New value of Q matrix: 0.472236
New value of Value function: 0.472236
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3144
New value of Q matrix: 0.472234
New value of Value function: 0.472234
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 0.416664
New value of Value function: 0.472234
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3145
New value of Q matrix: 0.472233
New value of Value function: 0.472233
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3146
New value of Q matrix: 0.472231
New value of Value function: 0.472231
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3147
New value of Q matrix: 0.47223
New value of Value function: 0.47223
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 0.422226
New value of Value function: 0.47223
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3148
New value of Q matrix: 0.472228
New value of Value function: 0.472228
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3149
New value of Q matrix: 0.472227
New value of Value function: 0.472227
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3150
New value of Q matrix: 0.472225
New value of Value function: 0.472225
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 0.443588
New value of Value function: 0.472225
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3151
New value of Q matrix: 0.472224
New value of Value function: 0.472224
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3152
New value of Q matrix: 0.472222
New value of Value function: 0.472222
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3153
New value of Q matrix: 0.472221
New value of Value function: 0.472221
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3154
New value of Q matrix: 0.472219
New value of Value function: 0.472219
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 0.416854
New value of Value function: 0.472219
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3155
New value of Q matrix: 0.472218
New value of Value function: 0.472218
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 0.422404
New value of Value function: 0.472218
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 0.443676
New value of Value function: 0.472218
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 0.443763
New value of Value function: 0.472218
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 0.44385
New value of Value function: 0.472218
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3156
New value of Q matrix: 0.472216
New value of Value function: 0.472216
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 0.42258
New value of Value function: 0.472216
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3157
New value of Q matrix: 0.472215
New value of Value function: 0.472215
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3158
New value of Q matrix: 0.472213
New value of Value function: 0.472213
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3159
New value of Q matrix: 0.472212
New value of Value function: 0.472212
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3160
New value of Q matrix: 0.47221
New value of Value function: 0.47221
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3161
New value of Q matrix: 0.472209
New value of Value function: 0.472209
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 0.443937
New value of Value function: 0.472209
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3162
New value of Q matrix: 0.472207
New value of Value function: 0.472207
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 0.422755
New value of Value function: 0.472207
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3163
New value of Q matrix: 0.472206
New value of Value function: 0.472206
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3164
New value of Q matrix: 0.472204
New value of Value function: 0.472204
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3165
New value of Q matrix: 0.472203
New value of Value function: 0.472203
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 0.444022
New value of Value function: 0.472203
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3166
New value of Q matrix: 0.472201
New value of Value function: 0.472201
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3167
New value of Q matrix: 0.4722
New value of Value function: 0.4722
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3168
New value of Q matrix: 0.472198
New value of Value function: 0.472198
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 0.444107
New value of Value function: 0.472198
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3169
New value of Q matrix: 0.472197
New value of Value function: 0.472197
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 0.422928
New value of Value function: 0.472197
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3170
New value of Q matrix: 0.472195
New value of Value function: 0.472195
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3171
New value of Q matrix: 0.472194
New value of Value function: 0.472194
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3172
New value of Q matrix: 0.472192
New value of Value function: 0.472192
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3173
New value of Q matrix: 0.472191
New value of Value function: 0.472191
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3174
New value of Q matrix: 0.472189
New value of Value function: 0.472189
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 0.423234
New value of Value function: 0.472189
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3175
New value of Q matrix: 0.472188
New value of Value function: 0.472188
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3176
New value of Q matrix: 0.472186
New value of Value function: 0.472186
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3177
New value of Q matrix: 0.472185
New value of Value function: 0.472185
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3178
New value of Q matrix: 0.472183
New value of Value function: 0.472183
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3179
New value of Q matrix: 0.472182
New value of Value function: 0.472182
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3180
New value of Q matrix: 0.47218
New value of Value function: 0.47218
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3181
New value of Q matrix: 0.472179
New value of Value function: 0.472179
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 0.444192
New value of Value function: 0.472179
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3182
New value of Q matrix: 0.472177
New value of Value function: 0.472177
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3183
New value of Q matrix: 0.472176
New value of Value function: 0.472176
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3184
New value of Q matrix: 0.472174
New value of Value function: 0.472174
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3185
New value of Q matrix: 0.472173
New value of Value function: 0.472173
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3186
New value of Q matrix: 0.472171
New value of Value function: 0.472171
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 0.444275
New value of Value function: 0.472171
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3187
New value of Q matrix: 0.47217
New value of Value function: 0.47217
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3188
New value of Q matrix: 0.472168
New value of Value function: 0.472168
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3189
New value of Q matrix: 0.472167
New value of Value function: 0.472167
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3190
New value of Q matrix: 0.472165
New value of Value function: 0.472165
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3191
New value of Q matrix: 0.472164
New value of Value function: 0.472164
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3192
New value of Q matrix: 0.472163
New value of Value function: 0.472163
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3193
New value of Q matrix: 0.472161
New value of Value function: 0.472161
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3194
New value of Q matrix: 0.47216
New value of Value function: 0.47216
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3195
New value of Q matrix: 0.472158
New value of Value function: 0.472158
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 0.4231
New value of Value function: 0.472158
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 0.417043
New value of Value function: 0.472158
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 0.423404
New value of Value function: 0.472158
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3196
New value of Q matrix: 0.472157
New value of Value function: 0.472157
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3197
New value of Q matrix: 0.472155
New value of Value function: 0.472155
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 0.423572
New value of Value function: 0.472155
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 0.444358
New value of Value function: 0.472155
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3198
New value of Q matrix: 0.472154
New value of Value function: 0.472154
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3199
New value of Q matrix: 0.472152
New value of Value function: 0.472152
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3200
New value of Q matrix: 0.472151
New value of Value function: 0.472151
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3201
New value of Q matrix: 0.472149
New value of Value function: 0.472149
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3202
New value of Q matrix: 0.472148
New value of Value function: 0.472148
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3203
New value of Q matrix: 0.472146
New value of Value function: 0.472146
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 0.41723
New value of Value function: 0.472146
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 0.42374
New value of Value function: 0.472146
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 0.417416
New value of Value function: 0.472146
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3204
New value of Q matrix: 0.472145
New value of Value function: 0.472145
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3205
New value of Q matrix: 0.472143
New value of Value function: 0.472143
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3206
New value of Q matrix: 0.472142
New value of Value function: 0.472142
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3207
New value of Q matrix: 0.47214
New value of Value function: 0.47214
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 0.444441
New value of Value function: 0.47214
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3208
New value of Q matrix: 0.472139
New value of Value function: 0.472139
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3209
New value of Q matrix: 0.472137
New value of Value function: 0.472137
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3210
New value of Q matrix: 0.472136
New value of Value function: 0.472136
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3211
New value of Q matrix: 0.472134
New value of Value function: 0.472134
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3212
New value of Q matrix: 0.472133
New value of Value function: 0.472133
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3213
New value of Q matrix: 0.472132
New value of Value function: 0.472132
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3214
New value of Q matrix: 0.47213
New value of Value function: 0.47213
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3215
New value of Q matrix: 0.472129
New value of Value function: 0.472129
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 0.444522
New value of Value function: 0.472129
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3216
New value of Q matrix: 0.472127
New value of Value function: 0.472127
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3217
New value of Q matrix: 0.472126
New value of Value function: 0.472126
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3218
New value of Q matrix: 0.472124
New value of Value function: 0.472124
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3219
New value of Q matrix: 0.472123
New value of Value function: 0.472123
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 0.423906
New value of Value function: 0.472123
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3220
New value of Q matrix: 0.472121
New value of Value function: 0.472121
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 0.444603
New value of Value function: 0.472121
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3221
New value of Q matrix: 0.47212
New value of Value function: 0.47212
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3222
New value of Q matrix: 0.472118
New value of Value function: 0.472118
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3223
New value of Q matrix: 0.472117
New value of Value function: 0.472117
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 0.4176
New value of Value function: 0.472117
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 606
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 0.42327
New value of Value function: 0.472117
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3224
New value of Q matrix: 0.472115
New value of Value function: 0.472115
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3225
New value of Q matrix: 0.472114
New value of Value function: 0.472114
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 0.417783
New value of Value function: 0.472114
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3226
New value of Q matrix: 0.472112
New value of Value function: 0.472112
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3227
New value of Q matrix: 0.472111
New value of Value function: 0.472111
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3228
New value of Q matrix: 0.47211
New value of Value function: 0.47211
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3229
New value of Q matrix: 0.472108
New value of Value function: 0.472108
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3230
New value of Q matrix: 0.472107
New value of Value function: 0.472107
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3231
New value of Q matrix: 0.472105
New value of Value function: 0.472105
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 0.444684
New value of Value function: 0.472105
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3232
New value of Q matrix: 0.472104
New value of Value function: 0.472104
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3233
New value of Q matrix: 0.473677
New value of Value function: 0.473677
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 619
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.58374
New value of Value function: 2.58374
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 620
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 2.75099
New value of Value function: 2.75099
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 621
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.34645
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 622
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 623
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.43932
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 624
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 3.51363
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 625
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.39176
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 626
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 2.80045
New value of Value function: 2.80045
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 627
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 2.89703
New value of Value function: 2.89703
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 628
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.27508
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 629
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.86806
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 630
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.37049
New value of Value function: 2.89703
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 631
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 2.89577
New value of Value function: 2.89577
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 632
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 2.98033
New value of Value function: 2.98033
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 633
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 2.69798
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 634
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.68762
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 635
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 2.72445
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 636
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.20092
New value of Value function: 3.23325
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 637
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.23201
New value of Value function: 3.23201
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 638
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.3716
New value of Value function: 3.3716
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 639
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 7.06753
New value of Value function: 7.06753
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 640
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.71497
New value of Value function: 7.06753
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 641
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 2.80194
New value of Value function: 2.80194
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 642
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.37675
New value of Value function: 6.7433
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 643
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: -0.77225
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 644
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 0.534036
New value of Value function: 0.534036
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 645
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.20812
New value of Value function: 0.20812
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 646
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: -0.00258639
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3234
New value of Q matrix: 0.473676
New value of Value function: 0.473676
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3235
New value of Q matrix: 0.473674
New value of Value function: 0.473674
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 0.424076
New value of Value function: 0.473674
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3236
New value of Q matrix: 0.473673
New value of Value function: 0.473673
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 0.424246
New value of Value function: 0.473673
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3237
New value of Q matrix: 0.473672
New value of Value function: 0.473672
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 0.444769
New value of Value function: 0.473672
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3238
New value of Q matrix: 0.47367
New value of Value function: 0.47367
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3239
New value of Q matrix: 0.473669
New value of Value function: 0.473669
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3240
New value of Q matrix: 0.473667
New value of Value function: 0.473667
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3241
New value of Q matrix: 0.473666
New value of Value function: 0.473666
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3242
New value of Q matrix: 0.473664
New value of Value function: 0.473664
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3243
New value of Q matrix: 0.473663
New value of Value function: 0.473663
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3244
New value of Q matrix: 0.473661
New value of Value function: 0.473661
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3245
New value of Q matrix: 0.47366
New value of Value function: 0.47366
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3246
New value of Q matrix: 0.473658
New value of Value function: 0.473658
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 0.444854
New value of Value function: 0.473658
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3247
New value of Q matrix: 0.473657
New value of Value function: 0.473657
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3248
New value of Q matrix: 0.473656
New value of Value function: 0.473656
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3249
New value of Q matrix: 0.473654
New value of Value function: 0.473654
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3250
New value of Q matrix: 0.473653
New value of Value function: 0.473653
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 0.423445
New value of Value function: 0.473653
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3251
New value of Q matrix: 0.473651
New value of Value function: 0.473651
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3252
New value of Q matrix: 0.47365
New value of Value function: 0.47365
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3253
New value of Q matrix: 0.473648
New value of Value function: 0.473648
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3254
New value of Q matrix: 0.473647
New value of Value function: 0.473647
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3255
New value of Q matrix: 0.473645
New value of Value function: 0.473645
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3256
New value of Q matrix: 0.473644
New value of Value function: 0.473644
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3257
New value of Q matrix: 0.473642
New value of Value function: 0.473642
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3258
New value of Q matrix: 0.473641
New value of Value function: 0.473641
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 0.417971
New value of Value function: 0.473641
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 678
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3259
New value of Q matrix: 0.473639
New value of Value function: 0.473639
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3260
New value of Q matrix: 0.473638
New value of Value function: 0.473638
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3261
New value of Q matrix: 0.473637
New value of Value function: 0.473637
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3262
New value of Q matrix: 0.473635
New value of Value function: 0.473635
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 682
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3263
New value of Q matrix: 0.473634
New value of Value function: 0.473634
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 0.418157
New value of Value function: 0.473634
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3264
New value of Q matrix: 0.473632
New value of Value function: 0.473632
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3265
New value of Q matrix: 0.473631
New value of Value function: 0.473631
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 0.424413
New value of Value function: 0.473631
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3266
New value of Q matrix: 0.473629
New value of Value function: 0.473629
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3267
New value of Q matrix: 0.473628
New value of Value function: 0.473628
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3268
New value of Q matrix: 0.473626
New value of Value function: 0.473626
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3269
New value of Q matrix: 0.473625
New value of Value function: 0.473625
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3270
New value of Q matrix: 0.473624
New value of Value function: 0.473624
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 0.423619
New value of Value function: 0.473624
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3271
New value of Q matrix: 0.473622
New value of Value function: 0.473622
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 694
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 0.423791
New value of Value function: 0.473622
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 695
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 0.42458
New value of Value function: 0.473622
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 696
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3272
New value of Q matrix: 0.473621
New value of Value function: 0.473621
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 0.444938
New value of Value function: 0.473621
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3273
New value of Q matrix: 0.473619
New value of Value function: 0.473619
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3274
New value of Q matrix: 0.473618
New value of Value function: 0.473618
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3275
New value of Q matrix: 0.473616
New value of Value function: 0.473616
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3276
New value of Q matrix: 0.473615
New value of Value function: 0.473615
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3277
New value of Q matrix: 0.473613
New value of Value function: 0.473613
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 703
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3278
New value of Q matrix: 0.473612
New value of Value function: 0.473612
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3279
New value of Q matrix: 0.473611
New value of Value function: 0.473611
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3280
New value of Q matrix: 0.473609
New value of Value function: 0.473609
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3281
New value of Q matrix: 0.473608
New value of Value function: 0.473608
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3282
New value of Q matrix: 0.473606
New value of Value function: 0.473606
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3283
New value of Q matrix: 0.473605
New value of Value function: 0.473605
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3284
New value of Q matrix: 0.473603
New value of Value function: 0.473603
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3285
New value of Q matrix: 0.473602
New value of Value function: 0.473602
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3286
New value of Q matrix: 0.4736
New value of Value function: 0.4736
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 712
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3287
New value of Q matrix: 0.473599
New value of Value function: 0.473599
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 0.445021
New value of Value function: 0.473599
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3288
New value of Q matrix: 0.473598
New value of Value function: 0.473598
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 715
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 0.418341
New value of Value function: 0.473598
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 716
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3289
New value of Q matrix: 0.473596
New value of Value function: 0.473596
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3290
New value of Q matrix: 0.473595
New value of Value function: 0.473595
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 0.418524
New value of Value function: 0.473595
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3291
New value of Q matrix: 0.473593
New value of Value function: 0.473593
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3292
New value of Q matrix: 0.473592
New value of Value function: 0.473592
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3293
New value of Q matrix: 0.47359
New value of Value function: 0.47359
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 0.424745
New value of Value function: 0.47359
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3294
New value of Q matrix: 0.473589
New value of Value function: 0.473589
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3295
New value of Q matrix: 0.473587
New value of Value function: 0.473587
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 0.424909
New value of Value function: 0.473587
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3296
New value of Q matrix: 0.473586
New value of Value function: 0.473586
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3297
New value of Q matrix: 0.473585
New value of Value function: 0.473585
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3298
New value of Q matrix: 0.473583
New value of Value function: 0.473583
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3299
New value of Q matrix: 0.473582
New value of Value function: 0.473582
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3300
New value of Q matrix: 0.47358
New value of Value function: 0.47358
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 0.445104
New value of Value function: 0.47358
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 0.445186
New value of Value function: 0.47358
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 0.423961
New value of Value function: 0.47358
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3301
New value of Q matrix: 0.473579
New value of Value function: 0.473579
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 735
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3302
New value of Q matrix: 0.473577
New value of Value function: 0.473577
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3303
New value of Q matrix: 0.473576
New value of Value function: 0.473576
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3304
New value of Q matrix: 0.473575
New value of Value function: 0.473575
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3305
New value of Q matrix: 0.473573
New value of Value function: 0.473573
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 0.445268
New value of Value function: 0.473573
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 0.445349
New value of Value function: 0.473573
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3306
New value of Q matrix: 0.473572
New value of Value function: 0.473572
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 0.424131
New value of Value function: 0.473572
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3307
New value of Q matrix: 0.47357
New value of Value function: 0.47357
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3308
New value of Q matrix: 0.473569
New value of Value function: 0.473569
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 0.424299
New value of Value function: 0.473569
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3309
New value of Q matrix: 0.473567
New value of Value function: 0.473567
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3310
New value of Q matrix: 0.473566
New value of Value function: 0.473566
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3311
New value of Q matrix: 0.473565
New value of Value function: 0.473565
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 0.425072
New value of Value function: 0.473565
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3312
New value of Q matrix: 0.473563
New value of Value function: 0.473563
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 0.445429
New value of Value function: 0.473563
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 752
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3313
New value of Q matrix: 0.473562
New value of Value function: 0.473562
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3314
New value of Q matrix: 0.47356
New value of Value function: 0.47356
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3315
New value of Q matrix: 0.473559
New value of Value function: 0.473559
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3316
New value of Q matrix: 0.473557
New value of Value function: 0.473557
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 0.425233
New value of Value function: 0.473557
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3317
New value of Q matrix: 0.473556
New value of Value function: 0.473556
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 0.425394
New value of Value function: 0.473556
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3318
New value of Q matrix: 0.473555
New value of Value function: 0.473555
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 760
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3319
New value of Q matrix: 0.473553
New value of Value function: 0.473553
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3320
New value of Q matrix: 0.473552
New value of Value function: 0.473552
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3321
New value of Q matrix: 0.47355
New value of Value function: 0.47355
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3322
New value of Q matrix: 0.473549
New value of Value function: 0.473549
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 764
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 0.418706
New value of Value function: 0.473549
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3323
New value of Q matrix: 0.473547
New value of Value function: 0.473547
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3324
New value of Q matrix: 0.473546
New value of Value function: 0.473546
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3325
New value of Q matrix: 0.473545
New value of Value function: 0.473545
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 768
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3326
New value of Q matrix: 0.473543
New value of Value function: 0.473543
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 769
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3327
New value of Q matrix: 0.473542
New value of Value function: 0.473542
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 770
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3328
New value of Q matrix: 0.47354
New value of Value function: 0.47354
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 771
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 0.424465
New value of Value function: 0.47354
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 772
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3329
New value of Q matrix: 0.475117
New value of Value function: 0.475117
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 773
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.74916
New value of Value function: 2.74916
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 774
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.43033
New value of Value function: 2.74916
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 775
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.74744
New value of Value function: 2.74744
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 776
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 2.87554
New value of Value function: 2.87554
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 777
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.58793
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 778
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 3.64737
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 779
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.36234
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 780
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.858985
New value of Value function: 2.98033
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 781
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.33661
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 782
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 2.97914
New value of Value function: 2.97914
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 783
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.05399
New value of Value function: 3.05399
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 784
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 2.83449
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 785
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 2.85846
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 786
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.3704
New value of Value function: 3.3704
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 787
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.49545
New value of Value function: 3.49545
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 788
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 7.06361
New value of Value function: 7.06361
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 789
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 7.05799
New value of Value function: 7.05799
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 790
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.20547
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 791
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.652311
New value of Value function: 0.652311
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 792
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.16242
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 793
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: -0.723352
New value of Value function: 0.652311
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 794
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: -0.677714
New value of Value function: 0.652311
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 795
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.65068
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 796
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.552393
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 797
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: -0.635072
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 798
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.26482
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3330
New value of Q matrix: 0.475116
New value of Value function: 0.475116
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 0.418891
New value of Value function: 0.475116
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 0.424637
New value of Value function: 0.475116
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3331
New value of Q matrix: 0.475114
New value of Value function: 0.475114
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 0.445514
New value of Value function: 0.475114
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3332
New value of Q matrix: 0.475113
New value of Value function: 0.475113
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3333
New value of Q matrix: 0.475112
New value of Value function: 0.475112
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3334
New value of Q matrix: 0.47511
New value of Value function: 0.47511
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 0.424807
New value of Value function: 0.47511
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3335
New value of Q matrix: 0.475109
New value of Value function: 0.475109
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3336
New value of Q matrix: 0.475107
New value of Value function: 0.475107
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3337
New value of Q matrix: 0.475106
New value of Value function: 0.475106
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3338
New value of Q matrix: 0.475104
New value of Value function: 0.475104
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3339
New value of Q matrix: 0.475103
New value of Value function: 0.475103
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3340
New value of Q matrix: 0.475102
New value of Value function: 0.475102
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3341
New value of Q matrix: 0.4751
New value of Value function: 0.4751
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3342
New value of Q matrix: 0.475099
New value of Value function: 0.475099
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3343
New value of Q matrix: 0.475097
New value of Value function: 0.475097
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3344
New value of Q matrix: 0.475096
New value of Value function: 0.475096
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3345
New value of Q matrix: 0.475095
New value of Value function: 0.475095
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 0.424975
New value of Value function: 0.475095
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3346
New value of Q matrix: 0.475093
New value of Value function: 0.475093
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3347
New value of Q matrix: 0.475092
New value of Value function: 0.475092
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3348
New value of Q matrix: 0.47509
New value of Value function: 0.47509
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3349
New value of Q matrix: 0.475089
New value of Value function: 0.475089
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3350
New value of Q matrix: 0.475087
New value of Value function: 0.475087
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 0.419076
New value of Value function: 0.475087
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3351
New value of Q matrix: 0.475086
New value of Value function: 0.475086
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3352
New value of Q matrix: 0.475085
New value of Value function: 0.475085
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3353
New value of Q matrix: 0.475083
New value of Value function: 0.475083
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3354
New value of Q matrix: 0.475082
New value of Value function: 0.475082
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3355
New value of Q matrix: 0.47508
New value of Value function: 0.47508
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 0.425558
New value of Value function: 0.47508
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3356
New value of Q matrix: 0.475079
New value of Value function: 0.475079
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3357
New value of Q matrix: 0.475078
New value of Value function: 0.475078
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3358
New value of Q matrix: 0.475076
New value of Value function: 0.475076
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3359
New value of Q matrix: 0.475075
New value of Value function: 0.475075
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3360
New value of Q matrix: 0.475073
New value of Value function: 0.475073
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3361
New value of Q matrix: 0.475072
New value of Value function: 0.475072
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3362
New value of Q matrix: 0.47507
New value of Value function: 0.47507
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3363
New value of Q matrix: 0.475069
New value of Value function: 0.475069
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3364
New value of Q matrix: 0.475068
New value of Value function: 0.475068
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3365
New value of Q matrix: 0.475066
New value of Value function: 0.475066
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 0.425143
New value of Value function: 0.475066
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3366
New value of Q matrix: 0.475065
New value of Value function: 0.475065
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3367
New value of Q matrix: 0.475063
New value of Value function: 0.475063
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 0.425309
New value of Value function: 0.475063
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3368
New value of Q matrix: 0.475062
New value of Value function: 0.475062
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3369
New value of Q matrix: 0.475061
New value of Value function: 0.475061
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3370
New value of Q matrix: 0.475059
New value of Value function: 0.475059
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3371
New value of Q matrix: 0.475058
New value of Value function: 0.475058
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3372
New value of Q matrix: 0.475056
New value of Value function: 0.475056
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 0.425473
New value of Value function: 0.475056
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 0.445599
New value of Value function: 0.475056
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3373
New value of Q matrix: 0.475055
New value of Value function: 0.475055
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3374
New value of Q matrix: 0.475054
New value of Value function: 0.475054
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3375
New value of Q matrix: 0.475052
New value of Value function: 0.475052
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3376
New value of Q matrix: 0.475051
New value of Value function: 0.475051
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3377
New value of Q matrix: 0.475049
New value of Value function: 0.475049
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3378
New value of Q matrix: 0.475048
New value of Value function: 0.475048
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3379
New value of Q matrix: 0.475046
New value of Value function: 0.475046
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3380
New value of Q matrix: 0.475045
New value of Value function: 0.475045
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3381
New value of Q matrix: 0.475044
New value of Value function: 0.475044
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 0.425637
New value of Value function: 0.475044
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3382
New value of Q matrix: 0.475042
New value of Value function: 0.475042
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3383
New value of Q matrix: 0.475041
New value of Value function: 0.475041
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3384
New value of Q matrix: 0.475039
New value of Value function: 0.475039
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3385
New value of Q matrix: 0.475038
New value of Value function: 0.475038
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3386
New value of Q matrix: 0.475037
New value of Value function: 0.475037
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3387
New value of Q matrix: 0.475035
New value of Value function: 0.475035
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3388
New value of Q matrix: 0.475034
New value of Value function: 0.475034
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3389
New value of Q matrix: 0.475032
New value of Value function: 0.475032
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 0.445682
New value of Value function: 0.475032
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3390
New value of Q matrix: 0.475031
New value of Value function: 0.475031
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 0.419259
New value of Value function: 0.475031
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3391
New value of Q matrix: 0.47503
New value of Value function: 0.47503
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3392
New value of Q matrix: 0.475028
New value of Value function: 0.475028
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 0.425799
New value of Value function: 0.475028
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3393
New value of Q matrix: 0.475027
New value of Value function: 0.475027
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 0.425721
New value of Value function: 0.475027
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3394
New value of Q matrix: 0.475025
New value of Value function: 0.475025
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3395
New value of Q matrix: 0.475024
New value of Value function: 0.475024
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3396
New value of Q matrix: 0.475023
New value of Value function: 0.475023
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3397
New value of Q matrix: 0.475021
New value of Value function: 0.475021
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3398
New value of Q matrix: 0.47502
New value of Value function: 0.47502
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3399
New value of Q matrix: 0.475018
New value of Value function: 0.475018
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3400
New value of Q matrix: 0.475017
New value of Value function: 0.475017
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3401
New value of Q matrix: 0.475016
New value of Value function: 0.475016
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3402
New value of Q matrix: 0.475014
New value of Value function: 0.475014
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 0.425883
New value of Value function: 0.475014
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3403
New value of Q matrix: 0.475013
New value of Value function: 0.475013
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 0.445765
New value of Value function: 0.475013
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3404
New value of Q matrix: 0.475011
New value of Value function: 0.475011
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3405
New value of Q matrix: 0.47501
New value of Value function: 0.47501
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 0.426044
New value of Value function: 0.47501
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 894
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3406
New value of Q matrix: 0.475009
New value of Value function: 0.475009
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 0.41944
New value of Value function: 0.475009
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3407
New value of Q matrix: 0.475007
New value of Value function: 0.475007
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 897
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3408
New value of Q matrix: 0.475006
New value of Value function: 0.475006
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 0.445848
New value of Value function: 0.475006
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3409
New value of Q matrix: 0.475005
New value of Value function: 0.475005
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 900
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3410
New value of Q matrix: 0.475003
New value of Value function: 0.475003
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 901
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 0.44593
New value of Value function: 0.475003
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 902
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3411
New value of Q matrix: 0.475002
New value of Value function: 0.475002
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 903
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3412
New value of Q matrix: 0.475
New value of Value function: 0.475
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 904
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3413
New value of Q matrix: 0.474999
New value of Value function: 0.474999
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 905
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 0.41962
New value of Value function: 0.474999
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 906
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3414
New value of Q matrix: 0.474998
New value of Value function: 0.474998
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 907
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 0.42596
New value of Value function: 0.474998
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 908
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3415
New value of Q matrix: 0.474996
New value of Value function: 0.474996
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 909
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3416
New value of Q matrix: 0.474995
New value of Value function: 0.474995
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 910
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3417
New value of Q matrix: 0.474993
New value of Value function: 0.474993
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 911
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3418
New value of Q matrix: 0.474992
New value of Value function: 0.474992
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 912
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3419
New value of Q matrix: 0.474991
New value of Value function: 0.474991
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 913
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3420
New value of Q matrix: 0.474989
New value of Value function: 0.474989
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3421
New value of Q matrix: 0.474988
New value of Value function: 0.474988
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 915
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3422
New value of Q matrix: 0.4766
New value of Value function: 0.4766
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 916
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.99267
New value of Value function: 3.0229
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 917
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.93485
New value of Value function: 2.99267
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 918
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 2.98942
New value of Value function: 2.98942
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 919
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.30317
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 920
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 3.08608
New value of Value function: 3.08608
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 921
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.25648
New value of Value function: 9.92525
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 922
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.71545
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 923
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.77687
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 924
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.677
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 925
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.05286
New value of Value function: 3.05286
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 926
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.854385
New value of Value function: 3.05286
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 927
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.11973
New value of Value function: 3.11973
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 928
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 2.95241
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 929
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 2.9745
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 930
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.33071
New value of Value function: 3.49545
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 931
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.37397
New value of Value function: 3.49545
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 932
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.61185
New value of Value function: 3.61185
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 933
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 7.05446
New value of Value function: 7.05446
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 934
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 7.03644
New value of Value function: 7.03644
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 935
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.96607
New value of Value function: 6.96607
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 936
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 7.03007
New value of Value function: 7.03007
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 937
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.44121
New value of Value function: 6.96607
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 938
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.01436
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 939
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.1254
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 940
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.644173
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 941
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4005
	Distance: 6
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: -0.615226
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 942
----------
State: 4005
	Distance: 6
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.322087
New value of Value function: 0.322087
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 943
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: -0.577063
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 944
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 34
New value of Q matrix: -0.634448
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 945
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3423
New value of Q matrix: 0.476599
New value of Value function: 0.476599
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3424
New value of Q matrix: 0.476597
New value of Value function: 0.476597
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3425
New value of Q matrix: 0.476596
New value of Value function: 0.476596
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3426
New value of Q matrix: 0.476595
New value of Value function: 0.476595
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3427
New value of Q matrix: 0.476593
New value of Value function: 0.476593
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3428
New value of Q matrix: 0.476592
New value of Value function: 0.476592
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3429
New value of Q matrix: 0.476591
New value of Value function: 0.476591
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3430
New value of Q matrix: 0.476589
New value of Value function: 0.476589
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3431
New value of Q matrix: 0.476588
New value of Value function: 0.476588
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 0.426126
New value of Value function: 0.476588
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3432
New value of Q matrix: 0.476586
New value of Value function: 0.476586
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3433
New value of Q matrix: 0.476585
New value of Value function: 0.476585
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3434
New value of Q matrix: 0.476584
New value of Value function: 0.476584
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3435
New value of Q matrix: 0.476582
New value of Value function: 0.476582
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 959
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3436
New value of Q matrix: 0.476581
New value of Value function: 0.476581
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 960
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3437
New value of Q matrix: 0.476579
New value of Value function: 0.476579
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 961
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3438
New value of Q matrix: 0.476578
New value of Value function: 0.476578
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 0.419805
New value of Value function: 0.476578
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 963
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3439
New value of Q matrix: 0.476577
New value of Value function: 0.476577
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 964
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 0.426209
New value of Value function: 0.476577
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 965
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 0.426373
New value of Value function: 0.476577
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3440
New value of Q matrix: 0.476575
New value of Value function: 0.476575
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3441
New value of Q matrix: 0.476574
New value of Value function: 0.476574
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3442
New value of Q matrix: 0.476572
New value of Value function: 0.476572
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 969
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 0.446016
New value of Value function: 0.476572
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 0.419988
New value of Value function: 0.476572
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 0.42629
New value of Value function: 0.476572
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 0.42017
New value of Value function: 0.476572
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 973
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3443
New value of Q matrix: 0.476571
New value of Value function: 0.476571
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 0.42035
New value of Value function: 0.476571
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3444
New value of Q matrix: 0.47657
New value of Value function: 0.47657
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 0.426453
New value of Value function: 0.47657
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3445
New value of Q matrix: 0.476568
New value of Value function: 0.476568
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 978
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3446
New value of Q matrix: 0.476567
New value of Value function: 0.476567
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 0.426615
New value of Value function: 0.476567
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3447
New value of Q matrix: 0.476566
New value of Value function: 0.476566
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3448
New value of Q matrix: 0.476564
New value of Value function: 0.476564
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3449
New value of Q matrix: 0.476563
New value of Value function: 0.476563
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3450
New value of Q matrix: 0.476561
New value of Value function: 0.476561
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3451
New value of Q matrix: 0.47656
New value of Value function: 0.47656
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 0.446102
New value of Value function: 0.47656
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 986
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3452
New value of Q matrix: 0.476559
New value of Value function: 0.476559
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 987
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3453
New value of Q matrix: 0.476557
New value of Value function: 0.476557
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3454
New value of Q matrix: 0.476556
New value of Value function: 0.476556
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3455
New value of Q matrix: 0.476555
New value of Value function: 0.476555
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3456
New value of Q matrix: 0.476553
New value of Value function: 0.476553
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3457
New value of Q matrix: 0.476552
New value of Value function: 0.476552
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3458
New value of Q matrix: 0.47655
New value of Value function: 0.47655
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 0.426776
New value of Value function: 0.47655
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3459
New value of Q matrix: 0.476549
New value of Value function: 0.476549
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 0.426536
New value of Value function: 0.476549
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3460
New value of Q matrix: 0.476548
New value of Value function: 0.476548
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3461
New value of Q matrix: 0.476546
New value of Value function: 0.476546
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3462
New value of Q matrix: 0.476545
New value of Value function: 0.476545
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3463
New value of Q matrix: 0.476543
New value of Value function: 0.476543
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3464
New value of Q matrix: 0.476542
New value of Value function: 0.476542
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3465
New value of Q matrix: 0.476541
New value of Value function: 0.476541
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3466
New value of Q matrix: 0.476539
New value of Value function: 0.476539
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 0.426936
New value of Value function: 0.476539
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3467
New value of Q matrix: 0.476538
New value of Value function: 0.476538
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3468
New value of Q matrix: 0.476537
New value of Value function: 0.476537
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3469
New value of Q matrix: 0.476535
New value of Value function: 0.476535
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 0.426698
New value of Value function: 0.476535
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3470
New value of Q matrix: 0.476534
New value of Value function: 0.476534
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3471
New value of Q matrix: 0.476532
New value of Value function: 0.476532
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3472
New value of Q matrix: 0.476531
New value of Value function: 0.476531
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3473
New value of Q matrix: 0.47653
New value of Value function: 0.47653
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3474
New value of Q matrix: 0.476528
New value of Value function: 0.476528
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 0.420529
New value of Value function: 0.476528
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 0.446187
New value of Value function: 0.476528
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3475
New value of Q matrix: 0.476527
New value of Value function: 0.476527
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3476
New value of Q matrix: 0.476526
New value of Value function: 0.476526
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3477
New value of Q matrix: 0.476524
New value of Value function: 0.476524
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3478
New value of Q matrix: 0.476523
New value of Value function: 0.476523
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3479
New value of Q matrix: 0.476522
New value of Value function: 0.476522
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3480
New value of Q matrix: 0.47652
New value of Value function: 0.47652
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3481
New value of Q matrix: 0.476519
New value of Value function: 0.476519
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3482
New value of Q matrix: 0.476517
New value of Value function: 0.476517
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3483
New value of Q matrix: 0.476516
New value of Value function: 0.476516
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3484
New value of Q matrix: 0.476515
New value of Value function: 0.476515
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3485
New value of Q matrix: 0.476513
New value of Value function: 0.476513
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3486
New value of Q matrix: 0.476512
New value of Value function: 0.476512
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3487
New value of Q matrix: 0.476511
New value of Value function: 0.476511
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3488
New value of Q matrix: 0.476509
New value of Value function: 0.476509
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3489
New value of Q matrix: 0.476508
New value of Value function: 0.476508
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 0.420707
New value of Value function: 0.476508
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 0.426858
New value of Value function: 0.476508
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 0.420884
New value of Value function: 0.476508
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3490
New value of Q matrix: 0.476506
New value of Value function: 0.476506
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3491
New value of Q matrix: 0.476505
New value of Value function: 0.476505
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3492
New value of Q matrix: 0.476504
New value of Value function: 0.476504
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 0.427017
New value of Value function: 0.476504
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 0.427094
New value of Value function: 0.476504
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3493
New value of Q matrix: 0.476502
New value of Value function: 0.476502
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3494
New value of Q matrix: 0.476501
New value of Value function: 0.476501
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3495
New value of Q matrix: 0.4765
New value of Value function: 0.4765
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 0.427175
New value of Value function: 0.4765
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 0.427332
New value of Value function: 0.4765
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3496
New value of Q matrix: 0.476498
New value of Value function: 0.476498
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 0.421059
New value of Value function: 0.476498
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3497
New value of Q matrix: 0.476497
New value of Value function: 0.476497
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3498
New value of Q matrix: 0.476496
New value of Value function: 0.476496
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 0.446272
New value of Value function: 0.476496
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3499
New value of Q matrix: 0.476494
New value of Value function: 0.476494
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3500
New value of Q matrix: 0.476493
New value of Value function: 0.476493
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3501
New value of Q matrix: 0.476491
New value of Value function: 0.476491
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 0.427251
New value of Value function: 0.476491
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 0.421233
New value of Value function: 0.476491
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3502
New value of Q matrix: 0.47649
New value of Value function: 0.47649
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 0.446356
New value of Value function: 0.47649
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3503
New value of Q matrix: 0.476489
New value of Value function: 0.476489
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3504
New value of Q matrix: 0.476487
New value of Value function: 0.476487
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3505
New value of Q matrix: 0.476486
New value of Value function: 0.476486
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 0.446439
New value of Value function: 0.476486
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3506
New value of Q matrix: 0.476485
New value of Value function: 0.476485
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 0.421406
New value of Value function: 0.476485
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 0.427488
New value of Value function: 0.476485
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3507
New value of Q matrix: 0.476483
New value of Value function: 0.476483
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3508
New value of Q matrix: 0.476482
New value of Value function: 0.476482
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3509
New value of Q matrix: 0.476481
New value of Value function: 0.476481
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3510
New value of Q matrix: 0.476479
New value of Value function: 0.476479
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3511
New value of Q matrix: 0.476478
New value of Value function: 0.476478
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3512
New value of Q matrix: 0.476477
New value of Value function: 0.476477
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3513
New value of Q matrix: 0.476475
New value of Value function: 0.476475
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3514
New value of Q matrix: 0.476474
New value of Value function: 0.476474
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3515
New value of Q matrix: 0.476472
New value of Value function: 0.476472
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3516
New value of Q matrix: 0.476471
New value of Value function: 0.476471
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3517
New value of Q matrix: 0.47647
New value of Value function: 0.47647
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 0.446522
New value of Value function: 0.47647
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3518
New value of Q matrix: 0.476468
New value of Value function: 0.476468
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3519
New value of Q matrix: 0.476467
New value of Value function: 0.476467
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3520
New value of Q matrix: 0.476466
New value of Value function: 0.476466
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3521
New value of Q matrix: 0.476464
New value of Value function: 0.476464
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3522
New value of Q matrix: 0.476463
New value of Value function: 0.476463
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3523
New value of Q matrix: 0.476462
New value of Value function: 0.476462
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3524
New value of Q matrix: 0.47646
New value of Value function: 0.47646
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3525
New value of Q matrix: 0.476459
New value of Value function: 0.476459
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3526
New value of Q matrix: 0.476458
New value of Value function: 0.476458
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 0.427407
New value of Value function: 0.476458
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3527
New value of Q matrix: 0.476456
New value of Value function: 0.476456
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3528
New value of Q matrix: 0.476455
New value of Value function: 0.476455
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3529
New value of Q matrix: 0.476454
New value of Value function: 0.476454
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3530
New value of Q matrix: 0.476452
New value of Value function: 0.476452
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 0.427642
New value of Value function: 0.476452
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3531
New value of Q matrix: 0.476451
New value of Value function: 0.476451
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3532
New value of Q matrix: 0.476449
New value of Value function: 0.476449
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3533
New value of Q matrix: 0.476448
New value of Value function: 0.476448
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3534
New value of Q matrix: 0.476447
New value of Value function: 0.476447
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3535
New value of Q matrix: 0.476445
New value of Value function: 0.476445
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3536
New value of Q matrix: 0.476444
New value of Value function: 0.476444
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 0.446605
New value of Value function: 0.476444
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3537
New value of Q matrix: 0.476443
New value of Value function: 0.476443
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3538
New value of Q matrix: 0.476441
New value of Value function: 0.476441
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 0.446686
New value of Value function: 0.476441
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3539
New value of Q matrix: 0.47644
New value of Value function: 0.47644
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3540
New value of Q matrix: 0.476439
New value of Value function: 0.476439
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3541
New value of Q matrix: 0.476437
New value of Value function: 0.476437
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3542
New value of Q matrix: 0.476436
New value of Value function: 0.476436
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3543
New value of Q matrix: 0.476435
New value of Value function: 0.476435
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 0.446767
New value of Value function: 0.476435
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3544
New value of Q matrix: 0.476433
New value of Value function: 0.476433
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 0.421578
New value of Value function: 0.476433
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3545
New value of Q matrix: 0.476432
New value of Value function: 0.476432
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3546
New value of Q matrix: 0.476431
New value of Value function: 0.476431
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3547
New value of Q matrix: 0.476429
New value of Value function: 0.476429
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3548
New value of Q matrix: 0.476428
New value of Value function: 0.476428
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3549
New value of Q matrix: 0.476427
New value of Value function: 0.476427
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3550
New value of Q matrix: 0.476425
New value of Value function: 0.476425
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 0.427562
New value of Value function: 0.476425
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3551
New value of Q matrix: 0.476424
New value of Value function: 0.476424
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3552
New value of Q matrix: 0.476423
New value of Value function: 0.476423
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3553
New value of Q matrix: 0.476421
New value of Value function: 0.476421
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3554
New value of Q matrix: 0.47642
New value of Value function: 0.47642
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3555
New value of Q matrix: 0.476419
New value of Value function: 0.476419
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3556
New value of Q matrix: 0.476417
New value of Value function: 0.476417
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3557
New value of Q matrix: 0.476416
New value of Value function: 0.476416
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3558
New value of Q matrix: 0.476415
New value of Value function: 0.476415
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3559
New value of Q matrix: 0.477124
New value of Value function: 0.477124
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 123
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 124
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: -0.0155792
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 125
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: -0.0149301
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 126
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.20232
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 127
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 0.336113
New value of Value function: 0.336113
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 128
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.50572
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 129
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 3.97243
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 130
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.63418
New value of Value function: 3.05632
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 131
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.85901
New value of Value function: 9.85901
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 132
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 33
New value of Q matrix: 4.3906
New value of Value function: 4.90809
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 133
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.95208
New value of Value function: 9.85901
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 134
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.85901
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 135
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 34
New value of Q matrix: 4.40148
New value of Value function: 4.90809
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 136
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.90114
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 137
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.26249
New value of Value function: 3.26249
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 138
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 139
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.81453
New value of Value function: 9.81453
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 140
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 3.94822
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 141
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 142
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.84513
New value of Value function: 2.84513
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 143
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 3.65682
New value of Value function: 3.65682
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 144
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.41823
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 145
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.47694
New value of Value function: 3.65682
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 146
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.52471
New value of Value function: 3.65682
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 147
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 3.2012
New value of Value function: 3.52471
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 148
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.6526
New value of Value function: 10.6526
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 149
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.70558
New value of Value function: 5.70558
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 150
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.81692
New value of Value function: 5.81692
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 151
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.34823
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 152
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.193715
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 153
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: -0.0784212
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 0.427718
New value of Value function: 0.477124
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3560
New value of Q matrix: 0.477122
New value of Value function: 0.477122
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3561
New value of Q matrix: 0.477121
New value of Value function: 0.477121
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3562
New value of Q matrix: 0.47712
New value of Value function: 0.47712
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3563
New value of Q matrix: 0.477118
New value of Value function: 0.477118
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3564
New value of Q matrix: 0.477117
New value of Value function: 0.477117
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3565
New value of Q matrix: 0.477116
New value of Value function: 0.477116
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3566
New value of Q matrix: 0.477114
New value of Value function: 0.477114
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3567
New value of Q matrix: 0.477113
New value of Value function: 0.477113
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3568
New value of Q matrix: 0.477112
New value of Value function: 0.477112
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3569
New value of Q matrix: 0.47711
New value of Value function: 0.47711
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3570
New value of Q matrix: 0.477109
New value of Value function: 0.477109
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3571
New value of Q matrix: 0.477108
New value of Value function: 0.477108
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3572
New value of Q matrix: 0.477106
New value of Value function: 0.477106
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 0.427798
New value of Value function: 0.477106
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 0.44685
New value of Value function: 0.477106
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 0.446932
New value of Value function: 0.477106
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 0.427953
New value of Value function: 0.477106
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3573
New value of Q matrix: 0.477105
New value of Value function: 0.477105
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3574
New value of Q matrix: 0.477104
New value of Value function: 0.477104
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3575
New value of Q matrix: 0.477102
New value of Value function: 0.477102
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3576
New value of Q matrix: 0.477101
New value of Value function: 0.477101
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3577
New value of Q matrix: 0.4771
New value of Value function: 0.4771
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3578
New value of Q matrix: 0.477098
New value of Value function: 0.477098
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3579
New value of Q matrix: 0.477097
New value of Value function: 0.477097
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3580
New value of Q matrix: 0.477096
New value of Value function: 0.477096
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3581
New value of Q matrix: 0.477094
New value of Value function: 0.477094
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 0.428106
New value of Value function: 0.477094
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3582
New value of Q matrix: 0.477093
New value of Value function: 0.477093
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3583
New value of Q matrix: 0.477092
New value of Value function: 0.477092
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3584
New value of Q matrix: 0.47709
New value of Value function: 0.47709
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 0.427873
New value of Value function: 0.47709
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 0.428027
New value of Value function: 0.47709
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3585
New value of Q matrix: 0.477089
New value of Value function: 0.477089
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3586
New value of Q matrix: 0.477088
New value of Value function: 0.477088
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3587
New value of Q matrix: 0.477086
New value of Value function: 0.477086
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3588
New value of Q matrix: 0.477085
New value of Value function: 0.477085
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 0.42175
New value of Value function: 0.477085
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3589
New value of Q matrix: 0.477084
New value of Value function: 0.477084
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 0.428259
New value of Value function: 0.477084
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3590
New value of Q matrix: 0.477082
New value of Value function: 0.477082
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3591
New value of Q matrix: 0.477081
New value of Value function: 0.477081
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3592
New value of Q matrix: 0.47708
New value of Value function: 0.47708
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3593
New value of Q matrix: 0.477078
New value of Value function: 0.477078
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3594
New value of Q matrix: 0.477077
New value of Value function: 0.477077
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3595
New value of Q matrix: 0.477076
New value of Value function: 0.477076
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 0.428179
New value of Value function: 0.477076
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3596
New value of Q matrix: 0.477074
New value of Value function: 0.477074
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3597
New value of Q matrix: 0.477073
New value of Value function: 0.477073
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3598
New value of Q matrix: 0.477072
New value of Value function: 0.477072
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3599
New value of Q matrix: 0.47707
New value of Value function: 0.47707
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3600
New value of Q matrix: 0.477069
New value of Value function: 0.477069
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 0.447014
New value of Value function: 0.477069
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3601
New value of Q matrix: 0.477068
New value of Value function: 0.477068
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3602
New value of Q matrix: 0.477066
New value of Value function: 0.477066
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3603
New value of Q matrix: 0.477065
New value of Value function: 0.477065
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3604
New value of Q matrix: 0.477064
New value of Value function: 0.477064
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3605
New value of Q matrix: 0.477062
New value of Value function: 0.477062
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3606
New value of Q matrix: 0.477061
New value of Value function: 0.477061
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3607
New value of Q matrix: 0.47706
New value of Value function: 0.47706
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 0.428331
New value of Value function: 0.47706
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 0.428481
New value of Value function: 0.47706
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3608
New value of Q matrix: 0.477058
New value of Value function: 0.477058
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3609
New value of Q matrix: 0.477057
New value of Value function: 0.477057
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 0.42841
New value of Value function: 0.477057
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3610
New value of Q matrix: 0.477056
New value of Value function: 0.477056
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3611
New value of Q matrix: 0.477054
New value of Value function: 0.477054
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3612
New value of Q matrix: 0.477053
New value of Value function: 0.477053
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 0.428631
New value of Value function: 0.477053
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3613
New value of Q matrix: 0.477052
New value of Value function: 0.477052
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3614
New value of Q matrix: 0.47705
New value of Value function: 0.47705
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 0.447095
New value of Value function: 0.47705
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3615
New value of Q matrix: 0.477049
New value of Value function: 0.477049
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 0.447175
New value of Value function: 0.477049
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3616
New value of Q matrix: 0.477048
New value of Value function: 0.477048
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3617
New value of Q matrix: 0.477047
New value of Value function: 0.477047
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3618
New value of Q matrix: 0.477045
New value of Value function: 0.477045
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3619
New value of Q matrix: 0.477044
New value of Value function: 0.477044
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3620
New value of Q matrix: 0.477043
New value of Value function: 0.477043
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 0.421921
New value of Value function: 0.477043
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3621
New value of Q matrix: 0.477041
New value of Value function: 0.477041
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3622
New value of Q matrix: 0.47704
New value of Value function: 0.47704
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 0.422092
New value of Value function: 0.47704
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3623
New value of Q matrix: 0.477039
New value of Value function: 0.477039
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3624
New value of Q matrix: 0.477037
New value of Value function: 0.477037
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 0.42856
New value of Value function: 0.477037
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3625
New value of Q matrix: 0.477036
New value of Value function: 0.477036
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3626
New value of Q matrix: 0.477035
New value of Value function: 0.477035
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3627
New value of Q matrix: 0.477033
New value of Value function: 0.477033
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3628
New value of Q matrix: 0.477032
New value of Value function: 0.477032
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3629
New value of Q matrix: 0.477031
New value of Value function: 0.477031
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 0.428709
New value of Value function: 0.477031
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3630
New value of Q matrix: 0.477029
New value of Value function: 0.477029
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3631
New value of Q matrix: 0.477028
New value of Value function: 0.477028
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3632
New value of Q matrix: 0.477027
New value of Value function: 0.477027
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3633
New value of Q matrix: 0.477025
New value of Value function: 0.477025
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3634
New value of Q matrix: 0.477024
New value of Value function: 0.477024
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 0.447255
New value of Value function: 0.477024
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3635
New value of Q matrix: 0.477023
New value of Value function: 0.477023
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 0.428779
New value of Value function: 0.477023
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3636
New value of Q matrix: 0.477022
New value of Value function: 0.477022
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3637
New value of Q matrix: 0.47702
New value of Value function: 0.47702
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 0.428857
New value of Value function: 0.47702
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3638
New value of Q matrix: 0.477019
New value of Value function: 0.477019
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 0.447334
New value of Value function: 0.477019
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3639
New value of Q matrix: 0.477018
New value of Value function: 0.477018
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3640
New value of Q matrix: 0.477016
New value of Value function: 0.477016
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 0.428927
New value of Value function: 0.477016
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3641
New value of Q matrix: 0.477015
New value of Value function: 0.477015
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3642
New value of Q matrix: 0.477014
New value of Value function: 0.477014
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 0.429073
New value of Value function: 0.477014
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3643
New value of Q matrix: 0.477012
New value of Value function: 0.477012
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3644
New value of Q matrix: 0.477011
New value of Value function: 0.477011
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 0.429004
New value of Value function: 0.477011
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3645
New value of Q matrix: 0.47701
New value of Value function: 0.47701
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3646
New value of Q matrix: 0.477008
New value of Value function: 0.477008
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 0.429151
New value of Value function: 0.477008
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 0.429296
New value of Value function: 0.477008
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 0.447413
New value of Value function: 0.477008
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3647
New value of Q matrix: 0.477007
New value of Value function: 0.477007
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3648
New value of Q matrix: 0.477006
New value of Value function: 0.477006
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 0.42944
New value of Value function: 0.477006
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3649
New value of Q matrix: 0.477005
New value of Value function: 0.477005
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3650
New value of Q matrix: 0.477003
New value of Value function: 0.477003
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3651
New value of Q matrix: 0.477002
New value of Value function: 0.477002
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3652
New value of Q matrix: 0.477001
New value of Value function: 0.477001
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3653
New value of Q matrix: 0.476999
New value of Value function: 0.476999
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3654
New value of Q matrix: 0.479044
New value of Value function: 0.479044
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 282
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.44442
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 283
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.9197
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 284
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 4.00726
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 285
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.46313
New value of Value function: 4.46313
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 286
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 3.54517
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 287
----------
State: 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 288
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 3.6045
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 289
----------
State: 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 290
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 3.65476
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 291
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.1901
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 292
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.59806
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 293
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.25783
New value of Value function: 3.25783
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 294
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 3.44015
New value of Value function: 3.44015
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 295
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.11014
New value of Value function: 9.11014
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 296
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.43633
New value of Value function: 3.43633
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 297
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 4.07415
New value of Value function: 4.07415
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 298
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 24
New value of Q matrix: 3.74344
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 299
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.81453
New value of Value function: 9.81453
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 300
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.78435
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 301
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 2.79744
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 302
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 2.8952
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 303
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.7588
New value of Value function: 10.7588
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 304
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.81329
New value of Value function: 5.81329
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 305
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 5.89444
New value of Value function: 5.89444
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 306
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.42803
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 307
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 1.4628
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 308
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.103078
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3655
New value of Q matrix: 0.479043
New value of Value function: 0.479043
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3656
New value of Q matrix: 0.479042
New value of Value function: 0.479042
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3657
New value of Q matrix: 0.479041
New value of Value function: 0.479041
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3658
New value of Q matrix: 0.479039
New value of Value function: 0.479039
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3659
New value of Q matrix: 0.479038
New value of Value function: 0.479038
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3660
New value of Q matrix: 0.479037
New value of Value function: 0.479037
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3661
New value of Q matrix: 0.479035
New value of Value function: 0.479035
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3662
New value of Q matrix: 0.479034
New value of Value function: 0.479034
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 0.429225
New value of Value function: 0.479034
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3663
New value of Q matrix: 0.479033
New value of Value function: 0.479033
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3664
New value of Q matrix: 0.479031
New value of Value function: 0.479031
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3665
New value of Q matrix: 0.47903
New value of Value function: 0.47903
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3666
New value of Q matrix: 0.479029
New value of Value function: 0.479029
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3667
New value of Q matrix: 0.479027
New value of Value function: 0.479027
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3668
New value of Q matrix: 0.479026
New value of Value function: 0.479026
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3669
New value of Q matrix: 0.479025
New value of Value function: 0.479025
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3670
New value of Q matrix: 0.479024
New value of Value function: 0.479024
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3671
New value of Q matrix: 0.479022
New value of Value function: 0.479022
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3672
New value of Q matrix: 0.479021
New value of Value function: 0.479021
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3673
New value of Q matrix: 0.47902
New value of Value function: 0.47902
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3674
New value of Q matrix: 0.479018
New value of Value function: 0.479018
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 0.429589
New value of Value function: 0.479018
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 0.429738
New value of Value function: 0.479018
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3675
New value of Q matrix: 0.479017
New value of Value function: 0.479017
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 0.429886
New value of Value function: 0.479017
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3676
New value of Q matrix: 0.479016
New value of Value function: 0.479016
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3677
New value of Q matrix: 0.479014
New value of Value function: 0.479014
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3678
New value of Q matrix: 0.479013
New value of Value function: 0.479013
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3679
New value of Q matrix: 0.479012
New value of Value function: 0.479012
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 0.422267
New value of Value function: 0.479012
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3680
New value of Q matrix: 0.47901
New value of Value function: 0.47901
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3681
New value of Q matrix: 0.479009
New value of Value function: 0.479009
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3682
New value of Q matrix: 0.479008
New value of Value function: 0.479008
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3683
New value of Q matrix: 0.479007
New value of Value function: 0.479007
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3684
New value of Q matrix: 0.479005
New value of Value function: 0.479005
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3685
New value of Q matrix: 0.479004
New value of Value function: 0.479004
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3686
New value of Q matrix: 0.479003
New value of Value function: 0.479003
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3687
New value of Q matrix: 0.479001
New value of Value function: 0.479001
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3688
New value of Q matrix: 0.479
New value of Value function: 0.479
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3689
New value of Q matrix: 0.478999
New value of Value function: 0.478999
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3690
New value of Q matrix: 0.478997
New value of Value function: 0.478997
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3691
New value of Q matrix: 0.478996
New value of Value function: 0.478996
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3692
New value of Q matrix: 0.478995
New value of Value function: 0.478995
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3693
New value of Q matrix: 0.478994
New value of Value function: 0.478994
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3694
New value of Q matrix: 0.478992
New value of Value function: 0.478992
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3695
New value of Q matrix: 0.478991
New value of Value function: 0.478991
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3696
New value of Q matrix: 0.47899
New value of Value function: 0.47899
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3697
New value of Q matrix: 0.478988
New value of Value function: 0.478988
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 0.422441
New value of Value function: 0.478988
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3698
New value of Q matrix: 0.478987
New value of Value function: 0.478987
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3699
New value of Q matrix: 0.478986
New value of Value function: 0.478986
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3700
New value of Q matrix: 0.478985
New value of Value function: 0.478985
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3701
New value of Q matrix: 0.478983
New value of Value function: 0.478983
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 0.447498
New value of Value function: 0.478983
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3702
New value of Q matrix: 0.478982
New value of Value function: 0.478982
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3703
New value of Q matrix: 0.478981
New value of Value function: 0.478981
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 0.429376
New value of Value function: 0.478981
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3704
New value of Q matrix: 0.478979
New value of Value function: 0.478979
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3705
New value of Q matrix: 0.478978
New value of Value function: 0.478978
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 0.429526
New value of Value function: 0.478978
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 0.422614
New value of Value function: 0.478978
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3706
New value of Q matrix: 0.478977
New value of Value function: 0.478977
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 0.429675
New value of Value function: 0.478977
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3707
New value of Q matrix: 0.478975
New value of Value function: 0.478975
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 0.429823
New value of Value function: 0.478975
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3708
New value of Q matrix: 0.478974
New value of Value function: 0.478974
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3709
New value of Q matrix: 0.478973
New value of Value function: 0.478973
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 0.430033
New value of Value function: 0.478973
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3710
New value of Q matrix: 0.478972
New value of Value function: 0.478972
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3711
New value of Q matrix: 0.47897
New value of Value function: 0.47897
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3712
New value of Q matrix: 0.478969
New value of Value function: 0.478969
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3713
New value of Q matrix: 0.478968
New value of Value function: 0.478968
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3714
New value of Q matrix: 0.478966
New value of Value function: 0.478966
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3715
New value of Q matrix: 0.478965
New value of Value function: 0.478965
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3716
New value of Q matrix: 0.478964
New value of Value function: 0.478964
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3717
New value of Q matrix: 0.478963
New value of Value function: 0.478963
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3718
New value of Q matrix: 0.478961
New value of Value function: 0.478961
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3719
New value of Q matrix: 0.47896
New value of Value function: 0.47896
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3720
New value of Q matrix: 0.478959
New value of Value function: 0.478959
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3721
New value of Q matrix: 0.478957
New value of Value function: 0.478957
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3722
New value of Q matrix: 0.478956
New value of Value function: 0.478956
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3723
New value of Q matrix: 0.478955
New value of Value function: 0.478955
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 0.447582
New value of Value function: 0.478955
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 0.422786
New value of Value function: 0.478955
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3724
New value of Q matrix: 0.478954
New value of Value function: 0.478954
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3725
New value of Q matrix: 0.478952
New value of Value function: 0.478952
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 0.430178
New value of Value function: 0.478952
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 0.430323
New value of Value function: 0.478952
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3726
New value of Q matrix: 0.478951
New value of Value function: 0.478951
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3727
New value of Q matrix: 0.47895
New value of Value function: 0.47895
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 0.447665
New value of Value function: 0.47895
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 0.447748
New value of Value function: 0.47895
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3728
New value of Q matrix: 0.478948
New value of Value function: 0.478948
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3729
New value of Q matrix: 0.478947
New value of Value function: 0.478947
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3730
New value of Q matrix: 0.478946
New value of Value function: 0.478946
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3731
New value of Q matrix: 0.478945
New value of Value function: 0.478945
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3732
New value of Q matrix: 0.478943
New value of Value function: 0.478943
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3733
New value of Q matrix: 0.478942
New value of Value function: 0.478942
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 0.44783
New value of Value function: 0.478942
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3734
New value of Q matrix: 0.478941
New value of Value function: 0.478941
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3735
New value of Q matrix: 0.478939
New value of Value function: 0.478939
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3736
New value of Q matrix: 0.478938
New value of Value function: 0.478938
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3737
New value of Q matrix: 0.478937
New value of Value function: 0.478937
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3738
New value of Q matrix: 0.478936
New value of Value function: 0.478936
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 0.430467
New value of Value function: 0.478936
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3739
New value of Q matrix: 0.478934
New value of Value function: 0.478934
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 0.430609
New value of Value function: 0.478934
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3740
New value of Q matrix: 0.478933
New value of Value function: 0.478933
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3741
New value of Q matrix: 0.478932
New value of Value function: 0.478932
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3742
New value of Q matrix: 0.47893
New value of Value function: 0.47893
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3743
New value of Q matrix: 0.478929
New value of Value function: 0.478929
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3744
New value of Q matrix: 0.478928
New value of Value function: 0.478928
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3745
New value of Q matrix: 0.478927
New value of Value function: 0.478927
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 0.447912
New value of Value function: 0.478927
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 0.422957
New value of Value function: 0.478927
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3746
New value of Q matrix: 0.478925
New value of Value function: 0.478925
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 0.447993
New value of Value function: 0.478925
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3747
New value of Q matrix: 0.478924
New value of Value function: 0.478924
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3748
New value of Q matrix: 0.478923
New value of Value function: 0.478923
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3749
New value of Q matrix: 0.480916
New value of Value function: 0.480916
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 429
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.25808
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 430
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.48133
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 431
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.06537
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 432
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.82084
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 433
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.11573
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 434
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 3.82216
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 435
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.52259
New value of Value function: 5.52259
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 436
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.95845
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 437
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.93789
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 438
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.82398
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 439
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 27
New value of Q matrix: 3.60148
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 440
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.57544
New value of Value function: 4.57544
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 441
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 2.92221
New value of Value function: 4.81453
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 442
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.33291
New value of Value function: 3.52471
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 443
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.89117
New value of Value function: 5.89117
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 444
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.96931
New value of Value function: 5.96931
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 445
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.35511
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 446
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.09208
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 447
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.35924
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 448
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.71205
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3750
New value of Q matrix: 0.480914
New value of Value function: 0.480914
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3751
New value of Q matrix: 0.480913
New value of Value function: 0.480913
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 0.423133
New value of Value function: 0.480913
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3752
New value of Q matrix: 0.480912
New value of Value function: 0.480912
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 0.429976
New value of Value function: 0.480912
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3753
New value of Q matrix: 0.48091
New value of Value function: 0.48091
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3754
New value of Q matrix: 0.480909
New value of Value function: 0.480909
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 0.430128
New value of Value function: 0.480909
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 0.430758
New value of Value function: 0.480909
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 0.430279
New value of Value function: 0.480909
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3755
New value of Q matrix: 0.480908
New value of Value function: 0.480908
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3756
New value of Q matrix: 0.480907
New value of Value function: 0.480907
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3757
New value of Q matrix: 0.480905
New value of Value function: 0.480905
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3758
New value of Q matrix: 0.480904
New value of Value function: 0.480904
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3759
New value of Q matrix: 0.480903
New value of Value function: 0.480903
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 0.430905
New value of Value function: 0.480903
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 0.431051
New value of Value function: 0.480903
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3760
New value of Q matrix: 0.480902
New value of Value function: 0.480902
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 0.431196
New value of Value function: 0.480902
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3761
New value of Q matrix: 0.4809
New value of Value function: 0.4809
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3762
New value of Q matrix: 0.480899
New value of Value function: 0.480899
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3763
New value of Q matrix: 0.480898
New value of Value function: 0.480898
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 0.44808
New value of Value function: 0.480898
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3764
New value of Q matrix: 0.480896
New value of Value function: 0.480896
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 0.430429
New value of Value function: 0.480896
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3765
New value of Q matrix: 0.480895
New value of Value function: 0.480895
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 0.423308
New value of Value function: 0.480895
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3766
New value of Q matrix: 0.480894
New value of Value function: 0.480894
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3767
New value of Q matrix: 0.480893
New value of Value function: 0.480893
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3768
New value of Q matrix: 0.480891
New value of Value function: 0.480891
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3769
New value of Q matrix: 0.48089
New value of Value function: 0.48089
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3770
New value of Q matrix: 0.480889
New value of Value function: 0.480889
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3771
New value of Q matrix: 0.480887
New value of Value function: 0.480887
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3772
New value of Q matrix: 0.480886
New value of Value function: 0.480886
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3773
New value of Q matrix: 0.480885
New value of Value function: 0.480885
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 0.431341
New value of Value function: 0.480885
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 0.431484
New value of Value function: 0.480885
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3774
New value of Q matrix: 0.480884
New value of Value function: 0.480884
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3775
New value of Q matrix: 0.480882
New value of Value function: 0.480882
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 0.423481
New value of Value function: 0.480882
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3776
New value of Q matrix: 0.480881
New value of Value function: 0.480881
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 0.430579
New value of Value function: 0.480881
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3777
New value of Q matrix: 0.48088
New value of Value function: 0.48088
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3778
New value of Q matrix: 0.480879
New value of Value function: 0.480879
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3779
New value of Q matrix: 0.480877
New value of Value function: 0.480877
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 0.423654
New value of Value function: 0.480877
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3780
New value of Q matrix: 0.480876
New value of Value function: 0.480876
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 0.423825
New value of Value function: 0.480876
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 0.423995
New value of Value function: 0.480876
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3781
New value of Q matrix: 0.480875
New value of Value function: 0.480875
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3782
New value of Q matrix: 0.480873
New value of Value function: 0.480873
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3783
New value of Q matrix: 0.480872
New value of Value function: 0.480872
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3784
New value of Q matrix: 0.480871
New value of Value function: 0.480871
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 0.424164
New value of Value function: 0.480871
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3785
New value of Q matrix: 0.48087
New value of Value function: 0.48087
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3786
New value of Q matrix: 0.480868
New value of Value function: 0.480868
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3787
New value of Q matrix: 0.480867
New value of Value function: 0.480867
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3788
New value of Q matrix: 0.480866
New value of Value function: 0.480866
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 0.431627
New value of Value function: 0.480866
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3789
New value of Q matrix: 0.480865
New value of Value function: 0.480865
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3790
New value of Q matrix: 0.480863
New value of Value function: 0.480863
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 0.448166
New value of Value function: 0.480863
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3791
New value of Q matrix: 0.480862
New value of Value function: 0.480862
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3792
New value of Q matrix: 0.480861
New value of Value function: 0.480861
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3793
New value of Q matrix: 0.48086
New value of Value function: 0.48086
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3794
New value of Q matrix: 0.480858
New value of Value function: 0.480858
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3795
New value of Q matrix: 0.480857
New value of Value function: 0.480857
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3796
New value of Q matrix: 0.480856
New value of Value function: 0.480856
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3797
New value of Q matrix: 0.480854
New value of Value function: 0.480854
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3798
New value of Q matrix: 0.480853
New value of Value function: 0.480853
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3799
New value of Q matrix: 0.480852
New value of Value function: 0.480852
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3800
New value of Q matrix: 0.480851
New value of Value function: 0.480851
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3801
New value of Q matrix: 0.480849
New value of Value function: 0.480849
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3802
New value of Q matrix: 0.480848
New value of Value function: 0.480848
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3803
New value of Q matrix: 0.480847
New value of Value function: 0.480847
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3804
New value of Q matrix: 0.480846
New value of Value function: 0.480846
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 0.424332
New value of Value function: 0.480846
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3805
New value of Q matrix: 0.480844
New value of Value function: 0.480844
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3806
New value of Q matrix: 0.480843
New value of Value function: 0.480843
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3807
New value of Q matrix: 0.480842
New value of Value function: 0.480842
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 0.424499
New value of Value function: 0.480842
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3808
New value of Q matrix: 0.480841
New value of Value function: 0.480841
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 0.424664
New value of Value function: 0.480841
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3809
New value of Q matrix: 0.480839
New value of Value function: 0.480839
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3810
New value of Q matrix: 0.480838
New value of Value function: 0.480838
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3811
New value of Q matrix: 0.480837
New value of Value function: 0.480837
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3812
New value of Q matrix: 0.480835
New value of Value function: 0.480835
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3813
New value of Q matrix: 0.480834
New value of Value function: 0.480834
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 0.424829
New value of Value function: 0.480834
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 0.430727
New value of Value function: 0.480834
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3814
New value of Q matrix: 0.480833
New value of Value function: 0.480833
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3815
New value of Q matrix: 0.480832
New value of Value function: 0.480832
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 0.430874
New value of Value function: 0.480832
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3816
New value of Q matrix: 0.48083
New value of Value function: 0.48083
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3817
New value of Q matrix: 0.480829
New value of Value function: 0.480829
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3818
New value of Q matrix: 0.480828
New value of Value function: 0.480828
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3819
New value of Q matrix: 0.480827
New value of Value function: 0.480827
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 0.448251
New value of Value function: 0.480827
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3820
New value of Q matrix: 0.480825
New value of Value function: 0.480825
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3821
New value of Q matrix: 0.480824
New value of Value function: 0.480824
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 0.43102
New value of Value function: 0.480824
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 0.431768
New value of Value function: 0.480824
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3822
New value of Q matrix: 0.480823
New value of Value function: 0.480823
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 0.448336
New value of Value function: 0.480823
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 0.431908
New value of Value function: 0.480823
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3823
New value of Q matrix: 0.480822
New value of Value function: 0.480822
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 0.44842
New value of Value function: 0.480822
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 0.431165
New value of Value function: 0.480822
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3824
New value of Q matrix: 0.48082
New value of Value function: 0.48082
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 0.432048
New value of Value function: 0.48082
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3825
New value of Q matrix: 0.480819
New value of Value function: 0.480819
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3826
New value of Q matrix: 0.480818
New value of Value function: 0.480818
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3827
New value of Q matrix: 0.480817
New value of Value function: 0.480817
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 0.448504
New value of Value function: 0.480817
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3828
New value of Q matrix: 0.480815
New value of Value function: 0.480815
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3829
New value of Q matrix: 0.480814
New value of Value function: 0.480814
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3830
New value of Q matrix: 0.480813
New value of Value function: 0.480813
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3831
New value of Q matrix: 0.480812
New value of Value function: 0.480812
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 0.448588
New value of Value function: 0.480812
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 0.431309
New value of Value function: 0.480812
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3832
New value of Q matrix: 0.48081
New value of Value function: 0.48081
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3833
New value of Q matrix: 0.480809
New value of Value function: 0.480809
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3834
New value of Q matrix: 0.480808
New value of Value function: 0.480808
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3835
New value of Q matrix: 0.480807
New value of Value function: 0.480807
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3836
New value of Q matrix: 0.480805
New value of Value function: 0.480805
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3837
New value of Q matrix: 0.480804
New value of Value function: 0.480804
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3838
New value of Q matrix: 0.480803
New value of Value function: 0.480803
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 0.44867
New value of Value function: 0.480803
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3839
New value of Q matrix: 0.480802
New value of Value function: 0.480802
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 0.432187
New value of Value function: 0.480802
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3840
New value of Q matrix: 0.4808
New value of Value function: 0.4808
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3841
New value of Q matrix: 0.480799
New value of Value function: 0.480799
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3842
New value of Q matrix: 0.480798
New value of Value function: 0.480798
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3843
New value of Q matrix: 0.480797
New value of Value function: 0.480797
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 0.432324
New value of Value function: 0.480797
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3844
New value of Q matrix: 0.480795
New value of Value function: 0.480795
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3845
New value of Q matrix: 0.482738
New value of Value function: 0.482738
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 586
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 3.65248
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 587
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 588
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 3.78559
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 589
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 590
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.88912
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 591
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.8885
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 592
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 24
New value of Q matrix: 3.52195
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 593
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.2289
New value of Value function: 6.2289
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 594
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.66571
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 595
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 5.22689
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 596
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.76042
New value of Value function: 9.81453
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 597
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.5375
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 598
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 5.10611
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 599
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.9789
New value of Value function: 10.9789
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 600
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.81453
New value of Value function: 9.81453
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 601
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 28
New value of Q matrix: 3.45606
New value of Value function: 4.86316
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 602
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.56629
New value of Value function: 4.56629
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 603
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.52063
New value of Value function: 4.56629
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 604
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.55868
New value of Value function: 4.55868
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 605
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.42904
New value of Value function: 5.42904
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 606
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.6524
New value of Value function: 10.6524
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 607
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.5992
New value of Value function: 10.5992
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 608
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 10.5993
New value of Value function: 10.5993
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 609
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 10.5639
New value of Value function: 10.5639
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 610
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 10.5375
New value of Value function: 10.5375
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 611
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.3757
New value of Value function: 12.3757
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 612
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.9534
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 613
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.147025
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 614
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: -0.075401
New value of Value function: 2.42575
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3846
New value of Q matrix: 0.482737
New value of Value function: 0.482737
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3847
New value of Q matrix: 0.482735
New value of Value function: 0.482735
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 0.431458
New value of Value function: 0.482735
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 0.424999
New value of Value function: 0.482735
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 619
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 0.432467
New value of Value function: 0.482735
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3848
New value of Q matrix: 0.482734
New value of Value function: 0.482734
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3849
New value of Q matrix: 0.482733
New value of Value function: 0.482733
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3850
New value of Q matrix: 0.482732
New value of Value function: 0.482732
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 0.431607
New value of Value function: 0.482732
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3851
New value of Q matrix: 0.48273
New value of Value function: 0.48273
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3852
New value of Q matrix: 0.482729
New value of Value function: 0.482729
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3853
New value of Q matrix: 0.482728
New value of Value function: 0.482728
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 627
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3854
New value of Q matrix: 0.482727
New value of Value function: 0.482727
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3855
New value of Q matrix: 0.482725
New value of Value function: 0.482725
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3856
New value of Q matrix: 0.482724
New value of Value function: 0.482724
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 0.425167
New value of Value function: 0.482724
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 0.448758
New value of Value function: 0.482724
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3857
New value of Q matrix: 0.482723
New value of Value function: 0.482723
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 0.448846
New value of Value function: 0.482723
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3858
New value of Q matrix: 0.482722
New value of Value function: 0.482722
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3859
New value of Q matrix: 0.48272
New value of Value function: 0.48272
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3860
New value of Q matrix: 0.482719
New value of Value function: 0.482719
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3861
New value of Q matrix: 0.482718
New value of Value function: 0.482718
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3862
New value of Q matrix: 0.482717
New value of Value function: 0.482717
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3863
New value of Q matrix: 0.482715
New value of Value function: 0.482715
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 0.431754
New value of Value function: 0.482715
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3864
New value of Q matrix: 0.482714
New value of Value function: 0.482714
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3865
New value of Q matrix: 0.482713
New value of Value function: 0.482713
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 0.432609
New value of Value function: 0.482713
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3866
New value of Q matrix: 0.482712
New value of Value function: 0.482712
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3867
New value of Q matrix: 0.48271
New value of Value function: 0.48271
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3868
New value of Q matrix: 0.482709
New value of Value function: 0.482709
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3869
New value of Q matrix: 0.482708
New value of Value function: 0.482708
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 0.43275
New value of Value function: 0.482708
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 0.431901
New value of Value function: 0.482708
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3870
New value of Q matrix: 0.482707
New value of Value function: 0.482707
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3871
New value of Q matrix: 0.482705
New value of Value function: 0.482705
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3872
New value of Q matrix: 0.482704
New value of Value function: 0.482704
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3873
New value of Q matrix: 0.482703
New value of Value function: 0.482703
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3874
New value of Q matrix: 0.482702
New value of Value function: 0.482702
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 0.432046
New value of Value function: 0.482702
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3875
New value of Q matrix: 0.4827
New value of Value function: 0.4827
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3876
New value of Q matrix: 0.482699
New value of Value function: 0.482699
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3877
New value of Q matrix: 0.482698
New value of Value function: 0.482698
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3878
New value of Q matrix: 0.482697
New value of Value function: 0.482697
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3879
New value of Q matrix: 0.482695
New value of Value function: 0.482695
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3880
New value of Q matrix: 0.482694
New value of Value function: 0.482694
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3881
New value of Q matrix: 0.482693
New value of Value function: 0.482693
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3882
New value of Q matrix: 0.482692
New value of Value function: 0.482692
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 0.432191
New value of Value function: 0.482692
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 0.432334
New value of Value function: 0.482692
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 0.432477
New value of Value function: 0.482692
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3883
New value of Q matrix: 0.48269
New value of Value function: 0.48269
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3884
New value of Q matrix: 0.482689
New value of Value function: 0.482689
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3885
New value of Q matrix: 0.482688
New value of Value function: 0.482688
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3886
New value of Q matrix: 0.482687
New value of Value function: 0.482687
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3887
New value of Q matrix: 0.482685
New value of Value function: 0.482685
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3888
New value of Q matrix: 0.482684
New value of Value function: 0.482684
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3889
New value of Q matrix: 0.482683
New value of Value function: 0.482683
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 0.432619
New value of Value function: 0.482683
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 0.448933
New value of Value function: 0.482683
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3890
New value of Q matrix: 0.482682
New value of Value function: 0.482682
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3891
New value of Q matrix: 0.48268
New value of Value function: 0.48268
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 678
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3892
New value of Q matrix: 0.482679
New value of Value function: 0.482679
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3893
New value of Q matrix: 0.482678
New value of Value function: 0.482678
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3894
New value of Q matrix: 0.482677
New value of Value function: 0.482677
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3895
New value of Q matrix: 0.482676
New value of Value function: 0.482676
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 682
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3896
New value of Q matrix: 0.482674
New value of Value function: 0.482674
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3897
New value of Q matrix: 0.482673
New value of Value function: 0.482673
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3898
New value of Q matrix: 0.482672
New value of Value function: 0.482672
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 0.43276
New value of Value function: 0.482672
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3899
New value of Q matrix: 0.482671
New value of Value function: 0.482671
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3900
New value of Q matrix: 0.482669
New value of Value function: 0.482669
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 0.4329
New value of Value function: 0.482669
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3901
New value of Q matrix: 0.482668
New value of Value function: 0.482668
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3902
New value of Q matrix: 0.482667
New value of Value function: 0.482667
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3903
New value of Q matrix: 0.482666
New value of Value function: 0.482666
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3904
New value of Q matrix: 0.482664
New value of Value function: 0.482664
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3905
New value of Q matrix: 0.482663
New value of Value function: 0.482663
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 694
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3906
New value of Q matrix: 0.482662
New value of Value function: 0.482662
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 695
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3907
New value of Q matrix: 0.482661
New value of Value function: 0.482661
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 696
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3908
New value of Q matrix: 0.482659
New value of Value function: 0.482659
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 0.433039
New value of Value function: 0.482659
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3909
New value of Q matrix: 0.482658
New value of Value function: 0.482658
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3910
New value of Q matrix: 0.482657
New value of Value function: 0.482657
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3911
New value of Q matrix: 0.482656
New value of Value function: 0.482656
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3912
New value of Q matrix: 0.482654
New value of Value function: 0.482654
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3913
New value of Q matrix: 0.482653
New value of Value function: 0.482653
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 703
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3914
New value of Q matrix: 0.482652
New value of Value function: 0.482652
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3915
New value of Q matrix: 0.482651
New value of Value function: 0.482651
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3916
New value of Q matrix: 0.48265
New value of Value function: 0.48265
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3917
New value of Q matrix: 0.482648
New value of Value function: 0.482648
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 0.43289
New value of Value function: 0.482648
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3918
New value of Q matrix: 0.482647
New value of Value function: 0.482647
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3919
New value of Q matrix: 0.482646
New value of Value function: 0.482646
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3920
New value of Q matrix: 0.482645
New value of Value function: 0.482645
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3921
New value of Q matrix: 0.482643
New value of Value function: 0.482643
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 712
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3922
New value of Q matrix: 0.482642
New value of Value function: 0.482642
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 0.433029
New value of Value function: 0.482642
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3923
New value of Q matrix: 0.482641
New value of Value function: 0.482641
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 715
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3924
New value of Q matrix: 0.48264
New value of Value function: 0.48264
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 716
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3925
New value of Q matrix: 0.482638
New value of Value function: 0.482638
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3926
New value of Q matrix: 0.482637
New value of Value function: 0.482637
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3927
New value of Q matrix: 0.482636
New value of Value function: 0.482636
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3928
New value of Q matrix: 0.482635
New value of Value function: 0.482635
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3929
New value of Q matrix: 0.482634
New value of Value function: 0.482634
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3930
New value of Q matrix: 0.482632
New value of Value function: 0.482632
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 0.433167
New value of Value function: 0.482632
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3931
New value of Q matrix: 0.482631
New value of Value function: 0.482631
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 0.425334
New value of Value function: 0.482631
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3932
New value of Q matrix: 0.48263
New value of Value function: 0.48263
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3933
New value of Q matrix: 0.484529
New value of Value function: 0.484529
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 727
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.475
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 728
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 3.97652
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 729
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.88542
New value of Value function: 9.95
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 730
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.8505
New value of Value function: 9.8505
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 731
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.31871
New value of Value function: 9.95
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 732
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.31871
New value of Value function: 9.8505
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 733
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.23323
New value of Value function: 9.8505
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 734
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.21596
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 735
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 25
New value of Q matrix: 3.18107
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 736
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.1666
New value of Value function: 11.1666
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 737
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.7334
New value of Value function: 6.7334
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 738
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.52923
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 739
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 5.55755
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 740
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 11.9133
New value of Value function: 11.9133
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 741
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.76545
New value of Value function: 9.81453
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 742
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.76545
New value of Value function: 9.76545
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 743
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.84364
New value of Value function: 9.76545
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 744
----------
State: 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.3747
New value of Value function: 10.3747
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 745
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.37475
New value of Value function: 5.42904
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 746
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.9712
New value of Value function: 5.9712
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 747
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 3.51351
New value of Value function: 3.51351
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 748
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.47838
New value of Value function: 8.47838
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 749
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 2.94271
New value of Value function: 3.51351
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 750
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.25101
New value of Value function: 8.47838
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 751
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.45561
New value of Value function: 3.52471
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 752
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.35729
New value of Value function: 5.96931
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 753
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.56716
New value of Value function: 3.56716
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 754
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.96632
New value of Value function: 5.96632
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 755
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.54042
New value of Value function: 5.96632
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 756
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.96348
New value of Value function: 5.96348
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 757
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 6.02767
New value of Value function: 6.02767
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 758
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.13119
New value of Value function: 7.45025
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 759
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.413
New value of Value function: 7.413
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 760
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5113
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.025
New value of Value function: 7.413
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 761
----------
State: 5113
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.3389
New value of Value function: 12.3389
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 762
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.26538
New value of Value function: 7.413
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 763
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.37273
New value of Value function: 7.413
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 764
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 5.56427
New value of Value function: 7.413
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 0.433183
New value of Value function: 0.484529
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3934
New value of Q matrix: 0.484527
New value of Value function: 0.484527
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 0.433326
New value of Value function: 0.484527
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 768
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3935
New value of Q matrix: 0.484526
New value of Value function: 0.484526
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 769
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 0.433311
New value of Value function: 0.484526
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 770
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3936
New value of Q matrix: 0.484525
New value of Value function: 0.484525
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 771
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3937
New value of Q matrix: 0.484524
New value of Value function: 0.484524
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 772
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3938
New value of Q matrix: 0.484522
New value of Value function: 0.484522
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 773
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3939
New value of Q matrix: 0.484521
New value of Value function: 0.484521
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3940
New value of Q matrix: 0.48452
New value of Value function: 0.48452
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 775
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3941
New value of Q matrix: 0.484519
New value of Value function: 0.484519
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3942
New value of Q matrix: 0.484517
New value of Value function: 0.484517
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3943
New value of Q matrix: 0.484516
New value of Value function: 0.484516
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3944
New value of Q matrix: 0.484515
New value of Value function: 0.484515
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3945
New value of Q matrix: 0.484514
New value of Value function: 0.484514
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3946
New value of Q matrix: 0.484513
New value of Value function: 0.484513
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3947
New value of Q matrix: 0.484511
New value of Value function: 0.484511
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3948
New value of Q matrix: 0.48451
New value of Value function: 0.48451
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3949
New value of Q matrix: 0.484509
New value of Value function: 0.484509
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 784
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 0.433453
New value of Value function: 0.484509
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 0.449025
New value of Value function: 0.484509
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3950
New value of Q matrix: 0.484508
New value of Value function: 0.484508
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 0.425506
New value of Value function: 0.484508
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3951
New value of Q matrix: 0.484506
New value of Value function: 0.484506
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3952
New value of Q matrix: 0.484505
New value of Value function: 0.484505
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3953
New value of Q matrix: 0.484504
New value of Value function: 0.484504
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 0.433468
New value of Value function: 0.484504
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 0.425677
New value of Value function: 0.484504
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3954
New value of Q matrix: 0.484503
New value of Value function: 0.484503
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 794
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3955
New value of Q matrix: 0.484502
New value of Value function: 0.484502
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3956
New value of Q matrix: 0.4845
New value of Value function: 0.4845
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3957
New value of Q matrix: 0.484499
New value of Value function: 0.484499
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3958
New value of Q matrix: 0.484498
New value of Value function: 0.484498
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 0.425847
New value of Value function: 0.484498
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 0.449116
New value of Value function: 0.484498
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3959
New value of Q matrix: 0.484497
New value of Value function: 0.484497
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 0.433609
New value of Value function: 0.484497
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3960
New value of Q matrix: 0.484495
New value of Value function: 0.484495
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3961
New value of Q matrix: 0.484494
New value of Value function: 0.484494
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3962
New value of Q matrix: 0.484493
New value of Value function: 0.484493
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3963
New value of Q matrix: 0.484492
New value of Value function: 0.484492
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3964
New value of Q matrix: 0.48449
New value of Value function: 0.48449
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 0.433594
New value of Value function: 0.48449
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3965
New value of Q matrix: 0.484489
New value of Value function: 0.484489
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3966
New value of Q matrix: 0.484488
New value of Value function: 0.484488
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 0.449206
New value of Value function: 0.484488
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 0.43375
New value of Value function: 0.484488
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3967
New value of Q matrix: 0.484487
New value of Value function: 0.484487
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3968
New value of Q matrix: 0.484486
New value of Value function: 0.484486
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 0.426015
New value of Value function: 0.484486
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 0.433889
New value of Value function: 0.484486
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3969
New value of Q matrix: 0.484484
New value of Value function: 0.484484
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 0.433734
New value of Value function: 0.484484
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 0.433874
New value of Value function: 0.484484
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3970
New value of Q matrix: 0.484483
New value of Value function: 0.484483
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3971
New value of Q matrix: 0.484482
New value of Value function: 0.484482
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3972
New value of Q matrix: 0.484481
New value of Value function: 0.484481
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 0.434013
New value of Value function: 0.484481
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3973
New value of Q matrix: 0.48448
New value of Value function: 0.48448
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3974
New value of Q matrix: 0.484478
New value of Value function: 0.484478
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3975
New value of Q matrix: 0.484477
New value of Value function: 0.484477
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3976
New value of Q matrix: 0.484476
New value of Value function: 0.484476
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3977
New value of Q matrix: 0.484475
New value of Value function: 0.484475
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 0.449296
New value of Value function: 0.484475
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3978
New value of Q matrix: 0.484473
New value of Value function: 0.484473
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3979
New value of Q matrix: 0.484472
New value of Value function: 0.484472
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3980
New value of Q matrix: 0.484471
New value of Value function: 0.484471
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3981
New value of Q matrix: 0.48447
New value of Value function: 0.48447
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3982
New value of Q matrix: 0.484469
New value of Value function: 0.484469
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3983
New value of Q matrix: 0.484467
New value of Value function: 0.484467
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3984
New value of Q matrix: 0.484466
New value of Value function: 0.484466
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 0.43415
New value of Value function: 0.484466
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3985
New value of Q matrix: 0.484465
New value of Value function: 0.484465
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3986
New value of Q matrix: 0.484464
New value of Value function: 0.484464
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 0.449386
New value of Value function: 0.484464
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3987
New value of Q matrix: 0.484462
New value of Value function: 0.484462
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 0.434028
New value of Value function: 0.484462
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3988
New value of Q matrix: 0.484461
New value of Value function: 0.484461
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3989
New value of Q matrix: 0.48446
New value of Value function: 0.48446
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 0.434287
New value of Value function: 0.48446
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3990
New value of Q matrix: 0.484459
New value of Value function: 0.484459
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3991
New value of Q matrix: 0.484458
New value of Value function: 0.484458
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3992
New value of Q matrix: 0.484456
New value of Value function: 0.484456
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3993
New value of Q matrix: 0.484455
New value of Value function: 0.484455
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3994
New value of Q matrix: 0.484454
New value of Value function: 0.484454
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3995
New value of Q matrix: 0.484453
New value of Value function: 0.484453
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3996
New value of Q matrix: 0.484452
New value of Value function: 0.484452
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3997
New value of Q matrix: 0.48445
New value of Value function: 0.48445
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3998
New value of Q matrix: 0.484449
New value of Value function: 0.484449
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3999
New value of Q matrix: 0.484448
New value of Value function: 0.484448
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 0.434423
New value of Value function: 0.484448
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4000
New value of Q matrix: 0.484447
New value of Value function: 0.484447
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4001
New value of Q matrix: 0.484445
New value of Value function: 0.484445
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4002
New value of Q matrix: 0.484444
New value of Value function: 0.484444
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4003
New value of Q matrix: 0.484443
New value of Value function: 0.484443
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4004
New value of Q matrix: 0.484442
New value of Value function: 0.484442
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4005
New value of Q matrix: 0.484441
New value of Value function: 0.484441
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4006
New value of Q matrix: 0.484439
New value of Value function: 0.484439
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4007
New value of Q matrix: 0.484438
New value of Value function: 0.484438
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 0.426183
New value of Value function: 0.484438
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4008
New value of Q matrix: 0.484437
New value of Value function: 0.484437
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4009
New value of Q matrix: 0.484436
New value of Value function: 0.484436
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 0.434559
New value of Value function: 0.484436
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4010
New value of Q matrix: 0.484435
New value of Value function: 0.484435
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 0.434693
New value of Value function: 0.484435
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 0.434827
New value of Value function: 0.484435
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 0.449475
New value of Value function: 0.484435
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4011
New value of Q matrix: 0.484433
New value of Value function: 0.484433
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4012
New value of Q matrix: 0.484432
New value of Value function: 0.484432
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4013
New value of Q matrix: 0.484431
New value of Value function: 0.484431
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4014
New value of Q matrix: 0.48443
New value of Value function: 0.48443
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4015
New value of Q matrix: 0.484429
New value of Value function: 0.484429
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4016
New value of Q matrix: 0.484427
New value of Value function: 0.484427
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4017
New value of Q matrix: 0.484426
New value of Value function: 0.484426
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4018
New value of Q matrix: 0.484425
New value of Value function: 0.484425
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4019
New value of Q matrix: 0.484424
New value of Value function: 0.484424
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4020
New value of Q matrix: 0.484423
New value of Value function: 0.484423
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4021
New value of Q matrix: 0.484421
New value of Value function: 0.484421
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 0.449563
New value of Value function: 0.484421
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4022
New value of Q matrix: 0.48442
New value of Value function: 0.48442
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4023
New value of Q matrix: 0.484419
New value of Value function: 0.484419
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4024
New value of Q matrix: 0.484418
New value of Value function: 0.484418
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 0.426349
New value of Value function: 0.484418
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 0.434165
New value of Value function: 0.484418
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 0.426514
New value of Value function: 0.484418
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4025
New value of Q matrix: 0.484417
New value of Value function: 0.484417
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4026
New value of Q matrix: 0.486271
New value of Value function: 0.486271
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 892
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.05764
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 893
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.11635
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 894
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 3.93647
New value of Value function: 4.86953
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 895
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.59144
New value of Value function: 9.8505
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 896
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.11178
New value of Value function: 7.11178
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 897
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 5.88843
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 898
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 2.07329
New value of Value function: 4.90809
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 899
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.15838
New value of Value function: 9.85901
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 900
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.04968
New value of Value function: 9.76545
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 901
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.51846
New value of Value function: 9.76545
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 902
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.92656
New value of Value function: 8.47838
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 903
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 24
New value of Q matrix: 2.9615
New value of Value function: 3.51351
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 904
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.45711
New value of Value function: 8.47838
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 905
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.3936
New value of Value function: 8.47838
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 906
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.46527
New value of Value function: 8.47838
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 907
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 6.65311
New value of Value function: 8.47838
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 908
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.56561
New value of Value function: 3.56561
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 909
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.66568
New value of Value function: 3.66568
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 910
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 6.08468
New value of Value function: 6.08468
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 911
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 5.69999
New value of Value function: 7.413
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 912
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 1.49454
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 913
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 1.32733
New value of Value function: 2.2151
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4027
New value of Q matrix: 0.48627
New value of Value function: 0.48627
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 915
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4028
New value of Q matrix: 0.486268
New value of Value function: 0.486268
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 916
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4029
New value of Q matrix: 0.486267
New value of Value function: 0.486267
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4030
New value of Q matrix: 0.486266
New value of Value function: 0.486266
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4031
New value of Q matrix: 0.486265
New value of Value function: 0.486265
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4032
New value of Q matrix: 0.486264
New value of Value function: 0.486264
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4033
New value of Q matrix: 0.486262
New value of Value function: 0.486262
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 921
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4034
New value of Q matrix: 0.486261
New value of Value function: 0.486261
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 922
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4035
New value of Q matrix: 0.48626
New value of Value function: 0.48626
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4036
New value of Q matrix: 0.486259
New value of Value function: 0.486259
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 924
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4037
New value of Q matrix: 0.486258
New value of Value function: 0.486258
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 925
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 0.434308
New value of Value function: 0.486258
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 926
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4038
New value of Q matrix: 0.486256
New value of Value function: 0.486256
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 0.426684
New value of Value function: 0.486256
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4039
New value of Q matrix: 0.486255
New value of Value function: 0.486255
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 929
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 0.434449
New value of Value function: 0.486255
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 930
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4040
New value of Q matrix: 0.486254
New value of Value function: 0.486254
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 931
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4041
New value of Q matrix: 0.486253
New value of Value function: 0.486253
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 932
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 0.434589
New value of Value function: 0.486253
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 933
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4042
New value of Q matrix: 0.486252
New value of Value function: 0.486252
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 934
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4043
New value of Q matrix: 0.48625
New value of Value function: 0.48625
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 0.449656
New value of Value function: 0.48625
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 936
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4044
New value of Q matrix: 0.486249
New value of Value function: 0.486249
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 937
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4045
New value of Q matrix: 0.486248
New value of Value function: 0.486248
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 938
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4046
New value of Q matrix: 0.486247
New value of Value function: 0.486247
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4047
New value of Q matrix: 0.486246
New value of Value function: 0.486246
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4048
New value of Q matrix: 0.486244
New value of Value function: 0.486244
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4049
New value of Q matrix: 0.486243
New value of Value function: 0.486243
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 942
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4050
New value of Q matrix: 0.486242
New value of Value function: 0.486242
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 943
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4051
New value of Q matrix: 0.486241
New value of Value function: 0.486241
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 944
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4052
New value of Q matrix: 0.48624
New value of Value function: 0.48624
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 945
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4053
New value of Q matrix: 0.486238
New value of Value function: 0.486238
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4054
New value of Q matrix: 0.486237
New value of Value function: 0.486237
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4055
New value of Q matrix: 0.486236
New value of Value function: 0.486236
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4056
New value of Q matrix: 0.486235
New value of Value function: 0.486235
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4057
New value of Q matrix: 0.486234
New value of Value function: 0.486234
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4058
New value of Q matrix: 0.486232
New value of Value function: 0.486232
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 0.426853
New value of Value function: 0.486232
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4059
New value of Q matrix: 0.486231
New value of Value function: 0.486231
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 0.434729
New value of Value function: 0.486231
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4060
New value of Q matrix: 0.48623
New value of Value function: 0.48623
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4061
New value of Q matrix: 0.486229
New value of Value function: 0.486229
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4062
New value of Q matrix: 0.486228
New value of Value function: 0.486228
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 0.434965
New value of Value function: 0.486228
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4063
New value of Q matrix: 0.486226
New value of Value function: 0.486226
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 959
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4064
New value of Q matrix: 0.486225
New value of Value function: 0.486225
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 960
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 0.427021
New value of Value function: 0.486225
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 961
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4065
New value of Q matrix: 0.486224
New value of Value function: 0.486224
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 0.434868
New value of Value function: 0.486224
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 963
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4066
New value of Q matrix: 0.486223
New value of Value function: 0.486223
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 964
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4067
New value of Q matrix: 0.486222
New value of Value function: 0.486222
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 965
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4068
New value of Q matrix: 0.48622
New value of Value function: 0.48622
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4069
New value of Q matrix: 0.486219
New value of Value function: 0.486219
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4070
New value of Q matrix: 0.486218
New value of Value function: 0.486218
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4071
New value of Q matrix: 0.486217
New value of Value function: 0.486217
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 969
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4072
New value of Q matrix: 0.486216
New value of Value function: 0.486216
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4073
New value of Q matrix: 0.486214
New value of Value function: 0.486214
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4074
New value of Q matrix: 0.486213
New value of Value function: 0.486213
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4075
New value of Q matrix: 0.486212
New value of Value function: 0.486212
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 973
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4076
New value of Q matrix: 0.486211
New value of Value function: 0.486211
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4077
New value of Q matrix: 0.48621
New value of Value function: 0.48621
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 0.435102
New value of Value function: 0.48621
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4078
New value of Q matrix: 0.486208
New value of Value function: 0.486208
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4079
New value of Q matrix: 0.486207
New value of Value function: 0.486207
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 978
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 0.449748
New value of Value function: 0.486207
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4080
New value of Q matrix: 0.486206
New value of Value function: 0.486206
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4081
New value of Q matrix: 0.486205
New value of Value function: 0.486205
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4082
New value of Q matrix: 0.486204
New value of Value function: 0.486204
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4083
New value of Q matrix: 0.486203
New value of Value function: 0.486203
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4084
New value of Q matrix: 0.486201
New value of Value function: 0.486201
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4085
New value of Q matrix: 0.4862
New value of Value function: 0.4862
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 0.44984
New value of Value function: 0.4862
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 986
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4086
New value of Q matrix: 0.486199
New value of Value function: 0.486199
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 987
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4087
New value of Q matrix: 0.486198
New value of Value function: 0.486198
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4088
New value of Q matrix: 0.486197
New value of Value function: 0.486197
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4089
New value of Q matrix: 0.486195
New value of Value function: 0.486195
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 0.449931
New value of Value function: 0.486195
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4090
New value of Q matrix: 0.486194
New value of Value function: 0.486194
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4091
New value of Q matrix: 0.486193
New value of Value function: 0.486193
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4092
New value of Q matrix: 0.486192
New value of Value function: 0.486192
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4093
New value of Q matrix: 0.486191
New value of Value function: 0.486191
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4094
New value of Q matrix: 0.486189
New value of Value function: 0.486189
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4095
New value of Q matrix: 0.486188
New value of Value function: 0.486188
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4096
New value of Q matrix: 0.486187
New value of Value function: 0.486187
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4097
New value of Q matrix: 0.486186
New value of Value function: 0.486186
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4098
New value of Q matrix: 0.486185
New value of Value function: 0.486185
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4099
New value of Q matrix: 0.486184
New value of Value function: 0.486184
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 1
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.11865
New value of Value function: 3.11865
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 2
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.17887
New value of Value function: 3.17887
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 3
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.00757
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 4
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.31292
New value of Value function: 3.17887
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 5
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.23521
New value of Value function: 3.23521
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 6
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.07267
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 7
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.28802
New value of Value function: 3.28802
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 8
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 2.99955
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 9
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.40776
New value of Value function: 3.61185
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 10
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.56262
New value of Value function: 3.61185
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 11
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 3.77943
New value of Value function: 3.77943
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 12
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 3.68814
New value of Value function: 3.68814
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 13
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 7.06241
New value of Value function: 7.06241
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 14
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.693481
New value of Value function: 2.80194
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 15
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.71744
New value of Value function: 2.71744
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 16
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.18083
New value of Value function: 1.9767
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 17
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.96682
New value of Value function: 1.96682
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 18
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.96026
New value of Value function: 1.96026
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 19
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.14729
New value of Value function: 1.96026
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 20
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.565504
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 21
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: -0.597916
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 22
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 36
New value of Q matrix: -0.65127
New value of Value function: 0.65068
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4100
New value of Q matrix: 0.486182
New value of Value function: 0.486182
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4101
New value of Q matrix: 0.486181
New value of Value function: 0.486181
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4102
New value of Q matrix: 0.48618
New value of Value function: 0.48618
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 0.435238
New value of Value function: 0.48618
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4103
New value of Q matrix: 0.486179
New value of Value function: 0.486179
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 0.427187
New value of Value function: 0.486179
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4104
New value of Q matrix: 0.486178
New value of Value function: 0.486178
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4105
New value of Q matrix: 0.486176
New value of Value function: 0.486176
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4106
New value of Q matrix: 0.486175
New value of Value function: 0.486175
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4107
New value of Q matrix: 0.486174
New value of Value function: 0.486174
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4108
New value of Q matrix: 0.486173
New value of Value function: 0.486173
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4109
New value of Q matrix: 0.486172
New value of Value function: 0.486172
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4110
New value of Q matrix: 0.48617
New value of Value function: 0.48617
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4111
New value of Q matrix: 0.486169
New value of Value function: 0.486169
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 0.450022
New value of Value function: 0.486169
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4112
New value of Q matrix: 0.486168
New value of Value function: 0.486168
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 0.450112
New value of Value function: 0.486168
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4113
New value of Q matrix: 0.486167
New value of Value function: 0.486167
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4114
New value of Q matrix: 0.486166
New value of Value function: 0.486166
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4115
New value of Q matrix: 0.486165
New value of Value function: 0.486165
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 0.435374
New value of Value function: 0.486165
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4116
New value of Q matrix: 0.486163
New value of Value function: 0.486163
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4117
New value of Q matrix: 0.486162
New value of Value function: 0.486162
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4118
New value of Q matrix: 0.486161
New value of Value function: 0.486161
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4119
New value of Q matrix: 0.48616
New value of Value function: 0.48616
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4120
New value of Q matrix: 0.486159
New value of Value function: 0.486159
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4121
New value of Q matrix: 0.486157
New value of Value function: 0.486157
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4122
New value of Q matrix: 0.486156
New value of Value function: 0.486156
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4123
New value of Q matrix: 0.486155
New value of Value function: 0.486155
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 0.435006
New value of Value function: 0.486155
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4124
New value of Q matrix: 0.486154
New value of Value function: 0.486154
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4125
New value of Q matrix: 0.486153
New value of Value function: 0.486153
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 0.450202
New value of Value function: 0.486153
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4126
New value of Q matrix: 0.486152
New value of Value function: 0.486152
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4127
New value of Q matrix: 0.48615
New value of Value function: 0.48615
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 0.435143
New value of Value function: 0.48615
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 0.427353
New value of Value function: 0.48615
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4128
New value of Q matrix: 0.486149
New value of Value function: 0.486149
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 0.435279
New value of Value function: 0.486149
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4129
New value of Q matrix: 0.486148
New value of Value function: 0.486148
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 0.435414
New value of Value function: 0.486148
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4130
New value of Q matrix: 0.486147
New value of Value function: 0.486147
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4131
New value of Q matrix: 0.486146
New value of Value function: 0.486146
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 0.435508
New value of Value function: 0.486146
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4132
New value of Q matrix: 0.486145
New value of Value function: 0.486145
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4133
New value of Q matrix: 0.486143
New value of Value function: 0.486143
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4134
New value of Q matrix: 0.486142
New value of Value function: 0.486142
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4135
New value of Q matrix: 0.486141
New value of Value function: 0.486141
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 0.435549
New value of Value function: 0.486141
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 0.435642
New value of Value function: 0.486141
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4136
New value of Q matrix: 0.48614
New value of Value function: 0.48614
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4137
New value of Q matrix: 0.486139
New value of Value function: 0.486139
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4138
New value of Q matrix: 0.486137
New value of Value function: 0.486137
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4139
New value of Q matrix: 0.486136
New value of Value function: 0.486136
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4140
New value of Q matrix: 0.486135
New value of Value function: 0.486135
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4141
New value of Q matrix: 0.486134
New value of Value function: 0.486134
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4142
New value of Q matrix: 0.486133
New value of Value function: 0.486133
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4143
New value of Q matrix: 0.486132
New value of Value function: 0.486132
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 0.450291
New value of Value function: 0.486132
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4144
New value of Q matrix: 0.48613
New value of Value function: 0.48613
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4145
New value of Q matrix: 0.486129
New value of Value function: 0.486129
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4146
New value of Q matrix: 0.486128
New value of Value function: 0.486128
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4147
New value of Q matrix: 0.486127
New value of Value function: 0.486127
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4148
New value of Q matrix: 0.486126
New value of Value function: 0.486126
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4149
New value of Q matrix: 0.486125
New value of Value function: 0.486125
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4150
New value of Q matrix: 0.486123
New value of Value function: 0.486123
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4151
New value of Q matrix: 0.486122
New value of Value function: 0.486122
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 0.435775
New value of Value function: 0.486122
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 0.435682
New value of Value function: 0.486122
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 0.435907
New value of Value function: 0.486122
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4152
New value of Q matrix: 0.486121
New value of Value function: 0.486121
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4153
New value of Q matrix: 0.48612
New value of Value function: 0.48612
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 0.435815
New value of Value function: 0.48612
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4154
New value of Q matrix: 0.486119
New value of Value function: 0.486119
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4155
New value of Q matrix: 0.486118
New value of Value function: 0.486118
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4156
New value of Q matrix: 0.486116
New value of Value function: 0.486116
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4157
New value of Q matrix: 0.486115
New value of Value function: 0.486115
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4158
New value of Q matrix: 0.486114
New value of Value function: 0.486114
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4159
New value of Q matrix: 0.486113
New value of Value function: 0.486113
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4160
New value of Q matrix: 0.486112
New value of Value function: 0.486112
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4161
New value of Q matrix: 0.486111
New value of Value function: 0.486111
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4162
New value of Q matrix: 0.486109
New value of Value function: 0.486109
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4163
New value of Q matrix: 0.486108
New value of Value function: 0.486108
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4164
New value of Q matrix: 0.486107
New value of Value function: 0.486107
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4165
New value of Q matrix: 0.486106
New value of Value function: 0.486106
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4166
New value of Q matrix: 0.486105
New value of Value function: 0.486105
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4167
New value of Q matrix: 0.486104
New value of Value function: 0.486104
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4168
New value of Q matrix: 0.486102
New value of Value function: 0.486102
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4169
New value of Q matrix: 0.486101
New value of Value function: 0.486101
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 0.450379
New value of Value function: 0.486101
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4170
New value of Q matrix: 0.4861
New value of Value function: 0.4861
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 0.427517
New value of Value function: 0.4861
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4171
New value of Q matrix: 0.486099
New value of Value function: 0.486099
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4172
New value of Q matrix: 0.486098
New value of Value function: 0.486098
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4173
New value of Q matrix: 0.486097
New value of Value function: 0.486097
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4174
New value of Q matrix: 0.486095
New value of Value function: 0.486095
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 0.435947
New value of Value function: 0.486095
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4175
New value of Q matrix: 0.486094
New value of Value function: 0.486094
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4176
New value of Q matrix: 0.486093
New value of Value function: 0.486093
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4177
New value of Q matrix: 0.486092
New value of Value function: 0.486092
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4178
New value of Q matrix: 0.486091
New value of Value function: 0.486091
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4179
New value of Q matrix: 0.48609
New value of Value function: 0.48609
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4180
New value of Q matrix: 0.486088
New value of Value function: 0.486088
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4181
New value of Q matrix: 0.486087
New value of Value function: 0.486087
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4182
New value of Q matrix: 0.486086
New value of Value function: 0.486086
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4183
New value of Q matrix: 0.486085
New value of Value function: 0.486085
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4184
New value of Q matrix: 0.486084
New value of Value function: 0.486084
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4185
New value of Q matrix: 0.486083
New value of Value function: 0.486083
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4186
New value of Q matrix: 0.486081
New value of Value function: 0.486081
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4187
New value of Q matrix: 0.48608
New value of Value function: 0.48608
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4188
New value of Q matrix: 0.486079
New value of Value function: 0.486079
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 0.450467
New value of Value function: 0.486079
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4189
New value of Q matrix: 0.486078
New value of Value function: 0.486078
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 0.436078
New value of Value function: 0.486078
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4190
New value of Q matrix: 0.486077
New value of Value function: 0.486077
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4191
New value of Q matrix: 0.486076
New value of Value function: 0.486076
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4192
New value of Q matrix: 0.486074
New value of Value function: 0.486074
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 0.42768
New value of Value function: 0.486074
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 0.436209
New value of Value function: 0.486074
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4193
New value of Q matrix: 0.487381
New value of Value function: 0.487381
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 143
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.62323
New value of Value function: 3.62323
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 144
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.0372506
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 145
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.70588
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 146
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.44638
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 147
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.75962
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 148
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 4.36468
New value of Value function: 4.93762
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 149
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.6548
New value of Value function: 9.87562
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 150
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.63663
New value of Value function: 3.28802
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 151
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.656191
New value of Value function: 3.28802
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 152
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 2.36386
New value of Value function: 3.28802
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 153
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 3.80927
New value of Value function: 4.93762
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 154
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.28703
New value of Value function: 3.28703
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 155
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.33521
New value of Value function: 3.33521
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 156
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.02923
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 157
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.77824
New value of Value function: 3.77824
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 158
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.79392
New value of Value function: 3.77824
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 159
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.7771
New value of Value function: 3.7771
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 160
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.87165
New value of Value function: 3.87165
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 161
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 7.05947
New value of Value function: 7.05947
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 162
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 7.05472
New value of Value function: 7.05472
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 163
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.19396
New value of Value function: 1.96026
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 164
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.16342
New value of Value function: 1.96026
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 165
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 1.11982
New value of Value function: 1.11982
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 166
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.00240165
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 167
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.25829
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 168
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.28493
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 169
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.00224154
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 170
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: -0.159445
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4194
New value of Q matrix: 0.487379
New value of Value function: 0.487379
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4195
New value of Q matrix: 0.487378
New value of Value function: 0.487378
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4196
New value of Q matrix: 0.487377
New value of Value function: 0.487377
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4197
New value of Q matrix: 0.487376
New value of Value function: 0.487376
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4198
New value of Q matrix: 0.487375
New value of Value function: 0.487375
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 0.427846
New value of Value function: 0.487375
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4199
New value of Q matrix: 0.487374
New value of Value function: 0.487374
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 0.436043
New value of Value function: 0.487374
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4200
New value of Q matrix: 0.487372
New value of Value function: 0.487372
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4201
New value of Q matrix: 0.487371
New value of Value function: 0.487371
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 0.436177
New value of Value function: 0.487371
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4202
New value of Q matrix: 0.48737
New value of Value function: 0.48737
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4203
New value of Q matrix: 0.487369
New value of Value function: 0.487369
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4204
New value of Q matrix: 0.487368
New value of Value function: 0.487368
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4205
New value of Q matrix: 0.487367
New value of Value function: 0.487367
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 0.43631
New value of Value function: 0.487367
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4206
New value of Q matrix: 0.487366
New value of Value function: 0.487366
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 0.450558
New value of Value function: 0.487366
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4207
New value of Q matrix: 0.487364
New value of Value function: 0.487364
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4208
New value of Q matrix: 0.487363
New value of Value function: 0.487363
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4209
New value of Q matrix: 0.487362
New value of Value function: 0.487362
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4210
New value of Q matrix: 0.487361
New value of Value function: 0.487361
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4211
New value of Q matrix: 0.48736
New value of Value function: 0.48736
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4212
New value of Q matrix: 0.487359
New value of Value function: 0.487359
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4213
New value of Q matrix: 0.487357
New value of Value function: 0.487357
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4214
New value of Q matrix: 0.487356
New value of Value function: 0.487356
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 0.436443
New value of Value function: 0.487356
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4215
New value of Q matrix: 0.487355
New value of Value function: 0.487355
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4216
New value of Q matrix: 0.487354
New value of Value function: 0.487354
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4217
New value of Q matrix: 0.487353
New value of Value function: 0.487353
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4218
New value of Q matrix: 0.487352
New value of Value function: 0.487352
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4219
New value of Q matrix: 0.48735
New value of Value function: 0.48735
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 0.428011
New value of Value function: 0.48735
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4220
New value of Q matrix: 0.487349
New value of Value function: 0.487349
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 0.436575
New value of Value function: 0.487349
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4221
New value of Q matrix: 0.487348
New value of Value function: 0.487348
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4222
New value of Q matrix: 0.487347
New value of Value function: 0.487347
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4223
New value of Q matrix: 0.487346
New value of Value function: 0.487346
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4224
New value of Q matrix: 0.487345
New value of Value function: 0.487345
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 0.428176
New value of Value function: 0.487345
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4225
New value of Q matrix: 0.487344
New value of Value function: 0.487344
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 0.436342
New value of Value function: 0.487344
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 0.436706
New value of Value function: 0.487344
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4226
New value of Q matrix: 0.487342
New value of Value function: 0.487342
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4227
New value of Q matrix: 0.487341
New value of Value function: 0.487341
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4228
New value of Q matrix: 0.48734
New value of Value function: 0.48734
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4229
New value of Q matrix: 0.487339
New value of Value function: 0.487339
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4230
New value of Q matrix: 0.487338
New value of Value function: 0.487338
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4231
New value of Q matrix: 0.487337
New value of Value function: 0.487337
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4232
New value of Q matrix: 0.487335
New value of Value function: 0.487335
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 0.436475
New value of Value function: 0.487335
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 0.436606
New value of Value function: 0.487335
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4233
New value of Q matrix: 0.487334
New value of Value function: 0.487334
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4234
New value of Q matrix: 0.487333
New value of Value function: 0.487333
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 0.428339
New value of Value function: 0.487333
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4235
New value of Q matrix: 0.487332
New value of Value function: 0.487332
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4236
New value of Q matrix: 0.487331
New value of Value function: 0.487331
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 0.436836
New value of Value function: 0.487331
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4237
New value of Q matrix: 0.48733
New value of Value function: 0.48733
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 0.436966
New value of Value function: 0.48733
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4238
New value of Q matrix: 0.487329
New value of Value function: 0.487329
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4239
New value of Q matrix: 0.487327
New value of Value function: 0.487327
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4240
New value of Q matrix: 0.487326
New value of Value function: 0.487326
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4241
New value of Q matrix: 0.487325
New value of Value function: 0.487325
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4242
New value of Q matrix: 0.487324
New value of Value function: 0.487324
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4243
New value of Q matrix: 0.487323
New value of Value function: 0.487323
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 0.450648
New value of Value function: 0.487323
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4244
New value of Q matrix: 0.487322
New value of Value function: 0.487322
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 0.428501
New value of Value function: 0.487322
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4245
New value of Q matrix: 0.487321
New value of Value function: 0.487321
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4246
New value of Q matrix: 0.487319
New value of Value function: 0.487319
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4247
New value of Q matrix: 0.487318
New value of Value function: 0.487318
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4248
New value of Q matrix: 0.487317
New value of Value function: 0.487317
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4249
New value of Q matrix: 0.487316
New value of Value function: 0.487316
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4250
New value of Q matrix: 0.487315
New value of Value function: 0.487315
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4251
New value of Q matrix: 0.487314
New value of Value function: 0.487314
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4252
New value of Q matrix: 0.487313
New value of Value function: 0.487313
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4253
New value of Q matrix: 0.487311
New value of Value function: 0.487311
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 0.437095
New value of Value function: 0.487311
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4254
New value of Q matrix: 0.48731
New value of Value function: 0.48731
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 0.428662
New value of Value function: 0.48731
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4255
New value of Q matrix: 0.487309
New value of Value function: 0.487309
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4256
New value of Q matrix: 0.487308
New value of Value function: 0.487308
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4257
New value of Q matrix: 0.487307
New value of Value function: 0.487307
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4258
New value of Q matrix: 0.487306
New value of Value function: 0.487306
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 0.428822
New value of Value function: 0.487306
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4259
New value of Q matrix: 0.487304
New value of Value function: 0.487304
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4260
New value of Q matrix: 0.487303
New value of Value function: 0.487303
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4261
New value of Q matrix: 0.487302
New value of Value function: 0.487302
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4262
New value of Q matrix: 0.487301
New value of Value function: 0.487301
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4263
New value of Q matrix: 0.4873
New value of Value function: 0.4873
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4264
New value of Q matrix: 0.487299
New value of Value function: 0.487299
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4265
New value of Q matrix: 0.487298
New value of Value function: 0.487298
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4266
New value of Q matrix: 0.487296
New value of Value function: 0.487296
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 0.450738
New value of Value function: 0.487296
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4267
New value of Q matrix: 0.487295
New value of Value function: 0.487295
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 0.428981
New value of Value function: 0.487295
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4268
New value of Q matrix: 0.487294
New value of Value function: 0.487294
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4269
New value of Q matrix: 0.487293
New value of Value function: 0.487293
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4270
New value of Q matrix: 0.487292
New value of Value function: 0.487292
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 0.450827
New value of Value function: 0.487292
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4271
New value of Q matrix: 0.487291
New value of Value function: 0.487291
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 0.429139
New value of Value function: 0.487291
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4272
New value of Q matrix: 0.48729
New value of Value function: 0.48729
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4273
New value of Q matrix: 0.487289
New value of Value function: 0.487289
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4274
New value of Q matrix: 0.487287
New value of Value function: 0.487287
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 0.436737
New value of Value function: 0.487287
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4275
New value of Q matrix: 0.487286
New value of Value function: 0.487286
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4276
New value of Q matrix: 0.487285
New value of Value function: 0.487285
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4277
New value of Q matrix: 0.487284
New value of Value function: 0.487284
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 0.437223
New value of Value function: 0.487284
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 0.436867
New value of Value function: 0.487284
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4278
New value of Q matrix: 0.487283
New value of Value function: 0.487283
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4279
New value of Q matrix: 0.487282
New value of Value function: 0.487282
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4280
New value of Q matrix: 0.487281
New value of Value function: 0.487281
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4281
New value of Q matrix: 0.487279
New value of Value function: 0.487279
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4282
New value of Q matrix: 0.487278
New value of Value function: 0.487278
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 0.429296
New value of Value function: 0.487278
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4283
New value of Q matrix: 0.487277
New value of Value function: 0.487277
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4284
New value of Q matrix: 0.487276
New value of Value function: 0.487276
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4285
New value of Q matrix: 0.487275
New value of Value function: 0.487275
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4286
New value of Q matrix: 0.487274
New value of Value function: 0.487274
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 0.450916
New value of Value function: 0.487274
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4287
New value of Q matrix: 0.487273
New value of Value function: 0.487273
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 0.436997
New value of Value function: 0.487273
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4288
New value of Q matrix: 0.487859
New value of Value function: 0.487859
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 297
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -0.249199
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 298
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.972391
New value of Value function: 3.08608
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 299
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.17558
New value of Value function: 3.17558
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 300
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.80869
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 301
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.89918
New value of Value function: 4.93762
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 302
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 3.46862
New value of Value function: 4.93762
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 303
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.33426
New value of Value function: 3.33426
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 304
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.37845
New value of Value function: 3.37845
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 305
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.10216
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 306
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.12922
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 307
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.87054
New value of Value function: 3.87054
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 308
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.48844
New value of Value function: 3.87054
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 309
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.55712
New value of Value function: 3.87054
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 310
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.2015
New value of Value function: 3.87054
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 311
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.86947
New value of Value function: 3.86947
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 312
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 3.97273
New value of Value function: 3.97273
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 313
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 0.951619
New value of Value function: 2.71744
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 314
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 7.07916
New value of Value function: 7.07916
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 315
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.64682
New value of Value function: 2.64682
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 316
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.16053
New value of Value function: 1.96026
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 317
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.473672
New value of Value function: 1.11982
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 318
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.908676
New value of Value function: 1.11982
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 319
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.15794
New value of Value function: 1.96026
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 320
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: -0.603706
New value of Value function: 1.11982
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 321
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: -0.558645
New value of Value function: 1.11982
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 322
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 39
New value of Q matrix: -0.608859
New value of Value function: 1.11982
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 0.451006
New value of Value function: 0.487859
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4289
New value of Q matrix: 0.487857
New value of Value function: 0.487857
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 0.437127
New value of Value function: 0.487857
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 0.437352
New value of Value function: 0.487857
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4290
New value of Q matrix: 0.487856
New value of Value function: 0.487856
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 0.43748
New value of Value function: 0.487856
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 0.437607
New value of Value function: 0.487856
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4291
New value of Q matrix: 0.487855
New value of Value function: 0.487855
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4292
New value of Q matrix: 0.487854
New value of Value function: 0.487854
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4293
New value of Q matrix: 0.487853
New value of Value function: 0.487853
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4294
New value of Q matrix: 0.487852
New value of Value function: 0.487852
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4295
New value of Q matrix: 0.487851
New value of Value function: 0.487851
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 0.429454
New value of Value function: 0.487851
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4296
New value of Q matrix: 0.487849
New value of Value function: 0.487849
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4297
New value of Q matrix: 0.487848
New value of Value function: 0.487848
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 0.451095
New value of Value function: 0.487848
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4298
New value of Q matrix: 0.487847
New value of Value function: 0.487847
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 0.429611
New value of Value function: 0.487847
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4299
New value of Q matrix: 0.487846
New value of Value function: 0.487846
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4300
New value of Q matrix: 0.487845
New value of Value function: 0.487845
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4301
New value of Q matrix: 0.487844
New value of Value function: 0.487844
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4302
New value of Q matrix: 0.487843
New value of Value function: 0.487843
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4303
New value of Q matrix: 0.487842
New value of Value function: 0.487842
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4304
New value of Q matrix: 0.48784
New value of Value function: 0.48784
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4305
New value of Q matrix: 0.487839
New value of Value function: 0.487839
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4306
New value of Q matrix: 0.487838
New value of Value function: 0.487838
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 0.437734
New value of Value function: 0.487838
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4307
New value of Q matrix: 0.487837
New value of Value function: 0.487837
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4308
New value of Q matrix: 0.487836
New value of Value function: 0.487836
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4309
New value of Q matrix: 0.487835
New value of Value function: 0.487835
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4310
New value of Q matrix: 0.487834
New value of Value function: 0.487834
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4311
New value of Q matrix: 0.487832
New value of Value function: 0.487832
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4312
New value of Q matrix: 0.487831
New value of Value function: 0.487831
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4313
New value of Q matrix: 0.48783
New value of Value function: 0.48783
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4314
New value of Q matrix: 0.487829
New value of Value function: 0.487829
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 0.437256
New value of Value function: 0.487829
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4315
New value of Q matrix: 0.487828
New value of Value function: 0.487828
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4316
New value of Q matrix: 0.487827
New value of Value function: 0.487827
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4317
New value of Q matrix: 0.487826
New value of Value function: 0.487826
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4318
New value of Q matrix: 0.487825
New value of Value function: 0.487825
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4319
New value of Q matrix: 0.487823
New value of Value function: 0.487823
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4320
New value of Q matrix: 0.487822
New value of Value function: 0.487822
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 0.43786
New value of Value function: 0.487822
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 0.451184
New value of Value function: 0.487822
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4321
New value of Q matrix: 0.487821
New value of Value function: 0.487821
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4322
New value of Q matrix: 0.48782
New value of Value function: 0.48782
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 0.429767
New value of Value function: 0.48782
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4323
New value of Q matrix: 0.487819
New value of Value function: 0.487819
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4324
New value of Q matrix: 0.487818
New value of Value function: 0.487818
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4325
New value of Q matrix: 0.487817
New value of Value function: 0.487817
New value of Policy matrix: 0

