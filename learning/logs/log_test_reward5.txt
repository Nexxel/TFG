=======================================
Simulation: 1
Iteration: 1
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 5
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 6
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 10
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.079213
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 14
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.040013
New value of Value function: 0.040013
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 18
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000732934
New value of Value function: 0.000732934
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 19
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.040013
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 20
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.03992
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.03992
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142416
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00071856
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0398402
New value of Value function: 0.03992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 26
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00071856
New value of Value function: 0.03992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 27
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142275
New value of Value function: 0.03992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 28
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142275
New value of Value function: 0.03992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 29
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00211285
New value of Value function: 0.03992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 30
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0397636
New value of Value function: 0.03992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 31
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00142416
New value of Value function: 0.040013
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 32
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.0789815
New value of Value function: 0.0789815
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00143437
New value of Value function: 0.00143437
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 34
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00281734
New value of Value function: 0.0789815
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0788235
New value of Value function: 0.0788235
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0405404
New value of Value function: 0.0788235
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0779673
New value of Value function: 0.0779673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0400258
New value of Value function: 0.0400258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.58186e-05
New value of Value function: 0.00143437
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 40
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00213143
New value of Value function: 0.00213143
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00142583
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0790545
New value of Value function: 0.0790545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.117512
New value of Value function: 0.117512
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 44
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.83658e-05
New value of Value function: 0.00213143
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00212615
New value of Value function: 0.00213143
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 46
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0399332
New value of Value function: 0.0400258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00279909
New value of Value function: 0.0400258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.041133
New value of Value function: 0.0779673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 49
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.116446
New value of Value function: 0.116446
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00143874
New value of Value function: 0.00213143
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0399458
New value of Value function: 0.0399458
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 52
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000719024
New value of Value function: 0.0399458
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 53
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0412621
New value of Value function: 0.0412621
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00211521
New value of Value function: 0.117512
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.1552
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 56
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.59643e-05
New value of Value function: 0.00213143
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 57
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.36681e-05
New value of Value function: 0.00213143
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00010076
New value of Value function: 0.00213143
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000137111
New value of Value function: 0.00213143
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 60
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0048824
New value of Value function: 0.0048824
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00486651
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00419092
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0069007
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00756278
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00955628
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0027936
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0121588
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0102051
New value of Value function: 0.1552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.15489
New value of Value function: 0.15489
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00278801
New value of Value function: 0.15489
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.012789
New value of Value function: 0.15489
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0153213
New value of Value function: 0.15489
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.15458
New value of Value function: 0.15458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00551469
New value of Value function: 0.15458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0177973
New value of Value function: 0.15458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0202238
New value of Value function: 0.15458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00552016
New value of Value function: 0.15458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0081922
New value of Value function: 0.15458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.154271
New value of Value function: 0.154271
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0146925
New value of Value function: 0.154271
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00818126
New value of Value function: 0.154271
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0225962
New value of Value function: 0.154271
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.153962
New value of Value function: 0.153962
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.010789
New value of Value function: 0.153962
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 0.042887
New value of Value function: 0.153962
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 86
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00348582
New value of Value function: 0.0412621
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00551214
New value of Value function: 0.0412621
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.11486
New value of Value function: 0.11486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0398772
New value of Value function: 0.0412621
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000742717
New value of Value function: 0.0412621
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0805247
New value of Value function: 0.0805247
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00755607
New value of Value function: 0.00755607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0448005
New value of Value function: 0.153962
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 0.191019
New value of Value function: 0.191019
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 95
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000210454
New value of Value function: 0.00755607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 96
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0108433
New value of Value function: 0.0108433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0473429
New value of Value function: 0.191019
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0140115
New value of Value function: 0.191019
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 0.208648
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 100
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0826699
New value of Value function: 0.0826699
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0174869
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 0.0865912
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 103
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.000401424
New value of Value function: 0.0108433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 104
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.000588575
New value of Value function: 0.0108433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 105
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00160514
New value of Value function: 0.0108433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 106
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.000329548
New value of Value function: 0.0108433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 107
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.000518136
New value of Value function: 0.0108433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 108
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00426344
New value of Value function: 0.0108433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 0.125055
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 110
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0143821
New value of Value function: 0.0143821
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0208929
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.011784
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0181543
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0215468
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0242307
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0248716
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0275017
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.015304
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0187536
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0281298
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0313229
New value of Value function: 0.208648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.208231
New value of Value function: 0.208231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0306998
New value of Value function: 0.208231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.126302
New value of Value function: 0.208231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.033834
New value of Value function: 0.208231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0221267
New value of Value function: 0.208231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0254323
New value of Value function: 0.208231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0344446
New value of Value function: 0.208231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.127524
New value of Value function: 0.208231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.207814
New value of Value function: 0.207814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0374963
New value of Value function: 0.207814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0286643
New value of Value function: 0.207814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.040487
New value of Value function: 0.207814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.207399
New value of Value function: 0.207399
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.128706
New value of Value function: 0.207399
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0368905
New value of Value function: 0.207399
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.206984
New value of Value function: 0.206984
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0398784
New value of Value function: 0.206984
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0428065
New value of Value function: 0.206984
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.20657
New value of Value function: 0.20657
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0318093
New value of Value function: 0.20657
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.129851
New value of Value function: 0.20657
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.206157
New value of Value function: 0.206157
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0456612
New value of Value function: 0.206157
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.205744
New value of Value function: 0.205744
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0484514
New value of Value function: 0.205744
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.205333
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0348691
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0378677
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0433733
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0511783
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.13095
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0538508
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0408063
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0564697
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.132027
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0462018
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0590363
New value of Value function: 0.205333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.204922
New value of Value function: 0.204922
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.204512
New value of Value function: 0.204512
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0436714
New value of Value function: 0.204512
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.204103
New value of Value function: 0.204103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 0.24028
New value of Value function: 0.24028
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 164
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00566622
New value of Value function: 0.0143821
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 165
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00221592
New value of Value function: 0.0826699
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 166
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0853415
New value of Value function: 0.0853415
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.133711
New value of Value function: 0.24028
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 0.275733
New value of Value function: 0.275733
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 169
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0023425
New value of Value function: 0.0143821
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 170
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.000835681
New value of Value function: 0.0143821
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 171
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00107785
New value of Value function: 0.0143821
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 172
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.0740944
New value of Value function: 0.0740944
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 173
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0013337
New value of Value function: 0.0013337
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 174
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0775758
New value of Value function: 0.0775758
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 0.311615
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 176
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00369201
New value of Value function: 0.0775758
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00694926
New value of Value function: 0.0775758
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 178
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0774206
New value of Value function: 0.0774206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 179
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00296661
New value of Value function: 0.0774206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 180
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00244986
New value of Value function: 0.0774206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 181
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00430085
New value of Value function: 0.0774206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00515432
New value of Value function: 0.0774206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0420982
New value of Value function: 0.0853415
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0772658
New value of Value function: 0.0772658
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 185
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0813295
New value of Value function: 0.0813295
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.136646
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.048407
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0634647
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.139522
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0508869
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.053048
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0554782
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0599777
New value of Value function: 0.311615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.310992
New value of Value function: 0.310992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.31037
New value of Value function: 0.31037
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.309749
New value of Value function: 0.309749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0643536
New value of Value function: 0.309749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0677709
New value of Value function: 0.309749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0575625
New value of Value function: 0.309749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.142307
New value of Value function: 0.309749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.145036
New value of Value function: 0.309749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0719909
New value of Value function: 0.309749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.30913
New value of Value function: 0.30913
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 0.344411
New value of Value function: 0.344411
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 205
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00386479
New value of Value function: 0.0813295
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 206
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00651517
New value of Value function: 0.0813295
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 207
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0811669
New value of Value function: 0.0811669
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 208
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0052485
New value of Value function: 0.0811669
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 209
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0857429
New value of Value function: 0.0857429
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0626106
New value of Value function: 0.344411
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 0.379066
New value of Value function: 0.379066
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 212
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0908513
New value of Value function: 0.0908513
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.148959
New value of Value function: 0.379066
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.152803
New value of Value function: 0.379066
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 0.41312
New value of Value function: 0.41312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 216
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0084456
New value of Value function: 0.0908513
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 217
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00677885
New value of Value function: 0.0908513
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 218
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0964704
New value of Value function: 0.0964704
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0687946
New value of Value function: 0.41312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 0.446594
New value of Value function: 0.446594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 221
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.10258
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 0.479509
New value of Value function: 0.479509
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 223
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0082313
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 224
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00848971
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 225
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0101664
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 226
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0101342
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 227
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0414073
New value of Value function: 0.11486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 228
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00206748
New value of Value function: 0.00206748
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 229
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0426466
New value of Value function: 0.11486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 230
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.002761
New value of Value function: 0.11486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 231
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 232
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00206748
New value of Value function: 0.00206748
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 233
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00274299
New value of Value function: 0.11486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 234
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.72147e-05
New value of Value function: 0.00206748
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 235
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.72147e-05
New value of Value function: 0.00206748
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 236
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.64704e-05
New value of Value function: 0.00206748
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 237
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 238
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 239
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0392
New value of Value function: 0.0392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 240
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 241
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 242
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.040013
New value of Value function: 0.040013
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 243
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 244
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00071856
New value of Value function: 0.00071856
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 245
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000717123
New value of Value function: 0.000717123
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 246
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 0.000717123
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 247
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.29082e-05
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 248
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00863116
New value of Value function: 0.00863116
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.47855
New value of Value function: 0.47855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.079165
New value of Value function: 0.47855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.477593
New value of Value function: 0.477593
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.476637
New value of Value function: 0.476637
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0861612
New value of Value function: 0.476637
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.475684
New value of Value function: 0.475684
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.474733
New value of Value function: 0.474733
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0759639
New value of Value function: 0.474733
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0716117
New value of Value function: 0.474733
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.158292
New value of Value function: 0.474733
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.473783
New value of Value function: 0.473783
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.472836
New value of Value function: 0.472836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.163637
New value of Value function: 0.472836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.47189
New value of Value function: 0.47189
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.470946
New value of Value function: 0.470946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0786565
New value of Value function: 0.470946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.470004
New value of Value function: 0.470004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.469064
New value of Value function: 0.469064
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.468126
New value of Value function: 0.468126
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.46719
New value of Value function: 0.46719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0928474
New value of Value function: 0.46719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0993999
New value of Value function: 0.46719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.082854
New value of Value function: 0.46719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0854928
New value of Value function: 0.46719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0896064
New value of Value function: 0.46719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0921924
New value of Value function: 0.46719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.105821
New value of Value function: 0.46719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.466256
New value of Value function: 0.466256
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.112097
New value of Value function: 0.466256
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.465323
New value of Value function: 0.465323
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0987244
New value of Value function: 0.465323
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0961901
New value of Value function: 0.465323
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.464392
New value of Value function: 0.464392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.168724
New value of Value function: 0.464392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.118215
New value of Value function: 0.464392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.102625
New value of Value function: 0.464392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.108932
New value of Value function: 0.464392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.173708
New value of Value function: 0.464392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.178593
New value of Value function: 0.464392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.124209
New value of Value function: 0.464392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.463464
New value of Value function: 0.463464
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.462537
New value of Value function: 0.462537
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.130051
New value of Value function: 0.462537
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.115079
New value of Value function: 0.462537
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.121103
New value of Value function: 0.462537
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.183347
New value of Value function: 0.462537
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.188006
New value of Value function: 0.462537
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.135775
New value of Value function: 0.462537
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.461612
New value of Value function: 0.461612
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.141369
New value of Value function: 0.461612
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.460688
New value of Value function: 0.460688
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.192538
New value of Value function: 0.460688
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.196979
New value of Value function: 0.460688
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.146834
New value of Value function: 0.460688
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.459767
New value of Value function: 0.459767
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.458848
New value of Value function: 0.458848
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.45793
New value of Value function: 0.45793
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.457014
New value of Value function: 0.457014
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.152124
New value of Value function: 0.457014
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.4561
New value of Value function: 0.4561
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.157291
New value of Value function: 0.4561
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.162355
New value of Value function: 0.4561
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.10496
New value of Value function: 0.4561
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.11107
New value of Value function: 0.4561
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.455188
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.167301
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.201233
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.205402
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.126874
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.13253
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.117042
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.209487
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.122895
New value of Value function: 0.455188
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.454277
New value of Value function: 0.454277
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.213475
New value of Value function: 0.454277
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.453369
New value of Value function: 0.453369
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.452462
New value of Value function: 0.452462
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.138024
New value of Value function: 0.452462
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.451557
New value of Value function: 0.451557
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.143391
New value of Value function: 0.451557
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.450654
New value of Value function: 0.450654
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.449753
New value of Value function: 0.449753
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.448853
New value of Value function: 0.448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.148603
New value of Value function: 0.448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.217284
New value of Value function: 0.448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.221018
New value of Value function: 0.448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.447956
New value of Value function: 0.447956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.44706
New value of Value function: 0.44706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.172002
New value of Value function: 0.44706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.224645
New value of Value function: 0.44706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.446166
New value of Value function: 0.446166
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.176593
New value of Value function: 0.446166
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.445273
New value of Value function: 0.445273
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.444383
New value of Value function: 0.444383
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.18106
New value of Value function: 0.444383
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.443494
New value of Value function: 0.443494
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.185422
New value of Value function: 0.443494
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.189696
New value of Value function: 0.443494
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.193885
New value of Value function: 0.443494
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.153614
New value of Value function: 0.443494
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.158524
New value of Value function: 0.443494
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.442607
New value of Value function: 0.442607
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.128404
New value of Value function: 0.442607
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.441722
New value of Value function: 0.441722
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.440838
New value of Value function: 0.440838
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.197943
New value of Value function: 0.440838
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.228087
New value of Value function: 0.440838
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.439957
New value of Value function: 0.439957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.201903
New value of Value function: 0.439957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.205784
New value of Value function: 0.439957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.209588
New value of Value function: 0.439957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.213315
New value of Value function: 0.439957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.133755
New value of Value function: 0.439957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.231444
New value of Value function: 0.439957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.216968
New value of Value function: 0.439957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.439077
New value of Value function: 0.439077
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.234719
New value of Value function: 0.439077
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.438198
New value of Value function: 0.438198
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.437322
New value of Value function: 0.437322
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.436447
New value of Value function: 0.436447
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.16321
New value of Value function: 0.436447
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.167802
New value of Value function: 0.436447
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.220485
New value of Value function: 0.436447
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.435575
New value of Value function: 0.435575
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.434703
New value of Value function: 0.434703
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.433834
New value of Value function: 0.433834
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.138889
New value of Value function: 0.433834
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.237834
New value of Value function: 0.433834
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.432966
New value of Value function: 0.432966
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.4321
New value of Value function: 0.4321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.223853
New value of Value function: 0.4321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.431236
New value of Value function: 0.431236
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.240839
New value of Value function: 0.431236
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.243785
New value of Value function: 0.431236
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.430374
New value of Value function: 0.430374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.227123
New value of Value function: 0.430374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.230327
New value of Value function: 0.430374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.143858
New value of Value function: 0.430374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.148727
New value of Value function: 0.430374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.429513
New value of Value function: 0.429513
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.24664
New value of Value function: 0.429513
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.233452
New value of Value function: 0.429513
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.428654
New value of Value function: 0.428654
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 91
New value of Q matrix: 0.461927
New value of Value function: 0.461927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 393
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0118095
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 394
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00606127
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 395
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0101231
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 396
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.011999
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 397
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.0821568
New value of Value function: 0.11486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 398
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0117671
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 399
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00778648
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 400
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00766796
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 401
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00206748
New value of Value function: 0.00206748
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 402
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 0.154409
New value of Value function: 0.154409
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 403
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00936104
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 404
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0110203
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 405
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0131094
New value of Value function: 0.10258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 406
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0406158
New value of Value function: 0.0853415
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 407
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0831027
New value of Value function: 0.0853415
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 408
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.108843
New value of Value function: 0.108843
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.237097
New value of Value function: 0.461927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 92
New value of Q matrix: 0.474225
New value of Value function: 0.474225
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 411
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.1234
New value of Value function: 0.1234
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 412
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0148064
New value of Value function: 0.108843
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 413
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.115202
New value of Value function: 0.115202
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 93
New value of Q matrix: 0.506814
New value of Value function: 0.506814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 415
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.122021
New value of Value function: 0.122021
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.241478
New value of Value function: 0.506814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.245771
New value of Value function: 0.506814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 94
New value of Q matrix: 0.538874
New value of Value function: 0.538874
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 419
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0167066
New value of Value function: 0.122021
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 420
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0117962
New value of Value function: 0.122021
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 421
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.72147e-05
New value of Value function: 0.00206748
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 422
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000742815
New value of Value function: 0.00206748
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 423
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0048055
New value of Value function: 0.0048055
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 424
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 0.193518
New value of Value function: 0.193518
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 425
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.12928
New value of Value function: 0.12928
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.174146
New value of Value function: 0.538874
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 95
New value of Q matrix: 0.570424
New value of Value function: 0.570424
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 428
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0186995
New value of Value function: 0.12928
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 429
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0138588
New value of Value function: 0.12928
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 430
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.136962
New value of Value function: 0.136962
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 96
New value of Q matrix: 0.601481
New value of Value function: 0.601481
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 432
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0140256
New value of Value function: 0.136962
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 433
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0160469
New value of Value function: 0.136962
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 434
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.136688
New value of Value function: 0.136688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 435
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0207859
New value of Value function: 0.136688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 436
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0181864
New value of Value function: 0.136688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 437
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.0803942
New value of Value function: 0.136688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 438
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00246038
New value of Value function: 0.00246038
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 439
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.020283
New value of Value function: 0.136688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 440
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.193999
New value of Value function: 0.193999
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 441
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0108266
New value of Value function: 0.0108266
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.252534
New value of Value function: 0.601481
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 97
New value of Q matrix: 0.632943
New value of Value function: 0.632943
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 444
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.201512
New value of Value function: 0.201512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 98
New value of Q matrix: 0.663911
New value of Value function: 0.663911
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 446
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0235046
New value of Value function: 0.201512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 447
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0173723
New value of Value function: 0.201512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 448
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0824135
New value of Value function: 0.201512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 449
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.0832294
New value of Value function: 0.201512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 450
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.010805
New value of Value function: 0.010805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 451
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00260567
New value of Value function: 0.010805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 452
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00362721
New value of Value function: 0.010805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 453
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.257676
New value of Value function: 0.257676
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 454
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00150152
New value of Value function: 0.010805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 455
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00819283
New value of Value function: 0.010805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 456
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.264473
New value of Value function: 0.264473
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.157703
New value of Value function: 0.663911
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.662583
New value of Value function: 0.662583
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.252782
New value of Value function: 0.662583
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.25941
New value of Value function: 0.662583
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.259653
New value of Value function: 0.662583
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 100
New value of Q matrix: 0.689526
New value of Value function: 0.689526
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 463
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00731406
New value of Value function: 0.010805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 464
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 0.319378
New value of Value function: 0.319378
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 465
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0137778
New value of Value function: 0.0137778
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 466
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0227736
New value of Value function: 0.319378
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 467
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.318739
New value of Value function: 0.318739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 468
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0873021
New value of Value function: 0.318739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 469
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0165371
New value of Value function: 0.318739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 470
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0280555
New value of Value function: 0.318739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 471
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0865026
New value of Value function: 0.318739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 472
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.318101
New value of Value function: 0.318101
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 473
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0332202
New value of Value function: 0.318101
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 474
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.317465
New value of Value function: 0.317465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 475
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.323527
New value of Value function: 0.323527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.166961
New value of Value function: 0.689526
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.688147
New value of Value function: 0.688147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 102
New value of Q matrix: 0.720208
New value of Value function: 0.720208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 479
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.330021
New value of Value function: 0.330021
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.183626
New value of Value function: 0.720208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 103
New value of Q matrix: 0.746052
New value of Value function: 0.746052
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 482
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0137502
New value of Value function: 0.0137502
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 483
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0137227
New value of Value function: 0.0137227
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 484
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00171849
New value of Value function: 0.0137227
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 485
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0193886
New value of Value function: 0.0193886
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 486
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.145905
New value of Value function: 0.330021
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 487
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0076245
New value of Value function: 0.0193886
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 488
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0221468
New value of Value function: 0.330021
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 489
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0907129
New value of Value function: 0.330021
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 490
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.336849
New value of Value function: 0.336849
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 104
New value of Q matrix: 0.777194
New value of Value function: 0.777194
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 492
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.14905
New value of Value function: 0.336849
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 493
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0277671
New value of Value function: 0.336849
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 494
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.152132
New value of Value function: 0.336849
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 495
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0386191
New value of Value function: 0.336849
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 496
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0949619
New value of Value function: 0.336849
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 497
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0379332
New value of Value function: 0.336849
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 498
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00606328
New value of Value function: 0.00606328
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 499
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.336175
New value of Value function: 0.336175
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 500
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.151311
New value of Value function: 0.336175
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 501
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.134921
New value of Value function: 0.134921
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.268211
New value of Value function: 0.777194
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 54
New value of Q matrix: 0.308898
New value of Value function: 0.777194
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 504
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0432257
New value of Value function: 0.336175
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 505
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0991138
New value of Value function: 0.336175
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 506
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.335503
New value of Value function: 0.335503
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 507
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.342783
New value of Value function: 0.342783
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.193943
New value of Value function: 0.777194
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.775639
New value of Value function: 0.775639
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 106
New value of Q matrix: 0.806297
New value of Value function: 0.806297
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 511
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.103302
New value of Value function: 0.342783
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 512
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0333819
New value of Value function: 0.342783
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 513
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0424703
New value of Value function: 0.342783
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 514
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00819271
New value of Value function: 0.00819271
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 515
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 0.235817
New value of Value function: 0.235817
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 516
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.342097
New value of Value function: 0.342097
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 517
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.349768
New value of Value function: 0.349768
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.268973
New value of Value function: 0.806297
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 107
New value of Q matrix: 0.812599
New value of Value function: 0.812599
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 520
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.14685
New value of Value function: 0.14685
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 108
New value of Q matrix: 0.842643
New value of Value function: 0.842643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 522
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.154581
New value of Value function: 0.349768
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 523
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.211838
New value of Value function: 0.349768
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 524
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0137678
New value of Value function: 0.0193886
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 525
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0390101
New value of Value function: 0.349768
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 526
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.357941
New value of Value function: 0.357941
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 109
New value of Q matrix: 0.872233
New value of Value function: 0.872233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 528
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.26795
New value of Value function: 0.357941
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 529
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0199354
New value of Value function: 0.0199354
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 530
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.107679
New value of Value function: 0.357941
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 531
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.366482
New value of Value function: 0.366482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 55
New value of Q matrix: 0.325363
New value of Value function: 0.872233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 533
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0993349
New value of Value function: 0.14685
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 110
New value of Q matrix: 0.877432
New value of Value function: 0.877432
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 535
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 0.0519986
New value of Value function: 0.14685
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 536
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0458656
New value of Value function: 0.366482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 537
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0460384
New value of Value function: 0.235817
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 538
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 0.277698
New value of Value function: 0.277698
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 539
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0499468
New value of Value function: 0.366482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 540
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 0.31874
New value of Value function: 0.31874
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 541
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0546852
New value of Value function: 0.366482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 542
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0508549
New value of Value function: 0.31874
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 543
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 0.358962
New value of Value function: 0.358962
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 544
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.269188
New value of Value function: 0.366482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 545
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.053739
New value of Value function: 0.366482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 546
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00817632
New value of Value function: 0.00817632
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 547
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0144741
New value of Value function: 0.0144741
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 548
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 0.39838
New value of Value function: 0.39838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 549
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.112122
New value of Value function: 0.366482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 550
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.361796
New value of Value function: 0.361796
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 551
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0048149
New value of Value function: 0.14685
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 552
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.0974709
New value of Value function: 0.14685
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 553
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.059835
New value of Value function: 0.361796
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 554
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0570087
New value of Value function: 0.39838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 555
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0630393
New value of Value function: 0.39838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 556
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.120774
New value of Value function: 0.39838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 557
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000297004
New value of Value function: 0.0144741
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 558
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0144452
New value of Value function: 0.0144452
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 559
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0144163
New value of Value function: 0.0144163
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 560
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0212988
New value of Value function: 0.0212988
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 561
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 0.436924
New value of Value function: 0.436924
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 562
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.116392
New value of Value function: 0.361796
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 563
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0447422
New value of Value function: 0.361796
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 564
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.270317
New value of Value function: 0.361796
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 565
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.357203
New value of Value function: 0.357203
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 566
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.159706
New value of Value function: 0.159706
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 56
New value of Q matrix: 0.341731
New value of Value function: 0.877432
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 568
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.172306
New value of Value function: 0.172306
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.179415
New value of Value function: 0.877432
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.279388
New value of Value function: 0.877432
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.35069
New value of Value function: 0.877432
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.35947
New value of Value function: 0.877432
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 111
New value of Q matrix: 0.906313
New value of Value function: 0.906313
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 574
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.050277
New value of Value function: 0.357203
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 575
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.366373
New value of Value function: 0.366373
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.206378
New value of Value function: 0.906313
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.218564
New value of Value function: 0.906313
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.368594
New value of Value function: 0.906313
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 112
New value of Q matrix: 0.911288
New value of Value function: 0.911288
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 580
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.185263
New value of Value function: 0.185263
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.290203
New value of Value function: 0.911288
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 113
New value of Q matrix: 0.939657
New value of Value function: 0.939657
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 583
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.120658
New value of Value function: 0.366373
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 584
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.375959
New value of Value function: 0.375959
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.231107
New value of Value function: 0.939657
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 114
New value of Q matrix: 0.967631
New value of Value function: 0.967631
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 587
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.385857
New value of Value function: 0.385857
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.243902
New value of Value function: 0.967631
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.193244
New value of Value function: 0.967631
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.965696
New value of Value function: 0.965696
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 116
New value of Q matrix: 0.993327
New value of Value function: 0.993327
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 592
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.125191
New value of Value function: 0.385857
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 593
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0562169
New value of Value function: 0.385857
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 594
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.062038
New value of Value function: 0.385857
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 595
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.39602
New value of Value function: 0.39602
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 117
New value of Q matrix: 1.02059
New value of Value function: 1.02059
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 597
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.40647
New value of Value function: 0.40647
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.30277
New value of Value function: 1.02059
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 118
New value of Q matrix: 1.04749
New value of Value function: 1.04749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 600
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0681137
New value of Value function: 0.40647
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 601
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.417196
New value of Value function: 0.417196
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.380077
New value of Value function: 1.04749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 119
New value of Q matrix: 1.04988
New value of Value function: 1.04988
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 604
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.103386
New value of Value function: 0.185263
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 605
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.431521
New value of Value function: 0.431521
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 606
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.087313
New value of Value function: 0.185263
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 607
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0664057
New value of Value function: 0.417196
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 608
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.126126
New value of Value function: 0.431521
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 609
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.426225
New value of Value function: 0.426225
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 610
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 0.229067
New value of Value function: 0.229067
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 611
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.427749
New value of Value function: 0.427749
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 120
New value of Q matrix: 1.07658
New value of Value function: 1.07658
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 613
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.438573
New value of Value function: 0.438573
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.258402
New value of Value function: 1.07658
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.272613
New value of Value function: 1.07658
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.208758
New value of Value function: 1.07658
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 1.07443
New value of Value function: 1.07443
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 122
New value of Q matrix: 1.10083
New value of Value function: 1.10083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 619
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.130581
New value of Value function: 0.438573
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 620
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.449616
New value of Value function: 0.449616
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.316529
New value of Value function: 1.10083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.330014
New value of Value function: 1.10083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.286976
New value of Value function: 1.10083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.224398
New value of Value function: 1.10083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.343228
New value of Value function: 1.10083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.301051
New value of Value function: 1.10083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 627
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.392291
New value of Value function: 1.10083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 1.09863
New value of Value function: 1.09863
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.239685
New value of Value function: 1.09863
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 1.09643
New value of Value function: 1.09643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.404181
New value of Value function: 1.09643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.314766
New value of Value function: 1.09643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.254627
New value of Value function: 1.09643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.415833
New value of Value function: 1.09643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 1.09424
New value of Value function: 1.09424
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 126
New value of Q matrix: 1.12045
New value of Value function: 1.12045
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 637
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.136063
New value of Value function: 0.449616
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 638
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0748445
New value of Value function: 0.449616
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 639
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0814407
New value of Value function: 0.449616
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 640
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.460792
New value of Value function: 0.460792
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.269703
New value of Value function: 1.12045
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.284477
New value of Value function: 1.12045
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.298955
New value of Value function: 1.12045
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 1.11821
New value of Value function: 1.11821
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.328598
New value of Value function: 1.11821
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 1.11597
New value of Value function: 1.11597
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.356451
New value of Value function: 1.11597
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.427604
New value of Value function: 1.11597
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.439139
New value of Value function: 1.11597
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 1.11374
New value of Value function: 1.11374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 130
New value of Q matrix: 1.13976
New value of Value function: 1.13976
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 652
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.472092
New value of Value function: 0.472092
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.342542
New value of Value function: 1.13976
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.450872
New value of Value function: 1.13976
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.46237
New value of Value function: 1.13976
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.473639
New value of Value function: 1.13976
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 131
New value of Q matrix: 1.14109
New value of Value function: 1.14109
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 658
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.10899
New value of Value function: 0.229067
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 659
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0694506
New value of Value function: 0.426225
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 660
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00974265
New value of Value function: 0.426225
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 661
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0172198
New value of Value function: 0.426225
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 662
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0757336
New value of Value function: 0.426225
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 663
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.421824
New value of Value function: 0.421824
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 664
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 0.272984
New value of Value function: 0.272984
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 665
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.471148
New value of Value function: 0.471148
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 666
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0882926
New value of Value function: 0.471148
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 667
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.482265
New value of Value function: 0.482265
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 132
New value of Q matrix: 1.16695
New value of Value function: 1.16695
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 669
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.269824
New value of Value function: 0.482265
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 670
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.118353
New value of Value function: 0.272984
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.313981
New value of Value function: 1.16695
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.485171
New value of Value function: 1.16695
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 1.16461
New value of Value function: 1.16461
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 134
New value of Q matrix: 1.19
New value of Value function: 1.19
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 675
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0914404
New value of Value function: 0.482265
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 676
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 0.316205
New value of Value function: 0.316205
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 677
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.273108
New value of Value function: 0.482265
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 678
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.494039
New value of Value function: 0.494039
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.496887
New value of Value function: 1.19
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 135
New value of Q matrix: 1.21509
New value of Value function: 1.21509
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 681
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.276539
New value of Value function: 0.494039
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 682
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.50603
New value of Value function: 0.50603
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.329573
New value of Value function: 1.21509
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.508821
New value of Value function: 1.21509
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 1.21266
New value of Value function: 1.21266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 137
New value of Q matrix: 1.23752
New value of Value function: 1.23752
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 687
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0953033
New value of Value function: 0.50603
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 688
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 0.358989
New value of Value function: 0.358989
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 689
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.14245
New value of Value function: 0.50603
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 690
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.065461
New value of Value function: 0.50603
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 691
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00718976
New value of Value function: 0.0212988
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 692
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.358271
New value of Value function: 0.358271
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 693
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0920156
New value of Value function: 0.358271
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 694
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.357555
New value of Value function: 0.357555
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 695
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0966113
New value of Value function: 0.357555
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 696
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.35684
New value of Value function: 0.35684
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 697
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0538271
New value of Value function: 0.35684
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 698
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.146024
New value of Value function: 0.50603
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 699
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.356126
New value of Value function: 0.356126
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 700
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.114403
New value of Value function: 0.356126
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 701
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0818118
New value of Value function: 0.421824
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 702
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.163987
New value of Value function: 0.421824
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 703
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0284656
New value of Value function: 0.0284656
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 704
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.010281
New value of Value function: 0.421824
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 705
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.42098
New value of Value function: 0.42098
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 706
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.017653
New value of Value function: 0.42098
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 707
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.420138
New value of Value function: 0.420138
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 708
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0248624
New value of Value function: 0.420138
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 709
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.419298
New value of Value function: 0.419298
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 710
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 0.46002
New value of Value function: 0.46002
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 711
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0998075
New value of Value function: 0.50603
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 712
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.355414
New value of Value function: 0.355414
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 713
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.354703
New value of Value function: 0.354703
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 714
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 0.396717
New value of Value function: 0.396717
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 715
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.280116
New value of Value function: 0.50603
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 716
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.505018
New value of Value function: 0.505018
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 717
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 0.203462
New value of Value function: 0.505018
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 718
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0328642
New value of Value function: 0.0328642
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.52092
New value of Value function: 1.23752
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 138
New value of Q matrix: 1.25336
New value of Value function: 1.25336
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 721
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0280912
New value of Value function: 0.0328642
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 722
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.517478
New value of Value function: 0.517478
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.533062
New value of Value function: 1.25336
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 139
New value of Q matrix: 1.27761
New value of Value function: 1.27761
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 725
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0734664
New value of Value function: 0.517478
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 726
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.208708
New value of Value function: 0.517478
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 727
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.516443
New value of Value function: 0.516443
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 728
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.107107
New value of Value function: 0.516443
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 729
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.079138
New value of Value function: 0.516443
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 730
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 0.438079
New value of Value function: 0.438079
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 731
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.51541
New value of Value function: 0.51541
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 732
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0868326
New value of Value function: 0.51541
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 733
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.283792
New value of Value function: 0.51541
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 734
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.51438
New value of Value function: 0.51438
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 735
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.114224
New value of Value function: 0.51438
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 736
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.527089
New value of Value function: 0.527089
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.545398
New value of Value function: 1.27761
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.372319
New value of Value function: 1.27761
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.38787
New value of Value function: 1.27761
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.403109
New value of Value function: 1.27761
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 140
New value of Q matrix: 1.30154
New value of Value function: 1.30154
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 742
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.539975
New value of Value function: 0.539975
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 141
New value of Q matrix: 1.32523
New value of Value function: 1.32523
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 744
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.287835
New value of Value function: 0.539975
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 745
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.55303
New value of Value function: 0.55303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 142
New value of Q matrix: 1.34868
New value of Value function: 1.34868
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 747
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.292033
New value of Value function: 0.55303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 748
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.121894
New value of Value function: 0.55303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 749
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.129411
New value of Value function: 0.55303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 750
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.566245
New value of Value function: 0.566245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 143
New value of Q matrix: 1.3719
New value of Value function: 1.3719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 752
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.579615
New value of Value function: 0.579615
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 144
New value of Q matrix: 1.3949
New value of Value function: 1.3949
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 754
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.59313
New value of Value function: 0.59313
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.559598
New value of Value function: 1.3949
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 145
New value of Q matrix: 1.41767
New value of Value function: 1.41767
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 757
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0957723
New value of Value function: 0.59313
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 758
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.296869
New value of Value function: 0.59313
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 759
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.591944
New value of Value function: 0.591944
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 760
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.605623
New value of Value function: 0.605623
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 146
New value of Q matrix: 1.44022
New value of Value function: 1.44022
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 762
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.301833
New value of Value function: 0.605623
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 763
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.215435
New value of Value function: 0.605623
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 764
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.619435
New value of Value function: 0.619435
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 147
New value of Q matrix: 1.46257
New value of Value function: 1.46257
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 766
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.633372
New value of Value function: 0.633372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 148
New value of Q matrix: 1.48472
New value of Value function: 1.48472
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 768
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.105258
New value of Value function: 0.633372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 769
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.632106
New value of Value function: 0.632106
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 770
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.307174
New value of Value function: 0.632106
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 771
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.1382
New value of Value function: 0.632106
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 772
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.11453
New value of Value function: 0.632106
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 773
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.222504
New value of Value function: 0.632106
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 774
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.630842
New value of Value function: 0.630842
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 775
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.64495
New value of Value function: 0.64495
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.421772
New value of Value function: 1.48472
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 149
New value of Q matrix: 1.50663
New value of Value function: 1.50663
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 778
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.65917
New value of Value function: 0.65917
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 150
New value of Q matrix: 1.52836
New value of Value function: 1.52836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 780
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.312895
New value of Value function: 0.65917
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 781
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.124105
New value of Value function: 0.65917
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 782
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.122135
New value of Value function: 0.65917
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 783
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00755835
New value of Value function: 0.0284656
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 784
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0284087
New value of Value function: 0.0284087
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 785
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0178071
New value of Value function: 0.0284087
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 786
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.657852
New value of Value function: 0.657852
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 787
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.672205
New value of Value function: 0.672205
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 151
New value of Q matrix: 1.5499
New value of Value function: 1.5499
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 789
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.230154
New value of Value function: 0.672205
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 790
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.686659
New value of Value function: 0.686659
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.576304
New value of Value function: 1.5499
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 152
New value of Q matrix: 1.57126
New value of Value function: 1.57126
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 793
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.318997
New value of Value function: 0.686659
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 794
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.320503
New value of Value function: 0.686659
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 795
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.4576
New value of Value function: 0.4576
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 153
New value of Q matrix: 1.59219
New value of Value function: 1.59219
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 797
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.120204
New value of Value function: 0.686659
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 798
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0283519
New value of Value function: 0.0283519
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 799
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0360652
New value of Value function: 0.0360652
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 800
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 0.50318
New value of Value function: 0.50318
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 801
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.681163
New value of Value function: 0.681163
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 802
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.14694
New value of Value function: 0.4576
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 803
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.696199
New value of Value function: 0.696199
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.364351
New value of Value function: 1.59219
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 1.58901
New value of Value function: 1.58901
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 155
New value of Q matrix: 1.60976
New value of Value function: 1.60976
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 807
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.118449
New value of Value function: 0.696199
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 808
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00805636
New value of Value function: 0.0360652
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 809
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0359931
New value of Value function: 0.0359931
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 810
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0169525
New value of Value function: 0.0359931
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 811
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 0.545648
New value of Value function: 0.545648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 812
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.690512
New value of Value function: 0.690512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 813
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.144962
New value of Value function: 0.4576
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 156
New value of Q matrix: 1.6058
New value of Value function: 1.6058
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 815
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 0.164545
New value of Value function: 0.4576
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 816
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.326522
New value of Value function: 0.690512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 817
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.705606
New value of Value function: 0.705606
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 157
New value of Q matrix: 1.62639
New value of Value function: 1.62639
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 819
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.238251
New value of Value function: 0.705606
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 820
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.720769
New value of Value function: 0.720769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 158
New value of Q matrix: 1.64683
New value of Value function: 1.64683
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 822
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.24646
New value of Value function: 0.720769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 823
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.735996
New value of Value function: 0.735996
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 159
New value of Q matrix: 1.66714
New value of Value function: 1.66714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 825
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.751285
New value of Value function: 0.751285
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.387072
New value of Value function: 1.66714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.443345
New value of Value function: 1.66714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 160
New value of Q matrix: 1.68732
New value of Value function: 1.68732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 829
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.766631
New value of Value function: 0.766631
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.59515
New value of Value function: 1.68732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.46485
New value of Value function: 1.68732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.353354
New value of Value function: 1.68732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 1.68395
New value of Value function: 1.68395
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 162
New value of Q matrix: 1.70407
New value of Value function: 1.70407
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 835
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.781972
New value of Value function: 0.781972
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 163
New value of Q matrix: 1.72406
New value of Value function: 1.72406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 837
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.797366
New value of Value function: 0.797366
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.37732
New value of Value function: 1.72406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.400807
New value of Value function: 1.72406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 1.72062
New value of Value function: 1.72062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.486524
New value of Value function: 1.72062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 1.71717
New value of Value function: 1.71717
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 166
New value of Q matrix: 1.73718
New value of Value function: 1.73718
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 844
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.812688
New value of Value function: 0.812688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 167
New value of Q matrix: 1.75707
New value of Value function: 1.75707
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 846
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.150065
New value of Value function: 0.812688
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 847
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.828061
New value of Value function: 0.828061
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 168
New value of Q matrix: 1.77683
New value of Value function: 1.77683
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 849
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.256436
New value of Value function: 0.828061
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 850
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.843483
New value of Value function: 0.843483
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 169
New value of Q matrix: 1.79648
New value of Value function: 1.79648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 852
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.85895
New value of Value function: 0.85895
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.411667
New value of Value function: 1.79648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.435771
New value of Value function: 1.79648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.615584
New value of Value function: 1.79648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.635609
New value of Value function: 1.79648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 170
New value of Q matrix: 1.81601
New value of Value function: 1.81601
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 858
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.1553
New value of Value function: 0.85895
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 859
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.108212
New value of Value function: 0.4576
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 860
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.125901
New value of Value function: 0.85895
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 861
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0341868
New value of Value function: 0.545648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 862
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0899972
New value of Value function: 0.545648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 863
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0266971
New value of Value function: 0.545648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 864
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.544556
New value of Value function: 0.544556
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 865
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.541902
New value of Value function: 0.541902
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 866
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 0.503909
New value of Value function: 0.503909
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 867
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.874459
New value of Value function: 0.874459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.655585
New value of Value function: 1.81601
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 171
New value of Q matrix: 1.83543
New value of Value function: 1.83543
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 870
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.890008
New value of Value function: 0.890008
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 172
New value of Q matrix: 1.85474
New value of Value function: 1.85474
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 872
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.260378
New value of Value function: 0.890008
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 873
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.153072
New value of Value function: 0.503909
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 874
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 0.549851
New value of Value function: 0.549851
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 875
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.133138
New value of Value function: 0.890008
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 876
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 0.201355
New value of Value function: 0.541902
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 877
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00093894
New value of Value function: 0.0359931
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 878
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0450275
New value of Value function: 0.0450275
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 879
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 0.587084
New value of Value function: 0.587084
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 880
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.905593
New value of Value function: 0.905593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 173
New value of Q matrix: 1.87395
New value of Value function: 1.87395
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 882
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.141042
New value of Value function: 0.905593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 883
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 0.238138
New value of Value function: 0.587084
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 884
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0337516
New value of Value function: 0.0450275
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 885
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.168495
New value of Value function: 0.905593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 886
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.175022
New value of Value function: 0.905593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 887
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.171821
New value of Value function: 0.549851
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 888
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 0.274186
New value of Value function: 0.587084
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 889
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0493772
New value of Value function: 0.0493772
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 890
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.265068
New value of Value function: 0.905593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 891
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 0.595155
New value of Value function: 0.595155
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 892
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.921212
New value of Value function: 0.921212
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 174
New value of Q matrix: 1.89305
New value of Value function: 1.89305
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 894
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.336573
New value of Value function: 0.921212
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 895
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.936863
New value of Value function: 0.936863
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 175
New value of Q matrix: 1.91205
New value of Value function: 1.91205
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 897
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.27663
New value of Value function: 0.936863
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 898
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.952542
New value of Value function: 0.952542
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 176
New value of Q matrix: 1.93096
New value of Value function: 1.93096
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 900
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.346988
New value of Value function: 0.952542
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 901
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.357194
New value of Value function: 0.952542
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 902
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.968249
New value of Value function: 0.968249
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 903
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 177
New value of Q matrix: 1.94977
New value of Value function: 1.94977
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 904
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.367478
New value of Value function: 0.968249
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 905
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.983979
New value of Value function: 0.983979
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 906
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 178
New value of Q matrix: 1.96848
New value of Value function: 1.96848
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 907
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.37784
New value of Value function: 0.983979
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 908
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.999733
New value of Value function: 0.999733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 909
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.428223
New value of Value function: 1.96848
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 910
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 1.96455
New value of Value function: 1.96455
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 911
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 180
New value of Q matrix: 1.98325
New value of Value function: 1.98325
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 912
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 1.01544
New value of Value function: 1.01544
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 913
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 181
New value of Q matrix: 2.00186
New value of Value function: 2.00186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 914
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.28181
New value of Value function: 1.01544
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 915
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.11676
New value of Value function: 0.595155
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 916
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.619285
New value of Value function: 0.619285
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.455692
New value of Value function: 2.00186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.482612
New value of Value function: 2.00186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.678507
New value of Value function: 2.00186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 1.99786
New value of Value function: 1.99786
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 921
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 183
New value of Q matrix: 2.01618
New value of Value function: 2.01618
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 922
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 1.03142
New value of Value function: 1.03142
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 184
New value of Q matrix: 2.03442
New value of Value function: 2.03442
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 924
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 0.232113
New value of Value function: 1.03142
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 925
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0381022
New value of Value function: 0.0381022
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 926
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 1.04741
New value of Value function: 1.04741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.701556
New value of Value function: 2.03442
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.513413
New value of Value function: 2.03442
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 929
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 185
New value of Q matrix: 2.05259
New value of Value function: 2.05259
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 930
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 0.430969
New value of Value function: 1.04741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 931
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0260212
New value of Value function: 0.0381022
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 932
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.148789
New value of Value function: 1.04741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 933
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 0.634196
New value of Value function: 0.634196
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 934
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.441203
New value of Value function: 1.04741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 935
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 1.04532
New value of Value function: 1.04532
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 936
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 1.06136
New value of Value function: 1.06136
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 937
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 186
New value of Q matrix: 2.07064
New value of Value function: 2.07064
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 938
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 1.0774
New value of Value function: 1.0774
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 187
New value of Q matrix: 2.08862
New value of Value function: 2.08862
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 940
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 1.09345
New value of Value function: 1.09345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 188
New value of Q matrix: 2.10653
New value of Value function: 2.10653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 942
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.165495
New value of Value function: 1.09345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 943
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.452061
New value of Value function: 1.09345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 944
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.295856
New value of Value function: 1.09345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 945
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 0.503706
New value of Value function: 1.09345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 946
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0701245
New value of Value function: 0.0701245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.464973
New value of Value function: 2.10653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.493591
New value of Value function: 2.10653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.541062
New value of Value function: 2.10653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 189
New value of Q matrix: 2.10566
New value of Value function: 2.10566
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 951
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.106624
New value of Value function: 0.106624
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 190
New value of Q matrix: 2.10547
New value of Value function: 2.10547
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 953
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00191923
New value of Value function: 0.106624
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 954
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00380008
New value of Value function: 0.106624
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 955
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.14239
New value of Value function: 0.14239
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 191
New value of Q matrix: 2.10592
New value of Value function: 2.10592
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 957
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.177449
New value of Value function: 0.177449
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 192
New value of Q matrix: 2.107
New value of Value function: 2.107
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 959
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.211826
New value of Value function: 0.211826
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 960
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 193
New value of Q matrix: 2.10867
New value of Value function: 2.10867
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 961
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0313422
New value of Value function: 0.211826
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 962
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0345282
New value of Value function: 0.211826
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 963
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0376505
New value of Value function: 0.211826
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 964
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.245545
New value of Value function: 0.245545
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 965
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 194
New value of Q matrix: 2.11092
New value of Value function: 2.11092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 966
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.278631
New value of Value function: 0.278631
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.521715
New value of Value function: 2.11092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.725521
New value of Value function: 2.11092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 969
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.749007
New value of Value function: 2.11092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.772024
New value of Value function: 2.11092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.79458
New value of Value function: 2.11092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 195
New value of Q matrix: 2.11371
New value of Value function: 2.11371
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 973
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0423556
New value of Value function: 0.278631
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 974
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.311105
New value of Value function: 0.311105
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 196
New value of Q matrix: 2.11704
New value of Value function: 2.11704
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 976
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.34299
New value of Value function: 0.34299
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 197
New value of Q matrix: 2.12087
New value of Value function: 2.12087
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 978
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.374305
New value of Value function: 0.374305
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.511135
New value of Value function: 2.12087
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 2.11663
New value of Value function: 2.11663
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.568341
New value of Value function: 2.11663
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 199
New value of Q matrix: 2.13398
New value of Value function: 2.13398
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 983
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.309621
New value of Value function: 1.09345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 984
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 0.294209
New value of Value function: 1.09345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 985
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.405231
New value of Value function: 0.405231
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 986
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 200
New value of Q matrix: 2.15098
New value of Value function: 2.15098
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 987
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 0.560926
New value of Value function: 1.09345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 988
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.435844
New value of Value function: 0.435844
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.817406
New value of Value function: 2.15098
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 201
New value of Q matrix: 2.16764
New value of Value function: 2.16764
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 991
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 1.1106
New value of Value function: 1.1106
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.550299
New value of Value function: 2.16764
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 202
New value of Q matrix: 2.18428
New value of Value function: 2.18428
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 994
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.163074
New value of Value function: 1.1106
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 995
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0683804
New value of Value function: 0.0683804
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 996
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 1.1277
New value of Value function: 1.1277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.54023
New value of Value function: 2.18428
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 2.17991
New value of Value function: 2.17991
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 204
New value of Q matrix: 2.19661
New value of Value function: 2.19661
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1000
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 0.617553
New value of Value function: 1.1277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1001
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0493536
New value of Value function: 0.435844
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1002
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.466666
New value of Value function: 0.466666
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1003
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 205
New value of Q matrix: 2.20108
New value of Value function: 2.20108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1004
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.496952
New value of Value function: 0.496952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1005
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 206
New value of Q matrix: 2.20601
New value of Value function: 2.20601
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1006
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.526721
New value of Value function: 0.526721
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1007
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.840766
New value of Value function: 2.20601
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1008
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 89
New value of Q matrix: 0.855098
New value of Value function: 2.20601
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1009
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.646608
New value of Value function: 0.646608
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1010
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 207
New value of Q matrix: 2.21137
New value of Value function: 2.21137
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1011
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0132051
New value of Value function: 0.526721
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1012
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.555992
New value of Value function: 0.555992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1013
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 208
New value of Q matrix: 2.21715
New value of Value function: 2.21715
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1014
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0267316
New value of Value function: 0.555992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1015
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00325698
New value of Value function: 0.0683804
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1016
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0682437
New value of Value function: 0.0682437
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1017
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0453553
New value of Value function: 0.0682437
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1018
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.136887
New value of Value function: 0.136887
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1019
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0332396
New value of Value function: 0.555992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1020
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 0.373436
New value of Value function: 1.1277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1021
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0464956
New value of Value function: 0.555992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1022
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 1.12545
New value of Value function: 1.12545
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1023
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.180071
New value of Value function: 1.12545
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1024
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 1.12319
New value of Value function: 1.12319
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1025
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 1.14064
New value of Value function: 1.14064
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1026
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.877904
New value of Value function: 2.21715
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1027
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 209
New value of Q matrix: 2.23334
New value of Value function: 2.23334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1028
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 1.15803
New value of Value function: 1.15803
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1029
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.579493
New value of Value function: 2.23334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1030
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.900546
New value of Value function: 2.23334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1031
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 210
New value of Q matrix: 2.24951
New value of Value function: 2.24951
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1032
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 1.17536
New value of Value function: 1.17536
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1033
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 211
New value of Q matrix: 2.26568
New value of Value function: 2.26568
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1034
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.626358
New value of Value function: 1.17536
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1035
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 1.19263
New value of Value function: 1.19263
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1036
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.923318
New value of Value function: 2.26568
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1037
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 212
New value of Q matrix: 2.28183
New value of Value function: 2.28183
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1038
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 1.20985
New value of Value function: 1.20985
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1039
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.598047
New value of Value function: 2.28183
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1040
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 213
New value of Q matrix: 2.29797
New value of Value function: 2.29797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1041
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.310102
New value of Value function: 1.20985
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1042
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.387745
New value of Value function: 1.20985
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1043
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 1.22702
New value of Value function: 1.22702
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1044
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.609266
New value of Value function: 2.29797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1045
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.638445
New value of Value function: 2.29797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1046
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 214
New value of Q matrix: 2.30202
New value of Value function: 2.30202
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1047
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.586308
New value of Value function: 0.586308
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1048
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 215
New value of Q matrix: 2.30653
New value of Value function: 2.30653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1049
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.067652
New value of Value function: 0.586308
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1050
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.635917
New value of Value function: 1.22702
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1051
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 122
New value of Q matrix: 1.27303
New value of Value function: 1.27303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1052
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.6161
New value of Value function: 0.6161
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1053
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 216
New value of Q matrix: 2.31149
New value of Value function: 2.31149
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1054
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.645384
New value of Value function: 0.645384
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1055
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 217
New value of Q matrix: 2.31688
New value of Value function: 2.31688
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1056
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.674181
New value of Value function: 0.674181
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1057
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.66738
New value of Value function: 2.31688
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1058
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 218
New value of Q matrix: 2.32268
New value of Value function: 2.32268
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1059
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.702505
New value of Value function: 0.702505
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1060
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 219
New value of Q matrix: 2.32887
New value of Value function: 2.32887
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1061
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.730375
New value of Value function: 0.730375
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1062
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 220
New value of Q matrix: 2.33544
New value of Value function: 2.33544
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1063
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0500443
New value of Value function: 0.730375
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1064
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0615133
New value of Value function: 0.730375
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1065
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0621901
New value of Value function: 0.730375
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1066
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0892135
New value of Value function: 0.730375
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1067
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.178933
New value of Value function: 1.27303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1068
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0056558
New value of Value function: 0.136887
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1069
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0469122
New value of Value function: 0.136887
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1070
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00554268
New value of Value function: 0.136887
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1071
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1072
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00246396
New value of Value function: 0.00246396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1073
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.136613
New value of Value function: 0.136613
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1074
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00789086
New value of Value function: 0.136613
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1075
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.13634
New value of Value function: 0.13634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1076
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.156527
New value of Value function: 0.156527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1077
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 123
New value of Q matrix: 1.32072
New value of Value function: 1.32072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1078
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.757805
New value of Value function: 0.757805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1079
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 221
New value of Q matrix: 2.34237
New value of Value function: 2.34237
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1080
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0462153
New value of Value function: 0.757805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1081
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0745868
New value of Value function: 0.757805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1082
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.784812
New value of Value function: 0.784812
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1083
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 222
New value of Q matrix: 2.34965
New value of Value function: 2.34965
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1084
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.811409
New value of Value function: 0.811409
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1085
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.62838
New value of Value function: 2.34965
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1086
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.658106
New value of Value function: 2.34965
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1087
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.696326
New value of Value function: 2.34965
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1088
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.724693
New value of Value function: 2.34965
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1089
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 2.34495
New value of Value function: 2.34495
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1090
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.752408
New value of Value function: 2.34495
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1091
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 224
New value of Q matrix: 2.35266
New value of Value function: 2.35266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1092
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0748884
New value of Value function: 0.811409
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1093
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0877005
New value of Value function: 0.811409
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1094
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.100552
New value of Value function: 0.811409
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1095
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0902468
New value of Value function: 0.811409
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1096
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0105505
New value of Value function: 0.156527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1097
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0194309
New value of Value function: 0.156527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1098
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0103839
New value of Value function: 0.156527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1099
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.43513e-05
New value of Value function: 0.00246396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1100
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.43513e-05
New value of Value function: 0.00246396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1101
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.78155e-05
New value of Value function: 0.00246396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1102
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.43513e-05
New value of Value function: 0.00246396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1103
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.43513e-05
New value of Value function: 0.00246396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1104
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00013041
New value of Value function: 0.00246396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1105
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.64242e-05
New value of Value function: 0.00246396
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1106
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1107
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0600127
New value of Value function: 0.0600127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1108
----------
State: 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1109
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1110
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1111
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1112
----------
State: 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1113
----------
State: 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1114
----------
State: 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108023
New value of Value function: 0.00108023
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1115
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.118812
New value of Value function: 0.118812
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1116
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1117
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1118
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1119
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1120
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1121
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1122
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1123
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.94441e-05
New value of Value function: 1.94441e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1124
----------
State: 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.49994e-07
New value of Value function: 0.00108023
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1125
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.84993e-05
New value of Value function: 3.84993e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1126
----------
State: 637
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00319725
New value of Value function: 0.00319725
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1127
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213862
New value of Value function: 0.118812
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1128
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.176437
New value of Value function: 0.176437
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1129
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00321359
New value of Value function: 0.00321359
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1130
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.232966
New value of Value function: 0.232966
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1131
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.78447e-05
New value of Value function: 0.00321359
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1132
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00734271
New value of Value function: 0.00734271
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1133
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.288439
New value of Value function: 0.288439
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1134
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0123878
New value of Value function: 0.0123878
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1135
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0058975
New value of Value function: 0.288439
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1136
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.342893
New value of Value function: 0.342893
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1137
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00022298
New value of Value function: 0.0123878
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1138
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0183121
New value of Value function: 0.0183121
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1139
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.396365
New value of Value function: 0.396365
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1140
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000373881
New value of Value function: 0.0183121
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1141
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00713457
New value of Value function: 0.00863116
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1142
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0129141
New value of Value function: 0.396365
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1143
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.388593
New value of Value function: 0.388593
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1144
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00700737
New value of Value function: 0.00863116
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1145
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.380976
New value of Value function: 0.380976
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1146
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0508064
New value of Value function: 0.0508064
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.687291
New value of Value function: 2.35266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 93
New value of Q matrix: 0.925571
New value of Value function: 2.35266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1149
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0815478
New value of Value function: 0.0815478
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.715893
New value of Value function: 2.35266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.743923
New value of Value function: 2.35266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.779708
New value of Value function: 2.35266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.571773
New value of Value function: 2.35266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 2.34795
New value of Value function: 2.34795
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 2.34326
New value of Value function: 2.34326
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 2.33857
New value of Value function: 2.33857
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.949154
New value of Value function: 2.33857
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 2.33389
New value of Value function: 2.33389
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 2.32922
New value of Value function: 2.32922
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.972097
New value of Value function: 2.32922
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.994581
New value of Value function: 2.32922
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 2.32457
New value of Value function: 2.32457
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 2.31992
New value of Value function: 2.31992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.770803
New value of Value function: 2.31992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.805872
New value of Value function: 2.31992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.831513
New value of Value function: 2.31992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 2.31528
New value of Value function: 2.31528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.856558
New value of Value function: 2.31528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 1.01636
New value of Value function: 2.31528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.797062
New value of Value function: 2.31528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 2.31065
New value of Value function: 2.31065
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 2.30603
New value of Value function: 2.30603
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 1.03755
New value of Value function: 2.30603
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 2.30141
New value of Value function: 2.30141
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 2.29681
New value of Value function: 2.29681
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 2.29222
New value of Value function: 2.29222
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.601597
New value of Value function: 2.29222
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 2.28763
New value of Value function: 2.28763
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 2.28306
New value of Value function: 2.28306
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 1.05789
New value of Value function: 2.28306
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 2.27849
New value of Value function: 2.27849
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 2.27393
New value of Value function: 2.27393
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 2.26939
New value of Value function: 2.26939
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 2.26485
New value of Value function: 2.26485
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.821888
New value of Value function: 2.26485
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 2.26032
New value of Value function: 2.26032
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.846136
New value of Value function: 2.26032
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 2.2558
New value of Value function: 2.2558
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.63017
New value of Value function: 2.2558
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 2.25129
New value of Value function: 2.25129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 2.24678
New value of Value function: 2.24678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 2.24229
New value of Value function: 2.24229
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 2.23781
New value of Value function: 2.23781
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 2.23333
New value of Value function: 2.23333
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 2.22886
New value of Value function: 2.22886
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 1.07685
New value of Value function: 2.22886
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 2.22441
New value of Value function: 2.22441
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 2.21996
New value of Value function: 2.21996
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 2.21552
New value of Value function: 2.21552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 2.21109
New value of Value function: 2.21109
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 1.09511
New value of Value function: 2.21109
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 2.20666
New value of Value function: 2.20666
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 1.11293
New value of Value function: 2.20666
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 1.13039
New value of Value function: 2.20666
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 2.20225
New value of Value function: 2.20225
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.879067
New value of Value function: 2.20225
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 2.19785
New value of Value function: 2.19785
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 2.19345
New value of Value function: 2.19345
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 1.14727
New value of Value function: 2.19345
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 2.18906
New value of Value function: 2.18906
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 2.18468
New value of Value function: 2.18468
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 2.18032
New value of Value function: 2.18032
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 2.17595
New value of Value function: 2.17595
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.868381
New value of Value function: 2.17595
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 2.1716
New value of Value function: 2.1716
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 2.16726
New value of Value function: 2.16726
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.890024
New value of Value function: 2.16726
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 2.16292
New value of Value function: 2.16292
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 1.16325
New value of Value function: 2.16292
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 2.1586
New value of Value function: 2.1586
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.900341
New value of Value function: 2.1586
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 2.15428
New value of Value function: 2.15428
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 269
New value of Q matrix: 2.1658
New value of Value function: 2.1658
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1224
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.834165
New value of Value function: 0.834165
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 270
New value of Q matrix: 2.1775
New value of Value function: 2.1775
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1226
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.856677
New value of Value function: 0.856677
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 271
New value of Q matrix: 2.18937
New value of Value function: 2.18937
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1228
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0607112
New value of Value function: 0.856677
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1229
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.878952
New value of Value function: 0.878952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 272
New value of Q matrix: 2.2014
New value of Value function: 2.2014
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1231
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.114362
New value of Value function: 0.878952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1232
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0892118
New value of Value function: 0.878952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1233
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.127896
New value of Value function: 0.878952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1234
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.900999
New value of Value function: 0.900999
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 273
New value of Q matrix: 2.21359
New value of Value function: 2.21359
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1236
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.922823
New value of Value function: 0.922823
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.922179
New value of Value function: 2.21359
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 274
New value of Q matrix: 2.22593
New value of Value function: 2.22593
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1239
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.104038
New value of Value function: 0.922823
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1240
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.118568
New value of Value function: 0.922823
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1241
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.944434
New value of Value function: 0.944434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.657633
New value of Value function: 2.22593
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.943802
New value of Value function: 2.22593
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.684547
New value of Value function: 2.22593
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 2.22148
New value of Value function: 2.22148
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 2.21704
New value of Value function: 2.21704
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 277
New value of Q matrix: 2.2297
New value of Value function: 2.2297
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1248
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0711359
New value of Value function: 0.944434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1249
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.67381
New value of Value function: 0.67381
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 106
New value of Q matrix: 1.17212
New value of Value function: 2.2297
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1251
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.700468
New value of Value function: 0.700468
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 278
New value of Q matrix: 2.2421
New value of Value function: 2.2421
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1253
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.965903
New value of Value function: 0.965903
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 279
New value of Q matrix: 2.25465
New value of Value function: 2.25465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1255
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.987168
New value of Value function: 0.987168
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.96551
New value of Value function: 2.25465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.71144
New value of Value function: 2.25465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.912807
New value of Value function: 2.25465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 2.25014
New value of Value function: 2.25014
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 281
New value of Q matrix: 2.2629
New value of Value function: 2.2629
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1261
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.143107
New value of Value function: 0.987168
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1262
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.133966
New value of Value function: 0.987168
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1263
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 1.00816
New value of Value function: 1.00816
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.935283
New value of Value function: 2.2629
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 282
New value of Q matrix: 2.27579
New value of Value function: 2.27579
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1266
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0912593
New value of Value function: 1.00816
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1267
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0218598
New value of Value function: 0.156527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1268
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 685
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.105974
New value of Value function: 0.156527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1269
----------
State: 685
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00281749
New value of Value function: 0.00281749
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1270
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0242401
New value of Value function: 0.156527
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1271
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.17717
New value of Value function: 0.17717
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1272
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 0.458137
New value of Value function: 1.32072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1273
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 1.0006
New value of Value function: 1.0006
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1274
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.727423
New value of Value function: 0.727423
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 283
New value of Q matrix: 2.28829
New value of Value function: 2.28829
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1276
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.149298
New value of Value function: 1.0006
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1277
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 1.02178
New value of Value function: 1.02178
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 284
New value of Q matrix: 2.3063
New value of Value function: 2.3063
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1279
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 1.33582
New value of Value function: 1.33582
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 285
New value of Q matrix: 2.32421
New value of Value function: 2.32421
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1281
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 0.701591
New value of Value function: 1.33582
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1282
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 1.04318
New value of Value function: 1.04318
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.958413
New value of Value function: 2.32421
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 286
New value of Q matrix: 2.33651
New value of Value function: 2.33651
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1285
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0884904
New value of Value function: 1.04318
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1286
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 1.06437
New value of Value function: 1.06437
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 287
New value of Q matrix: 2.34894
New value of Value function: 2.34894
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1288
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 1.08537
New value of Value function: 1.08537
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 288
New value of Q matrix: 2.36149
New value of Value function: 2.36149
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1290
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.165848
New value of Value function: 1.08537
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1291
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.159781
New value of Value function: 1.08537
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1292
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.176122
New value of Value function: 1.08537
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1293
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 1.10617
New value of Value function: 1.10617
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 289
New value of Q matrix: 2.37417
New value of Value function: 2.37417
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1295
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 1.12678
New value of Value function: 1.12678
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 290
New value of Q matrix: 2.38697
New value of Value function: 2.38697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1297
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 1.14721
New value of Value function: 1.14721
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.740177
New value of Value function: 2.38697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 2.3822
New value of Value function: 2.3822
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 292
New value of Q matrix: 2.39521
New value of Value function: 2.39521
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1301
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0926232
New value of Value function: 1.14721
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1302
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0133653
New value of Value function: 0.17717
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1303
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.176815
New value of Value function: 0.176815
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1304
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.253929
New value of Value function: 0.253929
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1305
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.183181
New value of Value function: 1.14721
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1306
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.19325
New value of Value function: 1.14721
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1307
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0953415
New value of Value function: 1.14721
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1308
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0176687
New value of Value function: 0.253929
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1309
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0173597
New value of Value function: 0.253929
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1310
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0069854
New value of Value function: 0.0069854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1311
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.253421
New value of Value function: 0.253421
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1312
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.272397
New value of Value function: 0.272397
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1313
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 1.35221
New value of Value function: 1.35221
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 293
New value of Q matrix: 2.41164
New value of Value function: 2.41164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1315
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 1.36858
New value of Value function: 1.36858
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 294
New value of Q matrix: 2.42804
New value of Value function: 2.42804
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1317
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.180258
New value of Value function: 1.36858
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1318
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.291584
New value of Value function: 0.291584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1319
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 0.768209
New value of Value function: 1.36858
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1320
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 1.16797
New value of Value function: 1.16797
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 107
New value of Q matrix: 1.18177
New value of Value function: 2.42804
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1322
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.75658
New value of Value function: 0.75658
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 295
New value of Q matrix: 2.44051
New value of Value function: 2.44051
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1324
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 1.18854
New value of Value function: 1.18854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.990128
New value of Value function: 2.44051
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 296
New value of Q matrix: 2.45309
New value of Value function: 2.45309
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1327
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.20892
New value of Value function: 1.20892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 297
New value of Q matrix: 2.46579
New value of Value function: 2.46579
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1329
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.201278
New value of Value function: 1.20892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1330
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0986831
New value of Value function: 1.20892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1331
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0826808
New value of Value function: 0.291584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1332
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.108481
New value of Value function: 1.20892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1333
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 1.20651
New value of Value function: 1.20651
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1334
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.128029
New value of Value function: 1.20651
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1335
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 1.22676
New value of Value function: 1.22676
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 298
New value of Q matrix: 2.47855
New value of Value function: 2.47855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1337
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 1.24684
New value of Value function: 1.24684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.769987
New value of Value function: 2.47855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 1.20275
New value of Value function: 2.47855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 2.4736
New value of Value function: 2.4736
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.799112
New value of Value function: 2.4736
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 2.46865
New value of Value function: 2.46865
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 301
New value of Q matrix: 2.48172
New value of Value function: 2.48172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1344
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 1.26657
New value of Value function: 1.26657
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.983916
New value of Value function: 2.48172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 1.22336
New value of Value function: 2.48172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 1.00891
New value of Value function: 2.48172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 1.0334
New value of Value function: 2.48172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 302
New value of Q matrix: 2.49488
New value of Value function: 2.49488
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1350
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 1.28615
New value of Value function: 1.28615
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 1.01523
New value of Value function: 2.49488
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 303
New value of Q matrix: 2.50814
New value of Value function: 2.50814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1353
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 1.30557
New value of Value function: 1.30557
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.828276
New value of Value function: 2.50814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 2.50312
New value of Value function: 2.50312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 1.05779
New value of Value function: 2.50312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 1.08169
New value of Value function: 2.50312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 305
New value of Q matrix: 2.51656
New value of Value function: 2.51656
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1359
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 1.32476
New value of Value function: 1.32476
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 306
New value of Q matrix: 2.53007
New value of Value function: 2.53007
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1361
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.34381
New value of Value function: 1.34381
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 307
New value of Q matrix: 2.54366
New value of Value function: 2.54366
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1363
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 1.36271
New value of Value function: 1.36271
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 308
New value of Q matrix: 2.55732
New value of Value function: 2.55732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1365
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 1.38149
New value of Value function: 1.38149
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 1.10609
New value of Value function: 2.55732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 309
New value of Q matrix: 2.57104
New value of Value function: 2.57104
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1368
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 1.40014
New value of Value function: 1.40014
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 310
New value of Q matrix: 2.58482
New value of Value function: 2.58482
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1370
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 1.41866
New value of Value function: 1.41866
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 311
New value of Q matrix: 2.59866
New value of Value function: 2.59866
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1372
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 1.43707
New value of Value function: 1.43707
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 312
New value of Q matrix: 2.61255
New value of Value function: 2.61255
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1374
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.22312
New value of Value function: 1.43707
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1375
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.101958
New value of Value function: 1.43707
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1376
----------
State: 829
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.371619
New value of Value function: 0.371619
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1377
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.151335
New value of Value function: 1.43707
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1378
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 1.45535
New value of Value function: 1.45535
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 313
New value of Q matrix: 2.6265
New value of Value function: 2.6265
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1380
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 1.47352
New value of Value function: 1.47352
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 314
New value of Q matrix: 2.64049
New value of Value function: 2.64049
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1382
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 1.49158
New value of Value function: 1.49158
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 1.24643
New value of Value function: 2.64049
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 1.13149
New value of Value function: 2.64049
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 315
New value of Q matrix: 2.65453
New value of Value function: 2.65453
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1386
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 1.50953
New value of Value function: 1.50953
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 316
New value of Q matrix: 2.66861
New value of Value function: 2.66861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1388
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 1.52737
New value of Value function: 1.52737
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 1.04296
New value of Value function: 2.66861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 317
New value of Q matrix: 2.68273
New value of Value function: 2.68273
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1391
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 1.54512
New value of Value function: 1.54512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 1.15715
New value of Value function: 2.68273
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 318
New value of Q matrix: 2.69689
New value of Value function: 2.69689
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1394
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.246469
New value of Value function: 1.54512
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1395
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 1.56276
New value of Value function: 1.56276
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 319
New value of Q matrix: 2.71108
New value of Value function: 2.71108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1397
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 1.5803
New value of Value function: 1.5803
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 320
New value of Q matrix: 2.7253
New value of Value function: 2.7253
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1399
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 1.59775
New value of Value function: 1.59775
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 321
New value of Q matrix: 2.73956
New value of Value function: 2.73956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1401
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.218144
New value of Value function: 1.59775
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1402
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 1.61511
New value of Value function: 1.61511
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 322
New value of Q matrix: 2.75384
New value of Value function: 2.75384
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1404
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.242853
New value of Value function: 1.61511
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1405
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 1.63238
New value of Value function: 1.63238
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 323
New value of Q matrix: 2.76814
New value of Value function: 2.76814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1407
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 1.64955
New value of Value function: 1.64955
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 1.27132
New value of Value function: 2.76814
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 324
New value of Q matrix: 2.78247
New value of Value function: 2.78247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1410
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 1.66665
New value of Value function: 1.66665
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.861795
New value of Value function: 2.78247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 2.77691
New value of Value function: 2.77691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 112
New value of Q matrix: 1.27952
New value of Value function: 2.77691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1414
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.791432
New value of Value function: 0.791432
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 1.07209
New value of Value function: 2.77691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 326
New value of Q matrix: 2.79137
New value of Value function: 2.79137
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1417
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 1.68356
New value of Value function: 1.68356
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 327
New value of Q matrix: 2.80585
New value of Value function: 2.80585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1419
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 1.70039
New value of Value function: 1.70039
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.895065
New value of Value function: 2.80585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 2.80023
New value of Value function: 2.80023
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 329
New value of Q matrix: 2.81484
New value of Value function: 2.81484
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1423
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 1.71705
New value of Value function: 1.71705
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 330
New value of Q matrix: 2.82945
New value of Value function: 2.82945
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1425
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 1.73364
New value of Value function: 1.73364
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 1.30486
New value of Value function: 2.82945
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 331
New value of Q matrix: 2.84406
New value of Value function: 2.84406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1428
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 1.75016
New value of Value function: 1.75016
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 114
New value of Q matrix: 1.313
New value of Value function: 2.84406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1430
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.826797
New value of Value function: 0.826797
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 1.10184
New value of Value function: 2.84406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 332
New value of Q matrix: 2.85869
New value of Value function: 2.85869
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1433
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 1.76662
New value of Value function: 1.76662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 1.18547
New value of Value function: 2.85869
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 333
New value of Q matrix: 2.87331
New value of Value function: 2.87331
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1436
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.124553
New value of Value function: 1.76662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1437
----------
State: 853
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 127
New value of Q matrix: 1.43301
New value of Value function: 1.43301
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1438
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.269795
New value of Value function: 1.76662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1439
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 1.783
New value of Value function: 1.783
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 334
New value of Q matrix: 2.88794
New value of Value function: 2.88794
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1441
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 1.79933
New value of Value function: 1.79933
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.929146
New value of Value function: 2.88794
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 2.88216
New value of Value function: 2.88216
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 336
New value of Q matrix: 2.89691
New value of Value function: 2.89691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1445
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.180696
New value of Value function: 1.79933
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1446
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.20947
New value of Value function: 1.79933
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1447
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.237669
New value of Value function: 1.79933
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1448
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 1.81548
New value of Value function: 1.81548
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 337
New value of Q matrix: 2.91165
New value of Value function: 2.91165
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1450
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.297078
New value of Value function: 1.81548
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1451
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 1.83158
New value of Value function: 1.83158
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 1.21417
New value of Value function: 2.91165
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 1.33915
New value of Value function: 2.91165
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 338
New value of Q matrix: 2.92638
New value of Value function: 2.92638
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1455
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 1.84763
New value of Value function: 1.84763
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 339
New value of Q matrix: 2.94111
New value of Value function: 2.94111
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1457
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 1.86361
New value of Value function: 1.86361
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.963503
New value of Value function: 2.94111
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 2.93523
New value of Value function: 2.93523
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 341
New value of Q matrix: 2.95007
New value of Value function: 2.95007
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1461
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.155607
New value of Value function: 1.86361
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1462
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 1.85989
New value of Value function: 1.85989
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1463
----------
State: 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 709
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.275018
New value of Value function: 1.85989
New value of Policy matrix: 0

