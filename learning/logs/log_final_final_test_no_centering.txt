=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.12132
New value of Value function: 2.12132
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.899893
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.62863
New value of Value function: 2.62863
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.39766
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 2.81431
New value of Value function: 2.81431
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.21383
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 2.89735
New value of Value function: 2.89735
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.131619
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.02825
New value of Value function: 2.89735
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.02825
New value of Value function: 2.89735
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.88553
New value of Value function: 2.88553
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.692845
New value of Value function: 2.88553
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 2.92879
New value of Value function: 2.92879
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.0502473
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 2.95397
New value of Value function: 2.95397
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.0534367
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 2.96931
New value of Value function: 2.96931
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 46
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 49
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 52
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 53
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 55
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.49698
New value of Value function: 3.49698
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 56
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 57
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.0603806
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 4.0738
New value of Value function: 4.0738
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.022585
New value of Value function: 3.49698
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 60
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.03306
New value of Value function: 1.03306
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 4.79387
New value of Value function: 4.79387
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.48602
New value of Value function: 2.48602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 4.9865
New value of Value function: 4.9865
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.74301
New value of Value function: 3.74301
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 65
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 66
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.93664
New value of Value function: 1.93664
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 5.80843
New value of Value function: 5.80843
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 69
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 70
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.75034
New value of Value function: 2.75034
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 5.78555
New value of Value function: 5.78555
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 72
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 2.75034
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 73
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 74
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 76
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 79
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.97727
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.302577
New value of Value function: 0.302577
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 82
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 95
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 96
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 98
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 99
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 100
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 101
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 102
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 103
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 104
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.53553
New value of Value function: 3.53553
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 105
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 106
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 107
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 108
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 110
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 111
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 112
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 113
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 114
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 115
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 116
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 117
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 118
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 119
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 121
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 122
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 123
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 124
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 125
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 126
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 127
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 128
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 129
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 130
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 131
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 132
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.53553
New value of Value function: 3.53553
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 133
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 134
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 135
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 136
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 137
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 138
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 139
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 140
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 141
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 142
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 143
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3925
	Distance: 9
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 144
----------
State: 3925
	Distance: 9
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3925
	Distance: 9
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 145
----------
State: 3925
	Distance: 9
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3925
	Distance: 9
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 3925
	Distance: 9
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2725
	Distance: 6
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 147
----------
State: 2725
	Distance: 6
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.7277
New value of Value function: 2.7277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.77062
New value of Value function: 5.77062
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 1.23665
New value of Value function: 5.77062
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 150
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 151
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.71291
New value of Value function: 2.71291
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.75619
New value of Value function: 5.75619
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.74223
New value of Value function: 5.74223
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.72869
New value of Value function: 5.72869
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.13163
New value of Value function: 5.72869
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.13163
New value of Value function: 5.72869
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.71555
New value of Value function: 5.71555
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.70277
New value of Value function: 5.70277
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.69033
New value of Value function: 5.69033
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 5.67819
New value of Value function: 5.67819
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.87652
New value of Value function: 5.67819
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.66636
New value of Value function: 5.66636
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 5.65479
New value of Value function: 5.65479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.64348
New value of Value function: 5.64348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.63241
New value of Value function: 5.63241
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 2.23218
New value of Value function: 5.63241
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.62157
New value of Value function: 5.62157
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.61095
New value of Value function: 5.61095
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 5.60053
New value of Value function: 5.60053
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.5903
New value of Value function: 5.5903
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.58026
New value of Value function: 5.58026
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.18955
New value of Value function: 5.58026
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.5704
New value of Value function: 5.5704
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.16192
New value of Value function: 5.5704
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.5607
New value of Value function: 5.5607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.55117
New value of Value function: 5.55117
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.54178
New value of Value function: 5.54178
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.53255
New value of Value function: 5.53255
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.52345
New value of Value function: 5.52345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.51449
New value of Value function: 5.51449
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.50566
New value of Value function: 5.50566
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.49695
New value of Value function: 5.49695
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 2.94992
New value of Value function: 5.49695
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 5.48837
New value of Value function: 5.48837
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.27279
New value of Value function: 5.48837
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.4799
New value of Value function: 5.4799
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 5.47154
New value of Value function: 5.47154
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.4633
New value of Value function: 5.4633
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.45515
New value of Value function: 5.45515
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.44711
New value of Value function: 5.44711
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.43916
New value of Value function: 5.43916
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.43131
New value of Value function: 5.43131
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 5.42355
New value of Value function: 5.42355
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.41588
New value of Value function: 5.41588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.3064
New value of Value function: 5.41588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.4083
New value of Value function: 5.4083
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.4008
New value of Value function: 5.4008
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 5.39338
New value of Value function: 5.39338
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.38604
New value of Value function: 5.38604
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.7319
New value of Value function: 5.38604
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.46977
New value of Value function: 5.38604
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 55
New value of Q matrix: 5.06431
New value of Value function: 5.3064
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 3
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.70558
New value of Value function: 3.70558
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 4
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.82297
New value of Value function: 3.74301
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 5
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.70558
New value of Value function: 3.70558
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 6
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.07681
New value of Value function: 3.07681
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.28764
New value of Value function: 5.28764
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.95679
New value of Value function: 5.28764
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 5.27002
New value of Value function: 5.27002
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.25335
New value of Value function: 5.25335
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.23751
New value of Value function: 5.23751
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 5.22239
New value of Value function: 5.22239
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.0439
New value of Value function: 5.22239
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.8323
New value of Value function: 5.22239
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.17986
New value of Value function: 5.22239
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.20791
New value of Value function: 5.20791
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.19399
New value of Value function: 5.19399
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.61016
New value of Value function: 5.19399
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.18058
New value of Value function: 5.18058
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.16763
New value of Value function: 5.16763
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.15509
New value of Value function: 5.15509
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.14294
New value of Value function: 5.14294
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.13114
New value of Value function: 5.13114
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.11967
New value of Value function: 5.11967
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.1085
New value of Value function: 5.1085
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 5.09761
New value of Value function: 5.09761
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.08698
New value of Value function: 5.08698
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 5.07659
New value of Value function: 5.07659
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.06644
New value of Value function: 5.06644
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.0565
New value of Value function: 5.06431
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.05754
New value of Value function: 5.05754
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.05084
New value of Value function: 5.0565
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.04677
New value of Value function: 5.05084
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.04421
New value of Value function: 5.04677
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.02591
New value of Value function: 5.04677
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.03724
New value of Value function: 5.04421
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.03764
New value of Value function: 5.03764
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.03114
New value of Value function: 5.03724
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 5.02788
New value of Value function: 5.03114
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.0247
New value of Value function: 5.02788
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.0187
New value of Value function: 5.02591
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.01097
New value of Value function: 5.02591
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.00814
New value of Value function: 5.0247
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.00451
New value of Value function: 5.0247
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.01832
New value of Value function: 5.01832
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.01199
New value of Value function: 5.01199
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.00573
New value of Value function: 5.00814
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.99643
New value of Value function: 5.00814
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.75219
New value of Value function: 5.00814
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.99145
New value of Value function: 5.00573
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.98013
New value of Value function: 5.00573
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 4.99952
New value of Value function: 4.99952
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 4.99337
New value of Value function: 4.99643
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.96998
New value of Value function: 4.99643
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 4.98786
New value of Value function: 4.99337
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 4.98726
New value of Value function: 4.98786
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.06285
New value of Value function: 4.98786
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 4.97943
New value of Value function: 4.98726
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.82219
New value of Value function: 4.98726
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.96057
New value of Value function: 4.98726
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 4.98122
New value of Value function: 4.98122
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 4.97522
New value of Value function: 4.97943
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 4.97113
New value of Value function: 4.97522
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 4.96927
New value of Value function: 4.97113
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.96296
New value of Value function: 4.96927
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 4.96338
New value of Value function: 4.96338
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 4.95753
New value of Value function: 4.96296
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 4.95491
New value of Value function: 4.96057
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 4.95208
New value of Value function: 4.96057
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.94682
New value of Value function: 4.95491
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.85159
New value of Value function: 4.95491
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 4.94697
New value of Value function: 4.95208
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 4.94632
New value of Value function: 4.94697
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 4.93915
New value of Value function: 4.94682
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.9336
New value of Value function: 4.94632
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 4.94061
New value of Value function: 4.94061
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 4.93166
New value of Value function: 4.94061
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 4.93494
New value of Value function: 4.93494
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.9212
New value of Value function: 4.93494
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 4.92932
New value of Value function: 4.93166
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 4.92405
New value of Value function: 4.92932
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 4.92374
New value of Value function: 4.92405
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.22859
New value of Value function: 4.92405
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 4.91654
New value of Value function: 4.92374
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 4.9182
New value of Value function: 4.9212
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.9089
New value of Value function: 4.9182
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 4.90938
New value of Value function: 4.9182
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.35667
New value of Value function: 4.9182
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 4.9127
New value of Value function: 4.9127
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 4.90724
New value of Value function: 4.90938
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 4.09061
New value of Value function: 4.90938
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 92
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 93
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 94
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 95
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 96
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 97
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 98
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 99
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 100
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 101
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.50018
New value of Value function: 3.50018
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 102
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.35218
New value of Value function: 4.35218
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 103
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 104
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 105
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 106
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 107
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 108
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.77989
New value of Value function: 4.95
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 4.90206
New value of Value function: 4.9089
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3925
	Distance: 9
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 5.64647
New value of Value function: 5.64647
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 111
----------
State: 3925
	Distance: 9
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2325
	Distance: 5
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 112
----------
State: 2325
	Distance: 5
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.59001
New value of Value function: 2.59001
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2325
	Distance: 5
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 5.62706
New value of Value function: 5.62706
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 114
----------
State: 2325
	Distance: 5
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.57642
New value of Value function: 2.57642
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 6.14862
New value of Value function: 6.14862
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 116
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.92142
New value of Value function: 4.92142
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 117
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.89681
New value of Value function: 4.89681
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 118
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.87491
New value of Value function: 4.87491
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 119
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.85501
New value of Value function: 4.85501
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 120
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.83666
New value of Value function: 4.83666
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 121
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4.83666
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 122
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 123
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.7883
New value of Value function: 4.7883
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 124
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.81956
New value of Value function: 4.81956
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 125
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.8035
New value of Value function: 4.8035
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 126
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.78831
New value of Value function: 4.78831
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 127
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.77387
New value of Value function: 4.77387
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 128
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.76009
New value of Value function: 4.76009
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 129
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.74689
New value of Value function: 4.74689
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 130
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.7342
New value of Value function: 4.7342
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 131
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.74041
New value of Value function: 4.74041
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 132
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.9702
New value of Value function: 4.7883
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 133
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.259587
New value of Value function: 2.71291
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 134
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.72092
New value of Value function: 4.72092
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 135
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.72356
New value of Value function: 4.74041
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 136
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.69325
New value of Value function: 4.72356
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 137
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.69517
New value of Value function: 4.69517
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 138
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.71176
New value of Value function: 4.71176
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 139
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.950429
New value of Value function: 4.71176
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 140
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.163
New value of Value function: 9.163
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 141
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.67991
New value of Value function: 4.67991
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 142
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.70033
New value of Value function: 4.70033
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 143
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.65853
New value of Value function: 4.70033
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 144
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.66802
New value of Value function: 4.66802
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 145
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.63993
New value of Value function: 4.70033
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 146
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.66202
New value of Value function: 4.66202
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 147
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.68925
New value of Value function: 4.68925
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 148
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.67849
New value of Value function: 4.67849
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 149
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.66803
New value of Value function: 4.66803
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 150
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.65784
New value of Value function: 4.65784
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 151
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.95728
New value of Value function: 4.65784
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 6.04513
New value of Value function: 6.04513
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 153
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.519716
New value of Value function: 0.519716
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 154
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.64791
New value of Value function: 4.64791
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 155
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.63822
New value of Value function: 4.63993
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 156
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.80096
New value of Value function: 4.80096
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 157
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 158
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 159
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 160
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 161
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 162
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 163
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 164
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 165
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 166
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 167
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 168
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 169
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 170
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 171
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 172
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 173
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 174
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 175
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 176
----------
State: 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 177
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 178
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 179
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 180
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 181
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 182
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 183
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 184
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 185
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 186
----------
State: 3685
	Distance: 9
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 187
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.98468
New value of Value function: 2.98468
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 6.03194
New value of Value function: 6.03194
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 6.01908
New value of Value function: 6.01908
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 6.00653
New value of Value function: 6.00653
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 5.99427
New value of Value function: 5.99427
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.98228
New value of Value function: 5.98228
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 5.20855
New value of Value function: 5.98228
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.44315
New value of Value function: 5.98228
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.97054
New value of Value function: 5.97054
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.72051
New value of Value function: 5.97054
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.95905
New value of Value function: 5.95905
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.94779
New value of Value function: 5.94779
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 5.93675
New value of Value function: 5.93675
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.93534
New value of Value function: 5.93675
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.92591
New value of Value function: 5.92591
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.10537
New value of Value function: 5.92591
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.91527
New value of Value function: 5.91527
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.90481
New value of Value function: 5.90481
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.89453
New value of Value function: 5.89453
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.88442
New value of Value function: 5.88442
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.87447
New value of Value function: 5.87447
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.86468
New value of Value function: 5.86468
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.85504
New value of Value function: 5.85504
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.84554
New value of Value function: 5.84554
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.83618
New value of Value function: 5.83618
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.82696
New value of Value function: 5.82696
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.22451
New value of Value function: 5.82696
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 5.81786
New value of Value function: 5.81786
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.80888
New value of Value function: 5.80888
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 5.80002
New value of Value function: 5.80002
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.79128
New value of Value function: 5.79128
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.78264
New value of Value function: 5.78264
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.37181
New value of Value function: 5.78264
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.77412
New value of Value function: 5.77412
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.76569
New value of Value function: 5.76569
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.75737
New value of Value function: 5.75737
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.30853
New value of Value function: 5.75737
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 5.74915
New value of Value function: 5.74915
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.46824
New value of Value function: 5.74915
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.74102
New value of Value function: 5.74102
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 5.53041
New value of Value function: 5.74102
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.73298
New value of Value function: 5.73298
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.72503
New value of Value function: 5.72503
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 5.71716
New value of Value function: 5.71716
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.36971
New value of Value function: 5.71716
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.70938
New value of Value function: 5.70938
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 5.70169
New value of Value function: 5.70169
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 4.98868
New value of Value function: 5.70169
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.69407
New value of Value function: 5.69407
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.68652
New value of Value function: 5.68652
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.67906
New value of Value function: 5.67906
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.67166
New value of Value function: 5.67166
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.66434
New value of Value function: 5.66434
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.55185
New value of Value function: 5.66434
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.41052
New value of Value function: 5.66434
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.65709
New value of Value function: 5.65709
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.6499
New value of Value function: 5.6499
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.64279
New value of Value function: 5.64279
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.05428
New value of Value function: 5.64279
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.00295
New value of Value function: 5.64279
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.63573
New value of Value function: 5.63573
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.62874
New value of Value function: 5.62874
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.08602
New value of Value function: 5.62874
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.62181
New value of Value function: 5.62181
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 5.61495
New value of Value function: 5.61495
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.60814
New value of Value function: 5.60814
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.60139
New value of Value function: 5.60139
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.59469
New value of Value function: 5.59469
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.58805
New value of Value function: 5.58805
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.58147
New value of Value function: 5.58147
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.57493
New value of Value function: 5.57493
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.56845
New value of Value function: 5.56845
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.56202
New value of Value function: 5.56202
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.55564
New value of Value function: 5.55564
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.54931
New value of Value function: 5.55185
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.53701
New value of Value function: 5.54931
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.52586
New value of Value function: 5.54931
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.54303
New value of Value function: 5.54303
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.53679
New value of Value function: 5.53679
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 80
New value of Q matrix: 5.25317
New value of Value function: 5.52586
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 67
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 68
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 69
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.0353553
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 70
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 71
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 72
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 73
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.4706
New value of Value function: 2.4706
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.0997
New value of Value function: 5.52586
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.51204
New value of Value function: 5.51204
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.13845
New value of Value function: 5.51204
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.13956
New value of Value function: 5.51204
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.49868
New value of Value function: 5.49868
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.48571
New value of Value function: 5.48571
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.47313
New value of Value function: 5.47313
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.46089
New value of Value function: 5.46089
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.44897
New value of Value function: 5.44897
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 5.17598
New value of Value function: 5.44897
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 5.43736
New value of Value function: 5.43736
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.42602
New value of Value function: 5.42602
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.40397
New value of Value function: 5.42602
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 5.41494
New value of Value function: 5.41494
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.40411
New value of Value function: 5.40411
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.39352
New value of Value function: 5.40397
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.39497
New value of Value function: 5.39497
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.3861
New value of Value function: 5.39352
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.38314
New value of Value function: 5.3861
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.37736
New value of Value function: 5.38314
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.37296
New value of Value function: 5.37736
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.36875
New value of Value function: 5.37296
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 5.36299
New value of Value function: 5.36875
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.36026
New value of Value function: 5.36299
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.35319
New value of Value function: 5.36026
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 5.76471
New value of Value function: 5.76471
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 100
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.41214
New value of Value function: 6.41214
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 101
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.6378
New value of Value function: 2.6378
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.75581
New value of Value function: 5.75581
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 5.33556
New value of Value function: 5.35319
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 104
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 105
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 106
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.29966
New value of Value function: 2.29966
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 5.70815
New value of Value function: 5.70815
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 108
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.04604
New value of Value function: 6.41214
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 109
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.903
New value of Value function: 2.903
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.70185
New value of Value function: 5.70185
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.69559
New value of Value function: 5.69559
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.68938
New value of Value function: 5.68938
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.6832
New value of Value function: 5.6832
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.23967
New value of Value function: 5.6832
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.67708
New value of Value function: 5.67708
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 5.67099
New value of Value function: 5.67099
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 5.66494
New value of Value function: 5.66494
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 5.65894
New value of Value function: 5.65894
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 5.65297
New value of Value function: 5.65297
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.18784
New value of Value function: 5.65297
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 5.23164
New value of Value function: 5.65297
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 5.64705
New value of Value function: 5.64705
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.64116
New value of Value function: 5.64116
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 5.63531
New value of Value function: 5.63531
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 5.6295
New value of Value function: 5.6295
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 5.62372
New value of Value function: 5.62372
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 5.61798
New value of Value function: 5.61798
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 5.61228
New value of Value function: 5.61228
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 5.60661
New value of Value function: 5.60661
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 5.60098
New value of Value function: 5.60098
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 5.59537
New value of Value function: 5.59537
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 5.58981
New value of Value function: 5.58981
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 5.58427
New value of Value function: 5.58427
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 5.57877
New value of Value function: 5.57877
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 5.2627
New value of Value function: 5.57877
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 5.5733
New value of Value function: 5.5733
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 5.56786
New value of Value function: 5.56786
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 5.56245
New value of Value function: 5.56245
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 5.55708
New value of Value function: 5.55708
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 5.55173
New value of Value function: 5.55173
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 5.54641
New value of Value function: 5.54641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 5.54112
New value of Value function: 5.54112
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 5.53586
New value of Value function: 5.53586
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.35741
New value of Value function: 5.53586
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 5.53063
New value of Value function: 5.53063
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 5.52543
New value of Value function: 5.52543
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 5.28469
New value of Value function: 5.52543
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 5.52025
New value of Value function: 5.52025
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 5.3037
New value of Value function: 5.52025
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 5.51511
New value of Value function: 5.51511
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.37269
New value of Value function: 5.51511
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 5.50999
New value of Value function: 5.50999
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 5.50489
New value of Value function: 5.50489
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 5.49982
New value of Value function: 5.49982
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 5.49478
New value of Value function: 5.49478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 5.31797
New value of Value function: 5.49478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 5.48977
New value of Value function: 5.48977
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 5.48478
New value of Value function: 5.48478
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 5.47981
New value of Value function: 5.47981
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 5.47487
New value of Value function: 5.47487
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 5.46995
New value of Value function: 5.46995
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 5.46506
New value of Value function: 5.46506
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 5.46019
New value of Value function: 5.46019
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.37754
New value of Value function: 5.46019
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.26291
New value of Value function: 5.46019
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 5.45535
New value of Value function: 5.45535
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.28203
New value of Value function: 5.45535
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 5.45052
New value of Value function: 5.45052
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 5.44573
New value of Value function: 5.44573
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 5.29703
New value of Value function: 5.44573
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 5.44095
New value of Value function: 5.44095
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 5.4362
New value of Value function: 5.4362
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 5.43146
New value of Value function: 5.43146
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 5.42675
New value of Value function: 5.42675
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 5.42207
New value of Value function: 5.42207
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.30667
New value of Value function: 5.42207
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.32317
New value of Value function: 5.42207
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 5.4174
New value of Value function: 5.4174
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.355
New value of Value function: 5.4174
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 136
New value of Q matrix: 5.21011
New value of Value function: 5.37754
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 181
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 182
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 183
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 184
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.32377
New value of Value function: 2.32377
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 5.36631
New value of Value function: 5.36631
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 186
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.31591
New value of Value function: 2.31591
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 5.02476
New value of Value function: 5.355
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 188
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 189
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 190
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.53553
New value of Value function: 3.53553
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 191
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 192
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 193
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.30145
New value of Value function: 2.30145
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.34553
New value of Value function: 5.34553
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 5.31995
New value of Value function: 5.34553
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.33622
New value of Value function: 5.33622
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.32707
New value of Value function: 5.32707
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.31807
New value of Value function: 5.31995
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.30951
New value of Value function: 5.31995
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 5.31446
New value of Value function: 5.31446
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 5.30901
New value of Value function: 5.30951
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.30079
New value of Value function: 5.30901
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 96
New value of Q matrix: 5.36667
New value of Value function: 5.36667
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 4
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.797096
New value of Value function: 2.903
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 5
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.69559
New value of Value function: 3.69559
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 6
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 7
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 8
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 9
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 10
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.87356
New value of Value function: 4.87356
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 11
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.20277
New value of Value function: 2.20277
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 97
New value of Q matrix: 5.62897
New value of Value function: 5.62897
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 13
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 14
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 15
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 16
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 17
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 18
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.57268
New value of Value function: 2.57268
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 98
New value of Q matrix: 5.63845
New value of Value function: 5.63845
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 20
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.60652
New value of Value function: 2.60652
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 21
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.57932
New value of Value function: 2.57932
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 99
New value of Q matrix: 5.63262
New value of Value function: 5.63262
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 23
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.57592
New value of Value function: 2.57592
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 24
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.57757
New value of Value function: 2.57757
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 100
New value of Q matrix: 5.62438
New value of Value function: 5.62438
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 26
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.56386
New value of Value function: 2.56386
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 27
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.57285
New value of Value function: 2.57285
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 101
New value of Q matrix: 5.6158
New value of Value function: 5.6158
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 29
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.56198
New value of Value function: 2.56198
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 102
New value of Q matrix: 5.3568
New value of Value function: 5.3568
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 31
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.30323
New value of Value function: 2.30323
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 5.44265
New value of Value function: 5.44265
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 33
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.13911
New value of Value function: 6.13911
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 34
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.07772
New value of Value function: 2.57285
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 35
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.70953
New value of Value function: 6.70953
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 36
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -5
New value of Value function: 2.56198
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 37
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 38
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 39
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 40
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 41
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.85788
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 42
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.79347
New value of Value function: 6.79347
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 43
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 3.55729
New value of Value function: 3.55729
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 44
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.38823
New value of Value function: 2.38823
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 50
New value of Q matrix: 5.45743
New value of Value function: 5.45743
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 46
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.49683
New value of Value function: 2.49683
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 5.31964
New value of Value function: 5.45743
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.44979
New value of Value function: 5.44979
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 5.41248
New value of Value function: 5.41248
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 50
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.29259
New value of Value function: 2.29259
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 103
New value of Q matrix: 5.77908
New value of Value function: 5.77908
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 52
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.99766
New value of Value function: 6.99766
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 53
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.58846
New value of Value function: 2.58846
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 104
New value of Q matrix: 5.8519
New value of Value function: 5.8519
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 55
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.18133
New value of Value function: 3.18133
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 56
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 2.66591
New value of Value function: 2.66591
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.38294
New value of Value function: 5.8519
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.43731
New value of Value function: 5.8519
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 5.84619
New value of Value function: 5.84619
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 106
New value of Q matrix: 5.56974
New value of Value function: 5.56974
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 61
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 62
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 63
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 64
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 65
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 66
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 67
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 68
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 69
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 70
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 71
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.85788
New value of Value function: 2.85788
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 72
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.116662
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 73
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.90394
New value of Value function: 3.90394
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 74
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 75
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.51404
New value of Value function: 2.51404
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 107
New value of Q matrix: 5.56193
New value of Value function: 5.56193
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 77
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.50857
New value of Value function: 2.50857
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 5.0811
New value of Value function: 5.56193
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 79
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 80
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 81
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 82
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 83
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 84
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 85
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 86
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.51651
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 87
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.947
New value of Value function: 3.947
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 88
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.50631
New value of Value function: 2.50631
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 108
New value of Q matrix: 5.31541
New value of Value function: 5.43731
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 90
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.48124
New value of Value function: 2.48124
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 91
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.41907
New value of Value function: 2.41907
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.43017
New value of Value function: 5.43017
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.4231
New value of Value function: 5.4231
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.31183
New value of Value function: 5.4231
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 5.32053
New value of Value function: 5.4231
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.4161
New value of Value function: 5.4161
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.40916
New value of Value function: 5.40916
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.40229
New value of Value function: 5.40229
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.11746
New value of Value function: 5.40229
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.39549
New value of Value function: 5.39549
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.38874
New value of Value function: 5.38874
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.38206
New value of Value function: 5.38206
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.37543
New value of Value function: 5.37543
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 5.32064
New value of Value function: 5.37543
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 5.36887
New value of Value function: 5.36887
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.36236
New value of Value function: 5.36236
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.3559
New value of Value function: 5.3559
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.3495
New value of Value function: 5.3495
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.34315
New value of Value function: 5.34315
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.33685
New value of Value function: 5.33685
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.33061
New value of Value function: 5.33061
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 5.31652
New value of Value function: 5.33061
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 5.13901
New value of Value function: 5.33061
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.32441
New value of Value function: 5.32441
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.31826
New value of Value function: 5.31826
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.31216
New value of Value function: 5.31652
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.3066
New value of Value function: 5.31652
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 5.3115
New value of Value function: 5.31183
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.155
New value of Value function: 5.31183
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.30332
New value of Value function: 5.3115
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 113
New value of Q matrix: 5.09405
New value of Value function: 5.3066
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 122
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.54357
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 123
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.26227
New value of Value function: 4.26227
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 124
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.25353
New value of Value function: 2.25353
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.30059
New value of Value function: 5.30332
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 5.21354
New value of Value function: 5.30332
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.29494
New value of Value function: 5.30059
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.29463
New value of Value function: 5.29494
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 5.28667
New value of Value function: 5.29463
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 5.28871
New value of Value function: 5.28871
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 5.21544
New value of Value function: 5.28871
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 5.28283
New value of Value function: 5.28667
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.27851
New value of Value function: 5.28283
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.16494
New value of Value function: 5.28283
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 5.27112
New value of Value function: 5.28283
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.277
New value of Value function: 5.277
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.27121
New value of Value function: 5.27121
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.26545
New value of Value function: 5.27112
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.17196
New value of Value function: 5.27112
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.26317
New value of Value function: 5.26545
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.25974
New value of Value function: 5.26317
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.25532
New value of Value function: 5.25974
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.24822
New value of Value function: 5.25974
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.25407
New value of Value function: 5.25407
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 5.24844
New value of Value function: 5.24844
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 5.24284
New value of Value function: 5.24822
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.24056
New value of Value function: 5.24284
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 5.23729
New value of Value function: 5.24056
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.233
New value of Value function: 5.23729
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 5.23177
New value of Value function: 5.233
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 5.22552
New value of Value function: 5.23177
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 5.22628
New value of Value function: 5.22628
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.22083
New value of Value function: 5.22552
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.21813
New value of Value function: 5.22083
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 5.21542
New value of Value function: 5.21813
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 5.21124
New value of Value function: 5.21813
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.21083
New value of Value function: 5.21542
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 5.21004
New value of Value function: 5.21124
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 5.20684
New value of Value function: 5.21083
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 5.20278
New value of Value function: 5.21083
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.2036
New value of Value function: 5.21004
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 5.20469
New value of Value function: 5.20469
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 5.19938
New value of Value function: 5.2036
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 5.19645
New value of Value function: 5.20278
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 5.19842
New value of Value function: 5.19938
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 5.09905
New value of Value function: 5.19938
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 5.1941
New value of Value function: 5.19842
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 5.19407
New value of Value function: 5.19645
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.18938
New value of Value function: 5.1941
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 5.18886
New value of Value function: 5.19407
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 5.18416
New value of Value function: 5.19407
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 5.18301
New value of Value function: 5.19407
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 5.18974
New value of Value function: 5.18974
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 5.18543
New value of Value function: 5.18543
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 5.18114
New value of Value function: 5.18416
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 5.17898
New value of Value function: 5.18301
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.17608
New value of Value function: 5.18114
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 5.17687
New value of Value function: 5.17898
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 5.17382
New value of Value function: 5.17687
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 5.17261
New value of Value function: 5.17608
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.16923
New value of Value function: 5.17382
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 5.1687
New value of Value function: 5.17261
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 5.16838
New value of Value function: 5.17196
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.16523
New value of Value function: 5.16923
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.16244
New value of Value function: 5.1687
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 5.16361
New value of Value function: 5.16838
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 5.16416
New value of Value function: 5.16523
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.15856
New value of Value function: 5.16416
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 5.15995
New value of Value function: 5.16361
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 5.15854
New value of Value function: 5.16244
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.15572
New value of Value function: 5.15995
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 5.15577
New value of Value function: 5.15856
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.15195
New value of Value function: 5.15854
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 5.15351
New value of Value function: 5.15577
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 5.1516
New value of Value function: 5.15572
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.14906
New value of Value function: 5.15351
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 5.1485
New value of Value function: 5.15195
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.14284
New value of Value function: 5.15195
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.14541
New value of Value function: 5.1516
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 5.14745
New value of Value function: 5.1485
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 5.14353
New value of Value function: 5.14745
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 5.14331
New value of Value function: 5.14541
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.13663
New value of Value function: 5.14541
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.13893
New value of Value function: 5.14353
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 5.13858
New value of Value function: 5.14331
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 5.1392
New value of Value function: 5.1392
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.13048
New value of Value function: 5.1392
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.12514
New value of Value function: 5.1392
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 5.13509
New value of Value function: 5.13893
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.1325
New value of Value function: 5.13858
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 5.13366
New value of Value function: 5.13509
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.12001
New value of Value function: 5.13509
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 5.13101
New value of Value function: 5.13366
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 5.12876
New value of Value function: 5.1325
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.12614
New value of Value function: 5.13101
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 5.12694
New value of Value function: 5.12876
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 5.12389
New value of Value function: 5.12694
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.11993
New value of Value function: 5.12694
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 5.09687
New value of Value function: 5.12694
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 5.12289
New value of Value function: 5.12389
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 5.11905
New value of Value function: 5.12289
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 5.09453
New value of Value function: 5.12289
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 5.11885
New value of Value function: 5.12001
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.11371
New value of Value function: 5.11993
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 5.11491
New value of Value function: 5.11993
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 5.11367
New value of Value function: 5.11905
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 5.11424
New value of Value function: 5.11491
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 5.1109
New value of Value function: 5.11424
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 5.10945
New value of Value function: 5.11371
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 5.10746
New value of Value function: 5.11367
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.10747
New value of Value function: 5.1109
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 5.09132
New value of Value function: 5.1109
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 5.10691
New value of Value function: 5.10945
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 5.10468
New value of Value function: 5.10747
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.10132
New value of Value function: 5.10746
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.10127
New value of Value function: 5.10691
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 5.10015
New value of Value function: 5.10691
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 5.10294
New value of Value function: 5.10294
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 5.09898
New value of Value function: 5.10132
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.09522
New value of Value function: 5.10127
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.09512
New value of Value function: 5.10015
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 5.09543
New value of Value function: 5.09898
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 5.09503
New value of Value function: 5.09543
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 5.087
New value of Value function: 5.09543
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 5.09074
New value of Value function: 5.09522
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.08918
New value of Value function: 5.09512
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.08903
New value of Value function: 5.09503
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 5.0911
New value of Value function: 5.0911
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 5.08271
New value of Value function: 5.0911
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 5.08718
New value of Value function: 5.09074
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 5.08607
New value of Value function: 5.08918
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.08318
New value of Value function: 5.08903
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.08299
New value of Value function: 5.08718
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.07769
New value of Value function: 5.08718
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 5.08328
New value of Value function: 5.08607
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 5.08143
New value of Value function: 5.08328
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 5.0794
New value of Value function: 5.08299
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.077
New value of Value function: 5.08271
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 5.07807
New value of Value function: 5.08143
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 5.07681
New value of Value function: 5.0794
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 5.07552
New value of Value function: 5.07807
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 5.07346
New value of Value function: 5.07769
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.07179
New value of Value function: 5.077
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 5.07223
New value of Value function: 5.077
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.07106
New value of Value function: 5.07552
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 5.06795
New value of Value function: 5.07552
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 5.07166
New value of Value function: 5.07346
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 5.06795
New value of Value function: 5.07346
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 5.06886
New value of Value function: 5.07179
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.06593
New value of Value function: 5.07106
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.06517
New value of Value function: 5.06886
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 5.06429
New value of Value function: 5.06795
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 5.06412
New value of Value function: 5.06795
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 5.0634
New value of Value function: 5.06593
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.06012
New value of Value function: 5.06517
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 5.05982
New value of Value function: 5.06517
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 5.05903
New value of Value function: 5.06517
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.05932
New value of Value function: 5.06412
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 5.06031
New value of Value function: 5.06031
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 5.0565
New value of Value function: 5.06012
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 5.05532
New value of Value function: 5.06012
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.05436
New value of Value function: 5.05932
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 5.05117
New value of Value function: 5.05932
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.05352
New value of Value function: 5.05903
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 5.05452
New value of Value function: 5.0565
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 5.05271
New value of Value function: 5.05452
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 5.05004
New value of Value function: 5.05436
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.04863
New value of Value function: 5.05352
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 5.0469
New value of Value function: 5.05352
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.04776
New value of Value function: 5.05271
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 5.04894
New value of Value function: 5.05004
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 5.04557
New value of Value function: 5.04894
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.04299
New value of Value function: 5.04894
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 5.04142
New value of Value function: 5.04894
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 5.04517
New value of Value function: 5.04776
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.04204
New value of Value function: 5.0469
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 5.03778
New value of Value function: 5.0469
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 5.04244
New value of Value function: 5.04517
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 5.04142
New value of Value function: 5.04244
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 5.038
New value of Value function: 5.04204
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.03637
New value of Value function: 5.04142
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 5.037
New value of Value function: 5.04142
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 5.03769
New value of Value function: 5.038
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 5.03358
New value of Value function: 5.03778
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 5.03218
New value of Value function: 5.03769
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 5.03396
New value of Value function: 5.037
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 5.0326
New value of Value function: 5.03637
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 5.03074
New value of Value function: 5.03396
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 5.0255
New value of Value function: 5.03396
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 5.03025
New value of Value function: 5.03358
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 5.02918
New value of Value function: 5.0326
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 5.02822
New value of Value function: 5.03218
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.02663
New value of Value function: 5.03025
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 5.02655
New value of Value function: 5.02918
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 5.0248
New value of Value function: 5.02822
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 5.02386
New value of Value function: 5.02663
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.02111
New value of Value function: 5.02655
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 5.02287
New value of Value function: 5.0255
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.01995
New value of Value function: 5.0248
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 5.02044
New value of Value function: 5.02386
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 5.01952
New value of Value function: 5.02287
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 5.01919
New value of Value function: 5.02111
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.01563
New value of Value function: 5.02044
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 5.01611
New value of Value function: 5.01995
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.01444
New value of Value function: 5.01952
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 5.01556
New value of Value function: 5.01952
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.00952
New value of Value function: 5.01952
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 5.0152
New value of Value function: 5.01611
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 5.01179
New value of Value function: 5.01563
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.01019
New value of Value function: 5.01556
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 5.01191
New value of Value function: 5.0152
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 5.0109
New value of Value function: 5.01191
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.00434
New value of Value function: 5.01191
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 5.00827
New value of Value function: 5.01179
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 5.0067
New value of Value function: 5.01179
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 5.00749
New value of Value function: 5.01019
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.00479
New value of Value function: 5.00827
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 5.00465
New value of Value function: 5.00749
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 5.00321
New value of Value function: 5.0067
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 5.00243
New value of Value function: 5.00479
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 4.99942
New value of Value function: 5.00465
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 5.00104
New value of Value function: 5.00434
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 4.99895
New value of Value function: 5.00321
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 4.99896
New value of Value function: 5.00243
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.99819
New value of Value function: 5.00104
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 4.99381
New value of Value function: 5.00104
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 4.99744
New value of Value function: 4.99942
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 4.99409
New value of Value function: 4.99896
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 4.99396
New value of Value function: 4.99896
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.99472
New value of Value function: 4.99819
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 4.99397
New value of Value function: 4.99472
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 4.98886
New value of Value function: 4.99472
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 4.99049
New value of Value function: 4.99397
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.98976
New value of Value function: 4.99396
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 4.99038
New value of Value function: 4.99381
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.98706
New value of Value function: 4.99381
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 4.98849
New value of Value function: 4.99049
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.98629
New value of Value function: 4.98976
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 4.98557
New value of Value function: 4.98886
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 4.98324
New value of Value function: 4.98886
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 4.98232
New value of Value function: 4.98886
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 4.98361
New value of Value function: 4.98706
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.9835
New value of Value function: 4.98557
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 4.9814
New value of Value function: 4.98361
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 4.97838
New value of Value function: 4.9835
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 4.97996
New value of Value function: 4.98324
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 4.97798
New value of Value function: 4.98232
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 4.9736
New value of Value function: 4.98232
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 4.97815
New value of Value function: 4.9814
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 4.97725
New value of Value function: 4.97996
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 4.97643
New value of Value function: 4.97815
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 4.97401
New value of Value function: 4.97798
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 4.9702
New value of Value function: 4.97798
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 4.97277
New value of Value function: 4.97725
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 4.97312
New value of Value function: 4.97643
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.97291
New value of Value function: 4.9736
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 4.96844
New value of Value function: 4.97312
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.96942
New value of Value function: 4.97312
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 4.969
New value of Value function: 4.97277
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 4.96758
New value of Value function: 4.9702
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 4.9635
New value of Value function: 4.9702
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.96598
New value of Value function: 4.9702
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 4.96609
New value of Value function: 4.969
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 4.96491
New value of Value function: 4.96758
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 4.96243
New value of Value function: 4.96609
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 4.95769
New value of Value function: 4.96609
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 4.96199
New value of Value function: 4.96598
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 4.95866
New value of Value function: 4.96598
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 4.95824
New value of Value function: 4.96598
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 4.95433
New value of Value function: 4.96598
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.96249
New value of Value function: 4.96491
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 4.96082
New value of Value function: 4.96249
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.95902
New value of Value function: 4.96082
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 4.95676
New value of Value function: 4.95902
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.95556
New value of Value function: 4.95824
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 4.95418
New value of Value function: 4.95769
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 4.9526
New value of Value function: 4.95676
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 4.95271
New value of Value function: 4.95556
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.9521
New value of Value function: 4.95433
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 4.9493
New value of Value function: 4.95418
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 4.95013
New value of Value function: 4.95271
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 4.94756
New value of Value function: 4.95271
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 4.94868
New value of Value function: 4.9521
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.94866
New value of Value function: 4.95013
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 4.9461
New value of Value function: 4.9493
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 152
New value of Q matrix: 4.78825
New value of Value function: 4.9493
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 7
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 9
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.89981
New value of Value function: 1.89981
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 98
New value of Q matrix: 4.75239
New value of Value function: 4.94868
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 11
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 12
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.46447
New value of Value function: 1.46447
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 13
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.44982
New value of Value function: 1.44982
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 14
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.44982
New value of Value function: 1.46447
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 15
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.44764
New value of Value function: 1.44982
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 16
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.8992
New value of Value function: 1.8992
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 153
New value of Q matrix: 4.75972
New value of Value function: 4.94868
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 18
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 1.44982
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 19
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.8992
New value of Value function: 1.8992
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 4.94467
New value of Value function: 4.94866
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.94523
New value of Value function: 4.94756
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 4.77087
New value of Value function: 4.94756
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 4.94253
New value of Value function: 4.94523
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.94181
New value of Value function: 4.94467
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 4.94067
New value of Value function: 4.94253
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 4.93754
New value of Value function: 4.94181
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.9384
New value of Value function: 4.94067
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 4.93669
New value of Value function: 4.9384
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 4.935
New value of Value function: 4.93754
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 4.93178
New value of Value function: 4.93754
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 4.93258
New value of Value function: 4.93669
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 4.93272
New value of Value function: 4.93272
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 4.92877
New value of Value function: 4.93258
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 4.92764
New value of Value function: 4.93178
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 4.9284
New value of Value function: 4.92877
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 4.92484
New value of Value function: 4.9284
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 4.92503
New value of Value function: 4.92764
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 4.92274
New value of Value function: 4.92503
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.92168
New value of Value function: 4.92484
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 4.92092
New value of Value function: 4.92274
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 4.91787
New value of Value function: 4.92168
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.91833
New value of Value function: 4.92092
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 4.91332
New value of Value function: 4.92092
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 4.90924
New value of Value function: 4.92092
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 4.91702
New value of Value function: 4.91833
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 4.77876
New value of Value function: 4.91833
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.91499
New value of Value function: 4.91702
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 4.91313
New value of Value function: 4.91499
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.91166
New value of Value function: 4.91313
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 4.90926
New value of Value function: 4.91166
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.90834
New value of Value function: 4.90926
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 4.9054
New value of Value function: 4.90924
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 4.90445
New value of Value function: 4.90834
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.90503
New value of Value function: 4.9054
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 4.89978
New value of Value function: 4.9054
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 4.90156
New value of Value function: 4.90503
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.90173
New value of Value function: 4.90173
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 4.89523
New value of Value function: 4.90173
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.89844
New value of Value function: 4.90156
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 4.89773
New value of Value function: 4.89844
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.89516
New value of Value function: 4.89773
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.89206
New value of Value function: 4.89773
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 4.89392
New value of Value function: 4.89523
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.88901
New value of Value function: 4.89523
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 4.89052
New value of Value function: 4.89392
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 4.89012
New value of Value function: 4.89052
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.88586
New value of Value function: 4.89052
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 4.88583
New value of Value function: 4.89012
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 4.76132
New value of Value function: 4.89012
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 4.88634
New value of Value function: 4.88634
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 4.88257
New value of Value function: 4.88586
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 4.78343
New value of Value function: 4.88586
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.88261
New value of Value function: 4.88583
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.87959
New value of Value function: 4.88583
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 4.88117
New value of Value function: 4.88257
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 4.87881
New value of Value function: 4.88117
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 4.87654
New value of Value function: 4.87959
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.87637
New value of Value function: 4.87881
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 4.78715
New value of Value function: 4.87881
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 4.87507
New value of Value function: 4.87654
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 4.87193
New value of Value function: 4.87637
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.87315
New value of Value function: 4.87507
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 4.87134
New value of Value function: 4.87315
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.86994
New value of Value function: 4.87193
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 4.86735
New value of Value function: 4.87134
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 4.86763
New value of Value function: 4.86994
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.86675
New value of Value function: 4.86763
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 4.86362
New value of Value function: 4.86763
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 4.8607
New value of Value function: 4.86763
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 4.86393
New value of Value function: 4.86735
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 4.78965
New value of Value function: 4.86735
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 4.86279
New value of Value function: 4.86393
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 4.86024
New value of Value function: 4.86279
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 4.85826
New value of Value function: 4.8607
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 4.85753
New value of Value function: 4.86024
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 4.85657
New value of Value function: 4.85826
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 4.85375
New value of Value function: 4.85753
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 4.85436
New value of Value function: 4.85657
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 4.85291
New value of Value function: 4.85436
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 4.85121
New value of Value function: 4.85375
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 4.84926
New value of Value function: 4.85291
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 4.84926
New value of Value function: 4.85121
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 4.84807
New value of Value function: 4.84926
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 4.79053
New value of Value function: 4.84926
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 4.76527
New value of Value function: 4.84926
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 4.79134
New value of Value function: 4.84926
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 4.84479
New value of Value function: 4.84926
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 4.84562
New value of Value function: 4.84807
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 4.84493
New value of Value function: 4.84562
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 4.84043
New value of Value function: 4.84562
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 4.842
New value of Value function: 4.84493
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 4.8418
New value of Value function: 4.842
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 4.83839
New value of Value function: 4.8418
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 4.83868
New value of Value function: 4.84043
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 4.83601
New value of Value function: 4.83868
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 4.83557
New value of Value function: 4.83839
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 4.8348
New value of Value function: 4.83601
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 4.83161
New value of Value function: 4.83557
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 4.83247
New value of Value function: 4.8348
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 4.83121
New value of Value function: 4.83247
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 4.82732
New value of Value function: 4.83247
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 4.82938
New value of Value function: 4.83121
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 4.82764
New value of Value function: 4.82938
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 4.82629
New value of Value function: 4.82764
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 4.82299
New value of Value function: 4.82764
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 4.81907
New value of Value function: 4.82764
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 4.82408
New value of Value function: 4.82629
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 4.82321
New value of Value function: 4.82408
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 4.82054
New value of Value function: 4.82321
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 4.8172
New value of Value function: 4.82321
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 4.82015
New value of Value function: 4.82015
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 4.81486
New value of Value function: 4.82015
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 4.81708
New value of Value function: 4.8172
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 4.81367
New value of Value function: 4.81708
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 4.78958
New value of Value function: 4.81708
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 4.81403
New value of Value function: 4.81486
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 4.81057
New value of Value function: 4.81403
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 4.81099
New value of Value function: 4.81367
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 4.81016
New value of Value function: 4.81099
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 4.80795
New value of Value function: 4.81057
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 4.8063
New value of Value function: 4.81016
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 4.80666
New value of Value function: 4.80795
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 4.80492
New value of Value function: 4.80666
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 4.78714
New value of Value function: 4.80666
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 4.80318
New value of Value function: 4.8063
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 4.80205
New value of Value function: 4.80492
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 4.76443
New value of Value function: 4.80492
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 4.79983
New value of Value function: 4.80492
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 4.8019
New value of Value function: 4.80205
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 4.79783
New value of Value function: 4.8019
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 4.79889
New value of Value function: 4.79983
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 4.79636
New value of Value function: 4.79889
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 4.79588
New value of Value function: 4.79783
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 4.79362
New value of Value function: 4.79636
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 4.79291
New value of Value function: 4.79588
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 4.79289
New value of Value function: 4.79362
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 4.78943
New value of Value function: 4.79291
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 4.78384
New value of Value function: 4.79291
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 4.78947
New value of Value function: 4.79289
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 4.7808
New value of Value function: 4.79289
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 4.7899
New value of Value function: 4.7899
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 4.78691
New value of Value function: 4.78947
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 4.78604
New value of Value function: 4.78943
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 4.77775
New value of Value function: 4.78943
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 4.78526
New value of Value function: 4.78691
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 4.78394
New value of Value function: 4.78604
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.78262
New value of Value function: 4.78526
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 4.78111
New value of Value function: 4.78394
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 4.77722
New value of Value function: 4.78394
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 4.78097
New value of Value function: 4.78262
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.77921
New value of Value function: 4.78097
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 4.77801
New value of Value function: 4.77921
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 4.77582
New value of Value function: 4.77801
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 4.77506
New value of Value function: 4.77775
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 4.77404
New value of Value function: 4.77722
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 4.77311
New value of Value function: 4.77582
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 4.77243
New value of Value function: 4.77506
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 4.77212
New value of Value function: 4.77404
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 4.77034
New value of Value function: 4.77311
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 4.76902
New value of Value function: 4.77243
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.76906
New value of Value function: 4.77212
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 4.7668
New value of Value function: 4.77212
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 4.76918
New value of Value function: 4.76918
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 4.76331
New value of Value function: 4.76918
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 4.76625
New value of Value function: 4.76906
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.76569
New value of Value function: 4.76902
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.76257
New value of Value function: 4.76902
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.75968
New value of Value function: 4.76902
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 4.76494
New value of Value function: 4.76625
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 4.76333
New value of Value function: 4.76494
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 4.76089
New value of Value function: 4.76443
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 4.75971
New value of Value function: 4.76333
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 4.76041
New value of Value function: 4.76331
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 4.75966
New value of Value function: 4.76089
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 4.75753
New value of Value function: 4.76089
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.75685
New value of Value function: 4.75971
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 4.75502
New value of Value function: 4.75968
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.75634
New value of Value function: 4.75966
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 4.75602
New value of Value function: 4.75753
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 4.75463
New value of Value function: 4.75685
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 4.75283
New value of Value function: 4.75634
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.75302
New value of Value function: 4.75602
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.74909
New value of Value function: 4.75602
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 4.75239
New value of Value function: 4.75502
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 4.75036
New value of Value function: 4.75463
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 4.75174
New value of Value function: 4.75302
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.74971
New value of Value function: 4.75239
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 4.74878
New value of Value function: 4.75174
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 4.74533
New value of Value function: 4.75174
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 4.74885
New value of Value function: 4.75036
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 4.74573
New value of Value function: 4.74971
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.74641
New value of Value function: 4.74885
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 4.74142
New value of Value function: 4.74885
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 4.74597
New value of Value function: 4.74878
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 4.74518
New value of Value function: 4.74641
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 4.74313
New value of Value function: 4.74641
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.74312
New value of Value function: 4.74533
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 4.73721
New value of Value function: 4.74533
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 4.74136
New value of Value function: 4.74518
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 4.74038
New value of Value function: 4.74518
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 4.74159
New value of Value function: 4.74312
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.73984
New value of Value function: 4.74159
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 4.73802
New value of Value function: 4.74136
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 4.73741
New value of Value function: 4.74038
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 4.73753
New value of Value function: 4.73984
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.73657
New value of Value function: 4.73802
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 4.7334
New value of Value function: 4.73802
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 4.73446
New value of Value function: 4.73753
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 4.73043
New value of Value function: 4.73753
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 4.73467
New value of Value function: 4.73741
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 4.73347
New value of Value function: 4.73721
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 4.72765
New value of Value function: 4.73721
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 4.73265
New value of Value function: 4.73467
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 4.72965
New value of Value function: 4.73467
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 4.7249
New value of Value function: 4.73467
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 4.72616
New value of Value function: 4.73467
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 4.73183
New value of Value function: 4.73446
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.72232
New value of Value function: 4.73446
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.71992
New value of Value function: 4.73446
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 4.73091
New value of Value function: 4.73265
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.71757
New value of Value function: 4.73265
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 4.72812
New value of Value function: 4.73183
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 4.72899
New value of Value function: 4.73091
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 4.72737
New value of Value function: 4.72899
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 4.72616
New value of Value function: 4.72812
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 4.72361
New value of Value function: 4.72737
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 4.72385
New value of Value function: 4.72616
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 4.72228
New value of Value function: 4.72616
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.71495
New value of Value function: 4.72616
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 4.72334
New value of Value function: 4.72385
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 4.72055
New value of Value function: 4.72385
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 4.72034
New value of Value function: 4.72361
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 4.71912
New value of Value function: 4.72228
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 4.71841
New value of Value function: 4.72055
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 4.7148
New value of Value function: 4.72055
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 4.71774
New value of Value function: 4.72034
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 4.71684
New value of Value function: 4.71841
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 4.71456
New value of Value function: 4.71774
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 4.71493
New value of Value function: 4.71684
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 4.71055
New value of Value function: 4.71684
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 4.71225
New value of Value function: 4.71684
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 4.71335
New value of Value function: 4.71495
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.71177
New value of Value function: 4.71456
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.70878
New value of Value function: 4.71456
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 4.71072
New value of Value function: 4.71335
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 4.70988
New value of Value function: 4.71225
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 4.70946
New value of Value function: 4.71072
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 4.70675
New value of Value function: 4.71072
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 4.7069
New value of Value function: 4.71055
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 4.70339
New value of Value function: 4.71055
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 4.70614
New value of Value function: 4.70988
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 4.70642
New value of Value function: 4.70878
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 4.702
New value of Value function: 4.70878
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 4.69825
New value of Value function: 4.70878
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.70561
New value of Value function: 4.70675
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 4.70397
New value of Value function: 4.70642
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 4.70296
New value of Value function: 4.70561
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.70245
New value of Value function: 4.70397
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 4.7012
New value of Value function: 4.70339
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 4.6996
New value of Value function: 4.70296
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 4.69953
New value of Value function: 4.70245
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.6993
New value of Value function: 4.7012
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 4.69843
New value of Value function: 4.6996
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 4.69582
New value of Value function: 4.69953
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 4.6961
New value of Value function: 4.6993
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.69616
New value of Value function: 4.69843
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 4.69567
New value of Value function: 4.69825
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 4.69391
New value of Value function: 4.69616
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.69303
New value of Value function: 4.6961
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 4.69268
New value of Value function: 4.69582
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 4.69206
New value of Value function: 4.69567
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 4.69292
New value of Value function: 4.69391
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 4.68846
New value of Value function: 4.69391
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 4.68959
New value of Value function: 4.69303
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.68991
New value of Value function: 4.69292
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 4.69017
New value of Value function: 4.69268
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 4.68928
New value of Value function: 4.69017
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 4.68743
New value of Value function: 4.68991
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 4.68484
New value of Value function: 4.68991
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 4.68241
New value of Value function: 4.68991
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 4.68485
New value of Value function: 4.68991
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 4.68593
New value of Value function: 4.68991
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.6868
New value of Value function: 4.68959
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 4.6801
New value of Value function: 4.68959
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 4.6815
New value of Value function: 4.68959
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 4.68529
New value of Value function: 4.6868
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 4.67822
New value of Value function: 4.6868
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.68369
New value of Value function: 4.68593
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 4.68255
New value of Value function: 4.68529
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 4.68101
New value of Value function: 4.68369
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 4.677
New value of Value function: 4.68369
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.6806
New value of Value function: 4.68255
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 4.67918
New value of Value function: 4.6806
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.67751
New value of Value function: 4.6801
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 4.67738
New value of Value function: 4.67918
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 4.67582
New value of Value function: 4.67822
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 4.67453
New value of Value function: 4.67751
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.67444
New value of Value function: 4.67738
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 4.67467
New value of Value function: 4.677
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 4.67276
New value of Value function: 4.67582
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 4.67247
New value of Value function: 4.67467
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 4.67197
New value of Value function: 4.67453
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 4.66871
New value of Value function: 4.67453
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 4.67086
New value of Value function: 4.67444
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.67137
New value of Value function: 4.67247
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.66913
New value of Value function: 4.67197
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 4.66729
New value of Value function: 4.67197
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 4.66927
New value of Value function: 4.67137
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 4.6667
New value of Value function: 4.67137
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 4.66831
New value of Value function: 4.66913
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.66581
New value of Value function: 4.66871
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 4.66452
New value of Value function: 4.66831
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 4.66525
New value of Value function: 4.66729
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 4.66364
New value of Value function: 4.6667
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 4.66255
New value of Value function: 4.6667
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 4.66401
New value of Value function: 4.66525
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 4.66221
New value of Value function: 4.66452
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 4.66034
New value of Value function: 4.66401
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 4.66133
New value of Value function: 4.66364
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 4.66001
New value of Value function: 4.66255
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 4.65925
New value of Value function: 4.66221
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 4.65636
New value of Value function: 4.66221
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 4.65871
New value of Value function: 4.66221
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.65616
New value of Value function: 4.66221
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 4.65918
New value of Value function: 4.66001
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 4.65639
New value of Value function: 4.65918
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 4.65615
New value of Value function: 4.65871
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 4.65604
New value of Value function: 4.65639
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 4.65315
New value of Value function: 4.65639
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 4.65279
New value of Value function: 4.65636
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 4.65223
New value of Value function: 4.65616
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.65288
New value of Value function: 4.65604
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 4.65338
New value of Value function: 4.65338
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 4.65073
New value of Value function: 4.65315
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 4.65014
New value of Value function: 4.65288
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 4.6482
New value of Value function: 4.65288
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.6496
New value of Value function: 4.65279
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 4.6492
New value of Value function: 4.65223
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 4.64811
New value of Value function: 4.65014
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 4.64714
New value of Value function: 4.6496
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 4.64563
New value of Value function: 4.6496
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.64634
New value of Value function: 4.6492
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 4.64562
New value of Value function: 4.64811
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 4.64225
New value of Value function: 4.64811
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 4.64313
New value of Value function: 4.64811
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 4.64402
New value of Value function: 4.64714
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 4.64414
New value of Value function: 4.64634
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.64309
New value of Value function: 4.64414
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 4.64116
New value of Value function: 4.64402
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 4.63995
New value of Value function: 4.64313
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 4.6405
New value of Value function: 4.64309
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.63984
New value of Value function: 4.64225
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 4.6387
New value of Value function: 4.64116
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 4.63818
New value of Value function: 4.6405
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 4.63787
New value of Value function: 4.63995
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 4.63589
New value of Value function: 4.63984
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.63661
New value of Value function: 4.6387
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 4.63516
New value of Value function: 4.63818
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 4.63521
New value of Value function: 4.63787
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 4.63525
New value of Value function: 4.63661
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 4.63192
New value of Value function: 4.63661
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.63339
New value of Value function: 4.63525
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 4.63225
New value of Value function: 4.63525
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.63264
New value of Value function: 4.63516
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 4.63164
New value of Value function: 4.63339
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.63018
New value of Value function: 4.63264
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.63003
New value of Value function: 4.63225
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 4.62817
New value of Value function: 4.63225
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 4.6293
New value of Value function: 4.63192
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 4.62496
New value of Value function: 4.63192
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 4.6279
New value of Value function: 4.63018
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.62697
New value of Value function: 4.63003
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.62742
New value of Value function: 4.6293
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 4.62635
New value of Value function: 4.6279
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 4.62391
New value of Value function: 4.62742
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.62482
New value of Value function: 4.62697
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.62235
New value of Value function: 4.62697
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.62378
New value of Value function: 4.62635
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 4.62342
New value of Value function: 4.62496
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 4.62147
New value of Value function: 4.62391
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 4.61993
New value of Value function: 4.62378
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 4.61817
New value of Value function: 4.62378
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 211
New value of Q matrix: 4.64143
New value of Value function: 4.64143
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 4
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.68411
New value of Value function: 1.68411
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 212
New value of Q matrix: 4.62728
New value of Value function: 4.62728
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 6
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.60358
New value of Value function: 1.60358
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 7
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.62458
New value of Value function: 1.62458
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 213
New value of Q matrix: 4.62456
New value of Value function: 4.62456
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 9
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.58899
New value of Value function: 1.58899
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 214
New value of Q matrix: 4.62104
New value of Value function: 4.62342
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 11
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.58309
New value of Value function: 1.58309
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 4.6151
New value of Value function: 4.62342
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.61982
New value of Value function: 4.62342
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 4.62049
New value of Value function: 4.62104
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 4.61606
New value of Value function: 4.62104
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.61789
New value of Value function: 4.62049
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 4.61757
New value of Value function: 4.61982
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.61724
New value of Value function: 4.61789
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.6147
New value of Value function: 4.61789
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.61474
New value of Value function: 4.61757
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 4.61465
New value of Value function: 4.61606
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 4.61212
New value of Value function: 4.6151
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 4.61177
New value of Value function: 4.6151
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 4.60844
New value of Value function: 4.6151
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 4.61165
New value of Value function: 4.61474
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.61161
New value of Value function: 4.6147
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 4.61213
New value of Value function: 4.61213
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 4.60956
New value of Value function: 4.61177
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.6085
New value of Value function: 4.61177
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 4.60887
New value of Value function: 4.61165
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 4.60821
New value of Value function: 4.60956
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 4.607
New value of Value function: 4.60887
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 4.60598
New value of Value function: 4.6085
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.60538
New value of Value function: 4.60844
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.60454
New value of Value function: 4.60821
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 4.60478
New value of Value function: 4.607
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 4.60444
New value of Value function: 4.60598
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 4.6031
New value of Value function: 4.60538
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 4.60036
New value of Value function: 4.60538
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 4.5978
New value of Value function: 4.60538
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.60228
New value of Value function: 4.60478
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 4.60191
New value of Value function: 4.60478
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 4.60137
New value of Value function: 4.60454
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 4.59536
New value of Value function: 4.60454
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 4.5982
New value of Value function: 4.60454
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 4.60064
New value of Value function: 4.60228
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.59918
New value of Value function: 4.60191
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 4.59937
New value of Value function: 4.60064
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.59677
New value of Value function: 4.59937
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 4.59683
New value of Value function: 4.59918
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.5961
New value of Value function: 4.5982
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 4.59481
New value of Value function: 4.59683
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 4.59292
New value of Value function: 4.59683
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 4.59429
New value of Value function: 4.5961
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 4.58934
New value of Value function: 4.5961
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.59302
New value of Value function: 4.59536
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 4.5925
New value of Value function: 4.59481
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 4.59143
New value of Value function: 4.59429
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 4.58827
New value of Value function: 4.59429
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.59003
New value of Value function: 4.59429
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 4.59176
New value of Value function: 4.5925
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 4.58965
New value of Value function: 4.59176
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 4.58924
New value of Value function: 4.59003
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 4.58676
New value of Value function: 4.59003
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.58697
New value of Value function: 4.58965
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 4.58681
New value of Value function: 4.58934
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 4.58439
New value of Value function: 4.58934
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 4.58551
New value of Value function: 4.58827
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 4.58492
New value of Value function: 4.58697
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.58392
New value of Value function: 4.58681
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 4.58398
New value of Value function: 4.58551
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 4.58171
New value of Value function: 4.58492
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 4.58157
New value of Value function: 4.58439
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 4.58188
New value of Value function: 4.58398
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 4.58115
New value of Value function: 4.58392
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.58088
New value of Value function: 4.58188
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 4.57938
New value of Value function: 4.58171
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 4.57791
New value of Value function: 4.58157
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 4.57824
New value of Value function: 4.58115
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 4.57833
New value of Value function: 4.58088
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.57785
New value of Value function: 4.57938
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 4.57688
New value of Value function: 4.57833
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 4.57447
New value of Value function: 4.57833
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.57485
New value of Value function: 4.57833
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 4.57552
New value of Value function: 4.57824
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 4.57288
New value of Value function: 4.57824
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 4.57417
New value of Value function: 4.57824
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 4.57492
New value of Value function: 4.57492
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 4.57047
New value of Value function: 4.57492
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 4.57161
New value of Value function: 4.57485
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.57184
New value of Value function: 4.57447
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 4.57198
New value of Value function: 4.57288
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 4.57008
New value of Value function: 4.57198
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 4.56685
New value of Value function: 4.57198
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 4.5674
New value of Value function: 4.57198
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 4.56353
New value of Value function: 4.57198
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 4.56949
New value of Value function: 4.57184
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.56883
New value of Value function: 4.57161
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 4.56831
New value of Value function: 4.56949
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 4.56702
New value of Value function: 4.56883
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.56583
New value of Value function: 4.56831
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 4.56502
New value of Value function: 4.5674
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 4.56462
New value of Value function: 4.56702
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 4.56454
New value of Value function: 4.56583
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 4.56284
New value of Value function: 4.56502
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 4.56175
New value of Value function: 4.56462
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 4.55868
New value of Value function: 4.56462
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 4.56184
New value of Value function: 4.56454
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 4.5599
New value of Value function: 4.56454
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 4.56207
New value of Value function: 4.56284
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 4.55644
New value of Value function: 4.56284
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 4.55986
New value of Value function: 4.56207
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 4.55961
New value of Value function: 4.56184
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 4.55907
New value of Value function: 4.55986
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 4.55688
New value of Value function: 4.55961
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 4.55715
New value of Value function: 4.55907
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 4.55631
New value of Value function: 4.55868
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.55543
New value of Value function: 4.55715
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 4.5547
New value of Value function: 4.55688
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 4.55358
New value of Value function: 4.55688
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 4.55391
New value of Value function: 4.55644
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 4.55275
New value of Value function: 4.55543
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 4.55105
New value of Value function: 4.55543
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.55218
New value of Value function: 4.5547
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 4.55225
New value of Value function: 4.55358
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 4.55083
New value of Value function: 4.55275
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 4.54983
New value of Value function: 4.55275
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 4.54908
New value of Value function: 4.55218
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 4.54895
New value of Value function: 4.55105
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 4.5481
New value of Value function: 4.55083
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 4.54809
New value of Value function: 4.54983
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 4.54739
New value of Value function: 4.54908
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 4.54522
New value of Value function: 4.54908
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 4.54543
New value of Value function: 4.54895
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 4.54572
New value of Value function: 4.54809
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 4.54535
New value of Value function: 4.54739
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 4.54274
New value of Value function: 4.54739
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 4.54496
New value of Value function: 4.54572
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.54251
New value of Value function: 4.54543
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 4.54179
New value of Value function: 4.54522
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 4.54229
New value of Value function: 4.54496
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 4.54253
New value of Value function: 4.54274
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 4.54002
New value of Value function: 4.54253
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.5393
New value of Value function: 4.54253
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 4.54011
New value of Value function: 4.54229
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 4.53936
New value of Value function: 4.54179
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 4.53817
New value of Value function: 4.54011
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 4.5373
New value of Value function: 4.54011
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 4.53769
New value of Value function: 4.53936
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 4.53645
New value of Value function: 4.5393
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 4.53465
New value of Value function: 4.5393
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.53611
New value of Value function: 4.53769
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 4.53527
New value of Value function: 4.5373
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 4.53459
New value of Value function: 4.53645
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 4.53354
New value of Value function: 4.53611
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 4.5308
New value of Value function: 4.53611
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.53293
New value of Value function: 4.53527
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 4.53286
New value of Value function: 4.53465
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 4.53055
New value of Value function: 4.53465
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.52987
New value of Value function: 4.53465
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 4.53105
New value of Value function: 4.53459
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 4.53189
New value of Value function: 4.53189
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 4.52919
New value of Value function: 4.53105
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 4.52747
New value of Value function: 4.5308
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 4.5279
New value of Value function: 4.53055
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 4.52815
New value of Value function: 4.52987
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 4.52409
New value of Value function: 4.52987
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.52671
New value of Value function: 4.52919
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 4.5265
New value of Value function: 4.52815
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 4.52391
New value of Value function: 4.52815
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 4.52575
New value of Value function: 4.5279
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 4.52502
New value of Value function: 4.52671
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 4.52139
New value of Value function: 4.52671
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 4.51903
New value of Value function: 4.52671
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.52355
New value of Value function: 4.52575
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 4.52336
New value of Value function: 4.52502
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 4.52214
New value of Value function: 4.52409
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 4.52053
New value of Value function: 4.52355
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 4.52098
New value of Value function: 4.52355
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.52041
New value of Value function: 4.52214
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 4.51927
New value of Value function: 4.52098
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 4.51703
New value of Value function: 4.52098
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 4.5186
New value of Value function: 4.52041
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.51728
New value of Value function: 4.51927
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 4.5164
New value of Value function: 4.51903
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 4.51636
New value of Value function: 4.5186
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 4.51622
New value of Value function: 4.51728
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.51415
New value of Value function: 4.51703
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 4.51374
New value of Value function: 4.51703
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.51123
New value of Value function: 4.51703
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 4.5135
New value of Value function: 4.5164
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 4.51354
New value of Value function: 4.51622
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 4.51385
New value of Value function: 4.51385
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 4.50831
New value of Value function: 4.51385
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 4.51148
New value of Value function: 4.51374
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 4.51108
New value of Value function: 4.51354
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 4.50858
New value of Value function: 4.51354
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 4.5107
New value of Value function: 4.5135
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 4.50622
New value of Value function: 4.5135
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 4.50999
New value of Value function: 4.51148
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 4.50911
New value of Value function: 4.5107
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 4.50785
New value of Value function: 4.50999
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 4.50648
New value of Value function: 4.50911
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 4.50675
New value of Value function: 4.50831
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 4.50521
New value of Value function: 4.50785
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 4.50502
New value of Value function: 4.50675
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 4.5044
New value of Value function: 4.50648
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 4.503
New value of Value function: 4.50622
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 4.50214
New value of Value function: 4.50622
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 4.50358
New value of Value function: 4.50521
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 4.50212
New value of Value function: 4.50502
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 4.50219
New value of Value function: 4.50358
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 4.50095
New value of Value function: 4.503
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 4.49952
New value of Value function: 4.50219
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 4.49937
New value of Value function: 4.50214
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 4.49979
New value of Value function: 4.50212
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 4.49904
New value of Value function: 4.50095
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 4.49666
New value of Value function: 4.50095
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 4.49833
New value of Value function: 4.49979
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 4.49579
New value of Value function: 4.49979
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 4.49745
New value of Value function: 4.49952
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 4.49522
New value of Value function: 4.49952
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 4.49606
New value of Value function: 4.49904
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 4.49337
New value of Value function: 4.49904
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.49598
New value of Value function: 4.49666
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 4.49386
New value of Value function: 4.49606
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 4.49261
New value of Value function: 4.49598
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.49292
New value of Value function: 4.49522
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 4.49289
New value of Value function: 4.49386
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.48993
New value of Value function: 4.49386
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 4.49106
New value of Value function: 4.49337
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 4.49076
New value of Value function: 4.49289
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 4.49056
New value of Value function: 4.49261
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 4.48834
New value of Value function: 4.49261
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 4.48918
New value of Value function: 4.49106
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 4.48827
New value of Value function: 4.49076
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 4.48816
New value of Value function: 4.48993
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 4.48581
New value of Value function: 4.48993
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.48689
New value of Value function: 4.48834
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.48395
New value of Value function: 4.48834
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 4.48549
New value of Value function: 4.48834
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 4.48602
New value of Value function: 4.48816
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 4.48556
New value of Value function: 4.48602
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 4.4837
New value of Value function: 4.48581
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 4.4824
New value of Value function: 4.48556
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 4.48297
New value of Value function: 4.48549
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 4.48271
New value of Value function: 4.48395
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.48093
New value of Value function: 4.4837
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 4.48139
New value of Value function: 4.48297
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 4.48039
New value of Value function: 4.48271
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 4.47794
New value of Value function: 4.48271
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 4.47994
New value of Value function: 4.4824
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 4.479
New value of Value function: 4.48139
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 4.47727
New value of Value function: 4.48139
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 4.47908
New value of Value function: 4.48093
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.47792
New value of Value function: 4.47908
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 4.47678
New value of Value function: 4.479
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 4.47562
New value of Value function: 4.47794
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 4.47537
New value of Value function: 4.47792
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.47491
New value of Value function: 4.47727
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 4.47451
New value of Value function: 4.47678
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.47204
New value of Value function: 4.47678
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.46936
New value of Value function: 4.47678
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 4.4719
New value of Value function: 4.47678
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 4.47448
New value of Value function: 4.47562
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 4.47224
New value of Value function: 4.47537
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 4.4728
New value of Value function: 4.47448
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 4.47034
New value of Value function: 4.47448
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 4.46932
New value of Value function: 4.47448
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 4.47218
New value of Value function: 4.47224
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 4.46888
New value of Value function: 4.47218
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 4.46578
New value of Value function: 4.47218
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.46657
New value of Value function: 4.47218
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 4.46989
New value of Value function: 4.47034
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 4.46778
New value of Value function: 4.46989
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 4.4676
New value of Value function: 4.46932
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 4.46658
New value of Value function: 4.46778
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 4.46523
New value of Value function: 4.4676
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 4.46532
New value of Value function: 4.46658
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 4.46385
New value of Value function: 4.46657
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.4636
New value of Value function: 4.46578
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 4.46244
New value of Value function: 4.46532
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 4.46304
New value of Value function: 4.46523
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 4.46269
New value of Value function: 4.46385
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 4.46081
New value of Value function: 4.46385
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 4.46021
New value of Value function: 4.46385
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 4.46113
New value of Value function: 4.4636
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.46064
New value of Value function: 4.46244
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.4578
New value of Value function: 4.46244
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 4.45911
New value of Value function: 4.46113
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.45507
New value of Value function: 4.46113
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 4.45842
New value of Value function: 4.46081
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 4.45854
New value of Value function: 4.46021
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.45247
New value of Value function: 4.46021
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 4.45635
New value of Value function: 4.46021
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 4.45768
New value of Value function: 4.45911
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 4.4558
New value of Value function: 4.45842
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 4.45571
New value of Value function: 4.45768
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 4.45515
New value of Value function: 4.45635
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 4.45409
New value of Value function: 4.4558
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 4.4525
New value of Value function: 4.45571
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 4.45301
New value of Value function: 4.45515
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 4.45263
New value of Value function: 4.45409
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 4.45183
New value of Value function: 4.45301
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 4.45031
New value of Value function: 4.45263
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 4.45011
New value of Value function: 4.4525
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.44954
New value of Value function: 4.4525
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 4.44921
New value of Value function: 4.45183
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.44677
New value of Value function: 4.45183
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 4.44958
New value of Value function: 4.45031
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.44761
New value of Value function: 4.45031
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 4.44762
New value of Value function: 4.44958
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 4.44595
New value of Value function: 4.44958
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.44522
New value of Value function: 4.44958
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 4.44733
New value of Value function: 4.44762
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 4.44494
New value of Value function: 4.44733
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 4.44508
New value of Value function: 4.44677
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 4.44386
New value of Value function: 4.44595
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 4.44268
New value of Value function: 4.44522
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.44272
New value of Value function: 4.44508
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 4.44284
New value of Value function: 4.44494
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 4.44226
New value of Value function: 4.44386
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 4.44095
New value of Value function: 4.44284
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 4.43963
New value of Value function: 4.44284
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 4.43944
New value of Value function: 4.44284
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 4.4406
New value of Value function: 4.44272
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 4.43715
New value of Value function: 4.44272
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 4.43482
New value of Value function: 4.44272
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.44022
New value of Value function: 4.44095
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 4.43806
New value of Value function: 4.4406
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.43775
New value of Value function: 4.4406
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 4.43837
New value of Value function: 4.43944
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 4.43619
New value of Value function: 4.43837
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 4.43614
New value of Value function: 4.43806
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 4.43309
New value of Value function: 4.43806
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 4.43517
New value of Value function: 4.43775
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.43527
New value of Value function: 4.43614
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 4.43391
New value of Value function: 4.43527
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.43279
New value of Value function: 4.43517
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 4.43229
New value of Value function: 4.43482
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 4.43217
New value of Value function: 4.43391
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 4.43169
New value of Value function: 4.43309
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 4.42987
New value of Value function: 4.43279
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.43031
New value of Value function: 4.43229
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 4.42683
New value of Value function: 4.43229
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 4.42941
New value of Value function: 4.43217
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 4.42949
New value of Value function: 4.43217
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 4.42953
New value of Value function: 4.43031
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 4.42387
New value of Value function: 4.43031
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 4.42785
New value of Value function: 4.42953
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 4.42689
New value of Value function: 4.42949
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 4.42728
New value of Value function: 4.42941
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 4.42655
New value of Value function: 4.42785
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 4.42538
New value of Value function: 4.42728
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 4.42507
New value of Value function: 4.42689
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 4.42426
New value of Value function: 4.42655
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 4.42369
New value of Value function: 4.42538
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 4.42095
New value of Value function: 4.42538
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 4.42292
New value of Value function: 4.42507
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 4.42286
New value of Value function: 4.42426
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 4.42163
New value of Value function: 4.42387
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 4.42068
New value of Value function: 4.42292
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 4.41909
New value of Value function: 4.42292
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 4.42047
New value of Value function: 4.42286
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 4.42066
New value of Value function: 4.42095
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 4.41811
New value of Value function: 4.42068
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 4.4175
New value of Value function: 4.42066
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 4.41846
New value of Value function: 4.42047
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 4.41802
New value of Value function: 4.41909
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 4.41648
New value of Value function: 4.41846
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 4.41626
New value of Value function: 4.41811
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 4.41527
New value of Value function: 4.41802
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 4.41558
New value of Value function: 4.4175
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 4.41433
New value of Value function: 4.41648
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 4.41387
New value of Value function: 4.41626
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 4.41407
New value of Value function: 4.41558
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 4.41314
New value of Value function: 4.41527
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 4.41135
New value of Value function: 4.41527
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 4.41245
New value of Value function: 4.41433
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 4.41117
New value of Value function: 4.41407
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 4.40892
New value of Value function: 4.41407
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.40822
New value of Value function: 4.41407
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 4.41188
New value of Value function: 4.41314
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 4.41071
New value of Value function: 4.41245
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 4.40963
New value of Value function: 4.41188
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 4.4097
New value of Value function: 4.41071
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 4.40828
New value of Value function: 4.4097
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 4.40752
New value of Value function: 4.40963
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 4.40682
New value of Value function: 4.40892
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 4.40633
New value of Value function: 4.40828
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 4.40586
New value of Value function: 4.40822
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.40508
New value of Value function: 4.40752
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 4.40534
New value of Value function: 4.40682
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 4.40401
New value of Value function: 4.40633
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 4.40374
New value of Value function: 4.40586
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 4.40344
New value of Value function: 4.40534
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 4.4013
New value of Value function: 4.40534
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 4.40317
New value of Value function: 4.40508
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 4.40124
New value of Value function: 4.40508
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 4.40195
New value of Value function: 4.40344
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 4.40103
New value of Value function: 4.40317
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 4.39891
New value of Value function: 4.40317
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 4.401
New value of Value function: 4.4013
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 4.39851
New value of Value function: 4.40124
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 4.39867
New value of Value function: 4.40103
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 4.39862
New value of Value function: 4.401
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 4.39634
New value of Value function: 4.401
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 4.39883
New value of Value function: 4.39891
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.3958
New value of Value function: 4.39883
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.39291
New value of Value function: 4.39883
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 4.39667
New value of Value function: 4.39867
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 4.39611
New value of Value function: 4.39851
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 4.39573
New value of Value function: 4.39667
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 4.39396
New value of Value function: 4.39667
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 4.39451
New value of Value function: 4.39611
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 4.39298
New value of Value function: 4.39611
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 4.39355
New value of Value function: 4.39451
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 4.39236
New value of Value function: 4.39396
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 4.39157
New value of Value function: 4.39355
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 4.39099
New value of Value function: 4.39298
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 4.39021
New value of Value function: 4.39291
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 4.39024
New value of Value function: 4.39291
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.38982
New value of Value function: 4.39157
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 4.38918
New value of Value function: 4.39099
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 4.3875
New value of Value function: 4.39099
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 4.38845
New value of Value function: 4.39024
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 4.38809
New value of Value function: 4.38982
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.38674
New value of Value function: 4.38918
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 4.3868
New value of Value function: 4.38845
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 4.3859
New value of Value function: 4.38809
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 4.38349
New value of Value function: 4.38809
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.38376
New value of Value function: 4.38809
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 4.38594
New value of Value function: 4.3875
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 4.38388
New value of Value function: 4.3875
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 4.38474
New value of Value function: 4.3868
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 4.38213
New value of Value function: 4.3868
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 4.38442
New value of Value function: 4.38442
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 4.37953
New value of Value function: 4.38442
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 4.38204
New value of Value function: 4.38388
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 4.38174
New value of Value function: 4.38376
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.3807
New value of Value function: 4.38349
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 4.37975
New value of Value function: 4.38349
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 4.38096
New value of Value function: 4.38174
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 4.37961
New value of Value function: 4.38096
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 4.37844
New value of Value function: 4.3807
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.37765
New value of Value function: 4.37975
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 4.37739
New value of Value function: 4.37961
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 4.37748
New value of Value function: 4.37953
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 4.3768
New value of Value function: 4.37844
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 4.37592
New value of Value function: 4.37765
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.37461
New value of Value function: 4.37748
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 4.37535
New value of Value function: 4.37739
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 4.37411
New value of Value function: 4.37739
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 4.37503
New value of Value function: 4.37592
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 4.3734
New value of Value function: 4.37535
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 4.37269
New value of Value function: 4.37535
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 4.37323
New value of Value function: 4.37461
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.37157
New value of Value function: 4.37411
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 4.37139
New value of Value function: 4.3734
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.36868
New value of Value function: 4.3734
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.36598
New value of Value function: 4.3734
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 4.37089
New value of Value function: 4.37323
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 4.36347
New value of Value function: 4.37323
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 4.37111
New value of Value function: 4.37269
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 4.37034
New value of Value function: 4.37139
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 4.36868
New value of Value function: 4.37111
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 4.369
New value of Value function: 4.37089
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 4.36098
New value of Value function: 4.37089
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 4.36839
New value of Value function: 4.37034
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 4.366
New value of Value function: 4.37034
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 4.36799
New value of Value function: 4.369
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 4.36689
New value of Value function: 4.36868
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 4.36598
New value of Value function: 4.36799
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 4.36565
New value of Value function: 4.36689
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 4.35839
New value of Value function: 4.36689
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 4.36478
New value of Value function: 4.366
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 4.36351
New value of Value function: 4.36598
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 4.36328
New value of Value function: 4.36565
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 4.36331
New value of Value function: 4.36478
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 4.36068
New value of Value function: 4.36478
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 4.36267
New value of Value function: 4.36351
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 4.36103
New value of Value function: 4.36331
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 4.36098
New value of Value function: 4.36267
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 4.36057
New value of Value function: 4.36103
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 4.35802
New value of Value function: 4.36103
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 4.35552
New value of Value function: 4.36103
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 4.35559
New value of Value function: 4.36103
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 4.35855
New value of Value function: 4.36098
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 4.35621
New value of Value function: 4.36098
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 4.35849
New value of Value function: 4.36098
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 4.35865
New value of Value function: 4.35865
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 4.35633
New value of Value function: 4.35849
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 4.3564
New value of Value function: 4.3564
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 4.35431
New value of Value function: 4.35633
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 4.35401
New value of Value function: 4.35621
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 4.35374
New value of Value function: 4.35559
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.35262
New value of Value function: 4.35552
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 4.35285
New value of Value function: 4.35431
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 4.35222
New value of Value function: 4.35401
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 4.3517
New value of Value function: 4.35374
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 4.35127
New value of Value function: 4.35285
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 4.35019
New value of Value function: 4.35262
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 4.35015
New value of Value function: 4.35262
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.34966
New value of Value function: 4.3517
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.34684
New value of Value function: 4.3517
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 4.34939
New value of Value function: 4.35127
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 4.34881
New value of Value function: 4.35019
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 4.34753
New value of Value function: 4.35015
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 4.34807
New value of Value function: 4.34939
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 4.34708
New value of Value function: 4.34881
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 4.34487
New value of Value function: 4.34881
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 4.34278
New value of Value function: 4.34881
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 4.34496
New value of Value function: 4.34881
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.34636
New value of Value function: 4.34807
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 4.3425
New value of Value function: 4.34807
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 4.346
New value of Value function: 4.34684
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.3439
New value of Value function: 4.34636
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 4.34009
New value of Value function: 4.34636
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.34391
New value of Value function: 4.346
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 4.34392
New value of Value function: 4.34392
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 4.34185
New value of Value function: 4.34391
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.34147
New value of Value function: 4.3439
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.34096
New value of Value function: 4.34278
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 4.34049
New value of Value function: 4.34185
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 4.33978
New value of Value function: 4.34147
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 4.33825
New value of Value function: 4.34147
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.33903
New value of Value function: 4.34096
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.33804
New value of Value function: 4.34009
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 4.33746
New value of Value function: 4.33978
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 4.33772
New value of Value function: 4.33903
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.33659
New value of Value function: 4.33825
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 4.33597
New value of Value function: 4.33804
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.33512
New value of Value function: 4.33772
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 4.33566
New value of Value function: 4.33746
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 4.33484
New value of Value function: 4.33659
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.33417
New value of Value function: 4.33597
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 4.33369
New value of Value function: 4.33566
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 4.3336
New value of Value function: 4.33512
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.33221
New value of Value function: 4.33484
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 4.33222
New value of Value function: 4.33417
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.33174
New value of Value function: 4.33369
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 4.33142
New value of Value function: 4.3336
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 4.33155
New value of Value function: 4.33222
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 4.32961
New value of Value function: 4.33221
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.32935
New value of Value function: 4.33221
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.32931
New value of Value function: 4.33155
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 4.3295
New value of Value function: 4.33142
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 4.32915
New value of Value function: 4.32961
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 4.327
New value of Value function: 4.3295
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 4.32745
New value of Value function: 4.32935
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 4.32694
New value of Value function: 4.32931
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.32642
New value of Value function: 4.32915
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 4.32453
New value of Value function: 4.32915
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 4.32688
New value of Value function: 4.32745
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 4.3254
New value of Value function: 4.32694
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 4.32343
New value of Value function: 4.32694
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 4.32453
New value of Value function: 4.32688
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 4.32462
New value of Value function: 4.32642
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.32353
New value of Value function: 4.32462
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 4.32236
New value of Value function: 4.32453
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.32072
New value of Value function: 4.32453
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 4.32145
New value of Value function: 4.32453
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 4.32213
New value of Value function: 4.32453
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 4.32194
New value of Value function: 4.32236
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 4.32011
New value of Value function: 4.32213
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 4.31973
New value of Value function: 4.32194
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 4.31935
New value of Value function: 4.32145
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 4.31941
New value of Value function: 4.32072
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.31785
New value of Value function: 4.32011
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 4.31736
New value of Value function: 4.32011
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 4.31786
New value of Value function: 4.31941
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 4.31738
New value of Value function: 4.31935
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 4.31544
New value of Value function: 4.31935
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 4.31677
New value of Value function: 4.31786
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 4.31561
New value of Value function: 4.31785
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.31499
New value of Value function: 4.31736
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 4.31497
New value of Value function: 4.31677
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 4.31419
New value of Value function: 4.31561
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 4.31337
New value of Value function: 4.31544
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 4.31342
New value of Value function: 4.31499
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.31214
New value of Value function: 4.31497
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 4.31167
New value of Value function: 4.31497
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 4.31259
New value of Value function: 4.31342
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 4.3114
New value of Value function: 4.31337
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 4.31114
New value of Value function: 4.31259
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 4.30916
New value of Value function: 4.31259
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 4.31021
New value of Value function: 4.31214
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.3093
New value of Value function: 4.3114
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 4.30938
New value of Value function: 4.31114
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 4.3089
New value of Value function: 4.31021
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 4.30784
New value of Value function: 4.30938
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 4.30736
New value of Value function: 4.3093
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 4.30661
New value of Value function: 4.3093
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.30646
New value of Value function: 4.3089
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 4.30668
New value of Value function: 4.30784
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 4.30547
New value of Value function: 4.30736
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 458
New value of Q matrix: 4.30535
New value of Value function: 4.30668
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 4.30445
New value of Value function: 4.30661
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 4.30234
New value of Value function: 4.30661
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 4.30406
New value of Value function: 4.30646
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.30364
New value of Value function: 4.30547
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 332
New value of Q matrix: 4.43516
New value of Value function: 4.43516
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 3
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.67848
New value of Value function: 3.67848
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 4
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.8626
New value of Value function: 5.8626
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 5
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.803976
New value of Value function: 4.87356
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 6
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 7.18334
New value of Value function: 7.18334
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 7
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.86279
New value of Value function: 2.86279
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 333
New value of Q matrix: 4.74622
New value of Value function: 4.74622
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 9
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.68363
New value of Value function: 8.68363
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 10
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.29138
New value of Value function: 6.29138
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 11
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.36435
New value of Value function: 7.36435
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 12
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.85048
New value of Value function: 2.38823
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 13
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.66025
New value of Value function: 4.66025
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 14
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.9007
New value of Value function: 1.9007
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 334
New value of Q matrix: 4.90312
New value of Value function: 4.90312
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 16
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 3.72486
New value of Value function: 3.72486
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 335
New value of Q matrix: 5.00062
New value of Value function: 5.00062
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 18
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 3.1638
New value of Value function: 3.1638
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 336
New value of Q matrix: 5.06235
New value of Value function: 5.06235
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 20
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 21
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 22
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.01173
New value of Value function: 2.01173
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 337
New value of Q matrix: 5.21965
New value of Value function: 5.21965
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 24
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.21371
New value of Value function: 7.21371
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 25
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.99709
New value of Value function: 2.99709
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 338
New value of Q matrix: 5.31146
New value of Value function: 5.31146
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 27
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.67094
New value of Value function: 5.67094
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 28
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.32627
New value of Value function: 2.32627
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 339
New value of Q matrix: 5.4151
New value of Value function: 5.4151
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 30
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.61423
New value of Value function: 4.26227
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 31
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.40082
New value of Value function: 6.40082
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 32
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.34361
New value of Value function: 2.34361
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 4.35686
New value of Value function: 5.4151
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 4.3729
New value of Value function: 5.4151
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 340
New value of Q matrix: 5.51296
New value of Value function: 5.51296
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 36
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.21965
New value of Value function: 4.26227
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 37
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.21965
New value of Value function: 4.26227
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 38
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4.26227
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 39
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 40
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 41
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 42
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.95483
New value of Value function: 7.95483
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 43
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.874193
New value of Value function: 0.874193
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 44
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 45
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.45783
New value of Value function: 2.45783
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 341
New value of Q matrix: 5.42374
New value of Value function: 5.42374
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 47
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.780353
New value of Value function: 0.874193
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 48
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.16948
New value of Value function: 4.21965
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 342
New value of Q matrix: 5.51857
New value of Value function: 5.51857
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 50
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.81644
New value of Value function: 4.21965
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 459
New value of Q matrix: 4.3594
New value of Value function: 5.51857
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 4.41378
New value of Value function: 5.51857
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 4.46769
New value of Value function: 5.51857
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 5.51559
New value of Value function: 5.51559
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 5.51262
New value of Value function: 5.51262
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 4.37226
New value of Value function: 5.51262
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 345
New value of Q matrix: 5.50835
New value of Value function: 5.50835
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 58
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.4546
New value of Value function: 2.4546
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 4.43607
New value of Value function: 5.50835
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 346
New value of Q matrix: 5.42002
New value of Value function: 5.42002
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 61
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.73539
New value of Value function: 1.73539
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 347
New value of Q matrix: 5.38234
New value of Value function: 5.38234
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 63
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.03195
New value of Value function: 2.03195
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 4.51185
New value of Value function: 5.38234
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 5.37945
New value of Value function: 5.37945
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 349
New value of Q matrix: 5.35977
New value of Value function: 5.35977
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 67
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.15458
New value of Value function: 2.15458
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 350
New value of Q matrix: 5.34765
New value of Value function: 5.34765
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 69
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.21157
New value of Value function: 2.21157
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 351
New value of Q matrix: 5.3392
New value of Value function: 5.3392
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 71
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.151846
New value of Value function: 2.21157
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 4.5515
New value of Value function: 5.3392
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 352
New value of Q matrix: 5.21452
New value of Value function: 5.21452
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 74
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.16238
New value of Value function: 2.16238
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 353
New value of Q matrix: 5.21319
New value of Value function: 5.21319
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 76
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 2.19248
New value of Value function: 2.19248
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 4.47879
New value of Value function: 5.21319
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 354
New value of Q matrix: 5.21092
New value of Value function: 5.21092
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 79
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 2.18058
New value of Value function: 2.18058
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 355
New value of Q matrix: 5.20815
New value of Value function: 5.20815
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 81
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 2.17241
New value of Value function: 2.17241
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 356
New value of Q matrix: 5.09112
New value of Value function: 5.09112
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 83
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 84
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.52076
New value of Value function: 1.52076
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 85
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.50556
New value of Value function: 2.17241
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 86
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.88445
New value of Value function: 1.88445
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 87
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 3.74354
New value of Value function: 3.74354
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 88
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.07599
New value of Value function: 2.07599
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 4.51182
New value of Value function: 5.09112
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 357
New value of Q matrix: 4.98045
New value of Value function: 4.98045
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 91
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.93064
New value of Value function: 1.93064
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 358
New value of Q matrix: 4.9768
New value of Value function: 4.9768
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 93
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.68082
New value of Value function: 1.93064
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 94
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.79527
New value of Value function: 2.79527
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 95
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.76409
New value of Value function: 3.74354
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 96
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.7061
New value of Value function: 8.7061
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 97
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.34751
New value of Value function: 3.34751
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 98
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.15001
New value of Value function: 2.15001
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 359
New value of Q matrix: 5.04737
New value of Value function: 5.04737
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 100
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 4.41784
New value of Value function: 4.41784
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 101
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.626343
New value of Value function: 2.07599
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 102
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 5.14932
New value of Value function: 5.14932
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 103
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.03033
New value of Value function: 2.03033
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 360
New value of Q matrix: 5.0402
New value of Value function: 5.0402
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 105
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.97247
New value of Value function: 1.97247
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 361
New value of Q matrix: 5.0356
New value of Value function: 5.0356
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 107
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.96109
New value of Value function: 1.96109
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 108
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.95128
New value of Value function: 1.95128
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 109
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.98524
New value of Value function: 1.98524
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 362
New value of Q matrix: 5.03191
New value of Value function: 5.03191
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 111
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.00277
New value of Value function: 2.00277
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 112
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.02018
New value of Value function: 2.02018
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 113
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.01114
New value of Value function: 2.01114
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 114
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.00293
New value of Value function: 2.00293
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 115
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.21856
New value of Value function: 2.00293
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 116
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.9913
New value of Value function: 1.9913
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 117
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.9829
New value of Value function: 2.00293
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 118
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.9829
New value of Value function: 2.00293
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 119
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.99536
New value of Value function: 1.99536
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 120
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.98831
New value of Value function: 1.98831
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 121
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.98168
New value of Value function: 1.9829
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 122
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.97145
New value of Value function: 1.98168
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 123
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.97541
New value of Value function: 1.97541
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 124
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.96946
New value of Value function: 1.97145
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 125
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.9616
New value of Value function: 1.96946
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 126
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.96377
New value of Value function: 1.96377
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 127
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.95832
New value of Value function: 1.9616
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 128
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.95282
New value of Value function: 1.95832
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 129
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 1.96454
New value of Value function: 1.96454
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 4.57351
New value of Value function: 5.03191
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 363
New value of Q matrix: 5.02873
New value of Value function: 5.02873
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 132
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.98487
New value of Value function: 1.98487
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 364
New value of Q matrix: 5.02539
New value of Value function: 5.02539
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 134
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.95743
New value of Value function: 1.98487
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 135
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.96699
New value of Value function: 1.96699
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 136
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.9601
New value of Value function: 1.9601
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 137
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.97032
New value of Value function: 1.97032
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 365
New value of Q matrix: 5.02148
New value of Value function: 5.02148
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 139
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 1.97068
New value of Value function: 1.97068
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 460
New value of Q matrix: 4.38793
New value of Value function: 5.02148
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 5.01886
New value of Value function: 5.01886
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 367
New value of Q matrix: 5.01531
New value of Value function: 5.01531
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 143
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 1.96873
New value of Value function: 1.96873
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 4.41481
New value of Value function: 5.01531
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 5.0127
New value of Value function: 5.0127
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 369
New value of Q matrix: 5.00938
New value of Value function: 5.00938
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 147
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 1.96558
New value of Value function: 1.96558
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 4.59322
New value of Value function: 5.00938
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 370
New value of Q matrix: 5.00608
New value of Value function: 5.00608
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 150
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.097825
New value of Value function: 1.96558
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 151
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 4.29587
New value of Value function: 4.29587
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 371
New value of Q matrix: 5.12273
New value of Value function: 5.12273
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 153
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.0691532
New value of Value function: 4.29587
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 154
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.86545
New value of Value function: 5.86545
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 155
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 156
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.806796
New value of Value function: 0.806796
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 157
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.8068
New value of Value function: 5.86545
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 158
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.89088
New value of Value function: 5.8068
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 159
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.19529
New value of Value function: 4.19529
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 160
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.17431
New value of Value function: 4.17431
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 161
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.15564
New value of Value function: 4.15564
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 162
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.13868
New value of Value function: 4.13868
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 163
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.12303
New value of Value function: 4.12303
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 164
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.10846
New value of Value function: 4.10846
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 165
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.09476
New value of Value function: 4.09476
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 166
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.08181
New value of Value function: 4.08181
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 167
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.35563
New value of Value function: 4.08181
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 168
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.04099
New value of Value function: 9.04099
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 169
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.0695
New value of Value function: 4.0695
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 170
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.05776
New value of Value function: 4.05776
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 171
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -4.30501
New value of Value function: 4.05776
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 172
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.33682
New value of Value function: 6.33682
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 173
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.77615
New value of Value function: 6.77615
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 174
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.03761
New value of Value function: 2.34361
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 175
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.22192
New value of Value function: 2.22192
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 372
New value of Q matrix: 5.22096
New value of Value function: 5.22096
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 177
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.0465
New value of Value function: 4.0465
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 178
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.54062
New value of Value function: 4.0465
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 179
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.20021
New value of Value function: 2.20021
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 373
New value of Q matrix: 5.31338
New value of Value function: 5.31338
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 181
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5.79873
New value of Value function: 5.79873
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 182
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.26025
New value of Value function: 2.26025
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 374
New value of Q matrix: 5.49061
New value of Value function: 5.49061
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 184
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.24121
New value of Value function: 8.24121
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 185
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.73626
New value of Value function: 3.73626
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 186
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.29285
New value of Value function: 2.29285
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 234
New value of Q matrix: 4.42943
New value of Value function: 5.49061
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 188
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.23956
New value of Value function: 2.23956
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 189
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.38235
New value of Value function: 2.38235
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 375
New value of Q matrix: 5.553
New value of Value function: 5.553
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 191
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.36968
New value of Value function: 3.36968
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 192
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.38436
New value of Value function: 2.38436
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 4.63937
New value of Value function: 5.553
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 5.55014
New value of Value function: 5.55014
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 377
New value of Q matrix: 5.51902
New value of Value function: 5.51902
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 196
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 2.12314
New value of Value function: 2.12314
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 378
New value of Q matrix: 5.49757
New value of Value function: 5.49757
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 198
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 2.21946
New value of Value function: 2.21946
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 4.6803
New value of Value function: 5.49757
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 379
New value of Q matrix: 5.48214
New value of Value function: 5.48214
New value of Policy matrix: 0

