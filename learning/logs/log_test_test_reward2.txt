=======================================
Simulation: 1
Iteration: 1
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 49
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 0.0792
New value of Value function: 0.0792
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 52
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 53
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 55
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.03992
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 56
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0791216
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 57
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 58
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.0777744
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0014256
New value of Value function: 0.0792
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00282269
New value of Value function: 0.0792
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.117616
New value of Value function: 0.117616
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 62
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0770702
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 63
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 65
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.114102
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 0.155264
New value of Value function: 0.155264
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 67
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0755288
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 68
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 69
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0777758
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 70
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0792
New value of Value function: 0.0792
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 71
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.114795
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 72
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0014256
New value of Value function: 0.0792
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 73
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0790416
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 74
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.078885
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00212979
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 76
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0787314
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.117539
New value of Value function: 0.117539
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 79
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.111903
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 80
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00282131
New value of Value function: 0.117539
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00276488
New value of Value function: 0.117539
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 85
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 89
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0014256
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00211709
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00279475
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 95
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0014256
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 96
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.03992
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0398416
New value of Value function: 0.0398416
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 98
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00142275
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 99
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.003456
New value of Value function: 0.0398416
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 100
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142275
New value of Value function: 0.0398416
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 101
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0397619
New value of Value function: 0.0397619
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 102
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00410688
New value of Value function: 0.0397619
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 103
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0399157
New value of Value function: 0.0399157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 104
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0396852
New value of Value function: 0.0396852
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 105
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00210863
New value of Value function: 0.0399157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 106
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00473908
New value of Value function: 0.0396852
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 107
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00210863
New value of Value function: 0.0396852
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 108
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00211142
New value of Value function: 0.0396852
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0396058
New value of Value function: 0.0396058
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 110
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0027821
New value of Value function: 0.0396058
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 111
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0395322
New value of Value function: 0.0395322
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 112
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000718483
New value of Value function: 0.0399157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 113
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000718483
New value of Value function: 0.0399157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 114
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00278494
New value of Value function: 0.0399157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 115
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000718483
New value of Value function: 0.0399157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 116
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0398359
New value of Value function: 0.0398359
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 117
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00344082
New value of Value function: 0.0398359
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 118
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00343803
New value of Value function: 0.0395322
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 119
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00277803
New value of Value function: 0.0395322
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.0427225
New value of Value function: 0.0427225
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 121
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.039231
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 122
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00413828
New value of Value function: 0.0427225
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 123
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000769005
New value of Value function: 0.0427225
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 124
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.081868
New value of Value function: 0.081868
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 125
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0769728
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 126
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 0.120231
New value of Value function: 0.120231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 127
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 128
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 129
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 130
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 131
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 132
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 133
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0372053
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00350035
New value of Value function: 0.155264
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00556098
New value of Value function: 0.155264
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00824451
New value of Value function: 0.155264
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00622509
New value of Value function: 0.155264
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.154953
New value of Value function: 0.154953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00888974
New value of Value function: 0.154953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00278916
New value of Value function: 0.154953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.0427334
New value of Value function: 0.154953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 142
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 143
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0764108
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00278916
New value of Value function: 0.154953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00552253
New value of Value function: 0.154953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0108688
New value of Value function: 0.154953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.154643
New value of Value function: 0.154643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.154334
New value of Value function: 0.154334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00819009
New value of Value function: 0.154334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0134294
New value of Value function: 0.154334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.154025
New value of Value function: 0.154025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.153717
New value of Value function: 0.153717
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0114789
New value of Value function: 0.153717
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.15341
New value of Value function: 0.15341
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0159222
New value of Value function: 0.15341
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.153103
New value of Value function: 0.153103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0140051
New value of Value function: 0.153103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0446346
New value of Value function: 0.153103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0464977
New value of Value function: 0.153103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.152797
New value of Value function: 0.152797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.152491
New value of Value function: 0.152491
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0483126
New value of Value function: 0.152491
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0183486
New value of Value function: 0.152491
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.152186
New value of Value function: 0.152186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.151882
New value of Value function: 0.151882
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0164589
New value of Value function: 0.151882
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.151578
New value of Value function: 0.151578
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0107547
New value of Value function: 0.151578
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.013268
New value of Value function: 0.151578
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.151275
New value of Value function: 0.151275
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.150972
New value of Value function: 0.150972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.15067
New value of Value function: 0.15067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0188418
New value of Value function: 0.15067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0206937
New value of Value function: 0.15067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0229919
New value of Value function: 0.15067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.150369
New value of Value function: 0.150369
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0211716
New value of Value function: 0.150369
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.150068
New value of Value function: 0.150068
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.149768
New value of Value function: 0.149768
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.149469
New value of Value function: 0.149469
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.14917
New value of Value function: 0.14917
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0234332
New value of Value function: 0.14917
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0500314
New value of Value function: 0.14917
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.148871
New value of Value function: 0.148871
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.148574
New value of Value function: 0.148574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0252064
New value of Value function: 0.148574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0273766
New value of Value function: 0.148574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.148276
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0516998
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.029498
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0256335
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0277898
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.031577
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0336145
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0533347
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0356112
New value of Value function: 0.148276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.14798
New value of Value function: 0.14798
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.147684
New value of Value function: 0.147684
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.015661
New value of Value function: 0.147684
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0298924
New value of Value function: 0.147684
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0549264
New value of Value function: 0.147684
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.147389
New value of Value function: 0.147389
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.147094
New value of Value function: 0.147094
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.1468
New value of Value function: 0.1468
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0319369
New value of Value function: 0.1468
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.146506
New value of Value function: 0.146506
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.037536
New value of Value function: 0.146506
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.146213
New value of Value function: 0.146213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0179796
New value of Value function: 0.146213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0564597
New value of Value function: 0.146213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.145921
New value of Value function: 0.145921
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.145629
New value of Value function: 0.145629
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.145338
New value of Value function: 0.145338
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0339142
New value of Value function: 0.145338
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0202361
New value of Value function: 0.145338
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.145047
New value of Value function: 0.145047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.144757
New value of Value function: 0.144757
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.144467
New value of Value function: 0.144467
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0224317
New value of Value function: 0.144467
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0579309
New value of Value function: 0.144467
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.144178
New value of Value function: 0.144178
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0245783
New value of Value function: 0.144178
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0593675
New value of Value function: 0.144178
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0607753
New value of Value function: 0.144178
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.14389
New value of Value function: 0.14389
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0266768
New value of Value function: 0.14389
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0621498
New value of Value function: 0.14389
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.143602
New value of Value function: 0.143602
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0393702
New value of Value function: 0.143602
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0411676
New value of Value function: 0.143602
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.143315
New value of Value function: 0.143315
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0358156
New value of Value function: 0.143315
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.143028
New value of Value function: 0.143028
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.142742
New value of Value function: 0.142742
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.142457
New value of Value function: 0.142457
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.142172
New value of Value function: 0.142172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0376584
New value of Value function: 0.142172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0429033
New value of Value function: 0.142172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.141888
New value of Value function: 0.141888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0445992
New value of Value function: 0.141888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0394592
New value of Value function: 0.141888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.141604
New value of Value function: 0.141604
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.141321
New value of Value function: 0.141321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0634506
New value of Value function: 0.141321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.141038
New value of Value function: 0.141038
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0647203
New value of Value function: 0.141038
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0462459
New value of Value function: 0.141038
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.140756
New value of Value function: 0.140756
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.140474
New value of Value function: 0.140474
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.140193
New value of Value function: 0.140193
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0659494
New value of Value function: 0.140193
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0478445
New value of Value function: 0.140193
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.139913
New value of Value function: 0.139913
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0286617
New value of Value function: 0.139913
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0306069
New value of Value function: 0.139913
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.139633
New value of Value function: 0.139633
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.139354
New value of Value function: 0.139354
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.049396
New value of Value function: 0.139354
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0509164
New value of Value function: 0.139354
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0524065
New value of Value function: 0.139354
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.139075
New value of Value function: 0.139075
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.138797
New value of Value function: 0.138797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0411684
New value of Value function: 0.138797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0538567
New value of Value function: 0.138797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0428434
New value of Value function: 0.138797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0552779
New value of Value function: 0.138797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.138519
New value of Value function: 0.138519
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0324881
New value of Value function: 0.138519
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.138242
New value of Value function: 0.138242
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 68
New value of Q matrix: 0.175478
New value of Value function: 0.175478
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 271
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 272
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 273
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 274
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.148661
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0573309
New value of Value function: 0.175478
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 0.0961843
New value of Value function: 0.175478
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 277
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04108
New value of Value function: 0.04108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 278
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.147549
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 279
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.156268
New value of Value function: 0.156268
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 280
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021384
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 281
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00317563
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 282
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 0.0195394
New value of Value function: 0.0195394
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 283
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00073944
New value of Value function: 0.04108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 284
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00073944
New value of Value function: 0.04108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 285
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0403517
New value of Value function: 0.04108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 286
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.144246
New value of Value function: 0.0195394
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 287
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.145336
New value of Value function: 0.0195394
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 288
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.141009
New value of Value function: 0.0195394
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 289
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: -0.175376
New value of Value function: 0.0195394
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 290
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.153882
New value of Value function: 0.153882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 291
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00146409
New value of Value function: 0.04108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 292
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0430283
New value of Value function: 0.0430283
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 293
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00485708
New value of Value function: 0.153882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 294
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00547947
New value of Value function: 0.153882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 295
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0799267
New value of Value function: 0.153882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 296
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.153575
New value of Value function: 0.153575
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 297
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00416143
New value of Value function: 0.153575
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 298
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00684255
New value of Value function: 0.153575
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 299
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00752428
New value of Value function: 0.153575
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 300
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00947004
New value of Value function: 0.153575
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 301
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.153268
New value of Value function: 0.153268
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 302
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.150977
New value of Value function: 0.150977
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 303
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0448853
New value of Value function: 0.0448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 304
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.148765
New value of Value function: 0.148765
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 305
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0410764
New value of Value function: 0.0448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 306
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: -0.0200434
New value of Value function: 0.00317563
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 307
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00224274
New value of Value function: 0.0448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 308
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00487566
New value of Value function: 0.0448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 309
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0119584
New value of Value function: 0.148765
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 310
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00608692
New value of Value function: 0.148765
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 311
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142116
New value of Value function: 0.0398359
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 312
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142116
New value of Value function: 0.0398359
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 313
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00210978
New value of Value function: 0.0398359
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 314
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00210978
New value of Value function: 0.0398359
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 315
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0397562
New value of Value function: 0.0397562
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 316
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0027832
New value of Value function: 0.0397562
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 317
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00408761
New value of Value function: 0.0397562
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 318
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0396767
New value of Value function: 0.0396767
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 319
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00141829
New value of Value function: 0.0396767
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 320
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0395973
New value of Value function: 0.0395973
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 321
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00471861
New value of Value function: 0.0395973
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 322
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00210268
New value of Value function: 0.0395973
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 323
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0395182
New value of Value function: 0.0395182
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 324
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 0.0446242
New value of Value function: 0.0446242
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 325
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0391968
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 326
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0047384
New value of Value function: 0.0446242
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 327
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.014397
New value of Value function: 0.148765
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 328
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0100516
New value of Value function: 0.148765
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 329
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0167868
New value of Value function: 0.148765
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 330
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.148468
New value of Value function: 0.148468
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 331
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0191235
New value of Value function: 0.148468
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 332
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0086376
New value of Value function: 0.148468
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 333
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.012523
New value of Value function: 0.148468
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 334
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.148171
New value of Value function: 0.148171
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 335
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.146015
New value of Value function: 0.146015
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 336
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00558608
New value of Value function: 0.0448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 337
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00810264
New value of Value function: 0.0448853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 338
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0149008
New value of Value function: 0.146015
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 339
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0809564
New value of Value function: 0.146015
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 340
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0819656
New value of Value function: 0.146015
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 341
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.017231
New value of Value function: 0.146015
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 342
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 0.0587411
New value of Value function: 0.146015
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 343
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0373717
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 344
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00926808
New value of Value function: 0.146015
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 345
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.044535
New value of Value function: 0.044535
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 346
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0458084
New value of Value function: 0.0458084
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 347
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00680845
New value of Value function: 0.120231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 348
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0395661
New value of Value function: 0.120231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 349
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0470564
New value of Value function: 0.0470564
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 350
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00291778
New value of Value function: 0.120231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 351
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00502357
New value of Value function: 0.120231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 352
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.11999
New value of Value function: 0.11999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 353
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00708292
New value of Value function: 0.11999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 354
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0088321
New value of Value function: 0.11999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 355
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0108153
New value of Value function: 0.11999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 356
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0409346
New value of Value function: 0.11999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 357
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0409629
New value of Value function: 0.11999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 358
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0482751
New value of Value function: 0.0482751
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 359
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00910109
New value of Value function: 0.11999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 360
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0410126
New value of Value function: 0.11999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 361
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0494694
New value of Value function: 0.0494694
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 362
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.11975
New value of Value function: 0.11975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 363
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0127545
New value of Value function: 0.11975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 364
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0146549
New value of Value function: 0.11975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 365
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.119511
New value of Value function: 0.119511
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 366
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 0.157121
New value of Value function: 0.157121
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 367
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.112605
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 368
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.153978
New value of Value function: 0.153978
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 369
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00277161
New value of Value function: 0.00277161
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 370
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0171334
New value of Value function: 0.153978
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 371
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.150948
New value of Value function: 0.150948
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 372
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.98889e-05
New value of Value function: 0.00277161
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 373
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.00353885
New value of Value function: 0.00353885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 374
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.150289
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 375
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.36993e-05
New value of Value function: 0.00353885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 376
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 377
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 378
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 379
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0748826
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 380
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.110226
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0451451
New value of Value function: 0.175478
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.175127
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0473945
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0974129
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0349906
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0374431
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0677827
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0986169
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0997969
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0398465
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 0.107147
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 392
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.00235228
New value of Value function: 0.00353885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0495989
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0517592
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0422018
New value of Value function: 0.175127
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.174776
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.10815
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 0.145987
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 399
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.147284
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 400
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0372829
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 401
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 0.187929
New value of Value function: 0.187929
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 402
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 403
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 404
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 405
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 406
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.05988
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 407
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.144338
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 408
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0366173
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 409
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 0.225249
New value of Value function: 0.225249
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 410
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.106944
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 411
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0354594
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 412
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0597602
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 413
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00107568
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 414
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00212985
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 415
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 0.0186287
New value of Value function: 0.0186287
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 416
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.033386
New value of Value function: 0.00277161
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.100947
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.102074
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0538699
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0445038
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0467597
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.103178
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0559385
New value of Value function: 0.174776
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.174427
New value of Value function: 0.174427
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.174078
New value of Value function: 0.174078
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.17373
New value of Value function: 0.17373
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0579469
New value of Value function: 0.17373
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.146194
New value of Value function: 0.17373
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.173382
New value of Value function: 0.173382
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.146391
New value of Value function: 0.173382
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.146584
New value of Value function: 0.173382
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.104236
New value of Value function: 0.173382
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.173036
New value of Value function: 0.173036
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0599026
New value of Value function: 0.173036
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.146767
New value of Value function: 0.173036
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0618192
New value of Value function: 0.173036
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.146947
New value of Value function: 0.173036
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.105266
New value of Value function: 0.173036
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.172689
New value of Value function: 0.172689
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.106269
New value of Value function: 0.172689
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.172344
New value of Value function: 0.172344
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.171999
New value of Value function: 0.171999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.147104
New value of Value function: 0.171999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.107239
New value of Value function: 0.171999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0489205
New value of Value function: 0.171999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.147258
New value of Value function: 0.171999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.171655
New value of Value function: 0.171655
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.171312
New value of Value function: 0.171312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.147396
New value of Value function: 0.171312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.108178
New value of Value function: 0.171312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.170969
New value of Value function: 0.170969
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.170628
New value of Value function: 0.170628
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.170286
New value of Value function: 0.170286
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.169946
New value of Value function: 0.169946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0510011
New value of Value function: 0.169946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.109074
New value of Value function: 0.169946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0636418
New value of Value function: 0.169946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.169606
New value of Value function: 0.169606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.169267
New value of Value function: 0.169267
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.147495
New value of Value function: 0.169267
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0654158
New value of Value function: 0.169267
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.168928
New value of Value function: 0.168928
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0671482
New value of Value function: 0.168928
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.16859
New value of Value function: 0.16859
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.168253
New value of Value function: 0.168253
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.167917
New value of Value function: 0.167917
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.167581
New value of Value function: 0.167581
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0688217
New value of Value function: 0.167581
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0529975
New value of Value function: 0.167581
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.147562
New value of Value function: 0.167581
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.167246
New value of Value function: 0.167246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0704556
New value of Value function: 0.167246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.147621
New value of Value function: 0.167246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.166911
New value of Value function: 0.166911
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.166577
New value of Value function: 0.166577
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.166244
New value of Value function: 0.166244
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.165912
New value of Value function: 0.165912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0720329
New value of Value function: 0.165912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.16558
New value of Value function: 0.16558
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.165249
New value of Value function: 0.165249
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.164918
New value of Value function: 0.164918
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0549061
New value of Value function: 0.164918
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.109861
New value of Value function: 0.164918
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.110632
New value of Value function: 0.164918
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.164588
New value of Value function: 0.164588
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0735549
New value of Value function: 0.164588
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.0750464
New value of Value function: 0.164588
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.164259
New value of Value function: 0.164259
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0765021
New value of Value function: 0.164259
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.163931
New value of Value function: 0.163931
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.11137
New value of Value function: 0.163931
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.163603
New value of Value function: 0.163603
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.0779169
New value of Value function: 0.163603
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.112088
New value of Value function: 0.163603
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.163276
New value of Value function: 0.163276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.162949
New value of Value function: 0.162949
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.162623
New value of Value function: 0.162623
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.112773
New value of Value function: 0.162623
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.162298
New value of Value function: 0.162298
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.113439
New value of Value function: 0.162298
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.0792799
New value of Value function: 0.162298
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.14759
New value of Value function: 0.162298
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.161973
New value of Value function: 0.161973
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.161649
New value of Value function: 0.161649
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.080604
New value of Value function: 0.161649
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.161326
New value of Value function: 0.161326
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.114074
New value of Value function: 0.161326
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.161003
New value of Value function: 0.161003
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.160681
New value of Value function: 0.160681
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.14753
New value of Value function: 0.160681
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.114685
New value of Value function: 0.160681
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0567002
New value of Value function: 0.160681
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.16036
New value of Value function: 0.16036
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.0818784
New value of Value function: 0.16036
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.160039
New value of Value function: 0.160039
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.0831216
New value of Value function: 0.160039
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0584469
New value of Value function: 0.160039
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.0843398
New value of Value function: 0.160039
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.115272
New value of Value function: 0.160039
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.159719
New value of Value function: 0.159719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.1594
New value of Value function: 0.1594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.0855222
New value of Value function: 0.1594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.115836
New value of Value function: 0.1594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.159081
New value of Value function: 0.159081
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.147443
New value of Value function: 0.159081
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.147358
New value of Value function: 0.159081
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.158763
New value of Value function: 0.158763
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.158445
New value of Value function: 0.158445
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.0866638
New value of Value function: 0.158445
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.158128
New value of Value function: 0.158128
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.157812
New value of Value function: 0.157812
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.157496
New value of Value function: 0.157496
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.147245
New value of Value function: 0.157496
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.157181
New value of Value function: 0.157181
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0601073
New value of Value function: 0.157181
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.0877598
New value of Value function: 0.157181
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.0888339
New value of Value function: 0.157181
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.116348
New value of Value function: 0.157181
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.156867
New value of Value function: 0.156867
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.156553
New value of Value function: 0.156553
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.0898751
New value of Value function: 0.156553
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.15624
New value of Value function: 0.15624
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.116834
New value of Value function: 0.15624
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.155928
New value of Value function: 0.155928
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.117304
New value of Value function: 0.155928
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 128
New value of Q matrix: 0.192829
New value of Value function: 0.192829
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 547
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 548
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.84912e-05
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 549
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0365291
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.118428
New value of Value function: 0.192829
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 129
New value of Q matrix: 0.228992
New value of Value function: 0.228992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 552
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00107784
New value of Value function: 0.00107784
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 553
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.94011e-05
New value of Value function: 0.00107784
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 554
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00111344
New value of Value function: 0.00111344
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 555
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00316928
New value of Value function: 0.00316928
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 556
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00316294
New value of Value function: 0.00316294
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 557
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00315662
New value of Value function: 0.00315662
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 558
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.68191e-05
New value of Value function: 0.00315662
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 559
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000112502
New value of Value function: 0.00315662
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 560
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0195857
New value of Value function: 0.00315662
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 561
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000167071
New value of Value function: 0.00315662
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 562
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.0601838
New value of Value function: 0.0601838
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 563
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00217448
New value of Value function: 0.00217448
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 564
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: -0.178308
New value of Value function: 0.0601838
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 130
New value of Q matrix: 0.265495
New value of Value function: 0.265495
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 566
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.119019
New value of Value function: 0.119019
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 567
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00217013
New value of Value function: 0.00217013
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 568
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00218007
New value of Value function: 0.00218007
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 569
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00523583
New value of Value function: 0.119019
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 570
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.0408452
New value of Value function: 0.119019
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 571
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00426908
New value of Value function: 0.00426908
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 572
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00727346
New value of Value function: 0.119019
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 573
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0421707
New value of Value function: 0.119019
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 574
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.171869
New value of Value function: 0.119019
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 575
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 576
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00214235
New value of Value function: 0.00214235
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 577
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.176716
New value of Value function: 0.176716
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 578
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0710196
New value of Value function: 0.00426908
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 131
New value of Q matrix: 0.303366
New value of Value function: 0.303366
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 580
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0103089
New value of Value function: 0.176716
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 581
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.168393
New value of Value function: 0.176716
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 582
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00528038
New value of Value function: 0.00528038
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 583
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.16493
New value of Value function: 0.176716
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 584
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00318088
New value of Value function: 0.00528038
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 585
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.176362
New value of Value function: 0.176362
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 586
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.17601
New value of Value function: 0.17601
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 587
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.161536
New value of Value function: 0.17601
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 588
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00321231
New value of Value function: 0.00528038
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 589
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00834295
New value of Value function: 0.00834295
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 590
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0444954
New value of Value function: 0.17601
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 591
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: -0.114665
New value of Value function: 0.17601
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 592
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00426054
New value of Value function: 0.00426054
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 593
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00316817
New value of Value function: 0.00426054
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 594
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.175658
New value of Value function: 0.175658
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 595
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.232221
New value of Value function: 0.232221
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 596
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00425202
New value of Value function: 0.00425202
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 597
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00834696
New value of Value function: 0.00834696
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 598
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.287727
New value of Value function: 0.287727
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 599
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00325498
New value of Value function: 0.00834696
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 600
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.073996
New value of Value function: 0.00834295
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 601
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.0490827
New value of Value function: 0.146015
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 602
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 603
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0382627
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 604
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00832626
New value of Value function: 0.00832626
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 605
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0723662
New value of Value function: 0.00832626
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 606
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00830961
New value of Value function: 0.00830961
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 607
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0133225
New value of Value function: 0.0133225
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 608
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.342123
New value of Value function: 0.342123
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 609
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0143382
New value of Value function: 0.0143382
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 610
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.395538
New value of Value function: 0.395538
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 611
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0211711
New value of Value function: 0.0211711
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 612
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: -0.0519903
New value of Value function: 0.395538
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 613
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000400094
New value of Value function: 0.0211711
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 614
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.104139
New value of Value function: 0.0211711
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 132
New value of Q matrix: 0.33768
New value of Value function: 0.33768
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 616
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0103096
New value of Value function: 0.0211711
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 617
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0507252
New value of Value function: 0.395538
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 618
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.448009
New value of Value function: 0.448009
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 619
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.101675
New value of Value function: 0.0211711
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 620
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.133563
New value of Value function: 0.0211711
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.150379
New value of Value function: 0.33768
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.337004
New value of Value function: 0.337004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.122126
New value of Value function: 0.337004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.125749
New value of Value function: 0.337004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 134
New value of Q matrix: 0.378328
New value of Value function: 0.378328
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 626
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.110092
New value of Value function: 0.448009
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 627
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0288119
New value of Value function: 0.0288119
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 628
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.499567
New value of Value function: 0.499567
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 629
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0372278
New value of Value function: 0.0372278
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 630
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.550246
New value of Value function: 0.550246
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 631
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0463877
New value of Value function: 0.0463877
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 632
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.600076
New value of Value function: 0.600076
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 633
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00297145
New value of Value function: 0.0463877
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 634
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0462949
New value of Value function: 0.0462949
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 635
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0209047
New value of Value function: 0.0462949
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 636
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.598876
New value of Value function: 0.598876
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 637
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.597678
New value of Value function: 0.597678
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 638
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.646558
New value of Value function: 0.646558
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 639
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.130058
New value of Value function: 0.0462949
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 640
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0462023
New value of Value function: 0.0462023
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 641
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00122373
New value of Value function: 0.0462023
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 642
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00374366
New value of Value function: 0.0462023
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 643
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0461099
New value of Value function: 0.0461099
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 644
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0460177
New value of Value function: 0.0460177
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 645
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0044971
New value of Value function: 0.0460177
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 646
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0459257
New value of Value function: 0.0459257
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 647
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0321247
New value of Value function: 0.0459257
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 648
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.694453
New value of Value function: 0.694453
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 649
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.031722
New value of Value function: 0.0459257
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 650
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0631481
New value of Value function: 0.0631481
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 651
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00113667
New value of Value function: 0.00113667
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 652
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0255562
New value of Value function: 0.0631481
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 653
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.741391
New value of Value function: 0.741391
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 654
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0458338
New value of Value function: 0.0458338
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 655
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0582622
New value of Value function: 0.0582622
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 656
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0234477
New value of Value function: 0.741391
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 657
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.739908
New value of Value function: 0.739908
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 658
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.786159
New value of Value function: 0.786159
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 659
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0712478
New value of Value function: 0.0712478
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 660
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.169172
New value of Value function: 0.786159
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 661
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.126175
New value of Value function: 0.0712478
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 662
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: -0.156841
New value of Value function: 0.0712478
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.130044
New value of Value function: 0.378328
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.134253
New value of Value function: 0.378328
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.0948876
New value of Value function: 0.378328
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 135
New value of Q matrix: 0.412044
New value of Value function: 0.412044
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 667
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0153501
New value of Value function: 0.0712478
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 668
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0371296
New value of Value function: 0.786159
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 669
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.17994
New value of Value function: 0.786159
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 670
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.157169
New value of Value function: 0.786159
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 671
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0630218
New value of Value function: 0.0630218
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 672
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0628957
New value of Value function: 0.0628957
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 673
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.12292
New value of Value function: 0.12292
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 674
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.029194
New value of Value function: 0.0712478
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 675
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0385996
New value of Value function: 0.786159
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 676
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0687063
New value of Value function: 0.12292
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 677
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.122674
New value of Value function: 0.122674
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 678
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0391959
New value of Value function: 0.122674
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 679
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.784586
New value of Value function: 0.784586
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 680
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0519502
New value of Value function: 0.784586
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 681
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.783017
New value of Value function: 0.783017
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 682
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.237623
New value of Value function: 0.783017
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 683
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00568962
New value of Value function: 0.0712478
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 684
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0839172
New value of Value function: 0.0839172
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 685
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0650055
New value of Value function: 0.783017
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 686
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 0.828867
New value of Value function: 0.828867
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 687
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00708634
New value of Value function: 0.0839172
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 688
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0301206
New value of Value function: 0.0839172
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 689
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0837493
New value of Value function: 0.0837493
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 690
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0835818
New value of Value function: 0.0835818
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 691
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0310227
New value of Value function: 0.0835818
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 692
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0968298
New value of Value function: 0.0968298
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 693
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.151817
New value of Value function: 0.828867
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 694
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00220814
New value of Value function: 0.122674
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 695
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.122429
New value of Value function: 0.122429
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 696
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.110295
New value of Value function: 0.122429
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 697
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0651285
New value of Value function: 0.122429
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 698
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: -0.102935
New value of Value function: 0.122429
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 699
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 0.0884801
New value of Value function: 0.0884801
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 700
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 701
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0392
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 702
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 703
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 704
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 705
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 706
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0384074
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 707
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 0.12671
New value of Value function: 0.12671
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 708
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 709
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0600194
New value of Value function: 0.0600194
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 710
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 711
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 712
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 713
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00139372
New value of Value function: 0.00139372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 714
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: -0.04478
New value of Value function: 0.0186287
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 715
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.41381e-05
New value of Value function: 0.00139372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 716
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0325832
New value of Value function: 0.00139372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.100407
New value of Value function: 0.412044
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.105815
New value of Value function: 0.412044
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.111116
New value of Value function: 0.412044
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0663219
New value of Value function: 0.412044
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.41122
New value of Value function: 0.41122
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.410398
New value of Value function: 0.410398
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.409577
New value of Value function: 0.409577
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0723679
New value of Value function: 0.409577
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0782929
New value of Value function: 0.409577
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.408758
New value of Value function: 0.408758
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.40794
New value of Value function: 0.40794
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.138911
New value of Value function: 0.40794
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.154714
New value of Value function: 0.40794
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.407124
New value of Value function: 0.407124
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.143461
New value of Value function: 0.407124
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.14792
New value of Value function: 0.407124
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0840553
New value of Value function: 0.407124
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.40631
New value of Value function: 0.40631
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 735
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0896878
New value of Value function: 0.40631
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.158933
New value of Value function: 0.40631
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.163068
New value of Value function: 0.40631
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.405498
New value of Value function: 0.405498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.116192
New value of Value function: 0.405498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.121168
New value of Value function: 0.405498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.167106
New value of Value function: 0.405498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.126043
New value of Value function: 0.405498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.404687
New value of Value function: 0.404687
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.403877
New value of Value function: 0.403877
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0951638
New value of Value function: 0.403877
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.403069
New value of Value function: 0.403069
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0.402263
New value of Value function: 0.402263
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.401459
New value of Value function: 0.401459
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.400656
New value of Value function: 0.400656
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.130734
New value of Value function: 0.400656
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0.399855
New value of Value function: 0.399855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 752
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.135317
New value of Value function: 0.399855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.139808
New value of Value function: 0.399855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.399055
New value of Value function: 0.399055
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0.398257
New value of Value function: 0.398257
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.39746
New value of Value function: 0.39746
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0.396665
New value of Value function: 0.396665
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.395872
New value of Value function: 0.395872
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.100386
New value of Value function: 0.395872
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 760
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.170889
New value of Value function: 0.395872
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.152088
New value of Value function: 0.395872
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0.39508
New value of Value function: 0.39508
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0.39429
New value of Value function: 0.39429
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 764
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0.393502
New value of Value function: 0.393502
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.174555
New value of Value function: 0.393502
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0.392715
New value of Value function: 0.392715
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.156115
New value of Value function: 0.392715
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 768
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.144081
New value of Value function: 0.392715
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 769
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.148268
New value of Value function: 0.392715
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 770
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0.391929
New value of Value function: 0.391929
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 771
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0.391145
New value of Value function: 0.391145
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 772
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0.390363
New value of Value function: 0.390363
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 773
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0.389582
New value of Value function: 0.389582
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0.388803
New value of Value function: 0.388803
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 775
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.159991
New value of Value function: 0.388803
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0.388025
New value of Value function: 0.388025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.105363
New value of Value function: 0.388025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.387249
New value of Value function: 0.387249
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.163762
New value of Value function: 0.387249
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.386475
New value of Value function: 0.386475
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.385702
New value of Value function: 0.385702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.110198
New value of Value function: 0.385702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.152245
New value of Value function: 0.385702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 784
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.178006
New value of Value function: 0.385702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.167429
New value of Value function: 0.385702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.114937
New value of Value function: 0.385702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0.384931
New value of Value function: 0.384931
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.156129
New value of Value function: 0.384931
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.181375
New value of Value function: 0.384931
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.119567
New value of Value function: 0.384931
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.184676
New value of Value function: 0.384931
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0.384161
New value of Value function: 0.384161
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.159921
New value of Value function: 0.384161
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 794
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0.383392
New value of Value function: 0.383392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.124077
New value of Value function: 0.383392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0.382626
New value of Value function: 0.382626
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.128482
New value of Value function: 0.382626
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0.38186
New value of Value function: 0.38186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0.381097
New value of Value function: 0.381097
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.17094
New value of Value function: 0.381097
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.174381
New value of Value function: 0.381097
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.163583
New value of Value function: 0.381097
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.187842
New value of Value function: 0.381097
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0.380334
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.132759
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.13695
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.190932
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.177739
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.193959
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.181031
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.167157
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.141057
New value of Value function: 0.380334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0.379574
New value of Value function: 0.379574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0.378815
New value of Value function: 0.378815
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.184229
New value of Value function: 0.378815
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.170632
New value of Value function: 0.378815
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0.378057
New value of Value function: 0.378057
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0.377301
New value of Value function: 0.377301
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.187336
New value of Value function: 0.377301
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.19038
New value of Value function: 0.377301
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0.376546
New value of Value function: 0.376546
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0.375793
New value of Value function: 0.375793
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.145
New value of Value function: 0.375793
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.193337
New value of Value function: 0.375793
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.196844
New value of Value function: 0.375793
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0.375042
New value of Value function: 0.375042
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.173971
New value of Value function: 0.375042
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0.374291
New value of Value function: 0.374291
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0.373543
New value of Value function: 0.373543
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.177215
New value of Value function: 0.373543
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.180394
New value of Value function: 0.373543
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0.372796
New value of Value function: 0.372796
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0.37205
New value of Value function: 0.37205
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0.371306
New value of Value function: 0.371306
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.199591
New value of Value function: 0.371306
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.148783
New value of Value function: 0.371306
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0.370564
New value of Value function: 0.370564
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.202269
New value of Value function: 0.370564
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.152478
New value of Value function: 0.370564
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.156098
New value of Value function: 0.370564
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.159647
New value of Value function: 0.370564
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0.369822
New value of Value function: 0.369822
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.16311
New value of Value function: 0.369822
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0.369083
New value of Value function: 0.369083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.204867
New value of Value function: 0.369083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0.368345
New value of Value function: 0.368345
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.1961
New value of Value function: 0.368345
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.183417
New value of Value function: 0.368345
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0.367608
New value of Value function: 0.367608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0.366873
New value of Value function: 0.366873
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 194
New value of Q matrix: 0.401278
New value of Value function: 0.401278
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 852
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0328305
New value of Value function: 0.0968298
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 853
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0343776
New value of Value function: 0.0968298
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 854
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.105885
New value of Value function: 0.122429
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 855
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.180001
New value of Value function: 0.180001
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 856
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.046e-05
New value of Value function: 0.00113667
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 857
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.046e-05
New value of Value function: 0.00113667
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 858
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00435395
New value of Value function: 0.00435395
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 859
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.179641
New value of Value function: 0.179641
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 860
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.0984904
New value of Value function: 0.179641
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 861
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00750041
New value of Value function: 0.00750041
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 862
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0976432
New value of Value function: 0.179641
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 863
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0956904
New value of Value function: 0.179641
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 864
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.038416
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 865
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 866
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 867
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 868
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0374144
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 869
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118819
New value of Value function: 0.118819
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 870
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213875
New value of Value function: 0.00213875
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 871
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0600385
New value of Value function: 0.118819
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 872
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213875
New value of Value function: 0.00213875
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 873
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.176482
New value of Value function: 0.176482
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 874
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00119341
New value of Value function: 0.00213875
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 875
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00748541
New value of Value function: 0.00748541
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 876
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.85483e-05
New value of Value function: 0.00748541
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 877
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213447
New value of Value function: 0.00213875
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 878
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00317667
New value of Value function: 0.00317667
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 879
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.233009
New value of Value function: 0.233009
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 880
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00317031
New value of Value function: 0.00317031
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 881
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00730107
New value of Value function: 0.00730107
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 882
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0324719
New value of Value function: 0.233009
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 883
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.232543
New value of Value function: 0.232543
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 884
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.288024
New value of Value function: 0.288024
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 885
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0123395
New value of Value function: 0.0123395
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 886
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0226373
New value of Value function: 0.288024
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 887
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0105692
New value of Value function: 0.0105692
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 888
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.179282
New value of Value function: 0.179282
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 889
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.235886
New value of Value function: 0.235886
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 890
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000210297
New value of Value function: 0.0105692
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 891
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000190246
New value of Value function: 0.0105692
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 892
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00192938
New value of Value function: 0.0105692
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 893
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0966361
New value of Value function: 0.0966361
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 894
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0964429
New value of Value function: 0.0964429
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 895
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.09625
New value of Value function: 0.09625
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 896
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0960575
New value of Value function: 0.0960575
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 897
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.037936
New value of Value function: 0.0960575
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 898
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.235415
New value of Value function: 0.235415
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 899
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.290896
New value of Value function: 0.290896
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 900
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.015594
New value of Value function: 0.015594
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 901
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.290315
New value of Value function: 0.290315
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 902
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.15825
New value of Value function: 0.290315
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 903
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0958654
New value of Value function: 0.0958654
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 904
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.151979
New value of Value function: 0.0958654
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 905
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0956736
New value of Value function: 0.0956736
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 906
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0954823
New value of Value function: 0.0954823
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 907
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.042403
New value of Value function: 0.0954823
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 908
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.289734
New value of Value function: 0.289734
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 909
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0985525
New value of Value function: 0.289734
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 910
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.34422
New value of Value function: 0.34422
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 911
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0214781
New value of Value function: 0.0214781
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 912
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.397722
New value of Value function: 0.397722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 913
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0282075
New value of Value function: 0.0282075
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 914
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.450276
New value of Value function: 0.450276
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 915
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00171868
New value of Value function: 0.0282075
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 916
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.147221
New value of Value function: 0.0954823
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 917
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: -0.177053
New value of Value function: 0.0954823
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 195
New value of Q matrix: 0.434971
New value of Value function: 0.434971
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 919
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0952913
New value of Value function: 0.0952913
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 920
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0321174
New value of Value function: 0.0952913
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 921
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0331903
New value of Value function: 0.0952913
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 922
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: -0.205683
New value of Value function: 0.0952913
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 196
New value of Q matrix: 0.467987
New value of Value function: 0.467987
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 924
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0342418
New value of Value function: 0.0952913
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 925
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0951007
New value of Value function: 0.0951007
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 926
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.108118
New value of Value function: 0.108118
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 927
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.827209
New value of Value function: 0.827209
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 928
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.247761
New value of Value function: 0.827209
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 929
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.140676
New value of Value function: 0.827209
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 930
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.217031
New value of Value function: 0.450276
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 931
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0496599
New value of Value function: 0.108118
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 932
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.274636
New value of Value function: 0.450276
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 933
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.120846
New value of Value function: 0.120846
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 934
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 0.872841
New value of Value function: 0.872841
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 935
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0567716
New value of Value function: 0.120846
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 936
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.501778
New value of Value function: 0.501778
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 937
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0366754
New value of Value function: 0.0366754
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 938
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0875495
New value of Value function: 0.501778
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 939
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.500774
New value of Value function: 0.500774
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 940
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.284855
New value of Value function: 0.500774
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 941
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.258517
New value of Value function: 0.872841
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 942
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: -0.0825267
New value of Value function: 0.872841
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 943
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 197
New value of Q matrix: 0.500803
New value of Value function: 0.500803
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 944
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00911984
New value of Value function: 0.120846
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 945
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: -0.232555
New value of Value function: 0.120846
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.209784
New value of Value function: 0.500803
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0.499801
New value of Value function: 0.499801
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 199
New value of Q matrix: 0.53198
New value of Value function: 0.53198
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 949
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0357322
New value of Value function: 0.120846
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 950
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.120604
New value of Value function: 0.120604
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 951
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: -0.258328
New value of Value function: 0.120604
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.215164
New value of Value function: 0.53198
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.189324
New value of Value function: 0.53198
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0.530916
New value of Value function: 0.530916
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 201
New value of Q matrix: 0.562469
New value of Value function: 0.562469
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 956
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: -0.283037
New value of Value function: 0.120604
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 202
New value of Q matrix: 0.59339
New value of Value function: 0.59339
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 958
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0646501
New value of Value function: 0.120604
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 959
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0628241
New value of Value function: 0.500774
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 960
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0106982
New value of Value function: 0.0366754
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 961
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.499773
New value of Value function: 0.499773
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 962
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.341328
New value of Value function: 0.499773
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 963
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0111083
New value of Value function: 0.120604
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 964
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.120363
New value of Value function: 0.120363
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 965
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.120122
New value of Value function: 0.120122
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 966
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0130483
New value of Value function: 0.120122
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 967
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.119882
New value of Value function: 0.119882
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 968
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.119642
New value of Value function: 0.119642
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 969
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0371711
New value of Value function: 0.119642
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 970
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.072353
New value of Value function: 0.119642
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 971
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0705636
New value of Value function: 0.499773
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 972
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.550437
New value of Value function: 0.550437
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 973
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00404435
New value of Value function: 0.0366754
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 974
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.119403
New value of Value function: 0.119403
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 975
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0385769
New value of Value function: 0.119403
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 976
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.132726
New value of Value function: 0.132726
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 977
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.127955
New value of Value function: 0.872841
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 978
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.549337
New value of Value function: 0.549337
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 979
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.548238
New value of Value function: 0.548238
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 980
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.597933
New value of Value function: 0.597933
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 981
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0467046
New value of Value function: 0.0467046
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 982
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 0.646815
New value of Value function: 0.646815
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 983
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.011325
New value of Value function: 0.0467046
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 984
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0574132
New value of Value function: 0.0574132
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 985
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 0.694912
New value of Value function: 0.694912
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 986
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00635253
New value of Value function: 0.0574132
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 987
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0151764
New value of Value function: 0.132726
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 988
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.13246
New value of Value function: 0.13246
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 989
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.132196
New value of Value function: 0.132196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 990
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0834144
New value of Value function: 0.132196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 991
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 0.742048
New value of Value function: 0.742048
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 992
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0572984
New value of Value function: 0.0572984
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 993
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0135629
New value of Value function: 0.0572984
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 994
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 0.788238
New value of Value function: 0.788238
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 995
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0703407
New value of Value function: 0.0703407
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 996
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 0.833739
New value of Value function: 0.833739
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 997
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0839412
New value of Value function: 0.0839412
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 998
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 0.878576
New value of Value function: 0.878576
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 999
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0837733
New value of Value function: 0.0837733
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1000
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0126064
New value of Value function: 0.0837733
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1001
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.008605
New value of Value function: 0.0837733
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1002
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0401849
New value of Value function: 0.132196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1003
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.083254
New value of Value function: 0.132196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1004
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0836058
New value of Value function: 0.0836058
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1005
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.097748
New value of Value function: 0.097748
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1006
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.876818
New value of Value function: 0.876818
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1007
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0779938
New value of Value function: 0.876818
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1008
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0700158
New value of Value function: 0.876818
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1009
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.875065
New value of Value function: 0.875065
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1010
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 0.919323
New value of Value function: 0.919323
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1011
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.112341
New value of Value function: 0.112341
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1012
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.917484
New value of Value function: 0.917484
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1013
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.085667
New value of Value function: 0.917484
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1014
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 0.961157
New value of Value function: 0.961157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1015
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.112116
New value of Value function: 0.112116
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1016
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.127175
New value of Value function: 0.127175
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1017
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 1.00422
New value of Value function: 1.00422
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1018
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.142707
New value of Value function: 0.142707
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1019
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0505394
New value of Value function: 1.00422
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1020
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 1.00221
New value of Value function: 1.00221
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1021
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.101994
New value of Value function: 1.00221
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1022
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0314888
New value of Value function: 1.00221
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1023
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 1.00021
New value of Value function: 1.00021
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1024
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.998209
New value of Value function: 0.998209
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1025
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 1.04081
New value of Value function: 1.04081
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1026
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.158588
New value of Value function: 0.158588
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1027
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0121244
New value of Value function: 1.04081
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1028
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0712495
New value of Value function: 1.04081
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1029
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.287448
New value of Value function: 0.287448
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1030
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.341921
New value of Value function: 0.341921
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1031
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0182473
New value of Value function: 0.0182473
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1032
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.341237
New value of Value function: 0.341237
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1033
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.397267
New value of Value function: 0.397267
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1034
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.162567
New value of Value function: 0.162567
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1035
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0851108
New value of Value function: 0.397267
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1036
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.162242
New value of Value function: 0.162242
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1037
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.177731
New value of Value function: 0.177731
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1038
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 1.0832
New value of Value function: 1.0832
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1039
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.193674
New value of Value function: 0.193674
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1040
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.119451
New value of Value function: 1.0832
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1041
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 1.08103
New value of Value function: 1.08103
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1042
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 1.07887
New value of Value function: 1.07887
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1043
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 1.12078
New value of Value function: 1.12078
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1044
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.193287
New value of Value function: 0.193287
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1045
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.209595
New value of Value function: 0.209595
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1046
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 1.16213
New value of Value function: 1.16213
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1047
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.226322
New value of Value function: 0.226322
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1048
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 50
New value of Q matrix: 1.20297
New value of Value function: 1.20297
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1049
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.243449
New value of Value function: 0.243449
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1050
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0097715
New value of Value function: 1.20297
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1051
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 1.20056
New value of Value function: 1.20056
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1052
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0482145
New value of Value function: 1.20056
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1053
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0400994
New value of Value function: 1.20056
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1054
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0659885
New value of Value function: 0.397267
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1055
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.396472
New value of Value function: 0.396472
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1056
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.105019
New value of Value function: 0.396472
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1057
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 1.24093
New value of Value function: 1.24093
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1058
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0176738
New value of Value function: 0.243449
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1059
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.260916
New value of Value function: 0.260916
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1060
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 1.28081
New value of Value function: 1.28081
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1061
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.278753
New value of Value function: 0.278753
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1062
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.399519
New value of Value function: 1.28081
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1063
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.296232
New value of Value function: 0.296232
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1064
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.140117
New value of Value function: 1.28081
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1065
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 1.32052
New value of Value function: 1.32052
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1066
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.314077
New value of Value function: 0.314077
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1067
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0333455
New value of Value function: 1.32052
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1068
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.056448
New value of Value function: 1.32052
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1069
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.0321609
New value of Value function: 1.32052
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1070
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.412312
New value of Value function: 0.412312
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1071
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.415298
New value of Value function: 1.32052
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1072
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 1.31788
New value of Value function: 1.31788
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1073
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.31525
New value of Value function: 1.31525
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1074
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 1.3546
New value of Value function: 1.3546
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1075
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0229737
New value of Value function: 0.314077
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1076
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.313449
New value of Value function: 0.313449
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1077
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.312822
New value of Value function: 0.312822
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1078
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0179851
New value of Value function: 0.312822
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1079
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.312196
New value of Value function: 0.312196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1080
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0232449
New value of Value function: 0.312196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1081
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0244401
New value of Value function: 0.312196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1082
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.472612
New value of Value function: 1.3546
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1083
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.330335
New value of Value function: 0.330335
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1084
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.525539
New value of Value function: 1.3546
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1085
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0417607
New value of Value function: 0.132196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1086
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.274997
New value of Value function: 0.132196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1087
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.131931
New value of Value function: 0.131931
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1088
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0433003
New value of Value function: 0.131931
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1089
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.131667
New value of Value function: 0.131667
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1090
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.131404
New value of Value function: 0.131404
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1091
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0447995
New value of Value function: 0.131404
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1092
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: -0.298816
New value of Value function: 0.131404
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1093
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 203
New value of Q matrix: 0.623888
New value of Value function: 0.623888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1094
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.105972
New value of Value function: 0.131404
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1095
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.161697
New value of Value function: 1.3546
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1096
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 1.35189
New value of Value function: 1.35189
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1097
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.079653
New value of Value function: 1.35189
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1098
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 1.34918
New value of Value function: 1.34918
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1099
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.102345
New value of Value function: 1.34918
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1100
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.182748
New value of Value function: 1.34918
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1101
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 1.38815
New value of Value function: 1.38815
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1102
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0477666
New value of Value function: 0.330335
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1103
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.125285
New value of Value function: 1.38815
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1104
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 1.38537
New value of Value function: 1.38537
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1105
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 1.3826
New value of Value function: 1.3826
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1106
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 1.41731
New value of Value function: 1.41731
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1107
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.109798
New value of Value function: 0.131404
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1108
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.34924
New value of Value function: 0.34924
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1109
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 1.45525
New value of Value function: 1.45525
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1110
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.36845
New value of Value function: 0.36845
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1111
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.0351144
New value of Value function: 1.45525
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1112
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.387275
New value of Value function: 0.387275
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1113
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 1.45234
New value of Value function: 1.45234
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1114
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.541171
New value of Value function: 1.45234
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1115
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 1.44944
New value of Value function: 1.44944
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1116
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 1.48742
New value of Value function: 1.48742
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1117
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.386501
New value of Value function: 0.386501
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1118
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.405544
New value of Value function: 0.405544
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1119
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 1.52497
New value of Value function: 1.52497
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1120
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0541111
New value of Value function: 0.405544
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1121
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0107982
New value of Value function: 0.405544
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1122
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.131141
New value of Value function: 0.131141
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1123
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.144229
New value of Value function: 0.144229
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1124
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.269057
New value of Value function: 0.872841
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1125
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 0.91798
New value of Value function: 0.91798
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1126
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.114902
New value of Value function: 0.144229
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1127
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.424883
New value of Value function: 0.424883
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1128
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.592943
New value of Value function: 1.52497
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1129
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.148993
New value of Value function: 0.148993
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1130
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0514008
New value of Value function: 0.424883
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1131
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.206543
New value of Value function: 1.52497
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1132
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0418338
New value of Value function: 1.52497
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1133
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0302261
New value of Value function: 0.412312
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1134
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0285412
New value of Value function: 0.412312
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1135
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00108035
New value of Value function: 0.0600194
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1136
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0598994
New value of Value function: 0.0598994
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1137
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.036561
New value of Value function: 0.0598994
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1138
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0284082
New value of Value function: 0.0598994
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1139
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.411488
New value of Value function: 0.411488
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1140
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0244157
New value of Value function: 0.411488
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1141
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.410665
New value of Value function: 0.410665
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1142
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0720607
New value of Value function: 0.410665
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1143
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0780115
New value of Value function: 0.410665
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1144
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0205784
New value of Value function: 0.410665
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1145
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.409843
New value of Value function: 0.409843
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1146
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.0398332
New value of Value function: 0.409843
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1147
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.50869e-05
New value of Value function: 2.50869e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1148
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.95028e-05
New value of Value function: 0.00139372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1149
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96721e-05
New value of Value function: 4.96721e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1150
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.83423e-05
New value of Value function: 0.00139372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1151
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.41996e-05
New value of Value function: 0.00139372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1152
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00244403
New value of Value function: 0.00244403
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1153
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107819
New value of Value function: 0.0598994
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1154
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.118745
New value of Value function: 0.118745
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1155
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00239605
New value of Value function: 0.00239605
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1156
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.94097e-07
New value of Value function: 4.96721e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1157
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 9.18075e-05
New value of Value function: 9.18075e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1158
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0718816
New value of Value function: 0.00239605
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1159
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0427593
New value of Value function: 0.0427593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1160
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.218e-05
New value of Value function: 0.00239605
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1161
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.64444e-05
New value of Value function: 0.00239605
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1162
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00234978
New value of Value function: 0.00234978
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1163
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213742
New value of Value function: 0.00213742
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1164
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.118508
New value of Value function: 0.118508
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1165
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0610951
New value of Value function: 0.118508
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1166
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00422781
New value of Value function: 0.00422781
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1167
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0337518
New value of Value function: 0.118508
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1168
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.118271
New value of Value function: 0.118271
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1169
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0620021
New value of Value function: 0.118271
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1170
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.175948
New value of Value function: 0.175948
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1171
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000103232
New value of Value function: 0.00234978
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1172
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00237888
New value of Value function: 0.00237888
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1173
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.28199e-05
New value of Value function: 0.00422781
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1174
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00240741
New value of Value function: 0.00240741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1175
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00421936
New value of Value function: 0.00421936
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1176
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00737806
New value of Value function: 0.00737806
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1177
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.461779
New value of Value function: 0.461779
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1178
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00755894
New value of Value function: 0.00755894
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1179
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00242443
New value of Value function: 0.0182473
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1180
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.002512
New value of Value function: 0.0182473
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1181
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000178024
New value of Value function: 0.00755894
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1182
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0157198
New value of Value function: 0.0157198
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1183
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.0993195
New value of Value function: 0.461779
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1184
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00045742
New value of Value function: 0.0157198
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1185
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00441792
New value of Value function: 0.0157198
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1186
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0237174
New value of Value function: 0.0237174
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1187
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.512971
New value of Value function: 0.512971
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1188
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0235715
New value of Value function: 0.0235715
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1189
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0182108
New value of Value function: 0.0182108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1190
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0116952
New value of Value function: 0.0182108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1191
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0364004
New value of Value function: 0.512971
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1192
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000424287
New value of Value function: 0.0182108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1193
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00465736
New value of Value function: 0.0235715
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1194
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.02708
New value of Value function: 0.02708
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1195
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.511945
New value of Value function: 0.511945
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1196
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.562193
New value of Value function: 0.562193
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1197
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0366579
New value of Value function: 0.0366579
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1198
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.611609
New value of Value function: 0.611609
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1199
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000840089
New value of Value function: 0.0366579
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1200
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0235244
New value of Value function: 0.0235244
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1201
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.026221
New value of Value function: 0.026221
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1202
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.232901
New value of Value function: 0.232901
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1203
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0298887
New value of Value function: 0.0298887
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1204
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0236478
New value of Value function: 0.232901
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1205
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.232435
New value of Value function: 0.232435
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1206
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.28783
New value of Value function: 0.28783
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1207
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00754019
New value of Value function: 0.00754019
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1208
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0274613
New value of Value function: 0.28783
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1209
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0344719
New value of Value function: 0.0344719
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1210
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.282408
New value of Value function: 0.282408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1211
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.0783919
New value of Value function: 0.0783919
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1212
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0124727
New value of Value function: 0.0124727
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1213
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.336985
New value of Value function: 0.336985
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1214
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000325677
New value of Value function: 0.0124727
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1215
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.018289
New value of Value function: 0.018289
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1216
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.390574
New value of Value function: 0.390574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1217
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000413918
New value of Value function: 0.018289
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1218
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000396178
New value of Value function: 0.018289
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1219
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0249536
New value of Value function: 0.0249536
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1220
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.443212
New value of Value function: 0.443212
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1221
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0324323
New value of Value function: 0.0324323
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1222
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.015197
New value of Value function: 0.443212
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1223
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.442325
New value of Value function: 0.442325
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1224
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0090206
New value of Value function: 0.442325
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1225
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.43489
New value of Value function: 0.43489
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1226
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.137408
New value of Value function: 0.137408
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1227
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0324042
New value of Value function: 0.0324042
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1228
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0416105
New value of Value function: 0.0416105
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1229
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.00706507
New value of Value function: 0.43489
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1230
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0685901
New value of Value function: 0.43489
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1231
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.486941
New value of Value function: 0.486941
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1232
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0133292
New value of Value function: 0.0416105
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1233
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.485967
New value of Value function: 0.485967
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1234
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0356594
New value of Value function: 0.485967
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1235
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.478721
New value of Value function: 0.478721
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1236
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.195243
New value of Value function: 0.195243
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1237
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000902438
New value of Value function: 0.0324042
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1238
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00146766
New value of Value function: 0.0324042
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1239
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0325051
New value of Value function: 0.0325051
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1240
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0415273
New value of Value function: 0.0415273
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1241
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0414442
New value of Value function: 0.0414442
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1242
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0492323
New value of Value function: 0.0492323
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1243
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.472661
New value of Value function: 0.472661
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1244
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.251923
New value of Value function: 0.251923
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1245
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0327411
New value of Value function: 0.0327411
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1246
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000679312
New value of Value function: 0.0492323
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1247
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0329725
New value of Value function: 0.0329725
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1248
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000886182
New value of Value function: 0.0492323
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1249
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0567556
New value of Value function: 0.0567556
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1250
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0173481
New value of Value function: 0.472661
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1251
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0434542
New value of Value function: 0.472661
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1252
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.523802
New value of Value function: 0.523802
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1253
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0417415
New value of Value function: 0.0417415
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1254
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.51786
New value of Value function: 0.51786
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1255
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.251419
New value of Value function: 0.251419
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1256
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.307142
New value of Value function: 0.307142
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1257
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0502281
New value of Value function: 0.0502281
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1258
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00239771
New value of Value function: 0.51786
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1259
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.516824
New value of Value function: 0.516824
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1260
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.567392
New value of Value function: 0.567392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1261
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0594366
New value of Value function: 0.0594366
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1262
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0272142
New value of Value function: 0.567392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1263
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0527981
New value of Value function: 0.567392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1264
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.617114
New value of Value function: 0.617114
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1265
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0592695
New value of Value function: 0.0592695
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1266
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0667285
New value of Value function: 0.0667285
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1267
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.6103
New value of Value function: 0.6103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1268
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00761582
New value of Value function: 0.307142
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1269
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.306528
New value of Value function: 0.306528
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1270
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.130466
New value of Value function: 0.306528
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1271
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0627276
New value of Value function: 0.6103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1272
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0133352
New value of Value function: 0.6103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1273
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.60908
New value of Value function: 0.60908
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1274
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0376333
New value of Value function: 0.60908
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1275
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0478441
New value of Value function: 0.60908
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1276
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0724365
New value of Value function: 0.60908
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1277
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0819512
New value of Value function: 0.60908
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1278
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.602416
New value of Value function: 0.602416
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1279
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.305915
New value of Value function: 0.305915
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1280
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.305303
New value of Value function: 0.305303
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1281
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.117013
New value of Value function: 0.305303
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1282
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.595863
New value of Value function: 0.595863
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1283
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.0171824
New value of Value function: 0.305303
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1284
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.099214
New value of Value function: 0.0592695
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.203408
New value of Value function: 0.623888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.196767
New value of Value function: 0.623888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.171078
New value of Value function: 0.623888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0.62264
New value of Value function: 0.62264
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.20404
New value of Value function: 0.62264
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0.621395
New value of Value function: 0.621395
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0.620152
New value of Value function: 0.620152
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0.618912
New value of Value function: 0.618912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0.617674
New value of Value function: 0.617674
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.210458
New value of Value function: 0.617674
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0.616438
New value of Value function: 0.616438
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0.615206
New value of Value function: 0.615206
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.17873
New value of Value function: 0.615206
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.217323
New value of Value function: 0.615206
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0.613975
New value of Value function: 0.613975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0.612747
New value of Value function: 0.612747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0.611522
New value of Value function: 0.611522
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.186163
New value of Value function: 0.611522
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.221868
New value of Value function: 0.611522
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.193447
New value of Value function: 0.611522
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0.610299
New value of Value function: 0.610299
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0.609078
New value of Value function: 0.609078
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0.60786
New value of Value function: 0.60786
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0.606644
New value of Value function: 0.606644
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.210878
New value of Value function: 0.606644
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0.605431
New value of Value function: 0.605431
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0.60422
New value of Value function: 0.60422
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0.603012
New value of Value function: 0.603012
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0.601806
New value of Value function: 0.601806
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.217493
New value of Value function: 0.601806
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0.600602
New value of Value function: 0.600602
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.228242
New value of Value function: 0.600602
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0.599401
New value of Value function: 0.599401
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.223766
New value of Value function: 0.599401
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0.598202
New value of Value function: 0.598202
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.200346
New value of Value function: 0.598202
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.230058
New value of Value function: 0.598202
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 0.597006
New value of Value function: 0.597006
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.236203
New value of Value function: 0.597006
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0.595812
New value of Value function: 0.595812
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0.59462
New value of Value function: 0.59462
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.23438
New value of Value function: 0.59462
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 0.593431
New value of Value function: 0.593431
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0.592244
New value of Value function: 0.592244
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.206999
New value of Value function: 0.592244
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.21352
New value of Value function: 0.592244
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0.591059
New value of Value function: 0.591059
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 0.589877
New value of Value function: 0.589877
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 0.588697
New value of Value function: 0.588697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0.58752
New value of Value function: 0.58752
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0.586345
New value of Value function: 0.586345
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.585172
New value of Value function: 0.585172
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0.584002
New value of Value function: 0.584002
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.219761
New value of Value function: 0.584002
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.223656
New value of Value function: 0.584002
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.241991
New value of Value function: 0.584002
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.582834
New value of Value function: 0.582834
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.240183
New value of Value function: 0.582834
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0.581668
New value of Value function: 0.581668
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0.580505
New value of Value function: 0.580505
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 0.579344
New value of Value function: 0.579344
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.225794
New value of Value function: 0.579344
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 0.578185
New value of Value function: 0.578185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0.577029
New value of Value function: 0.577029
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.575875
New value of Value function: 0.575875
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 0.574723
New value of Value function: 0.574723
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 0.573574
New value of Value function: 0.573574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.231603
New value of Value function: 0.573574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0.572426
New value of Value function: 0.572426
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0.571282
New value of Value function: 0.571282
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 0.570139
New value of Value function: 0.570139
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 0.568999
New value of Value function: 0.568999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.245622
New value of Value function: 0.568999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 0.567861
New value of Value function: 0.567861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.229404
New value of Value function: 0.567861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 251
New value of Q matrix: 0.599185
New value of Value function: 0.599185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1361
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.162537
New value of Value function: 0.162537
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1362
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.126631
New value of Value function: 0.91798
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1363
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.175809
New value of Value function: 0.175809
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1364
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: -0.110091
New value of Value function: 0.91798
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 252
New value of Q matrix: 0.643725
New value of Value function: 0.643725
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1366
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 0.962785
New value of Value function: 0.962785
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1367
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.189623
New value of Value function: 0.189623
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1368
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 1.00694
New value of Value function: 1.00694
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1369
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.203956
New value of Value function: 0.203956
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1370
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 1.00493
New value of Value function: 1.00493
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1371
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 1.0485
New value of Value function: 1.0485
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1372
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.21875
New value of Value function: 0.21875
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1373
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 1.09147
New value of Value function: 1.09147
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1374
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.234021
New value of Value function: 0.234021
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1375
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 1.13385
New value of Value function: 1.13385
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1376
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.24975
New value of Value function: 0.24975
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1377
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.144508
New value of Value function: 1.13385
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1378
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 1.13158
New value of Value function: 1.13158
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1379
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.161986
New value of Value function: 1.13158
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1380
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 1.17345
New value of Value function: 1.17345
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1381
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.265877
New value of Value function: 0.265877
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1382
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.284798
New value of Value function: 1.17345
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1383
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.300224
New value of Value function: 1.17345
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1384
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 1.1711
New value of Value function: 1.1711
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1385
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 1.21246
New value of Value function: 1.21246
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1386
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.282384
New value of Value function: 0.282384
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1387
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 1.2533
New value of Value function: 1.2533
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1388
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.299296
New value of Value function: 0.299296
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1389
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 1.25079
New value of Value function: 1.25079
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1390
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: -0.136302
New value of Value function: 1.25079
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 253
New value of Q matrix: 0.693365
New value of Value function: 0.693365
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1392
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 1.29116
New value of Value function: 1.29116
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1393
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0202602
New value of Value function: 0.299296
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1394
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0252424
New value of Value function: 0.299296
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1395
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.298697
New value of Value function: 0.298697
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1396
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.2981
New value of Value function: 0.2981
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1397
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.297503
New value of Value function: 0.297503
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1398
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0300926
New value of Value function: 0.297503
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1399
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.314794
New value of Value function: 0.314794
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1400
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.181987
New value of Value function: 1.29116
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1401
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.201588
New value of Value function: 1.29116
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1402
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 1.28858
New value of Value function: 1.28858
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1403
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.317414
New value of Value function: 1.28858
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1404
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.220751
New value of Value function: 1.28858
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1405
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.334261
New value of Value function: 1.28858
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1406
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 1.286
New value of Value function: 1.286
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1407
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.350723
New value of Value function: 1.286
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1408
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.28343
New value of Value function: 1.28343
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1409
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.366811
New value of Value function: 1.28343
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1410
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 1.28086
New value of Value function: 1.28086
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1411
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.282002
New value of Value function: 1.28086
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1412
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.331554
New value of Value function: 0.331554
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1413
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 1.2783
New value of Value function: 1.2783
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1414
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -0.0979462
New value of Value function: 1.2783
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1415
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.229862
New value of Value function: 1.52497
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1416
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 1.51748
New value of Value function: 1.51748
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1417
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 1.3187
New value of Value function: 1.3187
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1418
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.34866
New value of Value function: 0.34866
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1419
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.109839
New value of Value function: 1.3187
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1420
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 1.35861
New value of Value function: 1.35861
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1421
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.347962
New value of Value function: 0.347962
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1422
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.365458
New value of Value function: 0.365458
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1423
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 1.35589
New value of Value function: 1.35589
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1424
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 1.39535
New value of Value function: 1.39535
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1425
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: -0.320359
New value of Value function: 0.365458
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 254
New value of Q matrix: 0.726076
New value of Value function: 0.726076
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1427
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.364727
New value of Value function: 0.364727
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1428
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: -0.340882
New value of Value function: 0.364727
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.253779
New value of Value function: 0.726076
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 0.724624
New value of Value function: 0.724624
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 256
New value of Q matrix: 0.756697
New value of Value function: 0.756697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1432
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.363998
New value of Value function: 0.363998
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1433
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.381834
New value of Value function: 0.381834
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1434
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 1.39256
New value of Value function: 1.39256
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1435
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 56
New value of Q matrix: 1.43158
New value of Value function: 1.43158
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1436
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0507765
New value of Value function: 0.381834
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1437
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.399966
New value of Value function: 0.399966
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1438
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 1.47015
New value of Value function: 1.47015
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1439
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.399166
New value of Value function: 0.399166
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1440
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: -0.360444
New value of Value function: 0.399166
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.262324
New value of Value function: 0.756697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 0.755183
New value of Value function: 0.755183
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 258
New value of Q matrix: 0.806542
New value of Value function: 0.806542
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1444
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 1.46721
New value of Value function: 1.46721
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1445
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: -0.0686727
New value of Value function: 1.46721
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1446
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 1.51445
New value of Value function: 1.51445
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1447
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 1.51057
New value of Value function: 1.51057
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1448
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 1.50505
New value of Value function: 1.50505
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1449
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.139794
New value of Value function: 0.399166
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1450
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.64827
New value of Value function: 1.51057
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1451
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.398367
New value of Value function: 0.398367
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1452
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.41759
New value of Value function: 0.41759
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1453
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 1.54787
New value of Value function: 1.54787
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1454
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.4371
New value of Value function: 0.4371
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1455
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 73
New value of Q matrix: 1.58478
New value of Value function: 1.58478
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1456
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.456884
New value of Value function: 0.456884
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1457
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 1.58018
New value of Value function: 1.58018
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1458
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 1.54317
New value of Value function: 1.54317
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1459
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.45597
New value of Value function: 0.45597
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1460
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0775381
New value of Value function: 0.45597
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1461
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 1.58052
New value of Value function: 1.58052
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1462
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.165442
New value of Value function: 0.45597
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1463
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.151222
New value of Value function: 1.58018
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1464
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0694403
New value of Value function: 1.58018
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1465
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0790604
New value of Value function: 1.58018
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1466
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.610386
New value of Value function: 0.610386
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1467
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.609165
New value of Value function: 0.609165
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1468
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.607947
New value of Value function: 0.607947
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1469
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.656448
New value of Value function: 0.656448
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1470
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0477408
New value of Value function: 0.0477408
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1471
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0882673
New value of Value function: 0.656448
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1472
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.170566
New value of Value function: 0.656448
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1473
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0512321
New value of Value function: 0.424883
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1474
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0232774
New value of Value function: 0.0477408
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1475
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.704178
New value of Value function: 0.704178
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1476
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0594612
New value of Value function: 0.0594612
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1477
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.751165
New value of Value function: 0.751165
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1478
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0156128
New value of Value function: 0.0594612
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1479
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.797212
New value of Value function: 0.797212
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1480
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0593423
New value of Value function: 0.0593423
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1481
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.02388
New value of Value function: 0.0593423
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1482
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0592236
New value of Value function: 0.0592236
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1483
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0723889
New value of Value function: 0.0723889
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1484
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.842571
New value of Value function: 0.842571
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1485
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0247054
New value of Value function: 0.0723889
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1486
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0166035
New value of Value function: 0.0723889
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1487
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00212629
New value of Value function: 0.0723889
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1488
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0722441
New value of Value function: 0.0722441
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1489
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0720997
New value of Value function: 0.0720997
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1490
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0858239
New value of Value function: 0.0858239
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1491
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.101668
New value of Value function: 0.842571
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1492
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 0.887264
New value of Value function: 0.887264
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1493
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.100078
New value of Value function: 0.100078
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1494
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.158534
New value of Value function: 0.887264
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1495
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0761195
New value of Value function: 0.0761195
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1496
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.594671
New value of Value function: 0.594671
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1497
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 0.643844
New value of Value function: 0.643844
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1498
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00250516
New value of Value function: 0.0592695
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1499
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0696733
New value of Value function: 0.0696733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1500
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 0.692222
New value of Value function: 0.692222
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1501
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0807398
New value of Value function: 0.0807398
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1502
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 0.739831
New value of Value function: 0.739831
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1503
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00390838
New value of Value function: 0.0807398
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1504
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0804952
New value of Value function: 0.0804952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1505
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0759672
New value of Value function: 0.0759672
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1506
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0758153
New value of Value function: 0.0758153
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1507
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00211464
New value of Value function: 0.0758153
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1508
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0957808
New value of Value function: 0.0804952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1509
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0803342
New value of Value function: 0.0803342
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1510
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0800922
New value of Value function: 0.0800922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1511
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0876159
New value of Value function: 0.0876159
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1512
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 0.786476
New value of Value function: 0.786476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1513
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0924236
New value of Value function: 0.0800922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1514
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.079932
New value of Value function: 0.079932
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1515
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00526898
New value of Value function: 0.079932
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1516
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0924899
New value of Value function: 0.0924899
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1517
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 0.832411
New value of Value function: 0.832411
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1518
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.105624
New value of Value function: 0.105624
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1519
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 0.877664
New value of Value function: 0.877664
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1520
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.119309
New value of Value function: 0.119309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1521
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.128795
New value of Value function: 0.877664
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1522
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00202536
New value of Value function: 0.0876159
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1523
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0874407
New value of Value function: 0.0874407
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1524
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.10149
New value of Value function: 0.10149
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1525
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 0.922258
New value of Value function: 0.922258
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1526
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.133523
New value of Value function: 0.133523
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1527
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0969128
New value of Value function: 0.922258
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1528
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 0.966216
New value of Value function: 0.966216
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1529
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0059011
New value of Value function: 0.133523
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1530
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.3616
New value of Value function: 0.3616
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1531
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.148245
New value of Value function: 0.148245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1532
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 1.00956
New value of Value function: 1.00956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1533
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.163452
New value of Value function: 0.163452
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1534
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0650593
New value of Value function: 1.00956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1535
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 1.05231
New value of Value function: 1.05231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1536
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.179125
New value of Value function: 0.179125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1537
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.113916
New value of Value function: 1.05231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1538
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 1.09449
New value of Value function: 1.09449
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1539
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00838785
New value of Value function: 0.179125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1540
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0036125
New value of Value function: 0.179125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1541
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00676449
New value of Value function: 0.179125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1542
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0873509
New value of Value function: 0.179125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1543
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: -0.111086
New value of Value function: 0.179125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 0.804929
New value of Value function: 0.804929
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 0.803319
New value of Value function: 0.803319
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.271537
New value of Value function: 0.803319
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 0.801713
New value of Value function: 0.801713
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 0.800109
New value of Value function: 0.800109
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 0.798509
New value of Value function: 0.798509
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 0.796912
New value of Value function: 0.796912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 0.795318
New value of Value function: 0.795318
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.241287
New value of Value function: 0.795318
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.280422
New value of Value function: 0.795318
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.251467
New value of Value function: 0.795318
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 0.793727
New value of Value function: 0.793727
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 0.79214
New value of Value function: 0.79214
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 0.790556
New value of Value function: 0.790556
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.239046
New value of Value function: 0.790556
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 0.788975
New value of Value function: 0.788975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.250662
New value of Value function: 0.788975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.289015
New value of Value function: 0.788975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 0.787397
New value of Value function: 0.787397
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.260611
New value of Value function: 0.787397
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 0.785822
New value of Value function: 0.785822
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.259794
New value of Value function: 0.785822
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.269543
New value of Value function: 0.785822
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.24841
New value of Value function: 0.785822
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 0.78425
New value of Value function: 0.78425
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 0.782682
New value of Value function: 0.782682
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 0.781116
New value of Value function: 0.781116
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 0.779554
New value of Value function: 0.779554
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 0.777995
New value of Value function: 0.777995
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 0.776439
New value of Value function: 0.776439
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.257417
New value of Value function: 0.776439
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 0.774886
New value of Value function: 0.774886
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 0.773336
New value of Value function: 0.773336
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.266189
New value of Value function: 0.773336
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.297155
New value of Value function: 0.773336
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 0.77179
New value of Value function: 0.77179
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 0.770246
New value of Value function: 0.770246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 0.768706
New value of Value function: 0.768706
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 0.767168
New value of Value function: 0.767168
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 0.765634
New value of Value function: 0.765634
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.304993
New value of Value function: 0.765634
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 0.764103
New value of Value function: 0.764103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 0.762574
New value of Value function: 0.762574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.31262
New value of Value function: 0.762574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 0.761049
New value of Value function: 0.761049
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 0.759527
New value of Value function: 0.759527
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 0.758008
New value of Value function: 0.758008
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 0.756492
New value of Value function: 0.756492
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 0.754979
New value of Value function: 0.754979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 0.753469
New value of Value function: 0.753469
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.31993
New value of Value function: 0.753469
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 0.751962
New value of Value function: 0.751962
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 0.750458
New value of Value function: 0.750458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 0.748957
New value of Value function: 0.748957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.327012
New value of Value function: 0.748957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 0.747459
New value of Value function: 0.747459
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 0.745965
New value of Value function: 0.745965
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 0.744473
New value of Value function: 0.744473
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 0.742984
New value of Value function: 0.742984
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 0.741498
New value of Value function: 0.741498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.277499
New value of Value function: 0.741498
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 0.740015
New value of Value function: 0.740015
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1606
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.274186
New value of Value function: 0.740015
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 0.738535
New value of Value function: 0.738535
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 0.737058
New value of Value function: 0.737058
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.281969
New value of Value function: 0.737058
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 0.735583
New value of Value function: 0.735583
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 0.734112
New value of Value function: 0.734112
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.289544
New value of Value function: 0.734112
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.285163
New value of Value function: 0.734112
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.296967
New value of Value function: 0.734112
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.333686
New value of Value function: 0.734112
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.340226
New value of Value function: 0.734112
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 0.732644
New value of Value function: 0.732644
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 0.731179
New value of Value function: 0.731179
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1619
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 0.729716
New value of Value function: 0.729716
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 0.728257
New value of Value function: 0.728257
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 310
New value of Q matrix: 0.761899
New value of Value function: 0.761899
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1622
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.455059
New value of Value function: 0.455059
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1623
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: -0.379521
New value of Value function: 0.455059
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 311
New value of Q matrix: 0.794852
New value of Value function: 0.794852
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1625
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0376818
New value of Value function: 0.455059
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1626
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.454148
New value of Value function: 0.454148
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1627
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.45324
New value of Value function: 0.45324
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1628
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.452334
New value of Value function: 0.452334
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1629
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.471736
New value of Value function: 0.471736
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1630
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.387924
New value of Value function: 1.58052
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1631
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.408615
New value of Value function: 1.58052
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1632
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 1.57736
New value of Value function: 1.57736
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1633
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 1.6143
New value of Value function: 1.6143
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1634
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.491359
New value of Value function: 0.491359
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1635
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.30542
New value of Value function: 1.6143
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1636
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 1.65086
New value of Value function: 1.65086
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1637
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.105703
New value of Value function: 0.491359
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1638
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 1.68669
New value of Value function: 1.68669
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1639
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.490376
New value of Value function: 0.490376
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1640
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: -0.397623
New value of Value function: 0.490376
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 312
New value of Q matrix: 0.827782
New value of Value function: 0.827782
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1642
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0672885
New value of Value function: 0.490376
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1643
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 1.68331
New value of Value function: 1.68331
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1644
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: -0.132742
New value of Value function: 1.68331
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 313
New value of Q matrix: 0.860053
New value of Value function: 0.860053
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1646
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.510868
New value of Value function: 0.510868
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1647
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 1.71884
New value of Value function: 1.71884
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1648
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.193072
New value of Value function: 0.510868
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1649
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 1.7154
New value of Value function: 1.7154
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1650
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: -0.0608919
New value of Value function: 1.7154
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1651
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.220088
New value of Value function: 0.510868
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1652
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 69
New value of Q matrix: 1.75029
New value of Value function: 1.75029
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1653
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0751383
New value of Value function: 0.510868
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1654
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.532156
New value of Value function: 0.532156
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1655
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: -0.038856
New value of Value function: 1.75029
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1656
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.105922
New value of Value function: 1.58018
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1657
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 1.57702
New value of Value function: 1.57702
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1658
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 1.57386
New value of Value function: 1.57386
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1659
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 77
New value of Q matrix: 1.61003
New value of Value function: 1.61003
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1660
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.445366
New value of Value function: 0.445366
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1661
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.119775
New value of Value function: 1.61003
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1662
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 0.93132
New value of Value function: 0.93132
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1663
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.11484
New value of Value function: 0.11484
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1664
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0524361
New value of Value function: 0.93132
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1665
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.929458
New value of Value function: 0.929458
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1666
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 0.972935
New value of Value function: 0.972935
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1667
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00918612
New value of Value function: 0.11484
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1668
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.465439
New value of Value function: 0.465439
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1669
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.134892
New value of Value function: 1.61003
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1670
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0689002
New value of Value function: 0.972935
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1671
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.196135
New value of Value function: 0.972935
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1672
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 1.60681
New value of Value function: 1.60681
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1673
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.177121
New value of Value function: 1.60681
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1674
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 1.6036
New value of Value function: 1.6036
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1675
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 80
New value of Q matrix: 1.63991
New value of Value function: 1.63991
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1676
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.485649
New value of Value function: 0.485649
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1677
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.149707
New value of Value function: 1.63991
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1678
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.97099
New value of Value function: 0.97099
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1679
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 1.01364
New value of Value function: 1.01364
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1680
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.130789
New value of Value function: 0.130789
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1681
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 1.05572
New value of Value function: 1.05572
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1682
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.130527
New value of Value function: 0.130527
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1683
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.14692
New value of Value function: 0.14692
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1684
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 1.05361
New value of Value function: 1.05361
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1685
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.221731
New value of Value function: 1.05361
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1686
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 1.67585
New value of Value function: 1.67585
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1687
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.484677
New value of Value function: 0.484677
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1688
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.505149
New value of Value function: 0.505149
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1689
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 1.6725
New value of Value function: 1.6725
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1690
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 83
New value of Q matrix: 1.70814
New value of Value function: 1.70814
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1691
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.504139
New value of Value function: 0.504139
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1692
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.524802
New value of Value function: 0.524802
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1693
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 84
New value of Q matrix: 1.74342
New value of Value function: 1.74342
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1694
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.545688
New value of Value function: 0.545688
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1695
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 85
New value of Q matrix: 1.77838
New value of Value function: 1.77838
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1696
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0323366
New value of Value function: 0.545688
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1697
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.566785
New value of Value function: 0.566785
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1698
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 86
New value of Q matrix: 1.81301
New value of Value function: 1.81301
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1699
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.063231
New value of Value function: 0.566785
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1700
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.052852
New value of Value function: 0.566785
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1701
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.162946
New value of Value function: 0.162946
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1702
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 1.09547
New value of Value function: 1.09547
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1703
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0192045
New value of Value function: 0.162946
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1704
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.162621
New value of Value function: 0.162621
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1705
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.179087
New value of Value function: 0.179087
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1706
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.249931
New value of Value function: 1.09547
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1707
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.705506
New value of Value function: 1.81301
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1708
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.588084
New value of Value function: 0.588084
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1709
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 1.80939
New value of Value function: 1.80939
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1710
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 88
New value of Q matrix: 1.84378
New value of Value function: 1.84378
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1711
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.586907
New value of Value function: 0.586907
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1712
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0725307
New value of Value function: 0.586907
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1713
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.585734
New value of Value function: 0.585734
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1714
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.607207
New value of Value function: 0.607207
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1715
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.179901
New value of Value function: 1.84378
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1716
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 1.8401
New value of Value function: 1.8401
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1717
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.258386
New value of Value function: 1.8401
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1718
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 1.83642
New value of Value function: 1.83642
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1719
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.196021
New value of Value function: 1.83642
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1720
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 1.09328
New value of Value function: 1.09328
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1721
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 1.13463
New value of Value function: 1.13463
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1722
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.178728
New value of Value function: 0.178728
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1723
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0220375
New value of Value function: 0.178728
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1724
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.178371
New value of Value function: 0.178371
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1725
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.195227
New value of Value function: 0.195227
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1726
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.175787
New value of Value function: 1.13463
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1727
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 1.13237
New value of Value function: 1.13237
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1728
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 1.1301
New value of Value function: 1.1301
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1729
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.308446
New value of Value function: 1.1301
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1730
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.211664
New value of Value function: 0.211664
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1731
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 1.12784
New value of Value function: 1.12784
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1732
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 1.16909
New value of Value function: 1.16909
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1733
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0254067
New value of Value function: 0.211664
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1734
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.228475
New value of Value function: 0.228475
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1735
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 1.21664
New value of Value function: 1.21664
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1736
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0215119
New value of Value function: 0.607207
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1737
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.605993
New value of Value function: 0.605993
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1738
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.604781
New value of Value function: 0.604781
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1739
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.625741
New value of Value function: 0.625741
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1740
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.762659
New value of Value function: 1.83642
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1741
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.624489
New value of Value function: 0.624489
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1742
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.645055
New value of Value function: 0.645055
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1743
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 91
New value of Q matrix: 1.8713
New value of Value function: 1.8713
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1744
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0854783
New value of Value function: 0.645055
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1745
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 1.86756
New value of Value function: 1.86756
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1746
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 1.86382
New value of Value function: 1.86382
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1747
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 94
New value of Q matrix: 1.89816
New value of Value function: 1.89816
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1748
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.643765
New value of Value function: 0.643765
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1749
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.642477
New value of Value function: 0.642477
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1750
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0826447
New value of Value function: 0.642477
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1751
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.663794
New value of Value function: 0.663794
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1752
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.207745
New value of Value function: 1.89816
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1753
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.214001
New value of Value function: 1.89816
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1754
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.194171
New value of Value function: 1.21664
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1755
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 1.21421
New value of Value function: 1.21421
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1756
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.121491
New value of Value function: 1.21421
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1757
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 1.21178
New value of Value function: 1.21178
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1758
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 1.25166
New value of Value function: 1.25166
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1759
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.246435
New value of Value function: 0.246435
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1760
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.24915
New value of Value function: 1.24915
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1761
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 1.28861
New value of Value function: 1.28861
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1762
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.264701
New value of Value function: 0.264701
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1763
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 1.28603
New value of Value function: 1.28603
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1764
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 1.32507
New value of Value function: 1.32507
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1765
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.283258
New value of Value function: 0.283258
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1766
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 1.36367
New value of Value function: 1.36367
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1767
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.282692
New value of Value function: 0.282692
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1768
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0140909
New value of Value function: 0.282692
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1769
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.282127
New value of Value function: 0.282127
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1770
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.30103
New value of Value function: 0.30103
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1771
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 1.36094
New value of Value function: 1.36094
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1772
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.143558
New value of Value function: 1.36094
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1773
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.255706
New value of Value function: 1.36094
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1774
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.319506
New value of Value function: 0.319506
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1775
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0920192
New value of Value function: 1.36094
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1776
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 1.35822
New value of Value function: 1.35822
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1777
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.165135
New value of Value function: 1.35822
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1778
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.114627
New value of Value function: 1.35822
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1779
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 1.3555
New value of Value function: 1.3555
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1780
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.35279
New value of Value function: 1.35279
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1781
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 1.39149
New value of Value function: 1.39149
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1782
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.338163
New value of Value function: 0.338163
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1783
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 1.42975
New value of Value function: 1.42975
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1784
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0309855
New value of Value function: 0.338163
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1785
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.357135
New value of Value function: 0.357135
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1786
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 1.46758
New value of Value function: 1.46758
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1787
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.376409
New value of Value function: 0.376409
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1788
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 1.505
New value of Value function: 1.505
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1789
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.395971
New value of Value function: 0.395971
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1790
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 1.54203
New value of Value function: 1.54203
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1791
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.415808
New value of Value function: 0.415808
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1792
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 1.53895
New value of Value function: 1.53895
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1793
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 1.57565
New value of Value function: 1.57565
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1794
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.414976
New value of Value function: 0.414976
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1795
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.435039
New value of Value function: 0.435039
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1796
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 1.61197
New value of Value function: 1.61197
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1797
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.455353
New value of Value function: 0.455353
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1798
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 1.64793
New value of Value function: 1.64793
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1799
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.475909
New value of Value function: 0.475909
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1800
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 1.68353
New value of Value function: 1.68353
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1801
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.496694
New value of Value function: 0.496694
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1802
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 1.68017
New value of Value function: 1.68017
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1803
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 1.7155
New value of Value function: 1.7155
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1804
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.495701
New value of Value function: 0.495701
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1805
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.516666
New value of Value function: 0.516666
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1806
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.143213
New value of Value function: 1.7155
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1807
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.281471
New value of Value function: 1.7155
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1808
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 1.71207
New value of Value function: 1.71207
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1809
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 1.74713
New value of Value function: 1.74713
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1810
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.537781
New value of Value function: 0.537781
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1811
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.333726
New value of Value function: 1.74713
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1812
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 71
New value of Q matrix: 1.78187
New value of Value function: 1.78187
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1813
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.536706
New value of Value function: 0.536706
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1814
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.033872
New value of Value function: 0.536706
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1815
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.558045
New value of Value function: 0.558045
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1816
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 1.81628
New value of Value function: 1.81628
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1817
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.579577
New value of Value function: 0.579577
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1818
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.361218
New value of Value function: 1.81628
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1819
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 95
New value of Q matrix: 1.93214
New value of Value function: 1.93214
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1820
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.662467
New value of Value function: 0.662467
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1821
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.683996
New value of Value function: 0.683996
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1822
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.287997
New value of Value function: 1.93214
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1823
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 1.92828
New value of Value function: 1.92828
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1824
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.819718
New value of Value function: 1.92828
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1825
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0440018
New value of Value function: 0.683996
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1826
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.682628
New value of Value function: 0.682628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1827
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0554091
New value of Value function: 0.682628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1828
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.681263
New value of Value function: 0.681263
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1829
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.702346
New value of Value function: 0.702346
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1830
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 1.92442
New value of Value function: 1.92442
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1831
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.354879
New value of Value function: 1.92442
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1832
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.093634
New value of Value function: 0.702346
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1833
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.722939
New value of Value function: 0.722939
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1834
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 98
New value of Q matrix: 1.95894
New value of Value function: 1.95894
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1835
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.743741
New value of Value function: 0.743741
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1836
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 1.95503
New value of Value function: 1.95503
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1837
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.872903
New value of Value function: 1.95503
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1838
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: -0.380092
New value of Value function: 0.532156
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1839
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.225265
New value of Value function: 0.532156
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1840
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.531092
New value of Value function: 0.531092
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1841
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.551975
New value of Value function: 0.551975
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1842
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 1.78522
New value of Value function: 1.78522
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1843
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.25595
New value of Value function: 0.551975
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1844
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 100
New value of Q matrix: 1.98931
New value of Value function: 1.98931
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1845
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.742254
New value of Value function: 0.742254
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1846
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.763216
New value of Value function: 0.763216
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1847
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 1.98533
New value of Value function: 1.98533
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1848
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 102
New value of Q matrix: 2.01937
New value of Value function: 2.01937
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1849
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.784301
New value of Value function: 0.784301
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1850
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 2.01533
New value of Value function: 2.01533
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1851
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.245996
New value of Value function: 2.01533
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1852
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 2.0113
New value of Value function: 2.0113
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1853
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 105
New value of Q matrix: 2.04519
New value of Value function: 2.04519
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1854
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.805428
New value of Value function: 0.805428
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1855
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 2.0411
New value of Value function: 2.0411
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1856
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.273769
New value of Value function: 2.0411
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1857
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.346274
New value of Value function: 1.81628
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1858
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.600679
New value of Value function: 0.600679
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1859
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 1.81264
New value of Value function: 1.81264
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1860
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.211161
New value of Value function: 1.81264
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1861
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.599477
New value of Value function: 0.599477
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1862
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.620115
New value of Value function: 0.620115
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1863
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 1.80902
New value of Value function: 1.80902
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1864
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 1.8054
New value of Value function: 1.8054
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1865
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 76
New value of Q matrix: 1.84046
New value of Value function: 1.84046
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1866
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0415279
New value of Value function: 0.620115
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1867
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.640841
New value of Value function: 0.640841
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1868
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.19496
New value of Value function: 1.84046
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1869
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 1.83677
New value of Value function: 1.83677
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1870
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 78
New value of Q matrix: 1.87157
New value of Value function: 1.87157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1871
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0522324
New value of Value function: 0.640841
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1872
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0627229
New value of Value function: 0.640841
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1873
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.661713
New value of Value function: 0.661713
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1874
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.425904
New value of Value function: 1.87157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1875
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0283067
New value of Value function: 0.661713
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1876
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.826059
New value of Value function: 0.826059
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1877
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 107
New value of Q matrix: 2.07514
New value of Value function: 2.07514
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1878
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0691699
New value of Value function: 0.826059
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1879
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.105139
New value of Value function: 0.826059
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1880
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 108
New value of Q matrix: 2.10851
New value of Value function: 2.10851
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1881
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.824407
New value of Value function: 0.824407
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1882
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.822758
New value of Value function: 0.822758
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1883
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.844256
New value of Value function: 0.844256
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1884
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 2.10429
New value of Value function: 2.10429
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1885
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 110
New value of Q matrix: 2.1374
New value of Value function: 2.1374
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1886
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.842568
New value of Value function: 0.842568
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1887
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0362479
New value of Value function: 0.842568
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1888
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.840883
New value of Value function: 0.840883
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1889
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.862538
New value of Value function: 0.862538
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1890
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.242063
New value of Value function: 2.1374
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1891
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 2.13313
New value of Value function: 2.13313
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1892
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.92538
New value of Value function: 2.13313
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1893
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.550871
New value of Value function: 0.550871
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1894
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.289227
New value of Value function: 0.550871
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1895
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.30669
New value of Value function: 2.13313
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1896
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 2.12886
New value of Value function: 2.12886
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1897
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 2.12461
New value of Value function: 2.12461
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1898
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 2.12036
New value of Value function: 2.12036
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1899
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 2.11612
New value of Value function: 2.11612
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1900
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.982398
New value of Value function: 2.11612
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1901
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0454386
New value of Value function: 0.862538
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1902
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0835512
New value of Value function: 0.550871
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1903
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.54977
New value of Value function: 0.54977
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1904
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.54867
New value of Value function: 0.54867
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1905
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0917563
New value of Value function: 0.54867
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1906
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.547573
New value of Value function: 0.547573
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1907
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.546478
New value of Value function: 0.546478
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1908
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.545385
New value of Value function: 0.545385
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1909
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0997381
New value of Value function: 0.545385
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1910
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.10756
New value of Value function: 0.545385
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1911
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.544294
New value of Value function: 0.544294
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1912
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.543205
New value of Value function: 0.543205
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1913
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.564475
New value of Value function: 0.564475
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1914
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 1.78165
New value of Value function: 1.78165
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1915
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 1.81618
New value of Value function: 1.81618
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1916
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.563346
New value of Value function: 0.563346
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1917
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.562219
New value of Value function: 0.562219
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1918
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.589065
New value of Value function: 0.589065
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1919
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.275312
New value of Value function: 2.11612
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1920
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 2.11188
New value of Value function: 2.11188
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1921
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 2.10766
New value of Value function: 2.10766
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1922
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 118
New value of Q matrix: 2.13611
New value of Value function: 2.13611
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1923
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.321893
New value of Value function: 0.589065
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1924
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 119
New value of Q matrix: 2.16891
New value of Value function: 2.16891
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1925
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.884328
New value of Value function: 0.884328
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1926
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.339597
New value of Value function: 2.16891
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1927
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 2.16458
New value of Value function: 2.16458
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1928
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 121
New value of Q matrix: 2.1972
New value of Value function: 2.1972
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1929
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.118954
New value of Value function: 0.884328
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1930
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.906191
New value of Value function: 0.906191
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1931
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 122
New value of Q matrix: 2.22957
New value of Value function: 2.22957
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1932
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.9282
New value of Value function: 0.9282
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1933
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 2.22511
New value of Value function: 2.22511
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1934
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 2.22066
New value of Value function: 2.22066
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1935
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 1.03946
New value of Value function: 2.22066
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1936
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.949607
New value of Value function: 0.949607
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1937
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 125
New value of Q matrix: 2.25334
New value of Value function: 2.25334
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1938
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.055133
New value of Value function: 0.949607
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1939
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.587887
New value of Value function: 0.587887
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1940
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.114171
New value of Value function: 0.587887
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1941
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.593222
New value of Value function: 0.593222
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1942
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.102439
New value of Value function: 0.949607
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1943
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.116087
New value of Value function: 0.593222
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1944
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.598451
New value of Value function: 0.598451
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1945
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.947708
New value of Value function: 0.947708
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1946
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.100828
New value of Value function: 0.947708
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1947
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.969314
New value of Value function: 0.969314
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1948
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 2.24883
New value of Value function: 2.24883
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1949
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.366493
New value of Value function: 2.24883
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1950
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.224749
New value of Value function: 1.87157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1951
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 1.86783
New value of Value function: 1.86783
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1952
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 1.8641
New value of Value function: 1.8641
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1953
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 1.89872
New value of Value function: 1.89872
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1954
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.660389
New value of Value function: 0.660389
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1955
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.681359
New value of Value function: 0.681359
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1956
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 1.89493
New value of Value function: 1.89493
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1957
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 83
New value of Q matrix: 1.92929
New value of Value function: 1.92929
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1958
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.702459
New value of Value function: 0.702459
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1959
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 84
New value of Q matrix: 1.96335
New value of Value function: 1.96335
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1960
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.701054
New value of Value function: 0.701054
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1961
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0458135
New value of Value function: 0.701054
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1962
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.699652
New value of Value function: 0.699652
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1963
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0451883
New value of Value function: 0.699652
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1964
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.134151
New value of Value function: 0.969314
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1965
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 85
New value of Q matrix: 1.99668
New value of Value function: 1.99668
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1966
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.721599
New value of Value function: 0.721599
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1967
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 86
New value of Q matrix: 2.02973
New value of Value function: 2.02973
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1968
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.720156
New value of Value function: 0.720156
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1969
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.742288
New value of Value function: 0.742288
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1970
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.457865
New value of Value function: 2.02973
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1971
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.310285
New value of Value function: 2.24883
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1972
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 127
New value of Q matrix: 2.2813
New value of Value function: 2.2813
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1973
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.967376
New value of Value function: 0.967376
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1974
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.989091
New value of Value function: 0.989091
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1975
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 128
New value of Q matrix: 2.31348
New value of Value function: 2.31348
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1976
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 1.01095
New value of Value function: 1.01095
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1977
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 2.30885
New value of Value function: 2.30885
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1978
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.345639
New value of Value function: 2.30885
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1979
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 2.30424
New value of Value function: 2.30424
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1980
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.395699
New value of Value function: 2.30424
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1981
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 2.02567
New value of Value function: 2.02567
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1982
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 88
New value of Q matrix: 2.05852
New value of Value function: 2.05852
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1983
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.764495
New value of Value function: 0.764495
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1984
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.243991
New value of Value function: 2.05852
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1985
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 2.0544
New value of Value function: 2.0544
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1986
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 90
New value of Q matrix: 2.08708
New value of Value function: 2.08708
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1987
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.786773
New value of Value function: 0.786773
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1988
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.376916
New value of Value function: 2.08708
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1989
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 91
New value of Q matrix: 2.1195
New value of Value function: 2.1195
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1990
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.809188
New value of Value function: 0.809188
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1991
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.277263
New value of Value function: 2.1195
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1992
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 2.11526
New value of Value function: 2.11526
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1993
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.443943
New value of Value function: 2.11526
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1994
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0594626
New value of Value function: 0.809188
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1995
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0601002
New value of Value function: 0.809188
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1996
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.137535
New value of Value function: 0.137535
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1997
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 2.11103
New value of Value function: 2.11103
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1998
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 94
New value of Q matrix: 2.13128
New value of Value function: 2.13128
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1999
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.173147
New value of Value function: 0.173147
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2000
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 95
New value of Q matrix: 2.16322
New value of Value function: 2.16322
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 2001
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.80757
New value of Value function: 0.80757
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2002
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0734345
New value of Value function: 0.80757
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2003
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0760047
New value of Value function: 0.80757
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2004
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.805955
New value of Value function: 0.805955
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2005
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.828774
New value of Value function: 0.828774
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2006
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.310655
New value of Value function: 2.16322
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 2007
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 2.1589
New value of Value function: 2.1589
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 2008
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.498181
New value of Value function: 2.1589
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 2009
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0051015
New value of Value function: 0.173147
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2010
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.189385
New value of Value function: 0.189385
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2011
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 1.13601
New value of Value function: 1.13601
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2012
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.189006
New value of Value function: 0.189006
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2013
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.188628
New value of Value function: 0.188628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2014
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0335107
New value of Value function: 0.188628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2015
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 1.17668
New value of Value function: 1.17668
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2016
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.206036
New value of Value function: 0.206036
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2017
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.1474
New value of Value function: 1.17668
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2018
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 1.21637
New value of Value function: 1.21637
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2019
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.10564
New value of Value function: 0.179125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2020
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0114443
New value of Value function: 0.179125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2021
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.178766
New value of Value function: 0.178766
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2022
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.197086
New value of Value function: 0.197086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2023
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.20816
New value of Value function: 1.21637
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2024
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0547353
New value of Value function: 0.206036
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2025
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 1.25576
New value of Value function: 1.25576
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2026
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00561989
New value of Value function: 0.206036
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2027
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.196853
New value of Value function: 0.196853
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2028
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.205624
New value of Value function: 0.205624
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2029
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.224115
New value of Value function: 0.224115
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 2030
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.134241
New value of Value function: 1.25576
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2031
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 1.29418
New value of Value function: 1.29418
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2032
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.216211
New value of Value function: 0.216211
New value of Policy matrix: 0

