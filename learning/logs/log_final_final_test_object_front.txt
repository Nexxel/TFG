=======================================
Simulation: 1
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 6
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 7
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 8
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.40007
New value of Value function: 4.40007
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.50018
New value of Value function: 5.50018
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 11
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 12
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.0499
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 6.73551
New value of Value function: 6.73551
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.44246
New value of Value function: 4.44246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 15
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 7.06678
New value of Value function: 7.06678
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.21928
New value of Value function: 4.21928
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 17
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 7.11611
New value of Value function: 7.11611
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.14132
New value of Value function: 4.14132
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 19
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 7.1095
New value of Value function: 7.1095
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.09991
New value of Value function: 4.14132
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 21
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 4.0993
New value of Value function: 4.09991
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 22
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 7.09037
New value of Value function: 7.09037
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.07092
New value of Value function: 4.0993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 24
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.06364
New value of Value function: 4.0993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 25
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.06097
New value of Value function: 4.0993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 26
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.05978
New value of Value function: 4.0993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 27
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 28
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 40
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 41
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 43
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 44
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 45
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 46
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 47
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 48
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 49
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 51
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 52
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 1.5
New value of Value function: 1.5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 73
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.515
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.485
New value of Value function: 1.5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 2.17082
New value of Value function: 2.17082
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 76
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 79
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.850888
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 3.31766
New value of Value function: 3.31766
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 82
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.284487
New value of Value function: 0.284487
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 3.1976
New value of Value function: 3.1976
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 85
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 95
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 4.24264
New value of Value function: 4.24264
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 96
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -1.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 97
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 98
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.57158
New value of Value function: 5.57158
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 99
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 100
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 101
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 102
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 103
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 104
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 105
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 106
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2573
	Distance: 6
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 107
----------
State: 2573
	Distance: 6
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 108
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 110
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 111
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 112
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 113
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 114
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 115
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 116
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 117
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 118
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 119
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 121
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 122
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 123
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 124
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 125
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 126
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 127
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 128
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 129
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 130
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 131
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 132
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 133
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 134
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 135
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 136
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 137
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 138
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 139
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.01
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 140
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -2.53553
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 141
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.165622
New value of Value function: 0.165622
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.18629
New value of Value function: 3.18629
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.15443
New value of Value function: 3.18629
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.17567
New value of Value function: 3.17567
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.947926
New value of Value function: 3.17567
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.16563
New value of Value function: 3.16563
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.57898
New value of Value function: 3.16563
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.15608
New value of Value function: 3.15608
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.14697
New value of Value function: 3.15443
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.14029
New value of Value function: 3.15443
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.13212
New value of Value function: 3.14029
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.1319
New value of Value function: 3.13212
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.11404
New value of Value function: 3.1319
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.12381
New value of Value function: 3.12381
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.116
New value of Value function: 3.116
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.10845
New value of Value function: 3.11404
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.10243
New value of Value function: 3.11404
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.09795
New value of Value function: 3.11404
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.09847
New value of Value function: 3.09847
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.08461
New value of Value function: 3.09795
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.07741
New value of Value function: 3.09795
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.09102
New value of Value function: 3.09102
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.08427
New value of Value function: 3.08427
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.0777
New value of Value function: 3.0777
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.06589
New value of Value function: 3.0777
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.07128
New value of Value function: 3.07128
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.06501
New value of Value function: 3.06589
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.05505
New value of Value function: 3.06501
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.98263
New value of Value function: 3.06501
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.05888
New value of Value function: 3.05888
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.57627
New value of Value function: 3.05888
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.05288
New value of Value function: 3.05505
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.04486
New value of Value function: 3.05288
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.04701
New value of Value function: 3.04701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.04125
New value of Value function: 3.04486
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.03523
New value of Value function: 3.04125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.0356
New value of Value function: 3.0356
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.03006
New value of Value function: 3.03523
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.02554
New value of Value function: 3.03523
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.02608
New value of Value function: 3.02608
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.01735
New value of Value function: 3.02554
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.13211
New value of Value function: 3.02554
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.02019
New value of Value function: 3.02019
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.01493
New value of Value function: 3.01735
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 2.25111
New value of Value function: 3.01735
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.81351
New value of Value function: 3.01735
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.00898
New value of Value function: 3.01493
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.00976
New value of Value function: 3.00976
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.00467
New value of Value function: 3.00898
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.8962
New value of Value function: 3.00898
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.00094
New value of Value function: 3.00467
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 2.99967
New value of Value function: 3.00094
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.99319
New value of Value function: 2.99967
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 2.99473
New value of Value function: 2.99473
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 2.98988
New value of Value function: 2.99319
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 2.98561
New value of Value function: 2.99319
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.98571
New value of Value function: 2.98571
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 2.97846
New value of Value function: 2.98561
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 2.98089
New value of Value function: 2.98089
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 2.97624
New value of Value function: 2.97846
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.86449
New value of Value function: 7.86449
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.78079
New value of Value function: 5.78079
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 3.85788
New value of Value function: 3.85788
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 2.53553
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 5
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 6
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 7
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 8
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 9
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 7.95
New value of Value function: 7.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 10
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 11
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 12
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 13
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 14
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 15
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 16
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 17
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 18
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.0513207
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.43122
New value of Value function: 2.97846
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 2.97144
New value of Value function: 2.97624
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 2.96572
New value of Value function: 2.97624
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 2.97164
New value of Value function: 2.97164
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 2.97597
New value of Value function: 2.97597
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 24
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 25
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 26
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 27
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -2.13597
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 28
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 29
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 30
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 31
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.95
New value of Value function: 0.95
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 32
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 33
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 34
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 35
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 36
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 37
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 38
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 39
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 40
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 41
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 42
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 43
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.919893
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 44
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 45
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 46
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 47
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 48
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 49
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 50
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.41766
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 51
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 52
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.70066
New value of Value function: 4.70066
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 53
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.8193
New value of Value function: 3.85788
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 54
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 4.90394
New value of Value function: 4.90394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 55
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 56
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2573
	Distance: 6
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.85788
New value of Value function: 7.85788
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 57
----------
State: 2573
	Distance: 6
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 58
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 59
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 60
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 61
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 62
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 63
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 64
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 65
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 66
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 67
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.0537907
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 3.72583
New value of Value function: 3.72583
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 69
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 70
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.47114
New value of Value function: 0.47114
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 3.68716
New value of Value function: 3.68716
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 72
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.53292
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 73
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 74
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 75
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.01
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 76
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 77
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 78
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 79
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 80
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 1
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.29373
New value of Value function: 9.29373
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.60279
New value of Value function: 7.60279
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 6.92143
New value of Value function: 6.92143
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.9707
New value of Value function: 10.9707
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.90394
New value of Value function: 8.90394
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.28631
New value of Value function: 7.28631
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 7
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.70004
New value of Value function: 4.70004
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 8
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 9
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5.99
New value of Value function: 5.99
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 10
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 3.475
New value of Value function: 3.475
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 11
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 1.40465
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 13
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 4.58185
New value of Value function: 4.58185
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 14
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 15
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.29289
New value of Value function: 4.95
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 16
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 17
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 18
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 19
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 20
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 21
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 22
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.599929
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 23
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 24
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.463965
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 25
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 5.12019
New value of Value function: 5.12019
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 26
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.92142
New value of Value function: 4.92142
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 27
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4.12379
New value of Value function: 4.92142
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 28
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 29
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 95.05
New value of Value function: 95.05
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 30
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1366
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 98.5355
New value of Value function: 98.5355
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.7396
New value of Value function: 10.7396
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 9.33761
New value of Value function: 9.33761
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 8.938
New value of Value function: 8.938
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 12.3928
New value of Value function: 12.3928
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.384
New value of Value function: 10.384
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.46967
New value of Value function: 8.46967
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 7
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 7.22245
New value of Value function: 7.22245
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 8
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.50018
New value of Value function: 5.12019
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 9
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.88548
New value of Value function: 5.88548
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 10
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -8
New value of Visit matrix: 3
New value of Q matrix: -3.7735
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 11
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.650288
New value of Value function: 0.650288
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 3.58584
New value of Value function: 3.58584
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 13
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 14
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 15
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.88675
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 16
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 17
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 18
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 19
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.491467
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 3.50039
New value of Value function: 3.50039
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 21
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -0.30723
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 22
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 23
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 0.00818911
New value of Value function: 0.00818911
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 3.42933
New value of Value function: 3.42933
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 25
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 0.154406
New value of Value function: 0.154406
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 3.38984
New value of Value function: 3.38984
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 27
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 0.0892084
New value of Value function: 0.0892084
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 28
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3.06245
New value of Value function: 3.06245
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 29
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 0.178119
New value of Value function: 0.178119
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 1.79251
New value of Value function: 3.38984
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 31
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 32
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 33
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 34
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 35
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 36
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 37
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.35594
New value of Value function: 0.35594
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 50
New value of Q matrix: 4.15872
New value of Value function: 4.15872
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 39
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 5.53698
New value of Value function: 5.53698
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 40
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.93932
New value of Value function: 2.95
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 4.02116
New value of Value function: 4.02116
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 42
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 0.0966527
New value of Value function: 0.0966527
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 43
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.980945
New value of Value function: 2.95
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 3.89282
New value of Value function: 3.89282
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 45
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 0.324968
New value of Value function: 0.324968
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 3.81437
New value of Value function: 3.81437
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 47
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.899094
New value of Value function: 0.324968
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 48
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 0.455235
New value of Value function: 0.455235
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 3.76488
New value of Value function: 3.76488
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 50
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 0.306926
New value of Value function: 0.306926
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 51
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 3.3259
New value of Value function: 3.3259
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 52
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.44887
New value of Value function: 5.44887
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 53
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.124049
New value of Value function: 0.306926
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 54
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 0.419257
New value of Value function: 0.419257
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 55
New value of Q matrix: 3.71771
New value of Value function: 3.71771
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 56
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.234043
New value of Value function: 0.419257
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 57
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.362591
New value of Value function: 0.419257
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 58
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 0.386566
New value of Value function: 0.386566
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 59
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.36544
New value of Value function: 3.36544
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 60
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.42547
New value of Value function: 5.42547
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 61
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.87428
New value of Value function: 0.87428
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 62
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 5.40443
New value of Value function: 5.40443
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 63
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.89681
New value of Value function: 4.89681
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 64
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 2.87752
New value of Value function: 4.89681
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 65
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 5.5612
New value of Value function: 5.5612
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 66
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.87491
New value of Value function: 4.87491
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 67
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.85501
New value of Value function: 4.85501
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 68
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.83666
New value of Value function: 4.83666
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 69
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.81956
New value of Value function: 4.81956
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 70
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.8035
New value of Value function: 4.8035
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 71
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 4.8035
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 72
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.75546
New value of Value function: 5.75546
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 73
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.78831
New value of Value function: 4.78831
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 74
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.77387
New value of Value function: 4.77387
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 75
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.76009
New value of Value function: 4.76009
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 76
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.74689
New value of Value function: 4.74689
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 77
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.7342
New value of Value function: 4.7342
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 78
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.72198
New value of Value function: 4.72198
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 79
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.71017
New value of Value function: 4.71017
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 80
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 3.60561
New value of Value function: 4.71017
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 81
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 5.59515
New value of Value function: 5.59515
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 82
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.69875
New value of Value function: 4.69875
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 83
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.68767
New value of Value function: 4.68767
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 84
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4.68767
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 85
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 86
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 87
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 88
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 89
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 90
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 91
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.6979
New value of Value function: 10.6979
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 92
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 5.67438
New value of Value function: 5.67438
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 93
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.67692
New value of Value function: 4.67692
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 94
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.66646
New value of Value function: 4.66646
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 95
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 53.337
New value of Value function: 53.337
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 96
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 93.0995
New value of Value function: 98.5355
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 97
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 97.525
New value of Value function: 97.525
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 98
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 3
New value of Q matrix: 96.4943
New value of Value function: 96.4943
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.39641
New value of Value function: 8.39641
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 3
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 4
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 5
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 6
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 7
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 8
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 9
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 10
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 11
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 12
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 13
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 14
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 15
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 16
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 17
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 18
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 19
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 20
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 21
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 22
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 23
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 24
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 25
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 26
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 27
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2457
	Distance: 6
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 28
----------
State: 2457
	Distance: 6
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2457
	Distance: 6
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 29
----------
State: 2457
	Distance: 6
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2457
	Distance: 6
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 30
----------
State: 2457
	Distance: 6
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.680533
New value of Value function: 0.680533
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 56
New value of Q matrix: 3.6218
New value of Value function: 3.6218
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 32
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.464609
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 3.53944
New value of Value function: 3.53944
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 34
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.958333
New value of Value function: 0.958333
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 35
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -1.05125
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 36
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2457
	Distance: 6
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.68397
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 37
----------
State: 2457
	Distance: 6
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.555739
New value of Value function: 0.555739
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 3.46861
New value of Value function: 3.46861
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 39
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 40
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 41
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.433924
New value of Value function: 0.433924
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.6819
New value of Value function: 3.46861
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.46409
New value of Value function: 3.46409
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.06941
New value of Value function: 3.46409
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 3.45964
New value of Value function: 3.45964
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 46
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.66263
New value of Value function: 3.66263
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 47
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 48
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.425043
New value of Value function: 0.425043
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 4.03457
New value of Value function: 4.03457
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 50
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.29754
New value of Value function: 5.29754
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 51
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.827515
New value of Value function: 0.827515
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 2.19501
New value of Value function: 4.03457
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 53
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 54
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 55
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 56
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 8.24457
New value of Value function: 8.24457
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 57
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 5.29754
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 58
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 59
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 60
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 61
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 62
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 63
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 64
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 65
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 66
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 67
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 68
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 69
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 70
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 71
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 72
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 73
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 74
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 75
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 76
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 77
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 78
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 79
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 80
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 81
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 82
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 83
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 84
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 85
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 86
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 87
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 88
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.00292893
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 89
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 90
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 91
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.00123791
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 92
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 93
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 94
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 95
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 96
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 97
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 98
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 99
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 100
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 101
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 102
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 103
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 104
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 105
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 106
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 107
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 108
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 109
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 110
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 111
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 112
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 113
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 114
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 115
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 116
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 117
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 118
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 119
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 120
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 121
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.8505
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 122
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 123
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 124
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 125
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 126
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 127
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 128
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 129
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 130
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 131
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 132
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 133
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 134
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 135
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 7.8505
New value of Value function: 7.8505
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 136
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 137
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 138
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 139
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 140
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 141
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 142
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 143
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 144
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 145
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.68719
New value of Value function: 3.68719
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 146
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 147
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.40007
New value of Value function: 6.40007
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 148
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.73205
New value of Value function: 3.73205
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 149
----------
State: 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 150
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 151
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 152
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 153
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 154
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 155
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 156
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 0.464466
New value of Value function: 0.464466
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 157
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 158
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -1.18076
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 159
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.3823
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 160
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 161
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.24457
New value of Value function: 0.24457
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 162
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.26555
New value of Value function: 5.26555
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 163
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.22217
New value of Value function: 0.22217
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 164
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.24275
New value of Value function: 5.24275
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 165
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.203782
New value of Value function: 0.203782
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 166
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.16212
New value of Value function: 5.24275
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 167
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.03
New value of Value function: 8.24457
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 168
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 169
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.95
New value of Value function: 3.95
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 170
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.58116
New value of Value function: 7.58116
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 171
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 5.76884
New value of Value function: 5.76884
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 172
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 10.643
New value of Value function: 10.643
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 173
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.72489
New value of Value function: 7.72489
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 174
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.366025
New value of Value function: 0.366025
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 175
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 176
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -1.63763
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 177
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 178
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 179
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 180
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 181
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 182
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 183
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 184
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 185
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 186
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 187
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.96464
New value of Value function: 1.96464
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 188
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 189
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 190
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 191
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 192
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.994225
New value of Value function: 0.994225
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 2.94262
New value of Value function: 4.03457
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 194
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5.98428
New value of Value function: 5.98428
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 195
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.984283
New value of Value function: 0.994225
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 196
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.94488
New value of Value function: 0.984283
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 197
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.97732
New value of Value function: 5.97732
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 198
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.977323
New value of Value function: 0.977323
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 199
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.97168
New value of Value function: 0.97168
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 200
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.966822
New value of Value function: 0.966822
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.98361
New value of Value function: 8.98361
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.89378
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 3
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.32528
New value of Value function: 9.32528
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 4
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.70004
New value of Value function: 5.70004
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 5
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 6
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 7
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 8
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 9
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 8.95
New value of Value function: 8.95
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 10
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.71473
New value of Value function: 6.71473
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 11
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.40007
New value of Value function: 4.40007
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 12
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.54467
New value of Value function: 1.54467
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 13
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.47464
New value of Value function: 4.47464
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 14
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.4784
New value of Value function: 1.4784
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 15
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.46362
New value of Value function: 4.47464
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 16
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.45415
New value of Value function: 1.45415
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 17
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.45712
New value of Value function: 4.46362
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 18
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.43842
New value of Value function: 1.43842
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 19
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.94301
New value of Value function: 6.94301
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 20
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.0895
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 21
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 5.75691
New value of Value function: 5.75691
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 22
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.38827
New value of Value function: 9.38827
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 23
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 7.00662
New value of Value function: 7.00662
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 24
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 11.5395
New value of Value function: 11.5395
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 25
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 5.96322
New value of Value function: 7.72489
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 26
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.9919
New value of Value function: 11.9919
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 27
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.33495
New value of Value function: 7.33495
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 28
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 2.4384
New value of Value function: 2.4384
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 29
----------
State: 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1854
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 1
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 9.32528
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 2
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 3
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 4
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 5
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 6
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 7
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 8
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 9
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 10
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 11
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 12
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.23203
New value of Value function: 9.23203
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 13
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 9.76453
New value of Value function: 9.76453
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 14
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.86745
New value of Value function: 5.86745
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 15
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 16
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 17
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 18
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 19
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 20
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 21
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 22
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 23
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 3.70055
New value of Value function: 3.70055
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 24
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.29415
New value of Value function: 9.29415
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 25
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.53594
New value of Value function: 7.53594
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 26
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 5.56397
New value of Value function: 5.56397
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 27
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.43476
New value of Value function: 4.43476
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 28
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.16212
New value of Value function: 5.16212
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 29
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 8.20621
New value of Value function: 8.20621
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 30
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.22441
New value of Value function: 5.22441
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 31
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.187974
New value of Value function: 0.187974
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 32
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 5.22441
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 33
----------
State: 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.994225
New value of Value function: 0.994225
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 62
New value of Q matrix: 4.56005
New value of Value function: 4.56005
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 35
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 5.22441
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 36
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 37
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 38
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 39
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 40
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 3.17217
New value of Value function: 3.17217
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 41
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.192195
New value of Value function: 5.22441
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 5.01513
New value of Value function: 5.01513
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 43
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 3.89375
New value of Value function: 5.16212
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 4.7865
New value of Value function: 4.7865
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 45
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.186094
New value of Value function: 0.187974
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 46
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.975976
New value of Value function: 0.975976
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 47
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.12415
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 48
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.39041
New value of Value function: 8.20621
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 49
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.27263
New value of Value function: 7.27263
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 50
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.06752
New value of Value function: 3.89375
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 51
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.98021
New value of Value function: 7.98021
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 52
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.85482
New value of Value function: 3.89375
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 53
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.67707
New value of Value function: 4.67707
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 54
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 0.426606
New value of Value function: 0.426606
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 55
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.40317
New value of Value function: 4.67707
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 56
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.94056
New value of Value function: 4.94056
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 57
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.28391
New value of Value function: 1.28391
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.43367
New value of Value function: 4.7865
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 4.72257
New value of Value function: 4.72257
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 60
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 0.224225
New value of Value function: 1.28391
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 61
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5.38406
New value of Value function: 5.38406
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 62
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.27649
New value of Value function: 1.27649
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 63
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.27011
New value of Value function: 1.27011
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 64
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.26443
New value of Value function: 1.26443
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 65
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.25927
New value of Value function: 1.25927
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 66
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.25451
New value of Value function: 1.25451
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 67
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.25007
New value of Value function: 1.25007
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 68
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.24591
New value of Value function: 1.24591
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 69
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.24197
New value of Value function: 1.24197
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 70
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 0.261702
New value of Value function: 1.24197
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 71
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.85788
New value of Value function: 5.38406
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 72
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 3.33022
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 73
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.65143
New value of Value function: 5.65143
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 74
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 75
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 76
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 77
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -3.54018
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 78
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 2.47684
New value of Value function: 2.47684
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 79
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 80
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.49679
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 81
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.98
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 82
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 83
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 9.76453
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 2
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 11.6669
New value of Value function: 11.6669
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 3
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 10.0948
New value of Value function: 10.0948
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 4
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.43372
New value of Value function: 4.43372
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 5
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 6
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 7
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 8
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.38939
New value of Value function: 1.38939
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 9
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 4.40768
New value of Value function: 4.40768
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 10
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.37116
New value of Value function: 1.37116
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 11
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 4.38717
New value of Value function: 4.38717
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 12
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 13
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 14
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 14.872
New value of Value function: 14.872
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 15
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 11.1529
New value of Value function: 11.1529
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 16
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 9.17475
New value of Value function: 9.17475
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 17
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 14.2846
New value of Value function: 14.2846
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 18
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 11.5449
New value of Value function: 11.5449
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 19
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 7.16279
New value of Value function: 7.16279
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 20
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 21
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 22
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 23
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 24
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.0412132
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 25
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 26
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 8.083
New value of Value function: 8.083
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 27
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 10.0912
New value of Value function: 10.0912
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 28
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.07592
New value of Value function: 7.07592
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 29
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 30
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 31
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 32
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 33
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 34
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 35
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 36
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 37
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 38
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 39
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 40
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 41
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.186897
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 42
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.99
New value of Value function: 2.99
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 43
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 2.0966
New value of Value function: 2.0966
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 44
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 52.7384
New value of Value function: 52.7384
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 45
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 2
New value of Q matrix: 96.4645
New value of Value function: 96.4645
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 9.86818
New value of Value function: 9.86818
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 4.513
New value of Value function: 4.513
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 3
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 9.75262
New value of Value function: 9.75262
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 4
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.59504
New value of Value function: 4.59504
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 5
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 9.69617
New value of Value function: 9.69617
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 6
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 4.59713
New value of Value function: 4.59713
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 7
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 9.65741
New value of Value function: 9.65741
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 8
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 4.5809
New value of Value function: 4.5809
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 9
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 9.62583
New value of Value function: 9.62583
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 10
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 4.5809
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 11
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 13.2012
New value of Value function: 13.2012
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 12
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.7102
New value of Value function: 10.7102
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 13
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 3.78312
New value of Value function: 7.53594
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 14
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.00695
New value of Value function: 6.00695
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 15
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 3.91645
New value of Value function: 3.91645
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 16
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.64496
New value of Value function: 8.64496
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 17
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.40626
New value of Value function: 5.40626
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 5.16935
New value of Value function: 5.16935
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 19
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.36739
New value of Value function: 7.36739
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 20
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.09122
New value of Value function: 5.65143
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 21
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 6.05201
New value of Value function: 6.05201
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 22
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.975
New value of Value function: 1.98
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 23
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.97186
New value of Value function: 4.97186
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 24
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.966
New value of Value function: 1.975
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 25
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 0.815181
New value of Value function: 1.975
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 26
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.9303
New value of Value function: 4.97186
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 27
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.96227
New value of Value function: 4.96227
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 28
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.94711
New value of Value function: 1.966
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 29
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 52.731
New value of Value function: 52.731
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 30
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 98.5057
New value of Value function: 98.5057
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 7.61706
New value of Value function: 9.62583
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 2
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 11.5502
New value of Value function: 11.6669
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 3
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 11.5698
New value of Value function: 11.5698
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 4
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 9.60315
New value of Value function: 9.60315
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 5
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.53509
New value of Value function: 4.5809
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 6
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 4.55078
New value of Value function: 4.55078
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 7
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.50711
New value of Value function: 9.60315
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 8
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 9.57941
New value of Value function: 9.57941
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 9
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 4.52539
New value of Value function: 4.53509
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 10
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.4905
New value of Value function: 9.57941
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 11
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 9.55827
New value of Value function: 9.55827
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 12
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.50302
New value of Value function: 4.52539
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 13
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 4.50322
New value of Value function: 4.50322
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 14
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 9.53531
New value of Value function: 9.53531
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 15
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 5.24132
New value of Value function: 5.24132
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 16
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.69497
New value of Value function: 6.69497
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 17
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 18
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 19
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 20
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 2.62802
New value of Value function: 2.62802
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 21
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 6.64115
New value of Value function: 6.64115
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 22
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.06577
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 23
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 5.64904
New value of Value function: 5.64904
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 24
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 5.61685
New value of Value function: 5.61685
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 25
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 5.64904
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 26
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 27
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 28
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 29
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 10.1397
New value of Value function: 10.1397
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 30
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 9.23203
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 31
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.98586
New value of Value function: 1.98586
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 32
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 1.98586
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 33
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.966
New value of Value function: 4.966
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 34
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.97439
New value of Value function: 1.97439
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 35
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.96452
New value of Value function: 1.96452
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 36
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.95573
New value of Value function: 1.95573
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 37
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.94775
New value of Value function: 1.94775
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 38
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.94039
New value of Value function: 1.94039
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 39
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 11.1397
New value of Value function: 11.1397
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 40
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 9.23203
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 41
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 42
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.56068
New value of Value function: 5.56068
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 43
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 4.89377
New value of Value function: 4.89377
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 44
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 45
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 46
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 47
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 48
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 49
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.535534
New value of Value function: 0.535534
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 50
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 51
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 52
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 53
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 54
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.9469
New value of Value function: 10.9469
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 55
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.94688
New value of Value function: 6.00695
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 56
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 9.46058
New value of Value function: 9.46058
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 57
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 7.20661
New value of Value function: 7.20661
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 58
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 3.99888
New value of Value function: 3.99888
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 59
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 7.09583
New value of Value function: 7.09583
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 60
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.9589
New value of Value function: 3.99888
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 61
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.516338
New value of Value function: 3.99888
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 62
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 63
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 64
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 65
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 66
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 67
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 68
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 69
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 70
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 71
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 72
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 73
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 74
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.11765
New value of Value function: 2.11765
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 5.38797
New value of Value function: 5.38797
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 76
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.9589
New value of Value function: 3.99888
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 77
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 6.31806
New value of Value function: 6.31806
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 78
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 9.46934
New value of Value function: 9.46934
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 79
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 8.33722
New value of Value function: 8.33722
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 80
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.25385
New value of Value function: 5.16212
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 81
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 8.92832
New value of Value function: 8.92832
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 82
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.13527
New value of Value function: 5.13527
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 83
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.1356
New value of Value function: 8.1356
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 84
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.08849
New value of Value function: 5.08849
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 85
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 4.96
New value of Value function: 8.1356
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 86
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 87
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 88
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 5.93656
New value of Value function: 5.93656
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 89
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 6.87719
New value of Value function: 7.00662
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 90
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 5.93656
New value of Value function: 5.93656
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 91
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 8.23077
New value of Value function: 8.23077
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 92
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.41011
New value of Value function: 7.41011
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 93
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.75766
New value of Value function: 3.75766
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 94
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 22.964
New value of Value function: 22.964
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 95
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 26.1049
New value of Value function: 52.7384
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 96
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 74.5545
New value of Value function: 74.5545
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 97
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 99.2529
New value of Value function: 99.2529
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 9.68146
New value of Value function: 9.68146
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 7.9082
New value of Value function: 7.9082
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.8605
New value of Value function: 8.95
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 4
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 4.01439
New value of Value function: 8.8605
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 5
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.2764
New value of Value function: 10.2764
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 6
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 4.66355
New value of Value function: 10.7102
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 7
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 7.1084
New value of Value function: 7.1084
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 8
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 7.04916
New value of Value function: 10.7102
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 9
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 11.0249
New value of Value function: 11.0249
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 10
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 10.0674
New value of Value function: 10.0674
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 11
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 10.5291
New value of Value function: 10.5291
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 12
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.83903
New value of Value function: 8.92832
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 13
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.33409
New value of Value function: 8.92832
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 6.17028
New value of Value function: 6.17028
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 15
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.42381
New value of Value function: 8.92832
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 16
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.34043
New value of Value function: 10.5291
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 17
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 12.0919
New value of Value function: 12.0919
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 18
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 11.0639
New value of Value function: 11.0639
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 19
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 9.27911
New value of Value function: 9.27911
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 20
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 5.08849
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 21
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.10858
New value of Value function: 3.10858
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 69
New value of Q matrix: 6.39508
New value of Value function: 6.39508
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 23
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 5.07137
New value of Value function: 5.07137
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 24
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.615
New value of Value function: 8.1356
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 25
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 11.8162
New value of Value function: 11.8162
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 26
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 5.78163
New value of Value function: 8.1356
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 27
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 9.50269
New value of Value function: 9.50269
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 28
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.02066
New value of Value function: 5.07137
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 29
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 5.06371
New value of Value function: 5.06371
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 30
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 32.6697
New value of Value function: 32.6697
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 31
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 32.2236
New value of Value function: 52.731
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 32
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 31.3611
New value of Value function: 32.2236
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 33
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.95465
New value of Value function: 1.95465
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 34
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.94488
New value of Value function: 1.94711
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 35
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 42.0833
New value of Value function: 42.0833
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 36
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 19.0104
New value of Value function: 99.2529
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 32.0625
New value of Value function: 32.0625
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 38
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 31.9191
New value of Value function: 31.9191
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 31.7888
New value of Value function: 31.7888
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 40
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 31.6687
New value of Value function: 31.6687
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 41
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 31.5567
New value of Value function: 31.5567
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 42
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 31.4515
New value of Value function: 31.4515
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 43
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 31.3521
New value of Value function: 31.3611
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 44
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 20.2494
New value of Value function: 31.3611
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 45
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 34.1803
New value of Value function: 34.1803
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 46
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 60.7138
New value of Value function: 60.7138
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 47
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 5
New value of Q matrix: 97.3509
New value of Value function: 97.3509
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 10.3683
New value of Value function: 10.3683
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.42334
New value of Value function: 7.9082
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 3
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 8.84005
New value of Value function: 8.84005
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 4
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.79785
New value of Value function: 8.79785
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 5
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 6.99308
New value of Value function: 8.79785
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 6
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 12.9397
New value of Value function: 12.9397
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 7
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 13.2662
New value of Value function: 13.2662
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 8
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 13.7204
New value of Value function: 13.7204
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 9
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 12.0253
New value of Value function: 12.0253
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 10
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 8.22525
New value of Value function: 8.83903
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 11
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.26595
New value of Value function: 3.26595
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 6.58847
New value of Value function: 6.58847
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 13
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 15.5862
New value of Value function: 15.5862
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 14
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 23.5496
New value of Value function: 23.5496
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 15
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 3.75152
New value of Value function: 3.75152
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 16
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 17.7752
New value of Value function: 17.7752
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 17
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 47.7616
New value of Value function: 47.7616
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 18
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 51.7263
New value of Value function: 60.7138
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 19
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 68.2479
New value of Value function: 68.2479
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 61.4484
New value of Value function: 61.4484
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 21
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 65.0677
New value of Value function: 65.0677
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 22
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 63.4327
New value of Value function: 63.4327
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 23
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 59.3206
New value of Value function: 65.0677
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 24
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2618
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 6
New value of Q matrix: 96.7994
New value of Value function: 96.7994
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 9.93746
New value of Value function: 10.3683
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 2
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 11.1947
New value of Value function: 11.1947
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 3
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 11.0426
New value of Value function: 11.0426
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 4
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 10.5749
New value of Value function: 10.5749
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 5
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 13.6841
New value of Value function: 13.6841
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 6
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.19686
New value of Value function: 10.384
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 7
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.6091
New value of Value function: 11.6091
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 8
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.1157
New value of Value function: 10.1157
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 9
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 8.38082
New value of Value function: 8.38082
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 10
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 20.84
New value of Value function: 20.84
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 11
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 74.4512
New value of Value function: 74.4512
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 12
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 96.9502
New value of Value function: 96.9502
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 13
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1366
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 98.2472
New value of Value function: 98.2472
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.84483
New value of Value function: 11.1947
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 2
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 4.7708
New value of Value function: 4.7708
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 3
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.86418
New value of Value function: 5.64904
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.0432
New value of Value function: 5.64904
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 5
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 5.69179
New value of Value function: 5.69179
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 6
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 4.71942
New value of Value function: 4.71942
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 7
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 5.69179
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 8
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 14.8104
New value of Value function: 14.8104
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 9
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 8.49456
New value of Value function: 8.49456
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 10
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 11
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 12
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 13
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 15
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 16
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 17
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 18
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 19
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 20
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.97
New value of Value function: 4.97
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 21
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 6.50018
New value of Value function: 6.50018
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 22
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.475
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 23
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.85788
New value of Value function: 7.85788
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 24
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 25
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 26
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 27
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 28
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 29
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 30
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.8705
New value of Value function: 2.8705
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 31
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 7.95
New value of Value function: 7.95
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 32
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 33
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 34
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 35
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.47581
New value of Value function: 2.47581
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.09223
New value of Value function: 6.58847
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.6134
New value of Value function: 6.58847
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 6.58065
New value of Value function: 6.58065
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 6.44752
New value of Value function: 6.44752
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 40
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.03422
New value of Value function: 7.03422
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 41
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 4.74466
New value of Value function: 4.74466
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 73
New value of Q matrix: 6.59379
New value of Value function: 6.59379
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 43
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.09911
New value of Value function: 5.09911
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 44
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 10.5491
New value of Value function: 10.5491
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 45
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 37.0814
New value of Value function: 37.0814
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 46
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 16.7124
New value of Value function: 74.4512
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 47
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 47.9429
New value of Value function: 47.9429
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 48
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 84.8736
New value of Value function: 84.8736
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 49
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 88.4875
New value of Value function: 88.4875
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 50
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 91.4468
New value of Value function: 91.4468
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 51
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 5
New value of Q matrix: 96.795
New value of Value function: 96.795
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 12.1825
New value of Value function: 12.1825
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 12.6076
New value of Value function: 12.6076
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 11.9793
New value of Value function: 11.9793
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 13.6841
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 5
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 6
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 7
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 8
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 9
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 10
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 11
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 12
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 13
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 14
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 15
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 16
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 17
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 18
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 11.4816
New value of Value function: 11.4816
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 19
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 12.3667
New value of Value function: 12.6076
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 20
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 11.4816
New value of Value function: 11.4816
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 21
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 12.3667
New value of Value function: 12.6076
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 22
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 11.4816
New value of Value function: 11.4816
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 23
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 12.6076
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 24
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.29063
New value of Value function: 8.29063
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 25
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 9.98855
New value of Value function: 9.98855
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 26
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 12.8353
New value of Value function: 12.8353
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 27
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 14.8308
New value of Value function: 14.8308
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 28
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 12.8962
New value of Value function: 12.8962
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 29
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.0272
New value of Value function: 8.0272
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 30
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 31
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 32
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 6.48891
New value of Value function: 6.48891
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 33
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 9.29702
New value of Value function: 10.6979
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 34
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.9301
New value of Value function: 8.38082
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 35
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 38.8517
New value of Value function: 38.8517
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 60.0324
New value of Value function: 60.0324
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 37
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 23.4039
New value of Value function: 91.4468
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 38
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 91.5019
New value of Value function: 91.5019
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 39
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 61.0903
New value of Value function: 88.4875
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 40
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 37.7274
New value of Value function: 91.5019
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 41
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 91.5355
New value of Value function: 91.5355
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 42
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 92.217
New value of Value function: 92.217
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 43
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1366
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 98.1034
New value of Value function: 98.1034
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 5.72278
New value of Value function: 12.1825
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 2
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 4.68953
New value of Value function: 4.68953
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 3
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.82462
New value of Value function: 5.69179
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 5.66721
New value of Value function: 5.66721
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 5
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 4.6632
New value of Value function: 4.6632
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 6
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 5.64456
New value of Value function: 5.64456
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 7
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 4.63946
New value of Value function: 4.63946
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 5.62354
New value of Value function: 5.62354
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 9
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 4.6177
New value of Value function: 4.6177
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.32769
New value of Value function: 5.62354
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 5.60388
New value of Value function: 5.60388
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 12
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.50507
New value of Value function: 5.50507
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 13
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.48243
New value of Value function: 5.48243
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 14
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.45002
New value of Value function: 5.50507
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 15
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.4503
New value of Value function: 5.4503
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 16
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.7138
New value of Value function: 5.48243
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 17
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 8.13971
New value of Value function: 8.13971
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 18
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 11.2322
New value of Value function: 11.2322
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 19
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 10.9185
New value of Value function: 10.9185
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 20
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 2.85493
New value of Value function: 2.85493
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 21
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.74705
New value of Value function: 8.74705
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 22
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.70332
New value of Value function: 8.70332
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 23
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.66439
New value of Value function: 8.66439
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 24
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 8.62902
New value of Value function: 8.62902
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 25
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 8.59641
New value of Value function: 8.59641
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 26
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.56601
New value of Value function: 8.56601
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 27
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 8.53746
New value of Value function: 8.53746
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 28
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 8.51046
New value of Value function: 8.51046
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 29
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 8.4848
New value of Value function: 8.4848
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 30
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 8.46031
New value of Value function: 8.46031
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 31
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 8.43685
New value of Value function: 8.43685
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 32
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 8.4143
New value of Value function: 8.4143
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 33
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 6.82638
New value of Value function: 8.4143
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 34
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.82638
New value of Value function: 2.85493
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 35
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 6.90656
New value of Value function: 6.90656
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 36
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 10.7947
New value of Value function: 10.7947
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 37
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 7.22192
New value of Value function: 7.22192
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 38
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.34133
New value of Value function: 9.34133
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 39
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 11.0439
New value of Value function: 11.0439
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 40
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 6.87719
New value of Value function: 8.23077
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 41
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 6.63625
New value of Value function: 6.63625
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 42
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 8.68383
New value of Value function: 8.68383
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 43
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 11.8086
New value of Value function: 11.8086
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 44
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 6.38313
New value of Value function: 7.41011
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 45
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.77263
New value of Value function: 11.8086
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 46
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.38735
New value of Value function: 11.8086
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 47
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 11.9754
New value of Value function: 11.9754
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 48
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.87326
New value of Value function: 7.87326
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 49
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 15.8686
New value of Value function: 15.8686
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 50
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 39.0098
New value of Value function: 39.0098
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 51
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 63.9119
New value of Value function: 63.9119
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 52
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 40.8335
New value of Value function: 63.4327
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 53
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 63.8084
New value of Value function: 63.8084
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 54
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 63.3314
New value of Value function: 63.3314
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 55
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 47.2816
New value of Value function: 63.8084
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 56
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 63.7633
New value of Value function: 63.7633
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 57
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 62.9501
New value of Value function: 62.9501
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 58
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 63.596
New value of Value function: 63.596
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 59
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.49275
New value of Value function: 62.9501
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 60
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 48.5195
New value of Value function: 48.5195
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 61
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 39.6972
New value of Value function: 60.7138
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 62
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 64.1067
New value of Value function: 64.1067
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 63
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 75.8768
New value of Value function: 75.8768
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 64
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 7
New value of Q matrix: 98.0091
New value of Value function: 98.0091
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 11.4851
New value of Value function: 11.4851
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 9.05923
New value of Value function: 9.05923
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 8.39257
New value of Value function: 8.39257
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 4
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 8.37159
New value of Value function: 8.37159
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 5
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 8.35129
New value of Value function: 8.35129
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 6
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 7.63408
New value of Value function: 8.35129
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 7
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 9.14437
New value of Value function: 9.14437
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 8
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 7.8759
New value of Value function: 8.35129
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 9
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 9.19101
New value of Value function: 9.19101
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 10
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 7.9875
New value of Value function: 8.35129
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 11
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 9.21815
New value of Value function: 9.21815
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 12
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 8.3316
New value of Value function: 8.3316
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 13
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 8.31249
New value of Value function: 8.31249
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 14
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 8.2939
New value of Value function: 8.2939
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 15
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 8.2758
New value of Value function: 8.2758
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 16
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 8.25816
New value of Value function: 8.25816
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 17
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 7.20135
New value of Value function: 8.25816
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 18
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 12.4296
New value of Value function: 12.4296
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 19
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 9.72667
New value of Value function: 13.2662
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 20
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.781005
New value of Value function: 10.7947
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 21
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 8.24094
New value of Value function: 8.24094
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 22
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 8.22412
New value of Value function: 8.22412
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 23
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 8.20767
New value of Value function: 8.20767
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 24
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 9.03671
New value of Value function: 9.03671
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 25
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 14.5855
New value of Value function: 14.5855
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 26
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 15.2758
New value of Value function: 15.2758
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 27
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 14.782
New value of Value function: 14.782
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 28
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 11.9338
New value of Value function: 11.9338
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 29
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.77653
New value of Value function: 8.77653
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 30
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.72586
New value of Value function: 8.72586
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 31
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.68223
New value of Value function: 8.68223
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 32
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.6434
New value of Value function: 8.6434
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 33
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.06172
New value of Value function: 8.6434
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 34
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 1.97792
New value of Value function: 6.31806
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 35
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.11481
New value of Value function: 3.11481
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.30034
New value of Value function: 6.59379
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 6.58612
New value of Value function: 6.58612
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 75
New value of Q matrix: 6.89429
New value of Value function: 6.89429
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 39
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 8.81685
New value of Value function: 8.81685
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 40
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 11.8146
New value of Value function: 11.8146
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 41
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.742799
New value of Value function: 8.6434
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 42
----------
State: 2057
	Distance: 5
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.52504
New value of Value function: 3.52504
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 76
New value of Q matrix: 7.42913
New value of Value function: 7.42913
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 44
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 8.60811
New value of Value function: 8.60811
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 45
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 8.57558
New value of Value function: 8.57558
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 46
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.54526
New value of Value function: 8.54526
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 47
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.82821
New value of Value function: 8.54526
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 77
New value of Q matrix: 7.88847
New value of Value function: 7.88847
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 49
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 8.51677
New value of Value function: 8.51677
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 50
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 8.48984
New value of Value function: 8.48984
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 51
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.31494
New value of Value function: 8.48984
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 52
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 11.6911
New value of Value function: 11.6911
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 53
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 8.46424
New value of Value function: 8.46424
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 54
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 11.6103
New value of Value function: 11.6103
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 55
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 17.3732
New value of Value function: 17.3732
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 56
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 17.9423
New value of Value function: 17.9423
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 57
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 10.5908
New value of Value function: 10.5908
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 58
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 5.04593
New value of Value function: 17.7752
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 59
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.44456
New value of Value function: 11.6103
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 60
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 14.8872
New value of Value function: 14.8872
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 61
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 18.881
New value of Value function: 18.881
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 62
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 27.3462
New value of Value function: 27.3462
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 63
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 56.3729
New value of Value function: 56.3729
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 64
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 69.8425
New value of Value function: 69.8425
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 65
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 59.63
New value of Value function: 59.63
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 66
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 80.5713
New value of Value function: 80.5713
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 67
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 8
New value of Q matrix: 98.713
New value of Value function: 98.713
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 12.6611
New value of Value function: 12.6611
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 14.3074
New value of Value function: 14.3074
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 13.7357
New value of Value function: 13.7357
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 15.9407
New value of Value function: 15.9407
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 12.9142
New value of Value function: 12.9142
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 10.019
New value of Value function: 10.019
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 7
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 33.0005
New value of Value function: 33.0005
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 8
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 68.4746
New value of Value function: 68.4746
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 9
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 92.7243
New value of Value function: 92.7243
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 10
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 13.9127
New value of Value function: 13.9127
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 11.4655
New value of Value function: 14.3074
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 3
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 15.6643
New value of Value function: 15.6643
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 4
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 14.654
New value of Value function: 14.654
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 5
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.5928
New value of Value function: 16.5928
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 6
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.5824
New value of Value function: 13.5824
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 7
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 19.7953
New value of Value function: 19.7953
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 8
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 48.8362
New value of Value function: 48.8362
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 9
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 74.7546
New value of Value function: 74.7546
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 10
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 29.1871
New value of Value function: 92.7243
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 11
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 66.9637
New value of Value function: 66.9637
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 95.8225
New value of Value function: 95.8225
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 13
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 13.953
New value of Value function: 13.953
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: 4.4541
New value of Value function: 9.21815
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 3
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 3
New value of Q matrix: 14.2003
New value of Value function: 14.2003
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 4
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 9.46088
New value of Value function: 9.46088
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 5
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.395795
New value of Value function: 9.03671
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 6
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 4.59754
New value of Value function: 5.4503
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 7
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 5.88386
New value of Value function: 5.88386
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 8
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.95604
New value of Value function: 6.95604
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 9
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 9.5399
New value of Value function: 9.5399
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 10
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 9.30054
New value of Value function: 9.30054
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 11
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.20027
New value of Value function: 8.20027
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 12
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 8.77066
New value of Value function: 8.77066
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 13
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 7.13977
New value of Value function: 9.30054
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 14
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 8.4891
New value of Value function: 8.4891
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 15
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 11.557
New value of Value function: 11.557
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 16
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 14.0297
New value of Value function: 14.0297
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 17
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 9.6144
New value of Value function: 9.6144
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 18
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 10.8342
New value of Value function: 10.8342
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 19
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.5433
New value of Value function: 16.5433
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 20
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.8167
New value of Value function: 16.8167
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 21
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 16.3493
New value of Value function: 16.3493
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 22
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 14.7782
New value of Value function: 14.7782
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 23
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 14.4404
New value of Value function: 14.4404
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 24
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 16.7789
New value of Value function: 16.7789
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 25
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 22.6116
New value of Value function: 22.6116
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 26
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 16.082
New value of Value function: 27.3462
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 27
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 21.3231
New value of Value function: 21.3231
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 78
New value of Q matrix: 14.0192
New value of Value function: 14.0192
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 29
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 72.3094
New value of Value function: 72.3094
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 30
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 9
New value of Q matrix: 99.142
New value of Value function: 99.142
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 15.2124
New value of Value function: 15.2124
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 16.8231
New value of Value function: 16.8231
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 15.4544
New value of Value function: 15.4544
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 17.2107
New value of Value function: 17.2107
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 13.5824
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 6
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 10.2999
New value of Value function: 10.2999
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 7
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 16.1711
New value of Value function: 16.1711
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 8
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 17.6015
New value of Value function: 17.6015
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 9
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 17.0656
New value of Value function: 17.0656
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 10
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 36.9615
New value of Value function: 36.9615
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 11
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 78.5958
New value of Value function: 78.5958
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 37.9898
New value of Value function: 95.8225
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 13
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 16
New value of Q matrix: 80.032
New value of Value function: 80.032
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 14
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 97.8945
New value of Value function: 97.8945
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 15
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 4.62138
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 16
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 55.7746
New value of Value function: 55.7746
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 17
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 68.6775
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 18
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 17
New value of Q matrix: 84.3694
New value of Value function: 84.3694
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 19
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 99.0671
New value of Value function: 99.0671
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 20
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1366
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 7
New value of Q matrix: 98.8203
New value of Value function: 98.8203
New value of Policy matrix: 4

=======================================
Simulation: 22
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 16.3695
New value of Value function: 16.3695
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 14.4616
New value of Value function: 16.8231
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 3
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 18.0316
New value of Value function: 18.0316
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 4
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 16.7736
New value of Value function: 16.7736
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 5
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 18.896
New value of Value function: 18.896
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 6
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 24.4606
New value of Value function: 24.4606
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 7
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 36.5919
New value of Value function: 36.9615
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 8
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 51.46
New value of Value function: 51.46
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 9
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 81.5725
New value of Value function: 81.5725
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 10
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 87.8359
New value of Value function: 87.8359
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 11
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 100.118
New value of Value function: 100.118
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 12
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 16.0423
New value of Value function: 16.0423
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 11
New value of Q matrix: 7.95725
New value of Value function: 7.95725
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 3
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.29147
New value of Value function: 8.29147
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 4
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.3965
New value of Value function: 11.3965
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 5
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 7.49117
New value of Value function: 10.8342
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 6
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 12
New value of Q matrix: 6.8751
New value of Value function: 6.8751
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 7
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 15.7259
New value of Value function: 15.7259
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 8
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 14.5437
New value of Value function: 14.5437
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 9
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 18.2731
New value of Value function: 18.2731
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 10
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 14.9561
New value of Value function: 14.9561
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 11
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 11.2877
New value of Value function: 11.2877
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 12
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 18.1477
New value of Value function: 18.1477
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 13
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 21.6628
New value of Value function: 21.6628
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 14
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 6.81394
New value of Value function: 16.7789
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 79
New value of Q matrix: 14.6483
New value of Value function: 14.6483
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 16
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 17.3346
New value of Value function: 17.3346
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 17
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 9.01391
New value of Value function: 21.6628
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 18
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 6.65101
New value of Value function: 18.1477
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 19
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 17.2684
New value of Value function: 17.2684
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 20
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 9.37338
New value of Value function: 18.1477
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 21
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 18.8487
New value of Value function: 18.8487
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 22
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 20.2903
New value of Value function: 20.2903
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 23
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 22.4006
New value of Value function: 22.4006
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 24
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 18.7872
New value of Value function: 18.7872
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 80
New value of Q matrix: 21.3496
New value of Value function: 21.3496
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 26
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 80.7038
New value of Value function: 80.7038
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 27
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 10
New value of Q matrix: 99.4133
New value of Value function: 99.4133
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 17.2275
New value of Value function: 17.2275
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 19.0229
New value of Value function: 19.0229
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 17.5311
New value of Value function: 17.5311
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 21.8751
New value of Value function: 21.8751
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 33.5495
New value of Value function: 33.5495
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 61.8009
New value of Value function: 61.8009
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 7
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 31.8033
New value of Value function: 81.5725
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 8
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.95
New value of Value function: 61.8009
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 9
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 12.4889
New value of Value function: 12.4889
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 10
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 7.36402
New value of Value function: 10.6979
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 11
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 14.2799
New value of Value function: 14.2799
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 12
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 8.61775
New value of Value function: 10.6979
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 13
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 14.9354
New value of Value function: 14.9354
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 14
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 9.29226
New value of Value function: 10.6979
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 15
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 15.2286
New value of Value function: 15.2286
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 16
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 10.6411
New value of Value function: 10.6411
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 17
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 60.2009
New value of Value function: 60.2009
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 18
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 100.819
New value of Value function: 100.819
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 19
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 94
New value of Visit matrix: 8
New value of Q matrix: 97.116
New value of Value function: 97.116
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 16.2978
New value of Value function: 16.2978
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 9.23899
New value of Value function: 9.23899
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 9.42174
New value of Value function: 14.5437
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 4
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 7.58905
New value of Value function: 14.5437
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 5
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 18.3226
New value of Value function: 18.3226
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 6
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 14.8386
New value of Value function: 14.8386
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 7
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 18.7257
New value of Value function: 18.7257
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 8
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 19.9766
New value of Value function: 19.9766
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 9
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 20.5161
New value of Value function: 20.5161
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 10
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 19.5417
New value of Value function: 19.5417
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 11
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 15.3946
New value of Value function: 15.3946
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 21.0042
New value of Value function: 21.0042
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 13
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 17.4458
New value of Value function: 17.4458
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 14
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 35.3146
New value of Value function: 35.3146
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 15
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 79.567
New value of Value function: 79.567
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 16
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 80.9508
New value of Value function: 80.9508
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 17
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 78.8942
New value of Value function: 78.8942
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 18
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 87.7253
New value of Value function: 87.7253
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 19
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 11
New value of Q matrix: 99.5902
New value of Value function: 99.5902
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 15.9342
New value of Value function: 15.9342
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 10.9632
New value of Value function: 10.9632
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 15.7385
New value of Value function: 15.7385
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 4
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 20.6392
New value of Value function: 20.6392
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 5
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 21.585
New value of Value function: 21.585
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 6
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 21.505
New value of Value function: 21.505
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 7
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 9.17485
New value of Value function: 19.5417
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 8
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 14.3205
New value of Value function: 14.3205
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 9
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 19.7187
New value of Value function: 19.7187
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 10
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 14.4838
New value of Value function: 14.4838
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 11
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 11.6538
New value of Value function: 11.6538
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 8.08428
New value of Value function: 21.0042
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 20.981
New value of Value function: 20.981
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 83
New value of Q matrix: 20.891
New value of Value function: 20.891
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 15
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 17.9171
New value of Value function: 17.9171
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 16
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 11.7677
New value of Value function: 22.4006
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 17
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 21.4765
New value of Value function: 21.4765
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 18
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 20.4042
New value of Value function: 20.4042
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 19
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 21.7761
New value of Value function: 21.7761
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 20
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 46.9056
New value of Value function: 46.9056
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 21
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 6.19885
New value of Value function: 78.8942
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 84
New value of Q matrix: 27.4609
New value of Value function: 27.4609
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 23
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 80.2182
New value of Value function: 80.2182
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 24
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 92.3063
New value of Value function: 92.3063
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 25
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 12
New value of Q matrix: 99.7085
New value of Value function: 99.7085
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 15.9207
New value of Value function: 15.9207
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 12.4137
New value of Value function: 12.4137
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 10.6071
New value of Value function: 15.7385
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 4
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 16.9068
New value of Value function: 16.9068
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 5
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 22.3669
New value of Value function: 22.3669
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 6
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.55513
New value of Value function: 21.585
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 7
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 22.9432
New value of Value function: 22.9432
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 8
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 20.4231
New value of Value function: 20.4231
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 9
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 16.9016
New value of Value function: 16.9016
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 10
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 22.3308
New value of Value function: 22.3308
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 11
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 20.4968
New value of Value function: 20.4968
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 12
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 17.7286
New value of Value function: 17.7286
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 13
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 28.2312
New value of Value function: 28.2312
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 14
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 55.7469
New value of Value function: 55.7469
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 15
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 85.5095
New value of Value function: 85.5095
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 16
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 13
New value of Q matrix: 99.7894
New value of Value function: 99.7894
New value of Policy matrix: 4

=======================================
Simulation: 28
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 16.1458
New value of Value function: 16.1458
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 16
New value of Q matrix: 13.7447
New value of Value function: 13.7447
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 11.7657
New value of Value function: 16.9068
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 4
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 18.1841
New value of Value function: 18.1841
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 5
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 23.9104
New value of Value function: 23.9104
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 6
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 23.5744
New value of Value function: 23.5744
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 7
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 5.24581
New value of Value function: 20.4231
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 8
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 18.4821
New value of Value function: 18.4821
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 9
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 20.2556
New value of Value function: 20.2556
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 10
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 18.9002
New value of Value function: 18.9002
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 11
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 11.9134
New value of Value function: 22.3308
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 12
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 21.8706
New value of Value function: 21.8706
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 13
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 21.2146
New value of Value function: 21.2146
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 14
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 16.7707
New value of Value function: 16.7707
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 85
New value of Q matrix: 26.6086
New value of Value function: 26.6086
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 16
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 26.7317
New value of Value function: 26.7317
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 17
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 44.0978
New value of Value function: 44.0978
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 18
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 30.3345
New value of Value function: 30.3345
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 19
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 39.4568
New value of Value function: 39.4568
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 86
New value of Q matrix: 33.1913
New value of Value function: 33.1913
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 21
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 28.5066
New value of Value function: 85.5095
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 22
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 91.0161
New value of Value function: 91.0161
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 23
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 85.9086
New value of Value function: 85.9086
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 24
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 94.4304
New value of Value function: 94.4304
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 25
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 14
New value of Q matrix: 99.8457
New value of Value function: 99.8457
New value of Policy matrix: 4

=======================================
Simulation: 29
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 17.3928
New value of Value function: 17.3928
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 19.9136
New value of Value function: 19.9136
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 16
New value of Q matrix: 18.8124
New value of Value function: 18.8124
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 26.4067
New value of Value function: 26.4067
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 42.6004
New value of Value function: 42.6004
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 68.7163
New value of Value function: 68.7163
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 7
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 84.5403
New value of Value function: 84.5403
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 8
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 90.8125
New value of Value function: 90.8125
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 9
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 55.9908
New value of Value function: 100.819
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 10
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 93.0482
New value of Value function: 93.0482
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 11
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 101.364
New value of Value function: 101.364
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 12
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 13.5781
New value of Value function: 17.3928
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 2
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 18.5652
New value of Value function: 18.5652
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 3
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 20.8717
New value of Value function: 20.8717
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 4
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 17
New value of Q matrix: 20.8328
New value of Value function: 20.8328
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 5
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 31.9571
New value of Value function: 31.9571
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 6
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 6.8705
New value of Value function: 42.6004
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 7
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 7.95
New value of Value function: 7.95
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 8
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.84299
New value of Value function: 7.84299
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 9
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 18.4468
New value of Value function: 18.4468
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 13.6242
New value of Value function: 33.1913
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 10.0906
New value of Value function: 33.1913
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 33.1558
New value of Value function: 33.1558
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 88
New value of Q matrix: 31.8879
New value of Value function: 31.8879
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 14
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 14.6908
New value of Value function: 14.6908
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 15
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 12.1756
New value of Value function: 12.1756
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 89
New value of Q matrix: 34.6788
New value of Value function: 34.6788
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 17
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 70.6861
New value of Value function: 70.6861
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 18
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 94.8599
New value of Value function: 94.8599
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 19
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 101.761
New value of Value function: 101.761
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 20
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 94.0649
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 21
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 101.616
New value of Value function: 101.616
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 22
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 99
New value of Visit matrix: 9
New value of Q matrix: 97.744
New value of Value function: 97.744
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 18.5718
New value of Value function: 18.5718
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 17
New value of Q matrix: 15.0199
New value of Value function: 15.0199
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 15.6867
New value of Value function: 18.1841
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 4
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.577
New value of Value function: 11.577
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 5
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 4
New value of Q matrix: 4.02971
New value of Value function: 4.02971
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 6
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 6
New value of Q matrix: 8.16513
New value of Value function: 8.16513
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 7
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 5
New value of Q matrix: 3.15933
New value of Value function: 3.15933
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 8
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 8.16513
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 9
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.99
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 10
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.50018
New value of Value function: 5.50018
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 11
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 14.9997
New value of Value function: 14.9997
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 12
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 14.9903
New value of Value function: 14.9903
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 13
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 9.92463
New value of Value function: 9.92463
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 14
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 12.2224
New value of Value function: 12.2224
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 15
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.94759
New value of Value function: 7.87326
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 16
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 10.4269
New value of Value function: 10.4269
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 17
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 7.5655
New value of Value function: 7.5655
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 18
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 19
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 20
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 21
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 22
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 23
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 24
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 25
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.0462863
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 26
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 27
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -3.32319
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 28
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.962498
New value of Value function: 0.962498
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 29
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 18.4889
New value of Value function: 18.4889
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 15.3
New value of Value function: 34.6788
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 31
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 9.70322
New value of Value function: 9.70322
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 32
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.00217
New value of Value function: 8.00217
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 33
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 8.95952
New value of Value function: 8.95952
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 34
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 9.55905
New value of Value function: 10.4269
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 35
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 15.2253
New value of Value function: 15.2253
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 36
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 10.2635
New value of Value function: 10.2635
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 37
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 12.2996
New value of Value function: 12.2996
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 38
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 7.37086
New value of Value function: 7.37086
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 39
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 40
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 41
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 42
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 43
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 44
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 45
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 46
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 47
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 48
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 49
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 50
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 51
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 52
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 53
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 54
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 55
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 56
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 57
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 58
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 59
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 60
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 61
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 1.83219
New value of Value function: 1.83219
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 62
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 19.3759
New value of Value function: 19.3759
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 34.6422
New value of Value function: 34.6422
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 34.6059
New value of Value function: 34.6059
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 15.7278
New value of Value function: 34.6059
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 34.5698
New value of Value function: 34.5698
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 34.534
New value of Value function: 34.534
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 34.4984
New value of Value function: 34.4984
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 19.3196
New value of Value function: 34.4984
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 34.463
New value of Value function: 34.463
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 34.4278
New value of Value function: 34.4278
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 14.9881
New value of Value function: 34.4278
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 22.6656
New value of Value function: 34.4278
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 34.3928
New value of Value function: 34.3928
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 34.3581
New value of Value function: 34.3581
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 34.3236
New value of Value function: 34.3236
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 34.2892
New value of Value function: 34.2892
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 34.2551
New value of Value function: 34.2551
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 34.2212
New value of Value function: 34.2212
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 34.1875
New value of Value function: 34.1875
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 34.154
New value of Value function: 34.154
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 34.1206
New value of Value function: 34.1206
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 34.0875
New value of Value function: 34.0875
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 34.0545
New value of Value function: 34.0545
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 34.0218
New value of Value function: 34.0218
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 33.9892
New value of Value function: 33.9892
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 33.9568
New value of Value function: 33.9568
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 33.9245
New value of Value function: 33.9245
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 33.8925
New value of Value function: 33.8925
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 33.8606
New value of Value function: 33.8606
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 33.8289
New value of Value function: 33.8289
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 33.7973
New value of Value function: 33.7973
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 33.766
New value of Value function: 33.766
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 33.7348
New value of Value function: 33.7348
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 33.7037
New value of Value function: 33.7037
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 18.6638
New value of Value function: 33.7037
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 33.6728
New value of Value function: 33.6728
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 26.4382
New value of Value function: 33.6728
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 33.6421
New value of Value function: 33.6421
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 22.2359
New value of Value function: 33.6421
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 33.6115
New value of Value function: 33.6115
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 33.581
New value of Value function: 33.581
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 33.5508
New value of Value function: 33.5508
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 24.477
New value of Value function: 33.5508
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 33.5206
New value of Value function: 33.5206
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 33.4907
New value of Value function: 33.4907
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 33.4608
New value of Value function: 33.4608
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 26.2069
New value of Value function: 33.4608
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 33.4311
New value of Value function: 33.4311
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 33.4016
New value of Value function: 33.4016
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 33.3722
New value of Value function: 33.3722
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 21.4829
New value of Value function: 33.3722
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 33.3429
New value of Value function: 33.3429
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 33.3138
New value of Value function: 33.3138
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 33.2848
New value of Value function: 33.2848
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 33.2559
New value of Value function: 33.2559
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 23.6846
New value of Value function: 33.2559
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 33.2272
New value of Value function: 33.2272
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 11.9032
New value of Value function: 33.2272
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 33.1986
New value of Value function: 33.1986
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 33.1701
New value of Value function: 33.1701
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 33.1418
New value of Value function: 33.1418
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 138
New value of Q matrix: 32.8287
New value of Value function: 32.8287
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 124
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 27.3508
New value of Value function: 27.3508
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 139
New value of Q matrix: 32.5954
New value of Value function: 32.5954
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 126
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 26.3034
New value of Value function: 26.3034
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 127
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 13.8811
New value of Value function: 17.7286
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 128
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 19.4115
New value of Value function: 19.4115
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 129
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 21.5584
New value of Value function: 21.7761
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 130
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 19.7374
New value of Value function: 21.5584
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 131
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 20.5018
New value of Value function: 20.5018
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 132
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 22.9489
New value of Value function: 22.9489
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 133
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 31.8024
New value of Value function: 31.8024
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 134
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 44.8825
New value of Value function: 44.8825
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 135
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 26.5982
New value of Value function: 62.9501
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 136
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 47.6049
New value of Value function: 47.6049
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 137
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 74.9795
New value of Value function: 74.9795
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 138
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 15
New value of Q matrix: 98.5945
New value of Value function: 98.5945
New value of Policy matrix: 4

=======================================
Simulation: 32
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 19.6793
New value of Value function: 19.6793
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 22.0599
New value of Value function: 22.0599
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 15.7023
New value of Value function: 20.8328
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 4
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 18.5441
New value of Value function: 20.8328
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 5
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 23.6152
New value of Value function: 23.6152
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 6
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 35.8862
New value of Value function: 35.8862
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 7
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 4.88717
New value of Value function: 42.6004
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 8
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 43.1743
New value of Value function: 43.1743
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 9
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 50.7328
New value of Value function: 50.7328
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 10
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 74.2574
New value of Value function: 74.2574
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 11
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 90.8899
New value of Value function: 90.8899
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 101.65
New value of Value function: 101.65
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 13
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 99
New value of Visit matrix: 10
New value of Q matrix: 98.1412
New value of Value function: 98.1412
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 19.7087
New value of Value function: 19.7087
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 15.9585
New value of Value function: 15.9585
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 10.7935
New value of Value function: 18.1841
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 4
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 17.248
New value of Value function: 17.248
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 5
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.85237
New value of Value function: 9.85237
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 6
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 6
New value of Q matrix: 2.72012
New value of Value function: 2.72012
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 7
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 7
New value of Q matrix: 8.36461
New value of Value function: 8.36461
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 8
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 7
New value of Q matrix: 2.55413
New value of Value function: 2.55413
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 9
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 8
New value of Q matrix: 8.42259
New value of Value function: 8.42259
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 10
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 8
New value of Q matrix: 2.47785
New value of Value function: 2.47785
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 11
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 9
New value of Q matrix: 8.43275
New value of Value function: 8.43275
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 12
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 9
New value of Q matrix: 2.43471
New value of Value function: 2.43471
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 13
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 10
New value of Q matrix: 8.42567
New value of Value function: 8.42567
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 14
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 10
New value of Q matrix: 2.4052
New value of Value function: 2.4052
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 15
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 11
New value of Q matrix: 8.41225
New value of Value function: 8.41225
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 16
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 11
New value of Q matrix: 2.38196
New value of Value function: 2.38196
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 17
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 12
New value of Q matrix: 8.39663
New value of Value function: 8.39663
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 18
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.75385
New value of Value function: 4.75385
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 19
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.78705
New value of Value function: 9.78705
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 20
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 4.70812
New value of Value function: 4.70812
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 21
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 9.73561
New value of Value function: 9.73561
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 22
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.66778
New value of Value function: 4.66778
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 23
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.69233
New value of Value function: 9.69233
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 24
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 4.63159
New value of Value function: 4.63159
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 25
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.65448
New value of Value function: 9.65448
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 26
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 4.59865
New value of Value function: 4.59865
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 27
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 9.62054
New value of Value function: 9.62054
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 28
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 4.56831
New value of Value function: 4.56831
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 29
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 9.58958
New value of Value function: 9.58958
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 30
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 20.6519
New value of Value function: 20.6519
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 31
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 22.8185
New value of Value function: 22.8185
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 32
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 24.5467
New value of Value function: 24.5467
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 33
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 35.7102
New value of Value function: 35.7102
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 34
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 54.5122
New value of Value function: 54.5122
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 35
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 87.0188
New value of Value function: 87.0188
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 36
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 93.0667
New value of Value function: 93.0667
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 37
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 89.9863
New value of Value function: 89.9863
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 38
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 16
New value of Q matrix: 98.9459
New value of Value function: 98.9459
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 11.265
New value of Value function: 19.7087
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 2
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 17.7736
New value of Value function: 17.7736
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 3
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 3.87644
New value of Value function: 3.87644
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 4
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 5
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 6
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 7
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 8
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 9
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 17.0583
New value of Value function: 17.0583
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 10
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 16.8981
New value of Value function: 16.8981
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 11
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 15.6727
New value of Value function: 15.6727
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 12
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 2.57763
New value of Value function: 2.57763
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 13
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 14
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 15
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 16
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 17
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 18
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 19
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 20
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 21
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 22
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.55185
New value of Value function: 4.55185
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 23
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 2.57763
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 24
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 6.97
New value of Value function: 6.97
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 25
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.96457
New value of Value function: 8.96457
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 26
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.43518
New value of Value function: 6.50018
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 27
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.1781
New value of Value function: 10.1781
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 28
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 6.86465
New value of Value function: 6.86465
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 29
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 10.3112
New value of Value function: 10.3112
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 30
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 12.2655
New value of Value function: 12.2655
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 31
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 20.6425
New value of Value function: 20.6425
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 28.3819
New value of Value function: 32.5954
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 32.5678
New value of Value function: 32.5678
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 27.3905
New value of Value function: 32.5678
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 25.3019
New value of Value function: 32.5678
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 32.5404
New value of Value function: 32.5404
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 26.5856
New value of Value function: 32.5404
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 142
New value of Q matrix: 31.0729
New value of Value function: 31.0729
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 39
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 16.675
New value of Value function: 16.675
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 143
New value of Q matrix: 30.1059
New value of Value function: 30.1059
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 41
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 16.5083
New value of Value function: 16.675
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 42
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 16.675
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 43
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 90.981
New value of Value function: 90.981
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 44
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 92.9168
New value of Value function: 92.9168
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 45
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 104
New value of Value function: 104
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 46
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 5
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 35
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 12.8546
New value of Value function: 15.6727
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 2
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 16.8073
New value of Value function: 16.8073
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 3
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 4
New value of Q matrix: 4.0167
New value of Value function: 4.0167
New value of Policy matrix: 0

=======================================
Simulation: 35
Iteration: 4
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 2.55508
New value of Value function: 2.55508
New value of Policy matrix: 0

=======================================
Simulation: 35
Iteration: 5
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.53607
New value of Value function: 4.53607
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 6
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 26.8393
New value of Value function: 26.8393
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 7
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 23.5925
New value of Value function: 23.5925
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 8
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 26.5774
New value of Value function: 26.5774
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 9
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 40.721
New value of Value function: 40.721
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 10
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 6.11072
New value of Value function: 50.7328
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 11
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 10.5668
New value of Value function: 10.5668
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 12
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.922
New value of Value function: 16.922
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 13
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 20.5645
New value of Value function: 20.5645
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 14
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 14.0009
New value of Value function: 14.0009
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 15
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3.35238
New value of Value function: 3.35238
New value of Policy matrix: 0

=======================================
Simulation: 35
Iteration: 16
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 26.8048
New value of Value function: 26.8048
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 144
New value of Q matrix: 29.2227
New value of Value function: 29.2227
New value of Policy matrix: 0

=======================================
Simulation: 35
Iteration: 18
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 13.529
New value of Value function: 16.5083
New value of Policy matrix: 4

=======================================
Simulation: 35
Iteration: 19
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 8.85432
New value of Value function: 8.85432
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 20
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 60.6899
New value of Value function: 60.6899
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 21
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 92.3999
New value of Value function: 92.3999
New value of Policy matrix: 0

=======================================
Simulation: 35
Iteration: 22
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 50.1591
New value of Value function: 92.9168
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 23
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 80.3323
New value of Value function: 80.3323
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 24
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 61.0576
New value of Value function: 92.9168
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 25
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.0595
New value of Value function: 80.3323
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 26
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 57.2208
New value of Value function: 57.2208
New value of Policy matrix: 0

=======================================
Simulation: 35
Iteration: 27
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 66.953
New value of Value function: 80.3323
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 28
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 11.1104
New value of Value function: 80.3323
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 29
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 15.3536
New value of Value function: 15.3536
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 30
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 66.0626
New value of Value function: 66.0626
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 31
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 101.764
New value of Value function: 101.764
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 32
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 11
New value of Q matrix: 97.1941
New value of Value function: 97.1941
New value of Policy matrix: 4

=======================================
Simulation: 36
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 15.2469
New value of Value function: 15.6727
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 2
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 13.362
New value of Value function: 16.8073
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 3
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 13.3053
New value of Value function: 13.362
New value of Policy matrix: 4

=======================================
Simulation: 36
Iteration: 4
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.9003
New value of Value function: 4.0167
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 5
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 11.1454
New value of Value function: 11.1454
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 6
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.4932
New value of Value function: 12.4932
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 7
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 12.8196
New value of Value function: 12.8196
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 8
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 7.6914
New value of Value function: 10.5668
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 9
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 14.0009
New value of Value function: 14.0009
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 10
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 8.51837
New value of Value function: 10.5668
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 11
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 14.597
New value of Value function: 14.597
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 12
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 9.60386
New value of Value function: 9.60386
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 13
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 15.428
New value of Value function: 15.428
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 14
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 16.922
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 15
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 13.2738
New value of Value function: 13.2738
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 16
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 15.3109
New value of Value function: 15.3109
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 17
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 25.9305
New value of Value function: 25.9305
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 145
New value of Q matrix: 28.4363
New value of Value function: 28.4363
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 19
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 17.5683
New value of Value function: 17.5683
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 20
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 11.1069
New value of Value function: 11.1069
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 21
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 7.34291
New value of Value function: 7.34291
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 22
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 8.43064
New value of Value function: 8.43064
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 23
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 17.9756
New value of Value function: 17.9756
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 146
New value of Q matrix: 28.5274
New value of Value function: 28.5274
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 25
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 25.6998
New value of Value function: 25.6998
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 147
New value of Q matrix: 31.3775
New value of Value function: 31.3775
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 27
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 76.7322
New value of Value function: 76.7322
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 28
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 92.7392
New value of Value function: 92.7392
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 29
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 96.8117
New value of Value function: 96.8117
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 30
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 104
New value of Value function: 104
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 31
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 40.4166
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 36
Iteration: 32
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 37
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 17.5635
New value of Value function: 17.5635
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 25.4119
New value of Value function: 25.4119
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 29.8726
New value of Value function: 29.8726
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 40.3138
New value of Value function: 40.721
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 5
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 44.2389
New value of Value function: 44.2389
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 6
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 7.49469
New value of Value function: 50.7328
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 7
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 13.6816
New value of Value function: 13.6816
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 8
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 16.2332
New value of Value function: 16.2332
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 9
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 14.3502
New value of Value function: 14.3502
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 148
New value of Q matrix: 30.2126
New value of Value function: 30.2126
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 11
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 33.5802
New value of Value function: 33.5802
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 12
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 88.8118
New value of Value function: 88.8118
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 13
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 94.7914
New value of Value function: 94.7914
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 14
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 66.5573
New value of Value function: 96.8117
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 15
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 85.6283
New value of Value function: 85.6283
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 16
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 99.5239
New value of Value function: 99.5239
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 17
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 104
New value of Value function: 104
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 18
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 62.559
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 37
Iteration: 19
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 7
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 46
New value of Q matrix: 19.4204
New value of Value function: 19.4204
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 5.25356
New value of Value function: 25.4119
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 3
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 2.19446
New value of Value function: 8.29063
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 4
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 3
New value of Q matrix: 20.4835
New value of Value function: 20.4835
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 5
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 27.5138
New value of Value function: 27.5138
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 6
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 33.1292
New value of Value function: 33.1292
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 7
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 46.8284
New value of Value function: 46.8284
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 8
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 60.8127
New value of Value function: 60.8127
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 9
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 88.6821
New value of Value function: 88.6821
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 10
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 96.91
New value of Value function: 96.91
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 11
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 101.131
New value of Value function: 101.131
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 71.3139
New value of Value function: 101.764
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 13
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 104
New value of Value function: 104
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 14
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 8
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 39
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 47
New value of Q matrix: 19.6215
New value of Value function: 19.6215
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 16.6568
New value of Value function: 16.6568
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 19.4794
New value of Value function: 19.4794
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 4
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.396768
New value of Value function: 23.9104
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 5
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 10.6632
New value of Value function: 10.6632
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 6
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 19.6799
New value of Value function: 19.6799
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 7
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 19.5539
New value of Value function: 19.5539
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 8
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 23.2494
New value of Value function: 23.2494
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 9
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 14.4831
New value of Value function: 19.5539
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 10
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 22.381
New value of Value function: 22.381
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 11
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 22.0721
New value of Value function: 22.0721
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 12
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 12.7252
New value of Value function: 22.8185
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 13
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 10.1102
New value of Value function: 23.2494
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 14
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 14.7155
New value of Value function: 14.7155
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 15
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 24.2681
New value of Value function: 24.2681
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 16
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 27.9167
New value of Value function: 27.9167
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 17
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 40.8658
New value of Value function: 40.8658
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 18
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 62.764
New value of Value function: 62.764
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 19
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 89.7912
New value of Value function: 89.7912
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 92.7733
New value of Value function: 92.7733
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 21
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 92.0642
New value of Value function: 92.0642
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 22
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 17
New value of Q matrix: 97.9889
New value of Value function: 97.9889
New value of Policy matrix: 4

=======================================
Simulation: 40
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 48
New value of Q matrix: 19.8912
New value of Value function: 19.8912
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: 8.18408
New value of Value function: 16.6568
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 3
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 15.2122
New value of Value function: 16.8981
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 4
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 5
New value of Q matrix: 19.8462
New value of Value function: 19.8462
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 5
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 17.468
New value of Value function: 17.468
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 6
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 20.3647
New value of Value function: 20.3647
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 7
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 25.0493
New value of Value function: 25.0493
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 8
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 12.7091
New value of Value function: 23.2494
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 9
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 24.7408
New value of Value function: 24.7408
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 10
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 23.7101
New value of Value function: 23.7101
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 11
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 21.7698
New value of Value function: 21.7698
New value of Policy matrix: 0

=======================================
Simulation: 40
Iteration: 12
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 31.5741
New value of Value function: 31.5741
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 13
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 36.7247
New value of Value function: 36.7247
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 14
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 23.9376
New value of Value function: 23.9376
New value of Policy matrix: 0

=======================================
Simulation: 40
Iteration: 15
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 43.2428
New value of Value function: 43.2428
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 16
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 69.5775
New value of Value function: 69.5775
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 17
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 93.5797
New value of Value function: 93.5797
New value of Policy matrix: 0

=======================================
Simulation: 40
Iteration: 18
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 18
New value of Q matrix: 98.4629
New value of Value function: 98.4629
New value of Policy matrix: 4

=======================================
Simulation: 41
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 21.6551
New value of Value function: 21.6551
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 29.8134
New value of Value function: 29.8134
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 36.1633
New value of Value function: 36.1633
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 24.3009
New value of Value function: 46.8284
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 5
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 7.88866
New value of Value function: 36.1633
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 6
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 23.8951
New value of Value function: 23.8951
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 7
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 38.498
New value of Value function: 38.498
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 8
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 31.698
New value of Value function: 46.8284
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 9
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 40.307
New value of Value function: 40.307
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 10
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 51.0442
New value of Value function: 51.0442
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 11
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 68.8083
New value of Value function: 68.8083
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 12
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 92.6687
New value of Value function: 92.6687
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 13
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 57.8039
New value of Value function: 101.131
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 14
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 102.588
New value of Value function: 102.588
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 15
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 90.1271
New value of Value function: 94.8599
New value of Policy matrix: 0

=======================================
Simulation: 41
Iteration: 16
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 83.0617
New value of Value function: 83.0617
New value of Policy matrix: 0

=======================================
Simulation: 41
Iteration: 17
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 75.4429
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 41
Iteration: 18
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 95.2582
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 41
Iteration: 19
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 96.5647
New value of Value function: 97.1941
New value of Policy matrix: 4

=======================================
Simulation: 41
Iteration: 20
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 83.2952
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 41
Iteration: 21
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 9
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 42
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 21.7454
New value of Value function: 21.7454
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.3043
New value of Value function: 17.468
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 3
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.4452
New value of Value function: 10.4452
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 4
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.98
New value of Value function: 6.98
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 5
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 17.1766
New value of Value function: 17.1766
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 6
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 9.0806
New value of Value function: 12.2996
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 7
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 7.02422
New value of Value function: 12.2996
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 8
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 17.1766
New value of Value function: 17.1766
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 9
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 9.89977
New value of Value function: 12.2996
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 10
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 17.1766
New value of Value function: 17.1766
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 11
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 12.2989
New value of Value function: 12.2989
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 12
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 7.24397
New value of Value function: 7.24397
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 13
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.6413
New value of Value function: 5.6413
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 14
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 7.83641
New value of Value function: 7.83641
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 15
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 32.4987
New value of Value function: 32.4987
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 16
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 56.8132
New value of Value function: 56.8132
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 17
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 79.5597
New value of Value function: 79.5597
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 18
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 17
New value of Q matrix: 89.6181
New value of Value function: 89.6181
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 19
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 67.2583
New value of Value function: 79.5597
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 20
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 85.6388
New value of Value function: 85.6388
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 21
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 19
New value of Q matrix: 97.6685
New value of Value function: 97.6685
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 51
New value of Q matrix: 23.5335
New value of Value function: 23.5335
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 33.1064
New value of Value function: 33.1064
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 25
New value of Q matrix: 42.5523
New value of Value function: 42.5523
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 55.9806
New value of Value function: 55.9806
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 75.5832
New value of Value function: 75.5832
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 49.3608
New value of Value function: 92.6687
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 7
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 50.4207
New value of Value function: 75.5832
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 8
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 50.996
New value of Value function: 55.9806
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 9
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 61.1844
New value of Value function: 61.1844
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 10
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 80.5704
New value of Value function: 80.5704
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 11
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 94.3828
New value of Value function: 94.3828
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 12
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 99.2174
New value of Value function: 99.2174
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 13
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 103.354
New value of Value function: 103.354
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 14
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 41.1428
New value of Value function: 101.764
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 15
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 60.2009
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 16
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.53553
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 17
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 18
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 19
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 20
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 21
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 22
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 1.53553
New value of Value function: 1.53553
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 23
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 56.5989
New value of Value function: 56.5989
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 24
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 80.9737
New value of Value function: 80.9737
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 25
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 78.1436
New value of Value function: 101.764
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 26
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 96.3282
New value of Value function: 96.3282
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 27
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 101.646
New value of Value function: 101.646
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 28
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 94
New value of Visit matrix: 12
New value of Q matrix: 96.272
New value of Value function: 96.5647
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 25.5085
New value of Value function: 25.5085
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 36.0956
New value of Value function: 36.0956
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 17.6237
New value of Value function: 42.5523
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 4
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 32.943
New value of Value function: 32.943
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 5
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 46.2825
New value of Value function: 46.2825
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 6
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.18816
New value of Value function: 61.1844
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 7
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 24.5004
New value of Value function: 24.5004
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 8
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 27
New value of Q matrix: 41.2736
New value of Value function: 41.2736
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 9
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 28.6785
New value of Value function: 28.6785
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 10
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 38.1318
New value of Value function: 38.1318
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 11
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 28
New value of Q matrix: 45.1097
New value of Value function: 45.1097
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 12
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 66.2117
New value of Value function: 66.2117
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 13
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 84.6697
New value of Value function: 84.6697
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 14
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 82.2447
New value of Value function: 94.3828
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 15
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 97.3509
New value of Value function: 97.3509
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 16
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 102.414
New value of Value function: 102.414
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 17
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 97.4336
New value of Value function: 97.4336
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 18
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 101.935
New value of Value function: 101.935
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 19
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 42.4262
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 44
Iteration: 20
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 89.8417
New value of Value function: 89.8417
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 21
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 62.3349
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 44
Iteration: 22
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 93.7868
New value of Value function: 93.7868
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 23
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1286
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 98
New value of Visit matrix: 10
New value of Q matrix: 99.3675
New value of Value function: 99.3675
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 27.8769
New value of Value function: 27.8769
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 40.4847
New value of Value function: 40.4847
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 29
New value of Q matrix: 49.091
New value of Value function: 49.091
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 12.5804
New value of Value function: 66.2117
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 5
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 7.58801
New value of Value function: 28.6785
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 6
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 32.6098
New value of Value function: 32.6098
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 7
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 43.1078
New value of Value function: 43.1078
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 8
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 30
New value of Q matrix: 52.2785
New value of Value function: 52.2785
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 9
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 70.9265
New value of Value function: 70.9265
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 10
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 88.4057
New value of Value function: 88.4057
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 11
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 99.372
New value of Value function: 99.372
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 12
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 19
New value of Q matrix: 101.965
New value of Value function: 101.965
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 13
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 98.3484
New value of Value function: 98.3484
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 14
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 83.6375
New value of Value function: 101.935
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 15
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 25
New value of Q matrix: 99.0618
New value of Value function: 99.0618
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 16
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 23
New value of Q matrix: 102.026
New value of Value function: 102.026
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 17
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 11
New value of Q matrix: 99.5582
New value of Value function: 99.5582
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 30.5713
New value of Value function: 30.5713
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 45.7843
New value of Value function: 45.7843
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 31
New value of Q matrix: 55.68
New value of Value function: 55.68
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 75.3346
New value of Value function: 75.3346
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 91.673
New value of Value function: 91.673
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 100.807
New value of Value function: 100.807
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 7
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 77.2314
New value of Value function: 101.965
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 8
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 39.3321
New value of Value function: 100.807
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 9
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 82.3804
New value of Value function: 82.3804
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 10
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 101.902
New value of Value function: 101.902
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 11
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 79.3748
New value of Value function: 101.965
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 12
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 20
New value of Q matrix: 101.989
New value of Value function: 101.989
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 13
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 99.6392
New value of Value function: 99.6392
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 14
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 24
New value of Q matrix: 102.136
New value of Value function: 102.136
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 15
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 82.8959
New value of Value function: 99.5582
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 16
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 25
New value of Q matrix: 102.221
New value of Value function: 102.221
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 17
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 12
New value of Q matrix: 99.6858
New value of Value function: 99.6858
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 55
New value of Q matrix: 29.4551
New value of Value function: 29.4551
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 18.2739
New value of Value function: 18.2739
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 14
New value of Q matrix: 21.2825
New value of Value function: 21.2825
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 4
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 26.237
New value of Value function: 26.237
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 5
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 25.6738
New value of Value function: 25.6738
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 6
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 26.3854
New value of Value function: 26.3854
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 7
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 31.0569
New value of Value function: 31.0569
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 8
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 23.5817
New value of Value function: 23.5817
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 9
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 19.2821
New value of Value function: 19.2821
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 149
New value of Q matrix: 29.9247
New value of Value function: 29.9247
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 11
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 28.0359
New value of Value function: 28.0359
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 12
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 18.0191
New value of Value function: 43.2428
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 13
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 34.4076
New value of Value function: 34.4076
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 14
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 39.7717
New value of Value function: 39.7717
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 15
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 29.9654
New value of Value function: 29.9654
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 16
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 42.662
New value of Value function: 42.662
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 17
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 43.9445
New value of Value function: 43.9445
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 18
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 39.6948
New value of Value function: 69.5775
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 19
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 47.7899
New value of Value function: 69.5775
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 91.0384
New value of Value function: 91.0384
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 21
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 12.6216
New value of Value function: 93.5797
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 150
New value of Q matrix: 35.2906
New value of Value function: 35.2906
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 23
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 94.6696
New value of Value function: 94.6696
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 24
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1854
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 93
New value of Visit matrix: 20
New value of Q matrix: 96.6246
New value of Value function: 96.6246
New value of Policy matrix: 4

=======================================
Simulation: 48
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 32.2442
New value of Value function: 32.2442
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 48.5438
New value of Value function: 48.5438
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 32
New value of Q matrix: 59.1981
New value of Value function: 59.1981
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 79.4189
New value of Value function: 79.4189
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 94.7026
New value of Value function: 94.7026
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 23
New value of Q matrix: 101.969
New value of Value function: 101.969
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 7
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 98.3603
New value of Value function: 98.3603
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 8
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 102.786
New value of Value function: 102.786
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 9
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 21
New value of Q matrix: 102.132
New value of Value function: 102.132
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 10
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 98.6428
New value of Value function: 99.6392
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 11
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 100.132
New value of Value function: 100.132
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 102.313
New value of Value function: 102.313
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 13
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 95.7323
New value of Value function: 99.6858
New value of Policy matrix: 4

=======================================
Simulation: 48
Iteration: 14
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 96.2896
New value of Value function: 96.5647
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 15
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 101.983
New value of Value function: 101.983
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 16
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 97.2138
New value of Value function: 97.2138
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 17
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 13
New value of Q matrix: 99.7729
New value of Value function: 99.7729
New value of Policy matrix: 4

=======================================
Simulation: 49
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 31.0318
New value of Value function: 31.0318
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 19.0832
New value of Value function: 19.0832
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 15
New value of Q matrix: 22.2358
New value of Value function: 22.2358
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 4
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 27.3163
New value of Value function: 27.3163
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 5
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 26.9951
New value of Value function: 26.9951
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 6
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 29.029
New value of Value function: 29.029
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 7
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 32.8266
New value of Value function: 32.8266
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 8
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 45.5051
New value of Value function: 45.5051
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 9
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 3.26994
New value of Value function: 43.9445
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 10
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 7.11662
New value of Value function: 7.11662
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 11
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 2.02633
New value of Value function: 8.68383
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 12
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 9.21136
New value of Value function: 9.21136
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 13
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 8.44828
New value of Value function: 12.2989
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 14
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 9.53288
New value of Value function: 9.53288
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 15
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 12.2649
New value of Value function: 12.2649
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 16
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 15.8839
New value of Value function: 15.8839
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 17
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 44.0128
New value of Value function: 44.0128
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 18
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 65.9741
New value of Value function: 65.9741
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 19
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 14
New value of Q matrix: 86.5713
New value of Value function: 86.5713
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 93.2454
New value of Value function: 93.2454
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 21
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 21
New value of Q matrix: 97.3612
New value of Value function: 97.3612
New value of Policy matrix: 4

=======================================
Simulation: 50
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 11.3532
New value of Value function: 31.0318
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 2
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 5.79819
New value of Value function: 11.557
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 3
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 12.7673
New value of Value function: 12.7673
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 4
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.08445
New value of Value function: 11.557
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 5
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 20.1276
New value of Value function: 20.1276
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 6
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 58
New value of Q matrix: 30.0943
New value of Value function: 30.0943
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 7
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 19.9027
New value of Value function: 19.9027
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 8
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 24.3582
New value of Value function: 24.3582
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 9
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 28.5846
New value of Value function: 28.5846
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 10
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 30.7578
New value of Value function: 30.7578
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 11
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 35.7563
New value of Value function: 35.7563
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 12
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 36.2375
New value of Value function: 36.2375
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 13
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 36.3457
New value of Value function: 36.3457
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 14
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 25.4945
New value of Value function: 36.2375
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 15
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 31.1532
New value of Value function: 31.1532
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 16
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 38.8931
New value of Value function: 39.7717
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 17
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 23.6733
New value of Value function: 31.1532
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 18
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 32.4194
New value of Value function: 32.4194
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 19
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 46.7787
New value of Value function: 46.7787
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 20
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 24.1784
New value of Value function: 69.5775
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 21
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 44.2877
New value of Value function: 44.2877
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 22
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 32.2418
New value of Value function: 32.2418
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 23
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 34.74
New value of Value function: 34.74
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 24
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 42.7534
New value of Value function: 42.7534
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 25
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 55.3443
New value of Value function: 55.3443
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 26
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 40.5147
New value of Value function: 93.2454
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 27
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 75.4066
New value of Value function: 75.4066
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 28
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 95.4449
New value of Value function: 95.4449
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 29
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 22
New value of Q matrix: 97.9238
New value of Value function: 97.9238
New value of Policy matrix: 4

=======================================
Simulation: 51
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 59
New value of Q matrix: 33.084
New value of Value function: 33.084
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 51.3903
New value of Value function: 51.3903
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 33
New value of Q matrix: 62.7539
New value of Value function: 62.7539
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 4
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 83.2112
New value of Value function: 83.2112
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 97.2163
New value of Value function: 97.2163
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 6
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 25
New value of Q matrix: 102.504
New value of Value function: 102.504
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 7
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 99.6861
New value of Value function: 99.6861
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 8
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 102.345
New value of Value function: 102.345
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 9
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 95.6989
New value of Value function: 100.132
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 10
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 87.9202
New value of Value function: 99.7729
New value of Policy matrix: 4

=======================================
Simulation: 51
Iteration: 11
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 28
New value of Q matrix: 100.478
New value of Value function: 100.478
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 28
New value of Q matrix: 102.133
New value of Value function: 102.133
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 13
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 96.2354
New value of Value function: 99.7729
New value of Policy matrix: 4

=======================================
Simulation: 51
Iteration: 14
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 97.4945
New value of Value function: 97.4945
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 15
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 14
New value of Q matrix: 99.8336
New value of Value function: 99.8336
New value of Policy matrix: 4

=======================================
Simulation: 52
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 60
New value of Q matrix: 36.0265
New value of Value function: 36.0265
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 29
New value of Q matrix: 45.853
New value of Value function: 45.853
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 3
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 55.3266
New value of Value function: 55.3266
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 4
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 34
New value of Q matrix: 66.2911
New value of Value function: 66.2911
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 5
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 86.6816
New value of Value function: 86.6816
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 6
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 99.107
New value of Value function: 99.107
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 7
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 102.54
New value of Value function: 102.54
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 8
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 100.564
New value of Value function: 100.564
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 9
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 23
New value of Q matrix: 102.58
New value of Value function: 102.58
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 10
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 98.7742
New value of Value function: 100.478
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 11
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 15
New value of Q matrix: 99.8766
New value of Value function: 99.8766
New value of Policy matrix: 4

=======================================
Simulation: 53
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 61
New value of Q matrix: 34.5768
New value of Value function: 34.5768
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 20.9666
New value of Value function: 20.9666
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 3
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 17
New value of Q matrix: 24.7668
New value of Value function: 24.7668
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 4
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 28.8119
New value of Value function: 28.8119
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 5
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 17.639
New value of Value function: 28.5846
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 6
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 23.5238
New value of Value function: 28.5846
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 7
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 29.9001
New value of Value function: 29.9001
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 8
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 30.1597
New value of Value function: 30.1597
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 9
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 21.4454
New value of Value function: 30.7578
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 10
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 26.8732
New value of Value function: 26.8732
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 11
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 32.8027
New value of Value function: 32.8027
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 12
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 36.8154
New value of Value function: 36.8154
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 13
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 48.104
New value of Value function: 48.104
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 14
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 26.3962
New value of Value function: 55.3443
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 15
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 38.3926
New value of Value function: 42.7534
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 16
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 36.533
New value of Value function: 36.533
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 17
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 41.597
New value of Value function: 41.597
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 18
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 20.6421
New value of Value function: 22.9489
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 19
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 20
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 21
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 22
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 23
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 24
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 25
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 26
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 27
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 100.945
New value of Value function: 100.945
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 28
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 58.4449
New value of Value function: 97.9238
New value of Policy matrix: 4

=======================================
Simulation: 53
Iteration: 29
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 95.1906
New value of Value function: 95.1906
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 30
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 23
New value of Q matrix: 98.3567
New value of Value function: 98.3567
New value of Policy matrix: 4

=======================================
Simulation: 54
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 21.5845
New value of Value function: 34.5768
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 2
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 37.1417
New value of Value function: 37.1417
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 3
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 52.479
New value of Value function: 52.479
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 4
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 24.4431
New value of Value function: 45.853
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 5
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 36.7763
New value of Value function: 36.7763
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 6
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 50.3763
New value of Value function: 50.3763
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 7
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 35
New value of Q matrix: 69.7602
New value of Value function: 69.7602
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 8
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 8.8376
New value of Value function: 86.6816
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 9
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 16.0891
New value of Value function: 16.0891
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 10
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 13.4964
New value of Value function: 13.4964
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 11
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.14692
New value of Value function: 15.3109
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 12
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 17.488
New value of Value function: 17.488
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 13
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 22.8698
New value of Value function: 22.8698
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 14
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 33.1247
New value of Value function: 33.1247
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 151
New value of Q matrix: 35.3316
New value of Value function: 35.3316
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 16
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 49.1066
New value of Value function: 49.1066
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 17
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 94.2898
New value of Value function: 94.2898
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 18
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 101.194
New value of Value function: 101.194
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 19
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 84.0492
New value of Value function: 102.58
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 20
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 103.313
New value of Value function: 103.313
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 21
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 24
New value of Q matrix: 102.762
New value of Value function: 102.762
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 22
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 29
New value of Q matrix: 100.781
New value of Value function: 100.781
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 23
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 29
New value of Q matrix: 102.271
New value of Value function: 102.271
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 24
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1726
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 16
New value of Q matrix: 98.6574
New value of Value function: 98.6574
New value of Policy matrix: 4

=======================================
Simulation: 55
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 63
New value of Q matrix: 39.3756
New value of Value function: 39.3756
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 32.1671
New value of Value function: 50.3763
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 3
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 54.6305
New value of Value function: 54.6305
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 4
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 36
New value of Q matrix: 72.6027
New value of Value function: 72.6027
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 5
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 89.7874
New value of Value function: 89.7874
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 6
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 100.742
New value of Value function: 100.742
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 7
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 75.5571
New value of Value function: 103.313
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 8
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 102.024
New value of Value function: 102.024
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 9
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 103.959
New value of Value function: 103.959
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 10
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 25
New value of Q matrix: 102.964
New value of Value function: 102.964
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 11
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 30
New value of Q matrix: 101.049
New value of Value function: 101.049
New value of Policy matrix: 0

=======================================
Simulation: 55
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 30
New value of Q matrix: 102.161
New value of Value function: 102.161
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 13
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 17
New value of Q matrix: 98.9831
New value of Value function: 98.9831
New value of Policy matrix: 4

