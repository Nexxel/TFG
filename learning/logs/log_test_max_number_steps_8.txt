=======================================
Episode: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 0.3125
New value of Value function: 0.3125
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 23
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 24
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 25
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 26
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 27
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 28
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 29
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: -2.5
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 30
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: -2.5
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 31
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 32
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 33
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 34
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 35
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 36
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 37
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: -3
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 38
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -4.485
New value of Value function: -3
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 39
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -4.485
New value of Value function: -3
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 40
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -4.485
New value of Value function: -3
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 41
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -3.99
New value of Value function: -3
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 42
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 43
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -4.975
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 44
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 3
New value of Q matrix: -2.5
New value of Value function: -2.5
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 45
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -4.975
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 46
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -2.625
New value of Value function: -2.5
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 47
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 48
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 49
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: -2.5
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 50
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -2.75
New value of Value function: -2.5
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 51
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 52
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -3.7375
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 53
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -3.7375
New value of Value function: -2.75
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 54
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -2.83333
New value of Value function: -2.83333
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 55
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 56
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: -2.5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 57
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -3.9875
New value of Value function: -3
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 58
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -3.99
New value of Value function: -3
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 59
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -4.485
New value of Value function: -3
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 60
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -4.485
New value of Value function: -3.99
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 61
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -4.485
New value of Value function: -4.485
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 62
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -4.485
New value of Value function: -3
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 63
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -4.485
New value of Value function: -3.7375
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 64
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -4.72504
New value of Value function: -3.9875
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 65
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -4.97421
New value of Value function: -3.99
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 66
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -4.73002
New value of Value function: -4.485
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 67
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -5.40382
New value of Value function: -4.485
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 68
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -5.47005
New value of Value function: -4.485
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 69
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -5.47005
New value of Value function: -4.73002
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 70
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -6.02322
New value of Value function: -4.73002
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 71
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -5.32056
New value of Value function: -4.97421
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 72
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -6.40347
New value of Value function: -4.97421
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 73
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -5.71177
New value of Value function: -5.32056
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 74
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: -5.67383
New value of Value function: -5.40382
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 75
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -5.47005
New value of Value function: -4.485
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 76
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -5.07603
New value of Value function: -4.485
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 77
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -5.96257
New value of Value function: -4.485
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 78
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -5.47005
New value of Value function: -4.485
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 79
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -5.47005
New value of Value function: -4.485
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 80
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -5.47005
New value of Value function: -5.07603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 81
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -6.10885
New value of Value function: -5.07603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 82
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: -5.56757
New value of Value function: -5.47005
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 83
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -6.20637
New value of Value function: -5.47005
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 84
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3.5
New value of Visit matrix: 5
New value of Q matrix: -5.47006
New value of Value function: -5.47005
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 85
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -8.41535
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 86
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: -5.96503
New value of Value function: -5.47005
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 87
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -4.92305
New value of Value function: -4.92305
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 88
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -4.975
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 89
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -3.7375
New value of Value function: -2.5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 90
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -3.23021
New value of Value function: -2.5
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.103125
New value of Value function: 0.3125
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 0.442647
New value of Value function: 0.442647
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 93
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -3.7375
New value of Value function: -2.5
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 94
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -3.7375
New value of Value function: -2.625
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 95
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 3
New value of Q matrix: -4.19125
New value of Value function: -2.625
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 96
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -2.7
New value of Value function: -2.7
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 97
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -7.87382
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 98
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: -4.60255
New value of Value function: -4.60255
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 99
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -5.305
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 100
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -4.01413
New value of Value function: -3
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 101
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: -6.59564
New value of Value function: -4.60255
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 102
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 7
New value of Q matrix: -4.68404
New value of Value function: -4.68404
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 103
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: -3.52287
New value of Value function: -3.23021
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 104
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 8
New value of Q matrix: -4.81077
New value of Value function: -4.81077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 105
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 4
New value of Q matrix: -3.84713
New value of Value function: -3.52287
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 106
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 3
New value of Q matrix: -4.48755
New value of Value function: -3.52287
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 107
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 7
New value of Q matrix: -3.87498
New value of Value function: -3.7375
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 108
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -3.49167
New value of Value function: -3.49167
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 109
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 110
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: -3
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 111
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -4.47837
New value of Value function: -3
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 112
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 4
New value of Q matrix: -4.10794
New value of Value function: -3.84713
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 113
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 5
New value of Q matrix: -4.33944
New value of Value function: -3.87498
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 114
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: -4.13685
New value of Value function: -4.10794
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 115
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -4.97558
New value of Value function: -3
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 116
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -4.485
New value of Value function: -4.485
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 117
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -5.47005
New value of Value function: -4.975
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 118
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -5.77093
New value of Value function: -4.97558
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 119
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 5
New value of Q matrix: -4.59972
New value of Value function: -4.13685
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 120
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 6
New value of Q matrix: -4.71545
New value of Value function: -4.13685
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 121
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 9
New value of Q matrix: -4.41004
New value of Value function: -4.19125
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 122
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 4
New value of Q matrix: -4.80577
New value of Value function: -4.41004
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 123
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: -4.7453
New value of Value function: -4.48755
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 124
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 9
New value of Q matrix: -5.04765
New value of Value function: -5.04765
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 125
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 4
New value of Q matrix: -5.10133
New value of Value function: -4.59972
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 126
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 6
New value of Q matrix: -5.00872
New value of Value function: -4.71545
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 127
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 7
New value of Q matrix: -5.06585
New value of Value function: -4.7453
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 128
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 8
New value of Q matrix: -4.74512
New value of Value function: -4.74512
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 129
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 130
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 131
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 132
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 3
New value of Q matrix: -4.06589
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 133
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 9
New value of Q matrix: -5.01763
New value of Value function: -4.7453
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 134
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: -5.04092
New value of Value function: -4.80577
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 135
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 5
New value of Q matrix: -6.02096
New value of Value function: -5.04765
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 136
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 5
New value of Q matrix: -5.29616
New value of Value function: -5.00872
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 137
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 7
New value of Q matrix: -5.07462
New value of Value function: -5.01763
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 138
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -5.49859
New value of Value function: -3.7375
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 139
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 10
New value of Q matrix: -5.1629
New value of Value function: -5.1629
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 140
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 3
New value of Q matrix: -4.55837
New value of Value function: -4.01413
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 141
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 5
New value of Q matrix: -4.5061
New value of Value function: -4.5061
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 142
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -6.22123
New value of Value function: -4.5061
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 143
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 10
New value of Q matrix: -5.26261
New value of Value function: -5.04092
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 144
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 5
New value of Q matrix: -5.57916
New value of Value function: -5.04092
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 145
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -5.17376
New value of Value function: -5.04092
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.186899
New value of Value function: 0.442647
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 0.418583
New value of Value function: 0.418583
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 148
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 12
New value of Q matrix: -5.24506
New value of Value function: -5.07462
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 149
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 7
New value of Q matrix: -5.50949
New value of Value function: -5.07462
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 150
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: -5.4542
New value of Value function: -5.24506
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 151
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 11
New value of Q matrix: -5.39287
New value of Value function: -5.39287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 152
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 11
New value of Q matrix: -5.48352
New value of Value function: -5.24506
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 153
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 13
New value of Q matrix: -5.43333
New value of Value function: -5.43333
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 154
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: -5.64087
New value of Value function: -5.4542
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 155
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 12
New value of Q matrix: -5.60177
New value of Value function: -5.47005
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 156
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: -5.78322
New value of Value function: -5.48352
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 157
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 4
New value of Q matrix: -5.8428
New value of Value function: -5.60177
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 158
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: -5.17938
New value of Value function: -4.55837
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 159
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 13
New value of Q matrix: -5.78076
New value of Value function: -5.67383
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 160
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 12
New value of Q matrix: -5.68728
New value of Value function: -5.50949
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 161
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 8
New value of Q matrix: -5.81511
New value of Value function: -5.57916
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 162
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 6
New value of Q matrix: -5.06597
New value of Value function: -5.06597
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 163
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 164
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 1
New value of Q matrix: -2.5
New value of Value function: -2.5
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 165
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -3.7375
New value of Value function: -2.5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 166
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.5428
New value of Value function: -2.5
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.418362
New value of Value function: 0.418362
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 0.396679
New value of Value function: 0.396679
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 169
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 9
New value of Q matrix: -6.00402
New value of Value function: -5.06597
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 170
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 7
New value of Q matrix: -5.41588
New value of Value function: -5.41588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 171
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -5.3148
New value of Value function: -5.3148
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.39649
New value of Value function: 0.39649
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.130842
New value of Value function: 0.39649
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 0.366574
New value of Value function: 0.366574
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 175
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 10
New value of Q matrix: -5.98106
New value of Value function: -5.3148
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 176
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 9
New value of Q matrix: -5.58668
New value of Value function: -5.58668
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 177
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: -5.49172
New value of Value function: -5.49172
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.366415
New value of Value function: 0.366415
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.36275
New value of Value function: 0.366415
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 0.332947
New value of Value function: 0.36275
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 181
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 11
New value of Q matrix: -5.714
New value of Value function: -5.64087
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 182
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 15
New value of Q matrix: -5.80378
New value of Value function: -5.68728
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 183
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 13
New value of Q matrix: -5.87521
New value of Value function: -5.714
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 184
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 12
New value of Q matrix: -5.91757
New value of Value function: -5.80378
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 185
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 16
New value of Q matrix: -5.9564
New value of Value function: -5.87521
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 186
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 14
New value of Q matrix: -6.04959
New value of Value function: -5.91757
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 187
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 13
New value of Q matrix: -6.10532
New value of Value function: -5.9564
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 188
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 17
New value of Q matrix: -6.09996
New value of Value function: -5.98106
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 189
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 11
New value of Q matrix: -6.2029
New value of Value function: -6.00402
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 190
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 10
New value of Q matrix: -6.24801
New value of Value function: -6.04959
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 191
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 15
New value of Q matrix: -6.21222
New value of Value function: -6.09996
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 192
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 18
New value of Q matrix: -6.23546
New value of Value function: -6.10532
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 193
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 12
New value of Q matrix: -6.39801
New value of Value function: -6.10532
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 194
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 16
New value of Q matrix: -6.35798
New value of Value function: -6.10532
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 195
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 14
New value of Q matrix: -6.27953
New value of Value function: -6.23546
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 196
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 19
New value of Q matrix: -6.36375
New value of Value function: -6.24801
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 197
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 11
New value of Q matrix: -6.46961
New value of Value function: -6.27953
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 198
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 15
New value of Q matrix: -6.44202
New value of Value function: -6.35798
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 199
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 17
New value of Q matrix: -6.27662
New value of Value function: -6.27662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 200
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -3.7375
New value of Value function: -2.5
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 201
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 2
New value of Q matrix: -5.60693
New value of Value function: -3.5428
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 202
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 18
New value of Q matrix: -6.26167
New value of Value function: -6.26167
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 203
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 3
New value of Q matrix: -4.36433
New value of Value function: -3.7375
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 204
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -4.03863
New value of Value function: -3.7375
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.360937
New value of Value function: 0.360937
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.359734
New value of Value function: 0.359734
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.358834
New value of Value function: 0.358834
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 0.271668
New value of Value function: 0.358834
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 209
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 19
New value of Q matrix: -6.38995
New value of Value function: -6.36375
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 210
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 20
New value of Q matrix: -6.48557
New value of Value function: -6.38995
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 211
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 20
New value of Q matrix: -6.51175
New value of Value function: -6.39801
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 212
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 13
New value of Q matrix: -6.5854
New value of Value function: -6.44202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 213
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 16
New value of Q matrix: -6.59424
New value of Value function: -6.46961
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 214
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 12
New value of Q matrix: -6.67255
New value of Value function: -6.48557
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 215
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 21
New value of Q matrix: -6.60153
New value of Value function: -6.51175
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 216
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 21
New value of Q matrix: -6.6277
New value of Value function: -6.5854
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 217
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 14
New value of Q matrix: -6.75926
New value of Value function: -6.59424
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 218
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2.5
New value of Visit matrix: 15
New value of Q matrix: -6.91053
New value of Value function: -6.59424
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 219
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 17
New value of Q matrix: -6.73742
New value of Value function: -6.60153
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 220
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 18
New value of Q matrix: -6.86509
New value of Value function: -6.60153
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 221
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2.5
New value of Visit matrix: 22
New value of Q matrix: -6.71217
New value of Value function: -6.6277
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 222
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2.5
New value of Visit matrix: 22
New value of Q matrix: -6.73832
New value of Value function: -6.67255
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 223
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 13
New value of Q matrix: -6.85972
New value of Value function: -6.71217
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 224
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 19
New value of Q matrix: -6.98509
New value of Value function: -6.71217
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 225
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: -6.76892
New value of Value function: -6.71217
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.358117
New value of Value function: 0.358117
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.186765
New value of Value function: 0.358117
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.35752
New value of Value function: 0.35752
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 0.492142
New value of Value function: 0.492142
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 230
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2.5
New value of Visit matrix: 3
New value of Q matrix: -4.55837
New value of Value function: -4.03863
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 231
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2.5
New value of Visit matrix: 4
New value of Q matrix: -4.65353
New value of Value function: -4.06589
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 232
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -4.54698
New value of Value function: -4.06589
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.162407
New value of Value function: 0.492142
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.491527
New value of Value function: 0.491527
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.490981
New value of Value function: 0.490981
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.49049
New value of Value function: 0.49049
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.490044
New value of Value function: 0.490044
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.489635
New value of Value function: 0.489635
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.489259
New value of Value function: 0.489259
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 0.811455
New value of Value function: 0.811455
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 241
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 242
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -7.92583
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 243
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -6.48923
New value of Value function: -4.97558
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 244
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -4.78085
New value of Value function: -4.78085
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.810914
New value of Value function: 0.810914
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 1.07273
New value of Value function: 1.07273
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 247
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 248
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 249
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: -3
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 250
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.469
New value of Value function: -3
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.0721
New value of Value function: 1.0721
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.0715
New value of Value function: 1.0715
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.07094
New value of Value function: 1.07094
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.07041
New value of Value function: 1.07041
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.0699
New value of Value function: 1.0699
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 1.06941
New value of Value function: 1.06941
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.386484
New value of Value function: 1.06941
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.301939
New value of Value function: 1.06941
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 1.06894
New value of Value function: 1.06894
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.32995
New value of Value function: 1.06894
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.355961
New value of Value function: 1.06894
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 1.0685
New value of Value function: 1.0685
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 1.06807
New value of Value function: 1.06807
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 1.06766
New value of Value function: 1.06766
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.360809
New value of Value function: 1.06766
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 1.06727
New value of Value function: 1.06727
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 1.06688
New value of Value function: 1.06688
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.52043
New value of Value function: 1.06688
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.609728
New value of Value function: 1.06688
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 1.06652
New value of Value function: 1.06652
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 1.06616
New value of Value function: 1.06616
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.673409
New value of Value function: 1.06616
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 1.06582
New value of Value function: 1.06582
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.721128
New value of Value function: 1.06582
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.360551
New value of Value function: 1.06582
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 1.06548
New value of Value function: 1.06548
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 1.06516
New value of Value function: 1.06516
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 1.06485
New value of Value function: 1.06485
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.758136
New value of Value function: 1.06485
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 1.06454
New value of Value function: 1.06454
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.476109
New value of Value function: 1.06454
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 1.06425
New value of Value function: 1.06425
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.787683
New value of Value function: 1.06425
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 1.06396
New value of Value function: 1.06396
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 1.06368
New value of Value function: 1.06368
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 1.06341
New value of Value function: 1.06341
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 1.06314
New value of Value function: 1.06314
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 1.06288
New value of Value function: 1.06288
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 1.06263
New value of Value function: 1.06263
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 1.06238
New value of Value function: 1.06238
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 1.06214
New value of Value function: 1.06214
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 1.0619
New value of Value function: 1.0619
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 1.06167
New value of Value function: 1.06167
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 1.06145
New value of Value function: 1.06145
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.06123
New value of Value function: 1.06123
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 1.06101
New value of Value function: 1.06101
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.379907
New value of Value function: 1.06101
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 1.0608
New value of Value function: 1.0608
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 1.06059
New value of Value function: 1.06059
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 1.06039
New value of Value function: 1.06039
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.81151
New value of Value function: 1.06039
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.558062
New value of Value function: 1.06039
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 1.06019
New value of Value function: 1.06019
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.83135
New value of Value function: 1.06019
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 1.05999
New value of Value function: 1.05999
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.619478
New value of Value function: 1.05999
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 1.0598
New value of Value function: 1.0598
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.848107
New value of Value function: 1.0598
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.475541
New value of Value function: 1.0598
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.05961
New value of Value function: 1.05961
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 1.05942
New value of Value function: 1.05942
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.862444
New value of Value function: 1.05942
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 1.05924
New value of Value function: 1.05924
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.402199
New value of Value function: 1.05924
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 1.05906
New value of Value function: 1.05906
New value of Policy matrix: 3

