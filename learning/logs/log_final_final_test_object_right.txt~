=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 27
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 1.63246
New value of Value function: 1.63246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 33
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 34
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.82843
New value of Value function: 3.82843
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 39
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.20986
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.50484
New value of Value function: 4.50484
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 41
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 42
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 46
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.38387
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 3.38946
New value of Value function: 3.38946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 48
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.75242
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 49
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 50
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.355567
New value of Value function: 0.355567
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 3.27703
New value of Value function: 3.27703
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 52
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.295107
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 53
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 54
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 55
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 56
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 57
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 58
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.232605
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 4.5051
New value of Value function: 4.5051
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 60
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.949747
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 61
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.70489
New value of Value function: 1.70489
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 3.07429
New value of Value function: 3.07429
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 63
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 64
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 65
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 66
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 67
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 68
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.74465
New value of Value function: 0.74465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 4.91627
New value of Value function: 4.91627
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 70
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.88128
New value of Value function: 5.88128
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 71
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.17157
New value of Value function: 2.17157
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 72
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.14986
New value of Value function: 1.14986
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 73
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.0078
New value of Value function: 4.0078
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 74
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.91934
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 75
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 3.16521
New value of Value function: 3.16521
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 77
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 78
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 10
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 79
----------
State: 4293
	Distance: 10
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 80
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.53553
New value of Value function: 3.53553
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 83
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 86
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 87
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 88
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 89
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 10
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -1.35059
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 90
----------
State: 4293
	Distance: 10
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.10011
New value of Value function: 4.10011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 91
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 92
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 93
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 94
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 95
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 96
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 98
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 99
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -1.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 100
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 101
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 102
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 103
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 104
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 105
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 2.48553
New value of Value function: 2.48553
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 106
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 107
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 108
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 109
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 110
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 111
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 112
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.599929
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 113
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 114
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 115
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 116
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 117
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.265107
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 118
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 119
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 121
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 122
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 123
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 124
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 125
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 126
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 127
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 128
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: -0.464466
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 129
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 130
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 131
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.53932
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 132
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 3.35991
New value of Value function: 3.35991
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 133
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 134
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 135
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 136
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 137
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 1.34245
New value of Value function: 1.34245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 138
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 139
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 140
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 141
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 142
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.34205
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.49514
New value of Value function: 2.49514
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 144
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.54819
New value of Value function: 5.54819
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 145
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 1.53553
New value of Value function: 1.53553
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.52981
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.50004
New value of Value function: 4.50004
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.45504
New value of Value function: 4.0078
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 150
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.23388
New value of Value function: 5.23388
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 151
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.5039
New value of Value function: 4.5039
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 152
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.266763
New value of Value function: 0.266763
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 4.48968
New value of Value function: 4.48968
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 154
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.399042
New value of Value function: 0.266763
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 155
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.264096
New value of Value function: 0.266763
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 156
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.264096
New value of Value function: 0.266763
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 157
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: -0.299838
New value of Value function: 0.264096
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 158
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 3.79813
New value of Value function: 3.79813
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 159
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.262571
New value of Value function: 0.262571
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 160
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.261258
New value of Value function: 0.261258
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 161
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.26009
New value of Value function: 0.26009
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 162
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.259028
New value of Value function: 0.259028
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 163
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.258049
New value of Value function: 0.258049
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 164
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.257137
New value of Value function: 0.257137
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 165
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 0.281467
New value of Value function: 0.281467
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 166
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.44478
New value of Value function: 1.44478
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 4.18692
New value of Value function: 4.18692
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 168
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 0.0686391
New value of Value function: 0.257137
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 169
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 4.02635
New value of Value function: 4.02635
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 170
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.25628
New value of Value function: 0.25628
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 171
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.255469
New value of Value function: 0.255469
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 172
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.254699
New value of Value function: 0.254699
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 173
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.253964
New value of Value function: 0.253964
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 174
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 175
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.14505
New value of Value function: 1.14505
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 4.17399
New value of Value function: 4.17399
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 177
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.87091
New value of Value function: 3.87091
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 178
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 179
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.13225
New value of Value function: 1.13225
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.37742
New value of Value function: 4.17399
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.16415
New value of Value function: 4.16415
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 3.89708
New value of Value function: 3.89708
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 183
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.858106
New value of Value function: 0.858106
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 3.69648
New value of Value function: 3.69648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 185
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.65952
New value of Value function: 0.65952
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 3.68698
New value of Value function: 3.68698
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 187
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.652865
New value of Value function: 0.652865
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 3.67831
New value of Value function: 3.67831
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 189
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.646321
New value of Value function: 0.646321
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.37637
New value of Value function: 3.67831
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 3.6703
New value of Value function: 3.6703
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 192
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.639957
New value of Value function: 0.639957
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 3.6628
New value of Value function: 3.6628
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 194
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.63379
New value of Value function: 0.63379
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.08853
New value of Value function: 3.6628
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.65547
New value of Value function: 3.65547
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 3.64998
New value of Value function: 3.64998
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 198
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 0.625497
New value of Value function: 0.625497
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 3.64406
New value of Value function: 3.64406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 200
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 0.61874
New value of Value function: 0.61874
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.63717
New value of Value function: 3.63717
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 3.51885
New value of Value function: 3.51885
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 3
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3941
	Distance: 9
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 4
----------
State: 3941
	Distance: 9
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 5
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 6
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 7
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 8
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 9
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 10
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 11
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 12
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 13
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 14
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 15
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.483666
New value of Value function: 0.483666
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.50918
New value of Value function: 3.51885
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.51243
New value of Value function: 3.51243
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 4.30944
New value of Value function: 4.30944
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 19
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 20
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 21
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 22
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 23
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.26635
New value of Value function: 1.26635
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 4.25297
New value of Value function: 4.25297
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 25
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.3094
New value of Value function: 3.3094
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 26
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 27
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.21044
New value of Value function: 1.21044
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 4.03486
New value of Value function: 4.03486
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 29
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.994508
New value of Value function: 0.994508
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.93796
New value of Value function: 4.03486
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 4.02794
New value of Value function: 4.02794
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 4.02061
New value of Value function: 4.02061
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 33
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -2.80166
New value of Value function: 0.994508
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 34
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.04778
New value of Value function: 1.04778
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 4.0146
New value of Value function: 4.0146
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 36
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.984563
New value of Value function: 0.994508
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 37
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.984563
New value of Value function: 0.994508
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 38
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0.994508
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 39
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.98456
New value of Value function: 2.98456
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 40
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.980327
New value of Value function: 0.984563
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 4.00804
New value of Value function: 4.00804
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 42
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.978879
New value of Value function: 0.980327
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 43
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.973188
New value of Value function: 0.978879
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 3.84452
New value of Value function: 3.84452
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 45
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 46
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.04528
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 47
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.40969
New value of Value function: 4.40969
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 48
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 49
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.806071
New value of Value function: 0.806071
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 4.18487
New value of Value function: 4.18487
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 51
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3.70004
New value of Value function: 3.70004
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 52
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.70711
New value of Value function: 1.70711
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 53
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 54
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.309964
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 55
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 1.87621
New value of Value function: 1.87621
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 56
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 57
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 58
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 59
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.14302
New value of Value function: 1.14302
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 4.17644
New value of Value function: 4.17644
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 61
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.13712
New value of Value function: 1.13712
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 4.16852
New value of Value function: 4.16852
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 63
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -1.36807
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 64
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.03289
New value of Value function: 1.03289
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.2677
New value of Value function: 4.16852
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 4.16209
New value of Value function: 4.16209
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 3.98488
New value of Value function: 3.98488
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 68
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 69
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: -2.17275
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 70
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.02693
New value of Value function: 1.02693
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 71
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.01666
New value of Value function: 1.02693
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 72
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.02179
New value of Value function: 1.02179
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 73
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.01722
New value of Value function: 1.01722
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 74
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.01307
New value of Value function: 1.01666
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 75
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.00947
New value of Value function: 1.01307
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 76
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.00924
New value of Value function: 1.00947
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 77
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.00364
New value of Value function: 1.00924
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 78
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.00567
New value of Value function: 1.00567
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 79
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.00232
New value of Value function: 1.00364
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 80
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.945026
New value of Value function: 1.00364
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 3.8364
New value of Value function: 3.8364
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 82
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 83
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.33696
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 84
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.36827
New value of Value function: 4.36827
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 85
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 1.9381
New value of Value function: 1.9381
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 86
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 87
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.449059
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 88
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 1.96578
New value of Value function: 1.96578
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 89
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -0.844176
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 1.995
New value of Value function: 3.8364
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 91
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.88637
New value of Value function: 6.88637
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 92
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.6572
New value of Value function: 4.6572
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 93
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 1.96578
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 94
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2293
	Distance: 5
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 95
----------
State: 2293
	Distance: 5
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.94613
New value of Value function: 6.94613
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 96
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.535534
New value of Value function: 1.96578
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 97
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 98
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 99
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 100
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 101
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 102
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 103
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 104
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 105
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 106
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 107
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 108
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 109
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 110
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 111
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 112
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 113
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 114
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 115
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 116
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 117
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 118
----------
State: 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.798036
New value of Value function: 0.798036
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.83068
New value of Value function: 3.83068
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.40792
New value of Value function: 3.83068
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.82503
New value of Value function: 3.82503
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.81945
New value of Value function: 3.81945
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.81394
New value of Value function: 3.81394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.80849
New value of Value function: 3.80849
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.22279
New value of Value function: 3.80849
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.80311
New value of Value function: 3.80311
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.79778
New value of Value function: 3.79778
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.79251
New value of Value function: 3.79251
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.7873
New value of Value function: 3.7873
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.74943
New value of Value function: 3.7873
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.78215
New value of Value function: 3.78215
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.77732
New value of Value function: 3.78215
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.77705
New value of Value function: 3.77705
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.772
New value of Value function: 3.772
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.76701
New value of Value function: 3.76701
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.76206
New value of Value function: 3.76206
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.75716
New value of Value function: 3.75716
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.75231
New value of Value function: 3.75231
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.72494
New value of Value function: 3.75231
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.74751
New value of Value function: 3.74751
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.74275
New value of Value function: 3.74275
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.71697
New value of Value function: 3.74275
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.73803
New value of Value function: 3.73803
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.71092
New value of Value function: 3.73803
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.73336
New value of Value function: 3.73336
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.02657
New value of Value function: 3.73336
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.72873
New value of Value function: 3.72873
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.72414
New value of Value function: 3.72414
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.22567
New value of Value function: 3.72414
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.71959
New value of Value function: 3.71959
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.71508
New value of Value function: 3.71508
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.35623
New value of Value function: 3.71508
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.71061
New value of Value function: 3.71092
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.69236
New value of Value function: 3.71061
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.70617
New value of Value function: 3.70617
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.70177
New value of Value function: 3.70177
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.69741
New value of Value function: 3.69741
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.69308
New value of Value function: 3.69308
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.47201
New value of Value function: 3.69308
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.67617
New value of Value function: 3.69308
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.68879
New value of Value function: 3.68879
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.68453
New value of Value function: 3.68453
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.68031
New value of Value function: 3.68031
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.67611
New value of Value function: 3.67617
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.66116
New value of Value function: 3.67611
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.67195
New value of Value function: 3.67195
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.66782
New value of Value function: 3.66782
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.5118
New value of Value function: 3.66782
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.66372
New value of Value function: 3.66372
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.65965
New value of Value function: 3.66116
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.64732
New value of Value function: 3.65965
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.6556
New value of Value function: 3.6556
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.65159
New value of Value function: 3.65159
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.64761
New value of Value function: 3.64761
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.64365
New value of Value function: 3.64732
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.63443
New value of Value function: 3.64365
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.63972
New value of Value function: 3.63972
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.63582
New value of Value function: 3.63582
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.63194
New value of Value function: 3.63443
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.62231
New value of Value function: 3.63194
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.62809
New value of Value function: 3.62809
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.5312
New value of Value function: 3.62809
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.62427
New value of Value function: 3.62427
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.61147
New value of Value function: 3.62427
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.62047
New value of Value function: 3.62047
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.6167
New value of Value function: 3.6167
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.54283
New value of Value function: 3.6167
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.61295
New value of Value function: 3.61295
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.60922
New value of Value function: 3.61147
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 4.20578
New value of Value function: 4.20578
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 191
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 2.78154
New value of Value function: 2.78154
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 192
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.19378
New value of Value function: 1.19378
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 4.79085
New value of Value function: 4.79085
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 194
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.31706
New value of Value function: 2.31706
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 5.90778
New value of Value function: 5.90778
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 196
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.32438
New value of Value function: 6.32438
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 197
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 2.31706
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 198
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 199
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 200
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 5.88808
New value of Value function: 5.88808
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.86946
New value of Value function: 5.86946
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.85177
New value of Value function: 5.85177
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 5.83487
New value of Value function: 5.83487
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.81869
New value of Value function: 5.81869
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 95
New value of Q matrix: 4.11025
New value of Value function: 5.81869
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 7
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 4.56259
New value of Value function: 4.56259
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 5.06536
New value of Value function: 5.06536
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 9
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 10
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 11
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 12
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 13
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 14
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 15
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.00736
New value of Value function: 1.00736
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.05229
New value of Value function: 5.05229
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.03966
New value of Value function: 5.03966
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 96
New value of Q matrix: 4.45795
New value of Value function: 5.03966
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 19
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 3.70482
New value of Value function: 3.70482
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 4.78684
New value of Value function: 4.78684
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 21
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.00285
New value of Value function: 1.00285
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 22
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.30337
New value of Value function: 1.30337
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.77556
New value of Value function: 4.77556
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.7646
New value of Value function: 4.7646
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.73362
New value of Value function: 4.7646
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.75395
New value of Value function: 4.75395
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.74358
New value of Value function: 4.74358
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 97
New value of Q matrix: 4.68232
New value of Value function: 4.74358
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 29
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 3.06962
New value of Value function: 3.06962
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.80742
New value of Value function: 4.74358
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.93851
New value of Value function: 4.74358
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.73346
New value of Value function: 4.73346
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.72359
New value of Value function: 4.72359
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.71395
New value of Value function: 4.71395
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.70452
New value of Value function: 4.70452
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.6953
New value of Value function: 4.6953
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 98
New value of Q matrix: 4.81936
New value of Value function: 4.81936
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 38
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 2.67812
New value of Value function: 2.67812
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 99
New value of Q matrix: 4.90298
New value of Value function: 4.90298
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 40
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.93216
New value of Value function: 2.67812
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 41
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 2.4402
New value of Value function: 2.4402
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 100
New value of Q matrix: 4.95426
New value of Value function: 4.95426
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 43
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 4.38683
New value of Value function: 4.38683
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 44
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.93947
New value of Value function: 6.93947
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 45
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 3.18297
New value of Value function: 3.18297
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 46
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.77001
New value of Value function: 1.77001
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 101
New value of Q matrix: 5.07335
New value of Value function: 5.07335
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 48
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -2
New value of Value function: 3.18297
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 49
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 50
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 6.475
New value of Value function: 6.475
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 51
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 52
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 53
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.38745
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 54
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 1.11509
New value of Value function: 1.11509
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.07914
New value of Value function: 5.07335
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.07812
New value of Value function: 5.07335
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 5.06833
New value of Value function: 5.06833
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.32071
New value of Value function: 5.06833
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.28394
New value of Value function: 5.06833
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 5.06334
New value of Value function: 5.06334
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 104
New value of Q matrix: 4.96926
New value of Value function: 4.96926
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 62
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 63
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 64
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.91957
New value of Value function: 1.91957
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 105
New value of Q matrix: 4.77708
New value of Value function: 4.77708
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 66
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 67
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 68
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 69
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 70
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 71
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 72
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 73
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 74
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 75
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 76
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 77
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 78
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 79
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 80
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.95
New value of Value function: 1.95
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 81
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 2.96464
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 82
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.37886
New value of Value function: 6.37886
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 83
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.74431
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 84
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 6.70861
New value of Value function: 6.70861
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 85
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 86
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 87
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 88
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.0512332
New value of Value function: 0.0512332
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.42286
New value of Value function: 4.77708
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 5.32166
New value of Value function: 5.32166
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 91
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.02928
New value of Value function: 5.02928
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 92
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.33134
New value of Value function: 1.33134
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 5.04346
New value of Value function: 5.04346
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 94
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.30221
New value of Value function: 2.30221
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 95
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.90037
New value of Value function: 1.91957
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 96
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.97151
New value of Value function: 1.97151
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 5.08723
New value of Value function: 5.08723
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 98
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.62074
New value of Value function: 4.62074
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 99
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.68385
New value of Value function: 1.68385
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 5.54135
New value of Value function: 5.54135
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 101
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.55334
New value of Value function: 3.55334
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 5.71672
New value of Value function: 5.71672
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 103
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.5178
New value of Value function: 3.55334
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 104
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 3.28432
New value of Value function: 3.5178
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 105
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.36875
New value of Value function: 2.36875
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 5.85212
New value of Value function: 5.85212
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 107
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.49293
New value of Value function: 3.49293
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 108
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.47276
New value of Value function: 3.47276
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 109
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.4554
New value of Value function: 3.4554
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 110
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.43995
New value of Value function: 3.43995
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 111
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.4259
New value of Value function: 3.4259
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 112
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.41295
New value of Value function: 3.41295
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 113
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.40089
New value of Value function: 3.40089
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 114
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.38955
New value of Value function: 3.38955
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 115
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.37883
New value of Value function: 3.37883
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 116
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.36865
New value of Value function: 3.36865
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 117
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 3.30912
New value of Value function: 3.36865
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 118
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.58118
New value of Value function: 2.58118
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 5.93617
New value of Value function: 5.93617
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 120
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.35892
New value of Value function: 3.35892
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 121
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.34961
New value of Value function: 3.34961
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 122
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 3.14572
New value of Value function: 3.34961
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.62354
New value of Value function: 5.93617
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.92599
New value of Value function: 5.92599
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 6.07917
New value of Value function: 6.07917
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 126
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 2.86056
New value of Value function: 2.86056
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 127
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.46594
New value of Value function: 2.46594
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 5.85802
New value of Value function: 5.85802
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 129
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.36435
New value of Value function: 2.36435
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 6.04348
New value of Value function: 6.04348
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 131
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 5.4238
New value of Value function: 5.4238
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 132
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -2.17773
New value of Value function: 3.18297
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 133
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 6.3535
New value of Value function: 6.3535
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 134
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.44768
New value of Value function: 6.95
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 135
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.44768
New value of Value function: 6.3535
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 136
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.98304
New value of Value function: 6.3535
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 5.66935
New value of Value function: 5.66935
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 138
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.67865
New value of Value function: 1.67865
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 5.50802
New value of Value function: 5.50802
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 140
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.02493
New value of Value function: 2.02493
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.49931
New value of Value function: 5.49931
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 106
New value of Q matrix: 5.0263
New value of Value function: 5.49931
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 143
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 3.48166
New value of Value function: 3.48166
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 144
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.44432
New value of Value function: 2.44432
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.6706
New value of Value function: 5.49931
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 5.42206
New value of Value function: 5.42206
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 147
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.486205
New value of Value function: 2.02493
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 148
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.844112
New value of Value function: 2.02493
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 149
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.16492
New value of Value function: 2.16492
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.4137
New value of Value function: 5.4137
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.83299
New value of Value function: 5.4137
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 5.24239
New value of Value function: 5.24239
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 153
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.959822
New value of Value function: 1.30337
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 5.09886
New value of Value function: 5.09886
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 155
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.487702
New value of Value function: 1.30337
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 156
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 3.62539
New value of Value function: 3.62539
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 157
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 3.39429
New value of Value function: 3.39429
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 158
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 2.12068
New value of Value function: 2.12068
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 5.32102
New value of Value function: 5.32102
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 160
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 4.94589
New value of Value function: 4.94589
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 161
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 5.51324
New value of Value function: 5.51324
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 162
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.03227
New value of Value function: 5.03227
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 5.28835
New value of Value function: 5.28835
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 164
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 2.16126
New value of Value function: 2.16126
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 5.26666
New value of Value function: 5.26666
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 166
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 2.17884
New value of Value function: 2.17884
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.25906
New value of Value function: 5.25906
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 5.71607
New value of Value function: 5.71607
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 169
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 17
New value of Q matrix: 4.94178
New value of Value function: 4.94178
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 170
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.14532
New value of Value function: 2.17884
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 171
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.37155
New value of Value function: 2.17884
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 172
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 2.33065
New value of Value function: 2.33065
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.70798
New value of Value function: 5.70798
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 6.01386
New value of Value function: 6.01386
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 175
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 4.55654
New value of Value function: 4.55654
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 176
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 2.51851
New value of Value function: 2.51851
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.0901
New value of Value function: 6.01386
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 6.00552
New value of Value function: 6.00552
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 6.26525
New value of Value function: 6.26525
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 180
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 6.35778
New value of Value function: 6.35778
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 181
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.56894
New value of Value function: 3.56894
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 182
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.51097
New value of Value function: 4.55654
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 183
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 5.80121
New value of Value function: 5.80121
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 184
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 5.53772
New value of Value function: 5.53772
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 185
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 5.03945
New value of Value function: 5.03945
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 186
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.4617
New value of Value function: 6.4617
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 187
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.1943
New value of Value function: 3.1943
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 6.25125
New value of Value function: 6.25125
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 189
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.19152
New value of Value function: 3.19152
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 55
New value of Q matrix: 6.23889
New value of Value function: 6.23889
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 191
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 3.25824
New value of Value function: 3.25824
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 192
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.77043
New value of Value function: 2.77043
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.58456
New value of Value function: 6.23889
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 6.23056
New value of Value function: 6.23056
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 6.22231
New value of Value function: 6.22231
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 6.63917
New value of Value function: 6.63917
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 197
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 5.44776
New value of Value function: 5.44776
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 198
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.24226
New value of Value function: 3.24226
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 6.49
New value of Value function: 6.49
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 200
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 2.78022
New value of Value function: 2.78022
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 6.48162
New value of Value function: 6.48162
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 6.47332
New value of Value function: 6.47332
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 6.4651
New value of Value function: 6.4651
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 6.45695
New value of Value function: 6.45695
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 6.44888
New value of Value function: 6.44888
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 6.44088
New value of Value function: 6.44088
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 6.43296
New value of Value function: 6.43296
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 6.4251
New value of Value function: 6.4251
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 6.41731
New value of Value function: 6.41731
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 6.40958
New value of Value function: 6.40958
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 6.40192
New value of Value function: 6.40192
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 6.39432
New value of Value function: 6.39432
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 6.38679
New value of Value function: 6.38679
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.0667
New value of Value function: 6.38679
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 6.37931
New value of Value function: 6.37931
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 6.37189
New value of Value function: 6.37189
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 6.36454
New value of Value function: 6.36454
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 6.35724
New value of Value function: 6.35724
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 6.34999
New value of Value function: 6.34999
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 6.3428
New value of Value function: 6.3428
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 6.33567
New value of Value function: 6.33567
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.35445
New value of Value function: 6.33567
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 6.32858
New value of Value function: 6.32858
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.38704
New value of Value function: 6.32858
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 6.32155
New value of Value function: 6.32155
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 107
New value of Q matrix: 5.30894
New value of Value function: 6.32155
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 27
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.25833
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 6.31457
New value of Value function: 6.31457
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 6.30764
New value of Value function: 6.30764
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 6.30076
New value of Value function: 6.30076
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 6.29392
New value of Value function: 6.29392
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 108
New value of Q matrix: 5.56308
New value of Value function: 6.29392
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 33
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 34
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.23899
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 6.28713
New value of Value function: 6.28713
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 6.28039
New value of Value function: 6.28039
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.95592
New value of Value function: 6.28039
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 6.2737
New value of Value function: 6.2737
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 6.26705
New value of Value function: 6.26705
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 109
New value of Q matrix: 5.31758
New value of Value function: 6.26705
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 41
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.20438
New value of Value function: 3.20438
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 90
New value of Q matrix: 6.25707
New value of Value function: 6.25707
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 43
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.19449
New value of Value function: 3.20438
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 6.25051
New value of Value function: 6.25051
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 6.24399
New value of Value function: 6.24399
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 6.23751
New value of Value function: 6.23751
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.53354
New value of Value function: 6.23751
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 6.23108
New value of Value function: 6.23108
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 6.22469
New value of Value function: 6.22469
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.58724
New value of Value function: 6.22469
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 6.21834
New value of Value function: 6.21834
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 5.20092
New value of Value function: 6.21834
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 6.21202
New value of Value function: 6.21202
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 6.20575
New value of Value function: 6.20575
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 6.19951
New value of Value function: 6.19951
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 6.19331
New value of Value function: 6.19331
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 6.18715
New value of Value function: 6.18715
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 6.18102
New value of Value function: 6.18102
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 110
New value of Q matrix: 5.56857
New value of Value function: 6.18102
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 60
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 61
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.67008
New value of Value function: 4.95
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 103
New value of Q matrix: 6.18017
New value of Value function: 6.18017
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 63
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.14356
New value of Value function: 3.19449
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 111
New value of Q matrix: 5.78991
New value of Value function: 6.18017
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 65
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.92142
New value of Value function: 4.92142
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 66
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.89681
New value of Value function: 4.89681
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 67
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.87491
New value of Value function: 4.87491
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 68
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.85501
New value of Value function: 4.85501
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 69
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.83666
New value of Value function: 4.83666
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 70
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.13348
New value of Value function: 4.83666
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 71
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.81956
New value of Value function: 4.81956
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 72
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.8035
New value of Value function: 4.8035
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 73
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.78831
New value of Value function: 4.78831
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 74
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.77387
New value of Value function: 4.77387
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 75
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.76009
New value of Value function: 4.76009
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 76
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.74689
New value of Value function: 4.74689
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 77
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 4.74689
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 78
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.11836
New value of Value function: 3.11836
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 6.17411
New value of Value function: 6.17411
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 112
New value of Q matrix: 5.97034
New value of Value function: 6.17411
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 81
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.7342
New value of Value function: 4.7342
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 82
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.83745
New value of Value function: 4.7342
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 83
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.11236
New value of Value function: 3.19449
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.38321
New value of Value function: 6.17411
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 6.16808
New value of Value function: 6.16808
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 6.16209
New value of Value function: 6.16209
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 6.15613
New value of Value function: 6.15613
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 6.15021
New value of Value function: 6.15021
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 6.14432
New value of Value function: 6.14432
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 6.13846
New value of Value function: 6.13846
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 6.13263
New value of Value function: 6.13263
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.51816
New value of Value function: 6.13263
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 6.12684
New value of Value function: 6.12684
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 6.12107
New value of Value function: 6.12107
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 6.11534
New value of Value function: 6.11534
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.62132
New value of Value function: 6.11534
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 6.10964
New value of Value function: 6.10964
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 6.10397
New value of Value function: 6.10397
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 6.09832
New value of Value function: 6.09832
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 6.09271
New value of Value function: 6.09271
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 6.08712
New value of Value function: 6.08712
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 6.08157
New value of Value function: 6.08157
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 6.07604
New value of Value function: 6.07604
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 6.07054
New value of Value function: 6.07054
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 6.06506
New value of Value function: 6.06506
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 6.05962
New value of Value function: 6.05962
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 6.0542
New value of Value function: 6.0542
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 6.0488
New value of Value function: 6.0488
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 6.04344
New value of Value function: 6.04344
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 6.03809
New value of Value function: 6.03809
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 5.62824
New value of Value function: 6.03809
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.70111
New value of Value function: 6.03809
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 113
New value of Q matrix: 6.13182
New value of Value function: 6.13182
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 114
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.72198
New value of Value function: 4.72198
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 115
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.71017
New value of Value function: 4.71017
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 116
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 5.18297
New value of Value function: 5.18297
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 117
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.08452
New value of Value function: 3.08452
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 114
New value of Q matrix: 6.31907
New value of Value function: 6.31907
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 119
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 5.68567
New value of Value function: 5.68567
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 120
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.18345
New value of Value function: 3.18345
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.7544
New value of Value function: 6.31907
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 115
New value of Q matrix: 6.53446
New value of Value function: 6.53446
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 123
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 5.91864
New value of Value function: 5.91864
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 124
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.32628
New value of Value function: 3.32628
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 116
New value of Q matrix: 6.75033
New value of Value function: 6.75033
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 126
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.35887
New value of Value function: 5.91864
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.82192
New value of Value function: 6.75033
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 6.74409
New value of Value function: 6.74409
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 118
New value of Q matrix: 6.93882
New value of Value function: 6.93882
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 130
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.23099
New value of Value function: 5.91864
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 6.02484
New value of Value function: 6.93882
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 119
New value of Q matrix: 7.11489
New value of Value function: 7.11489
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 133
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 1.19677
New value of Value function: 5.91864
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 134
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.795
New value of Value function: 3.795
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 120
New value of Q matrix: 7.27414
New value of Value function: 7.27414
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 136
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 6.08607
New value of Value function: 6.08607
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 137
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.71765
New value of Value function: 3.71765
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 121
New value of Q matrix: 7.43333
New value of Value function: 7.43333
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 139
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 6.32873
New value of Value function: 6.32873
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 140
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 3.97948
New value of Value function: 3.97948
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 122
New value of Q matrix: 7.5992
New value of Value function: 7.5992
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 142
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 6.55965
New value of Value function: 6.55965
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 143
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 4.18499
New value of Value function: 4.18499
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 123
New value of Q matrix: 7.77006
New value of Value function: 7.77006
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 145
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 6.76595
New value of Value function: 6.76595
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 146
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.69829
New value of Value function: 4.18499
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 147
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 6.89168
New value of Value function: 6.89168
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 148
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.17019
New value of Value function: 4.17019
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 149
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 4.34425
New value of Value function: 4.34425
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 6.41788
New value of Value function: 7.77006
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 6.10757
New value of Value function: 7.77006
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 124
New value of Q matrix: 7.95439
New value of Value function: 7.95439
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 153
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 7.02105
New value of Value function: 7.02105
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 154
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 4.51204
New value of Value function: 4.51204
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 125
New value of Q matrix: 8.13296
New value of Value function: 8.13296
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 156
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 7.15549
New value of Value function: 7.15549
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 157
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 4.67473
New value of Value function: 4.67473
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 126
New value of Q matrix: 8.30677
New value of Value function: 8.30677
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 159
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.67859
New value of Value function: 7.15549
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 6.23053
New value of Value function: 8.30677
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 8.2994
New value of Value function: 8.2994
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 6.4047
New value of Value function: 8.2994
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 128
New value of Q matrix: 8.16307
New value of Value function: 8.16307
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 164
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 11.0839
New value of Value function: 11.0839
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 165
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 7.29189
New value of Value function: 7.29189
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 166
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 4.79214
New value of Value function: 4.79214
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 129
New value of Q matrix: 8.34408
New value of Value function: 8.34408
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 168
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 7.41734
New value of Value function: 7.41734
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 169
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.34317
New value of Value function: 4.79214
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 170
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 7.5047
New value of Value function: 7.5047
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 171
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 4.92208
New value of Value function: 4.92208
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 6.56685
New value of Value function: 8.34408
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 6.27478
New value of Value function: 8.34408
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 8.33676
New value of Value function: 8.33676
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 8.32948
New value of Value function: 8.32948
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 6.71302
New value of Value function: 8.32948
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 8.32223
New value of Value function: 8.32223
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 133
New value of Q matrix: 8.50497
New value of Value function: 8.50497
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 179
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 5.01012
New value of Value function: 7.5047
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 134
New value of Q matrix: 8.67124
New value of Value function: 8.67124
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 181
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 7.59976
New value of Value function: 7.59976
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 182
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 5.09912
New value of Value function: 5.09912
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 135
New value of Q matrix: 8.83068
New value of Value function: 8.83068
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 184
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.39257
New value of Value function: 7.59976
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 185
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 7.71185
New value of Value function: 7.71185
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 186
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 5.26521
New value of Value function: 5.26521
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 136
New value of Q matrix: 8.98537
New value of Value function: 8.98537
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 188
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 7.83329
New value of Value function: 7.83329
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 189
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 5.26521
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 190
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 191
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 192
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 193
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 194
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 195
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 196
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 197
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 198
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 199
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 200
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.8752
New value of Value function: 2.8752
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 8.9777
New value of Value function: 8.9777
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 138
New value of Q matrix: 8.95773
New value of Value function: 8.95773
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 3
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 6.82803
New value of Value function: 6.82803
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 4
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.39328
New value of Value function: 5.44776
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 5
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 5.61893
New value of Value function: 5.61893
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 6
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 4.85927
New value of Value function: 4.85927
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 7
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.24046
New value of Value function: 5.61893
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 8
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.28088
New value of Value function: 4.28088
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 9
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 2.26065
New value of Value function: 3.25824
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 6.65969
New value of Value function: 8.95773
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 139
New value of Q matrix: 8.726
New value of Value function: 8.726
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 12
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.12545
New value of Value function: 5.12545
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 13
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 3.15092
New value of Value function: 3.15092
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 14
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.29776
New value of Value function: 4.29776
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 7.04781
New value of Value function: 8.726
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 140
New value of Q matrix: 8.52233
New value of Value function: 8.52233
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 17
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.34065
New value of Value function: 3.34065
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 18
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 3.29055
New value of Value function: 3.34065
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 19
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 2.30725
New value of Value function: 2.58118
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 20
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.33203
New value of Value function: 3.33203
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 21
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1.34245
New value of Value function: 3.33203
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 22
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.85839
New value of Value function: 3.85839
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 133
New value of Q matrix: 6.6771
New value of Value function: 8.52233
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 24
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.3237
New value of Value function: 3.3237
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 25
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.31564
New value of Value function: 3.31564
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 26
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 4.64152
New value of Value function: 4.64152
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 27
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 6.65186
New value of Value function: 6.65186
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 28
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 4.60179
New value of Value function: 4.60179
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 29
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.91312
New value of Value function: 5.91312
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 30
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 31
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 32
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 33
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 34
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 35
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 3.66701
New value of Value function: 3.66701
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 36
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.36236
New value of Value function: 3.36236
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 141
New value of Q matrix: 8.3376
New value of Value function: 8.3376
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 38
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 4.13471
New value of Value function: 4.13471
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 6.63617
New value of Value function: 8.3376
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 7.27999
New value of Value function: 8.3376
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 8.3306
New value of Value function: 8.3306
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 143
New value of Q matrix: 8.22714
New value of Value function: 8.22714
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 43
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 4.51651
New value of Value function: 4.51651
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.81407
New value of Value function: 8.22714
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 8.22028
New value of Value function: 8.22028
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 145
New value of Q matrix: 8.15808
New value of Value function: 8.15808
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 47
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 4.7145
New value of Value function: 4.7145
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 146
New value of Q matrix: 8.11747
New value of Value function: 8.11747
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 49
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 4.82176
New value of Value function: 4.82176
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 147
New value of Q matrix: 8.0891
New value of Value function: 8.0891
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 51
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 4.88072
New value of Value function: 4.88072
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 148
New value of Q matrix: 8.06796
New value of Value function: 8.06796
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 53
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 4.91285
New value of Value function: 4.91285
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 149
New value of Q matrix: 8.05123
New value of Value function: 8.05123
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 55
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 3.78331
New value of Value function: 3.78331
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 56
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.97072
New value of Value function: 4.97072
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 150
New value of Q matrix: 7.6388
New value of Value function: 7.6388
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 58
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 59
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 60
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 61
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 62
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 63
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 64
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 65
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 66
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 67
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 68
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 69
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 70
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.56241
New value of Value function: 4.56241
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 151
New value of Q matrix: 7.62887
New value of Value function: 7.62887
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 72
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.55546
New value of Value function: 4.55546
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 152
New value of Q matrix: 7.61922
New value of Value function: 7.61922
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 74
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.54828
New value of Value function: 4.54828
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 134
New value of Q matrix: 6.683
New value of Value function: 7.61922
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 76
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 3.99402
New value of Value function: 3.99402
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 153
New value of Q matrix: 7.56545
New value of Value function: 7.56545
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 78
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 1.63034
New value of Value function: 3.99402
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 79
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.00965
New value of Value function: 6.00965
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 80
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.18396
New value of Value function: 5.18396
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 81
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 0.274142
New value of Value function: 0.274142
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 82
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 83
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 84
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 85
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 86
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 87
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.48979
New value of Value function: 4.48979
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 154
New value of Q matrix: 7.21942
New value of Value function: 7.27999
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 89
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 0.350505
New value of Value function: 0.350505
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 90
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.20719
New value of Value function: 4.48979
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 135
New value of Q matrix: 6.70633
New value of Value function: 7.27999
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 92
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 4.50903
New value of Value function: 4.50903
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 93
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.43082
New value of Value function: 4.43082
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 7.26623
New value of Value function: 7.26623
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 7.25273
New value of Value function: 7.25273
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 7.23949
New value of Value function: 7.23949
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 6.73153
New value of Value function: 7.23949
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 6.89301
New value of Value function: 7.23949
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 7.22649
New value of Value function: 7.22649
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 6.80625
New value of Value function: 7.22649
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 7.21372
New value of Value function: 7.21942
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 7.21363
New value of Value function: 7.21372
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 7.20116
New value of Value function: 7.21363
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 7.20785
New value of Value function: 7.20785
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 6.86362
New value of Value function: 7.20785
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 7.2021
New value of Value function: 7.2021
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 7.19637
New value of Value function: 7.20116
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 7.18881
New value of Value function: 7.19637
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 159
New value of Q matrix: 6.89109
New value of Value function: 7.18881
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 110
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.11692
New value of Value function: 4.11692
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 7.17666
New value of Value function: 7.17666
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 7.1647
New value of Value function: 7.1647
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 7.15292
New value of Value function: 7.15292
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 6.93412
New value of Value function: 7.15292
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 7.14131
New value of Value function: 7.14131
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 7.12988
New value of Value function: 7.12988
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 6.90433
New value of Value function: 7.12988
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 7.1186
New value of Value function: 7.1186
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 7.10749
New value of Value function: 7.10749
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 7.09652
New value of Value function: 7.09652
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 7.0857
New value of Value function: 7.0857
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 7.07502
New value of Value function: 7.07502
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 7.06447
New value of Value function: 7.06447
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 136
New value of Q matrix: 6.7713
New value of Value function: 7.06447
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 125
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 4.376
New value of Value function: 4.376
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 6.88595
New value of Value function: 7.06447
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 7.05405
New value of Value function: 7.05405
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 7.04376
New value of Value function: 7.04376
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 7.0336
New value of Value function: 7.0336
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 7.02355
New value of Value function: 7.02355
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 6.78685
New value of Value function: 7.02355
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 6.89733
New value of Value function: 7.02355
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 7.01362
New value of Value function: 7.01362
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 7.0038
New value of Value function: 7.0038
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 6.99408
New value of Value function: 6.99408
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 6.98448
New value of Value function: 6.98448
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 6.97497
New value of Value function: 6.97497
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 6.96557
New value of Value function: 6.96557
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 6.79613
New value of Value function: 6.96557
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 139
New value of Q matrix: 6.73873
New value of Value function: 6.96557
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 141
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 8.85399
New value of Value function: 8.85399
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 142
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 6.17549
New value of Value function: 6.17549
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 143
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5.30445
New value of Value function: 5.30445
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 144
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 4.25598
New value of Value function: 4.25598
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 6.95626
New value of Value function: 6.95626
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 6.92401
New value of Value function: 6.95626
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 6.94704
New value of Value function: 6.94704
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 6.93792
New value of Value function: 6.93792
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 6.7497
New value of Value function: 6.93792
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 6.92889
New value of Value function: 6.92889
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 6.91994
New value of Value function: 6.92401
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 6.90957
New value of Value function: 6.91994
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 6.91108
New value of Value function: 6.91108
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 6.90231
New value of Value function: 6.90957
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 6.89547
New value of Value function: 6.90433
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 6.89889
New value of Value function: 6.90231
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 6.89361
New value of Value function: 6.89889
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 6.89347
New value of Value function: 6.89733
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 163
New value of Q matrix: 6.93666
New value of Value function: 6.93666
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 160
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.04962
New value of Value function: 4.20719
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 6.89032
New value of Value function: 6.93666
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 6.88983
New value of Value function: 6.93666
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 141
New value of Q matrix: 6.43392
New value of Value function: 6.93666
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 164
----------
State: 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 3.13212
New value of Value function: 3.13212
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 165
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.07775
New value of Value function: 5.07775
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 166
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 167
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 168
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.0269736
New value of Value function: 0.0269736
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 169
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.05223
New value of Value function: 5.05223
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 170
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.00910615
New value of Value function: 0.00910615
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 171
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.0329
New value of Value function: 5.0329
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 172
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.0062126
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 173
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.01947
New value of Value function: 5.01947
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 174
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 175
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.07575
New value of Value function: 1.07575
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 176
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.74135
New value of Value function: 4.74135
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 177
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.306062
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 178
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.89068
New value of Value function: 4.89068
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 179
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 180
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 181
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 182
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 183
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 184
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.935007
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 185
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.61741
New value of Value function: 1.61741
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 186
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.94534
New value of Value function: 4.94534
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 187
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.8673
New value of Value function: 3.8673
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 6.89233
New value of Value function: 6.93666
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 6.93125
New value of Value function: 6.93125
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 142
New value of Q matrix: 6.55661
New value of Value function: 6.93125
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 191
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 3.18093
New value of Value function: 3.18093
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 192
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 2.14912
New value of Value function: 2.14912
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 193
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 3.15917
New value of Value function: 3.15917
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 194
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 2.13389
New value of Value function: 2.13389
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 195
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 3.14155
New value of Value function: 3.14155
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 196
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 2.12017
New value of Value function: 2.12017
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 197
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.66778
New value of Value function: 3.14155
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 198
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.747185
New value of Value function: 0.747185
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 199
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.15223
New value of Value function: 5.15223
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 200
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.83995
New value of Value function: 3.83995
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 6.92585
New value of Value function: 6.92585
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 143
New value of Q matrix: 6.78554
New value of Value function: 6.92585
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 3
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 5.56683
New value of Value function: 5.56683
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 166
New value of Q matrix: 7.1458
New value of Value function: 7.1458
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 5
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 6.15688
New value of Value function: 6.15688
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 6
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 3.13915
New value of Value function: 3.13915
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 6.92225
New value of Value function: 7.1458
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 7.14027
New value of Value function: 7.14027
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 144
New value of Q matrix: 6.92934
New value of Value function: 7.14027
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 10
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 5.11518
New value of Value function: 5.11518
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 168
New value of Q matrix: 7.29111
New value of Value function: 7.29111
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 1.04527
New value of Value function: 6.15688
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 13
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 4.85624
New value of Value function: 4.85624
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 169
New value of Q matrix: 7.42989
New value of Value function: 7.42989
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 15
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 5.72
New value of Value function: 5.72
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 16
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.75042
New value of Value function: 3.13915
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 17
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 3.46426
New value of Value function: 3.46426
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 170
New value of Q matrix: 7.52445
New value of Value function: 7.52445
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 19
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 6.72978
New value of Value function: 6.72978
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 20
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 5.67675
New value of Value function: 5.67675
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 21
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 6.34947
New value of Value function: 6.34947
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 22
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.39106
New value of Value function: 8.39106
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 23
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.73153
New value of Value function: 8.85399
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 171
New value of Q matrix: 7.84877
New value of Value function: 7.84877
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 25
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 4.67924
New value of Value function: 4.67924
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 26
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 5.94249
New value of Value function: 5.94249
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 27
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 7.23949
New value of Value function: 7.23949
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 28
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.46085
New value of Value function: 6.46085
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 29
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.96469
New value of Value function: 4.96469
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 30
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 4.38072
New value of Value function: 4.38072
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 172
New value of Q matrix: 7.80974
New value of Value function: 7.80974
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 32
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.73164
New value of Value function: 4.73164
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 173
New value of Q matrix: 7.80021
New value of Value function: 7.80021
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 34
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 2.77811
New value of Value function: 4.73164
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 35
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 6.39917
New value of Value function: 6.39917
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 36
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 5.03815
New value of Value function: 5.03815
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 37
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.57136
New value of Value function: 4.57136
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 174
New value of Q matrix: 7.82299
New value of Value function: 7.82299
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 39
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 5.01641
New value of Value function: 5.01641
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 145
New value of Q matrix: 7.01724
New value of Value function: 7.82299
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 41
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 5.23928
New value of Value function: 5.23928
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 42
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.61207
New value of Value function: 4.61207
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 7.05568
New value of Value function: 7.82299
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 7.81707
New value of Value function: 7.81707
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 146
New value of Q matrix: 7.11404
New value of Value function: 7.81707
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 46
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 6.11264
New value of Value function: 6.11264
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 47
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.05152
New value of Value function: 5.01947
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 48
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 7.18457
New value of Value function: 7.18457
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 49
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 5.75528
New value of Value function: 5.75528
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 50
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 0.422006
New value of Value function: 5.01641
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 51
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.84759
New value of Value function: 4.57136
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 52
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.44758
New value of Value function: 4.57136
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 7.05635
New value of Value function: 7.81707
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 7.16558
New value of Value function: 7.81707
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 176
New value of Q matrix: 7.99011
New value of Value function: 7.99011
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 56
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 7.94115
New value of Value function: 7.94115
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 57
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.71793
New value of Value function: 5.75528
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 58
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 5.75528
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 59
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3.73971
New value of Value function: 3.73971
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 60
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.35671
New value of Value function: 1.35671
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 61
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 6.21338
New value of Value function: 6.21338
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 62
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.45787
New value of Value function: 4.45787
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 177
New value of Q matrix: 7.94676
New value of Value function: 7.94676
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 64
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.66258
New value of Value function: 4.66258
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 178
New value of Q matrix: 7.92196
New value of Value function: 7.92196
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 66
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.738322
New value of Value function: 4.66258
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 67
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 68
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 69
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 70
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 71
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 72
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 73
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 74
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 75
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 76
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 77
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 78
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 79
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 80
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 81
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 82
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 83
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 3.71473
New value of Value function: 3.71473
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 84
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.1547
New value of Value function: 4.1547
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 85
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.886846
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 86
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.57735
New value of Value function: 4.57735
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 87
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 88
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 89
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 90
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 91
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.53158
New value of Value function: 3.53158
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 92
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 4.49626
New value of Value function: 4.57735
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 93
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.01857
New value of Value function: 3.53158
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 94
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 3.53158
New value of Value function: 3.53158
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 95
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.76636
New value of Value function: 4.76636
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 96
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.52777
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 97
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 3.80202
New value of Value function: 3.80202
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 98
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 99
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 100
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 101
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 102
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.45866
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 103
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.86175
New value of Value function: 4.86175
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 104
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 105
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.301743
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 106
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.914
New value of Value function: 4.914
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 107
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 108
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 109
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 110
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 111
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 112
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 113
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 114
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 115
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.218441
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 116
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 4.914
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 117
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 118
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 119
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 120
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 121
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 122
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 123
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 124
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 125
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 126
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 127
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 128
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 129
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 130
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 131
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 132
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 133
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 134
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 135
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 136
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 137
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 138
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 139
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 140
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 141
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 2.70232
New value of Value function: 2.70232
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 142
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 3.69773
New value of Value function: 3.73971
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 143
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.78847
New value of Value function: 6.78847
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 144
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.2898
New value of Value function: 5.2898
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 145
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 2.28297
New value of Value function: 4.914
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 146
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 5.99419
New value of Value function: 5.99419
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 147
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 4.2373
New value of Value function: 4.49626
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 148
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.223927
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 149
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 6.1808
New value of Value function: 6.1808
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 150
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.68558
New value of Value function: 4.68558
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 151
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 3.72037
New value of Value function: 3.72037
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 152
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 4.68419
New value of Value function: 4.68419
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 153
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.85087
New value of Value function: 3.72037
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 154
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 3.68324
New value of Value function: 3.68324
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 155
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 4.6653
New value of Value function: 4.6653
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 156
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 3.65687
New value of Value function: 3.65687
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 157
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 4.64518
New value of Value function: 4.64518
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 158
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.19497
New value of Value function: 3.65687
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 159
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.36861
New value of Value function: 3.65687
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 160
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 3.63489
New value of Value function: 3.63489
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 161
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.29936
New value of Value function: 4.64518
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 162
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 4.62614
New value of Value function: 4.62614
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 163
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 3.61544
New value of Value function: 3.61544
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 164
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 4.60843
New value of Value function: 4.60843
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 165
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 3.59774
New value of Value function: 3.59774
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 166
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 4.59193
New value of Value function: 4.59193
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 167
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 3.58139
New value of Value function: 3.58139
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 168
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 4.57648
New value of Value function: 4.57648
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 169
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 3.56611
New value of Value function: 3.56611
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 170
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 4.56192
New value of Value function: 4.56192
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 171
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.42978
New value of Value function: 3.56611
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 172
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 3.55173
New value of Value function: 3.55173
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 173
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.343
New value of Value function: 4.56192
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 174
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 6.30761
New value of Value function: 6.30761
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 175
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.29081
New value of Value function: 4.56192
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 176
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 4.54814
New value of Value function: 4.54814
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 177
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 3.53812
New value of Value function: 3.53812
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 178
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -4.70711
New value of Value function: 4.54814
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 179
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 180
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 9.24453
New value of Value function: 9.24453
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 181
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 6.30761
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 182
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.623889
New value of Value function: 0.623889
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 183
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 6.37657
New value of Value function: 6.37657
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 184
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 4.53503
New value of Value function: 4.53503
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 185
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 14
New value of Q matrix: 3.52518
New value of Value function: 3.52518
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 186
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 4.52252
New value of Value function: 4.52252
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 187
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 15
New value of Q matrix: 3.51281
New value of Value function: 3.51281
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 188
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 4.51054
New value of Value function: 4.51054
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 189
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 16
New value of Q matrix: 3.50097
New value of Value function: 3.50097
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 190
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.8279
New value of Value function: 4.51054
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 191
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 6.40619
New value of Value function: 6.40619
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 192
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.77035
New value of Value function: 4.51054
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 193
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 4.49903
New value of Value function: 4.49903
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 194
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 17
New value of Q matrix: 3.48959
New value of Value function: 3.48959
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 195
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 16
New value of Q matrix: 4.48794
New value of Value function: 4.48794
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 196
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 18
New value of Q matrix: 3.47862
New value of Value function: 3.47862
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 197
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 17
New value of Q matrix: 4.47725
New value of Value function: 4.47725
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 198
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 19
New value of Q matrix: 3.46803
New value of Value function: 3.46803
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 199
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.02061
New value of Value function: 4.47725
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 200
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 4.4669
New value of Value function: 4.4669
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 7.91604
New value of Value function: 7.91604
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 180
New value of Q matrix: 8.12764
New value of Value function: 8.12764
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 3
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 7.92269
New value of Value function: 7.92269
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 4
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 5.15977
New value of Value function: 5.15977
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 5
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 7.96524
New value of Value function: 7.96524
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 6
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 5.13227
New value of Value function: 5.13227
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 181
New value of Q matrix: 8.33264
New value of Value function: 8.33264
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 8
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 7.99111
New value of Value function: 7.99111
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 9
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 5.15985
New value of Value function: 5.15985
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 7.25466
New value of Value function: 8.33264
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 182
New value of Q matrix: 8.52377
New value of Value function: 8.52377
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 12
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 8.01667
New value of Value function: 8.01667
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 13
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 5.22379
New value of Value function: 5.22379
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 183
New value of Q matrix: 8.70213
New value of Value function: 8.70213
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 15
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 8.04969
New value of Value function: 8.04969
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 16
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.01275
New value of Value function: 5.22379
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 17
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.02338
New value of Value function: 3.02338
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 18
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.57878
New value of Value function: 5.22379
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 19
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 3.17155
New value of Value function: 3.17155
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 20
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.61551
New value of Value function: 7.61551
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 21
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.83922
New value of Value function: 5.83922
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 22
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 8.26114
New value of Value function: 8.26114
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 23
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.80914
New value of Value function: 6.80914
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 24
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.74105
New value of Value function: 2.31706
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 25
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.02593
New value of Value function: 7.02593
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 26
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.1956
New value of Value function: 6.1956
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 27
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 4.08676
New value of Value function: 4.08676
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 28
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.04589
New value of Value function: 3.04589
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 29
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.04589
New value of Value function: 4.08676
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 30
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.85093
New value of Value function: 4.85093
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 184
New value of Q matrix: 8.6358
New value of Value function: 8.6358
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 32
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 4.47729
New value of Value function: 4.47729
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 33
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.4058
New value of Value function: 4.4058
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 34
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.973984
New value of Value function: 0.973984
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 35
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.969629
New value of Value function: 0.973188
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 36
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.26132
New value of Value function: 3.26132
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 185
New value of Q matrix: 8.54733
New value of Value function: 8.54733
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 38
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 7.3656
New value of Value function: 7.3656
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 39
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.88255
New value of Value function: 4.88255
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 40
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.24543
New value of Value function: 4.24543
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 186
New value of Q matrix: 8.44876
New value of Value function: 8.44876
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 42
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.28964
New value of Value function: 4.24543
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 43
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 4.7022
New value of Value function: 4.7022
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 187
New value of Q matrix: 8.38747
New value of Value function: 8.38747
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 45
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.29194
New value of Value function: 4.6572
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 46
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 7.69661
New value of Value function: 7.69661
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 47
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.61965
New value of Value function: 4.88255
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 48
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.3036
New value of Value function: 7.69661
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 188
New value of Q matrix: 8.33406
New value of Value function: 8.33406
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 50
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 4.90952
New value of Value function: 4.90952
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 189
New value of Q matrix: 8.28144
New value of Value function: 8.28144
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 52
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 4.6572
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 53
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 8.61063
New value of Value function: 8.61063
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 54
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 4.78641
New value of Value function: 4.78641
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 55
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 1.97714
New value of Value function: 1.97714
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 56
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.998621
New value of Value function: 1.00232
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 57
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 2.32931
New value of Value function: 2.32931
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 149
New value of Q matrix: 7.53033
New value of Value function: 8.28144
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 59
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 7.77577
New value of Value function: 7.77577
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 60
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.87149
New value of Value function: 5.87149
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 61
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.94151
New value of Value function: 4.94151
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 62
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 63
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 64
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.19863
New value of Value function: 5.19863
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 7.2387
New value of Value function: 8.28144
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 7.27618
New value of Value function: 8.28144
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 190
New value of Q matrix: 8.06558
New value of Value function: 8.06558
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 68
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 3.13001
New value of Value function: 3.13001
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 191
New value of Q matrix: 8.07144
New value of Value function: 8.07144
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 70
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.16187
New value of Value function: 5.16187
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 71
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.12093
New value of Value function: 5.16187
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 72
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.11967
New value of Value function: 3.11967
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 73
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.91152
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 74
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 3.78447
New value of Value function: 3.78447
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 75
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.11025
New value of Value function: 2.11025
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 76
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.13206
New value of Value function: 5.13206
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 77
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 0.81862
New value of Value function: 5.13206
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 78
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.74663
New value of Value function: 3.78447
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 79
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 1.95262
New value of Value function: 3.78447
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 80
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 81
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 82
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 83
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 84
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 85
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 86
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 87
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 88
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 89
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 90
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 91
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 92
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 93
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 94
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 95
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 96
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 97
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 98
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 99
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 100
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 101
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 102
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 103
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 104
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 105
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 106
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 107
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 108
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 109
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 110
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 111
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 112
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 113
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 114
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 115
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 116
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 117
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 118
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 119
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 120
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 121
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 122
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 123
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 124
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 125
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 126
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 127
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 128
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 129
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 130
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 131
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 132
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 133
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.85788
New value of Value function: 2.85788
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 134
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 135
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 136
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 137
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 138
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.99938
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 139
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.90394
New value of Value function: 3.90394
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 140
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 141
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2213
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 142
----------
State: 2213
	Distance: 5
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 143
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 144
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 145
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 146
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 147
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -0.94683
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 148
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 149
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 150
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 151
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 152
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 8.06562
New value of Value function: 8.06562
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 193
New value of Q matrix: 8.18056
New value of Value function: 8.18056
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 3
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 7.52387
New value of Value function: 7.52387
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 4
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.37708
New value of Value function: 5.67675
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 5
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 0.9081
New value of Value function: 7.52387
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 6
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 11.4486
New value of Value function: 11.4486
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 7
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 8.14309
New value of Value function: 8.14309
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 8
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 6.14129
New value of Value function: 6.14129
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 9
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 5.92627
New value of Value function: 5.92627
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 10
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 8.12874
New value of Value function: 8.12874
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 11
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 6.74763
New value of Value function: 6.74763
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 12
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.74272
New value of Value function: 2.77043
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 13
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.81169
New value of Value function: 3.81169
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 194
New value of Q matrix: 8.28823
New value of Value function: 8.28823
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 15
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.28334
New value of Value function: 6.74763
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 16
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.88307
New value of Value function: 5.94249
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 17
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 7.5548
New value of Value function: 7.5548
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 18
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 8.31787
New value of Value function: 8.31787
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 19
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 6.74036
New value of Value function: 6.74036
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 20
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 7.69427
New value of Value function: 7.69427
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 21
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 6.32851
New value of Value function: 6.32851
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 22
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.05988
New value of Value function: 9.05988
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 23
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.96928
New value of Value function: 6.78847
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 24
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.2498
New value of Value function: 10.2498
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 25
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 6.36753
New value of Value function: 6.36753
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 26
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.93739
New value of Value function: 4.93739
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 195
New value of Q matrix: 8.35003
New value of Value function: 8.35003
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 28
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 5.92789
New value of Value function: 5.92789
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 150
New value of Q matrix: 7.67198
New value of Value function: 8.35003
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 30
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.67004
New value of Value function: 6.67004
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 31
----------
State: 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 3.96066
New value of Value function: 3.96066
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 32
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 6.84221
New value of Value function: 6.84221
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 33
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.86861
New value of Value function: 5.92789
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 34
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 5.73697
New value of Value function: 5.86861
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 196
New value of Q matrix: 8.38288
New value of Value function: 8.38288
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 36
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 2.26536
New value of Value function: 5.86861
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 197
New value of Q matrix: 8.41331
New value of Value function: 8.41331
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 38
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 3.34858
New value of Value function: 5.86861
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 151
New value of Q matrix: 7.82915
New value of Value function: 8.41331
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 40
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.52145
New value of Value function: 8.52145
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 41
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.82711
New value of Value function: 5.82711
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 42
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.79347
New value of Value function: 5.79347
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 43
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.027164
New value of Value function: 5.79347
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 44
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 5.70232
New value of Value function: 5.70232
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 45
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 3.67529
New value of Value function: 3.73971
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 46
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 2.70232
New value of Value function: 2.70232
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 47
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.75786
New value of Value function: 7.75786
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 48
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 4.4592
New value of Value function: 4.4592
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 49
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 20
New value of Q matrix: 3.45609
New value of Value function: 3.45609
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 50
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 4.45078
New value of Value function: 4.45078
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 51
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.42686
New value of Value function: 3.45609
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 52
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 21
New value of Q matrix: 3.44522
New value of Value function: 3.44522
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 53
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 4.44205
New value of Value function: 4.44205
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 54
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 22
New value of Q matrix: 3.43507
New value of Value function: 3.43507
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 55
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 4.43324
New value of Value function: 4.43324
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 56
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 3.43507
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 57
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 58
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 59
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 60
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 61
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 62
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 63
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 64
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 65
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 66
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 67
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 68
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 69
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 70
----------
State: 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 71
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 72
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 73
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 74
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 75
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 76
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 77
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 78
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 79
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 80
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 81
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 82
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 83
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 84
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 85
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 86
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 87
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 88
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 89
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 90
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 91
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 92
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 93
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 94
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 95
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.67098
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 96
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 5.06796
New value of Value function: 5.06796
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 97
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 9.54267
New value of Value function: 9.54267
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 98
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 10.3259
New value of Value function: 10.3259
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 99
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 7.21821
New value of Value function: 7.21821
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 7.06879
New value of Value function: 8.41331
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 198
New value of Q matrix: 8.53645
New value of Value function: 8.53645
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 102
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 6.5503
New value of Value function: 6.5503
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 199
New value of Q matrix: 8.60367
New value of Value function: 8.60367
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 104
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 6.1852
New value of Value function: 6.32851
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 7.51079
New value of Value function: 8.60367
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 8.59759
New value of Value function: 8.59759
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 201
New value of Q matrix: 8.60732
New value of Value function: 8.60732
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 108
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.7645
New value of Value function: 5.7645
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 109
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 1.80906
New value of Value function: 5.7645
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 110
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 8.51516
New value of Value function: 8.51516
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 111
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.68028
New value of Value function: 7.75786
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 112
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.67254
New value of Value function: 8.67254
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 113
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 6.32584
New value of Value function: 6.32584
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 114
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 7.25437
New value of Value function: 7.25437
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 115
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 8.90006
New value of Value function: 8.90006
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 116
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.41381
New value of Value function: 8.41381
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 117
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 6.02548
New value of Value function: 6.02548
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 118
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 7.61243
New value of Value function: 7.61243
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 119
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 9.21818
New value of Value function: 9.21818
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 120
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 8.21742
New value of Value function: 8.21742
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 121
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 5.76849
New value of Value function: 5.76849
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 122
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 7.77185
New value of Value function: 7.77185
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 123
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.7108
New value of Value function: 10.7108
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 124
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 5.47052
New value of Value function: 5.47052
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 125
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 8.01525
New value of Value function: 8.01525
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 126
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 5.32742
New value of Value function: 5.32742
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 127
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 8.10678
New value of Value function: 8.10678
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 128
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 5.24952
New value of Value function: 5.24952
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 129
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 8.13686
New value of Value function: 8.13686
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 130
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 5.20101
New value of Value function: 5.20101
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 131
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 8.1407
New value of Value function: 8.1407
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 132
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 5.16664
New value of Value function: 5.16664
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 133
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 8.13294
New value of Value function: 8.13294
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 134
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 5.13953
New value of Value function: 5.13953
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 135
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 8.12001
New value of Value function: 8.12001
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 136
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 5.11642
New value of Value function: 5.11642
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 137
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 8.10482
New value of Value function: 8.10482
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 138
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 5.09571
New value of Value function: 5.09571
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 139
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 8.08877
New value of Value function: 8.08877
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 140
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 5.07654
New value of Value function: 5.07654
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 141
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 8.0725
New value of Value function: 8.0725
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 142
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 5.05847
New value of Value function: 5.05847
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 143
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.65104
New value of Value function: 8.0725
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 144
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 8.05635
New value of Value function: 8.05635
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 145
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 5.04123
New value of Value function: 5.04123
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 146
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 8.05635
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 147
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 148
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 7.91505
New value of Value function: 7.91505
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 149
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.89593
New value of Value function: 8.89593
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 150
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 7.79155
New value of Value function: 7.79155
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 151
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 5.02787
New value of Value function: 5.02787
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 152
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 8.1891
New value of Value function: 8.1891
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 153
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 7.70686
New value of Value function: 10.7108
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 154
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.73872
New value of Value function: 5.73872
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 155
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 2.52839
New value of Value function: 5.73872
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 156
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.98441
New value of Value function: 4.98441
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 152
New value of Q matrix: 7.94563
New value of Value function: 8.60732
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 158
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 7.68391
New value of Value function: 7.68391
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 159
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.7153
New value of Value function: 5.73697
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 160
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 5.67714
New value of Value function: 5.7153
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 202
New value of Q matrix: 8.61089
New value of Value function: 8.61089
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 162
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 2.02438
New value of Value function: 5.7153
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 163
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 5.23109
New value of Value function: 5.23109
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 203
New value of Q matrix: 8.61421
New value of Value function: 8.61421
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 165
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 5.71364
New value of Value function: 5.7153
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 166
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 7.75304
New value of Value function: 7.75304
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 167
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 11
New value of Q matrix: 1.76942
New value of Value function: 5.7153
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 168
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 5.3639
New value of Value function: 5.3639
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 153
New value of Q matrix: 8.1608
New value of Value function: 8.61421
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 170
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.62445
New value of Value function: 8.62445
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 171
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.69369
New value of Value function: 5.71364
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 172
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 4.17537
New value of Value function: 5.69369
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 173
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 9.23118
New value of Value function: 9.23118
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 174
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.67356
New value of Value function: 5.67714
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 175
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 5.65583
New value of Value function: 5.67714
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 176
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 5.6373
New value of Value function: 5.65583
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 7.6997
New value of Value function: 8.61421
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 8.60818
New value of Value function: 8.60818
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 205
New value of Q matrix: 8.60756
New value of Value function: 8.60756
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 180
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.63795
New value of Value function: 5.63795
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 181
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.62095
New value of Value function: 5.6373
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 182
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 4.98191
New value of Value function: 5.62095
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 183
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 3.34246
New value of Value function: 3.34246
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 184
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 5.60472
New value of Value function: 5.60472
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 185
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.58918
New value of Value function: 5.58918
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 186
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.57424
New value of Value function: 5.57424
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 187
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.55985
New value of Value function: 5.55985
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 188
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.54595
New value of Value function: 5.54595
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 189
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.5325
New value of Value function: 5.5325
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 190
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.51946
New value of Value function: 5.51946
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 191
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 16
New value of Q matrix: 4.81369
New value of Value function: 5.51946
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 192
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.46426
New value of Value function: 4.46426
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 193
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.50679
New value of Value function: 5.50679
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 194
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.49448
New value of Value function: 5.49448
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 195
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.48249
New value of Value function: 5.48249
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 196
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 5.97841
New value of Value function: 5.97841
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 197
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 5.04669
New value of Value function: 5.04669
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 154
New value of Q matrix: 8.22187
New value of Value function: 8.60756
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 199
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 5.8467
New value of Value function: 5.8467
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 200
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 7.66884
New value of Value function: 7.66884
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 7.44152
New value of Value function: 8.60756
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 8.60156
New value of Value function: 8.60156
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 8.24546
New value of Value function: 8.60156
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 207
New value of Q matrix: 9
New value of Value function: 9
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 5
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.81781
New value of Value function: 11.4486
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 208
New value of Q matrix: 9.14295
New value of Value function: 9.14295
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 7
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.02169
New value of Value function: 8.14309
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 8
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 8.12712
New value of Value function: 8.12712
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 9
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 2.66886
New value of Value function: 8.12712
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 10
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 4.13229
New value of Value function: 4.13229
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 209
New value of Q matrix: 9.27469
New value of Value function: 9.27469
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 12
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 9.0779
New value of Value function: 9.0779
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 13
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 6.55907
New value of Value function: 6.55907
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 210
New value of Q matrix: 9.28979
New value of Value function: 9.28979
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 15
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.67008
New value of Value function: 8.67008
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 16
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 4.3534
New value of Value function: 8.31787
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 17
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 5.24732
New value of Value function: 5.24732
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 211
New value of Q matrix: 9.38118
New value of Value function: 9.38118
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 19
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 7.27008
New value of Value function: 7.27008
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 212
New value of Q matrix: 9.28488
New value of Value function: 9.28488
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 21
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.58408
New value of Value function: 9.58408
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 22
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.35965
New value of Value function: 9.23118
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 23
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 8.35385
New value of Value function: 8.35385
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 7.97216
New value of Value function: 9.28488
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 8.32124
New value of Value function: 9.28488
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 7.33014
New value of Value function: 9.28488
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 7.71491
New value of Value function: 9.28488
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 9.27851
New value of Value function: 9.27851
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 214
New value of Q matrix: 9.41467
New value of Value function: 9.41467
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 30
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 7.78991
New value of Value function: 7.78991
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 7.57331
New value of Value function: 9.41467
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 215
New value of Q matrix: 9.50315
New value of Value function: 9.50315
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 33
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 7.39446
New value of Value function: 7.39446
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 34
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.7902
New value of Value function: 5.7902
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 216
New value of Q matrix: 9.45451
New value of Value function: 9.45451
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 36
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 5.96445
New value of Value function: 5.96445
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 7.78997
New value of Value function: 9.45451
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 217
New value of Q matrix: 9.41719
New value of Value function: 9.41719
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 39
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 6.04463
New value of Value function: 6.04463
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 218
New value of Q matrix: 9.38786
New value of Value function: 9.38786
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 41
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 6.09904
New value of Value function: 6.09904
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 219
New value of Q matrix: 9.36422
New value of Value function: 9.36422
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 43
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 6.63058
New value of Value function: 6.63058
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 44
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 6.45377
New value of Value function: 6.45377
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 45
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 6.78877
New value of Value function: 6.78877
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 46
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 6.08732
New value of Value function: 6.08732
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 47
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 7.44349
New value of Value function: 7.44349
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 48
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.54634
New value of Value function: 5.54634
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 220
New value of Q matrix: 9.43197
New value of Value function: 9.43197
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 50
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 8.05296
New value of Value function: 8.05296
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 51
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 5.84543
New value of Value function: 5.84543
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 221
New value of Q matrix: 9.38858
New value of Value function: 9.38858
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 53
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.01219
New value of Value function: 5.84543
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 54
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 3.07576
New value of Value function: 8.05296
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 222
New value of Q matrix: 9.49488
New value of Value function: 9.49488
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 56
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 5.04148
New value of Value function: 8.05296
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 57
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.43774
New value of Value function: 7.75304
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 58
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 8.36859
New value of Value function: 8.36859
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 59
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 8.58915
New value of Value function: 8.58915
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 60
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 6.04148
New value of Value function: 6.04148
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 7.98379
New value of Value function: 9.49488
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 8.22859
New value of Value function: 9.49488
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 223
New value of Q matrix: 9.46048
New value of Value function: 9.46048
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 64
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.02134
New value of Value function: 6.02134
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 65
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 1.40706
New value of Value function: 6.02134
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 66
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 5.30008
New value of Value function: 5.30008
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 67
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 4.42646
New value of Value function: 4.42646
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 68
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.41815
New value of Value function: 3.43507
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 69
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 23
New value of Q matrix: 3.42405
New value of Value function: 3.42405
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 70
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 4.41898
New value of Value function: 4.41898
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 71
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 24
New value of Q matrix: 3.41399
New value of Value function: 3.41815
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 72
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 25
New value of Q matrix: 4.41197
New value of Value function: 4.41197
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 73
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.40734
New value of Value function: 3.41399
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 74
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 25
New value of Q matrix: 3.40476
New value of Value function: 3.40734
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 75
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 4.40438
New value of Value function: 4.40438
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 76
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.39707
New value of Value function: 3.40476
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 77
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 26
New value of Q matrix: 3.39605
New value of Value function: 3.39707
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 78
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 4.39644
New value of Value function: 4.39644
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 79
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.38726
New value of Value function: 3.39605
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 80
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.38028
New value of Value function: 3.39605
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 81
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.37542
New value of Value function: 3.39605
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 82
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 27
New value of Q matrix: 3.38766
New value of Value function: 3.38766
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 83
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 28
New value of Q matrix: 4.38838
New value of Value function: 4.38838
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 84
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 28
New value of Q matrix: 3.37951
New value of Value function: 3.37951
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 85
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 29
New value of Q matrix: 4.38045
New value of Value function: 4.38045
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 86
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 3.37951
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 87
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 88
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 89
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 90
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 91
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 92
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 93
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 94
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 95
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 96
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 97
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 98
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 99
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0146447
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 100
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 101
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 102
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 103
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 104
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 105
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 106
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 107
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 108
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 109
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 110
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 111
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 112
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 113
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 114
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 115
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 116
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 117
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 118
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 119
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 120
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 121
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 122
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 123
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 124
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 125
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 126
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.00618956
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 127
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 128
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 129
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 130
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 131
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 132
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 133
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 1
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 224
New value of Q matrix: 9.30216
New value of Value function: 9.30216
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 2
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 4.6515
New value of Value function: 4.6515
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 225
New value of Q matrix: 9.41841
New value of Value function: 9.41841
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 4
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 9.25488
New value of Value function: 9.25488
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 5
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 8.50705
New value of Value function: 8.50705
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 6
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 6.32422
New value of Value function: 6.32422
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 226
New value of Q matrix: 9.40986
New value of Value function: 9.40986
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 8
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 8.117
New value of Value function: 8.117
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 9
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 7.98255
New value of Value function: 7.98255
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 10
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.05916
New value of Value function: 8.05916
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 11
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 5.23587
New value of Value function: 5.23587
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 12
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.6372
New value of Value function: 10.6372
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 13
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.665295
New value of Value function: 9.54267
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 14
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 7.96151
New value of Value function: 7.96151
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 15
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.23469
New value of Value function: 9.54267
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 16
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 10.1646
New value of Value function: 10.1646
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 17
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 9.43348
New value of Value function: 9.43348
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 18
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 8.72802
New value of Value function: 8.72802
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 19
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 6.92234
New value of Value function: 6.92234
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 20
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 5.85312
New value of Value function: 5.85312
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 21
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 6.7707
New value of Value function: 6.7707
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 227
New value of Q matrix: 9.42932
New value of Value function: 9.42932
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 23
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 5.92151
New value of Value function: 6.7707
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 24
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 11.4443
New value of Value function: 11.4443
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 25
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 8.9391
New value of Value function: 8.9391
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 26
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 4.06331
New value of Value function: 8.58915
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 27
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 9.34297
New value of Value function: 9.34297
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 28
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 27
New value of Q matrix: 8.15534
New value of Value function: 8.15534
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 228
New value of Q matrix: 9.53823
New value of Value function: 9.53823
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 30
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 28
New value of Q matrix: 7.83171
New value of Value function: 7.83171
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 229
New value of Q matrix: 9.61853
New value of Value function: 9.61853
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 32
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 29
New value of Q matrix: 7.68218
New value of Value function: 7.68218
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 33
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 6.31899
New value of Value function: 6.31899
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 34
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 8.28083
New value of Value function: 8.28083
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 35
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.69683
New value of Value function: 6.02134
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 36
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 8.76222
New value of Value function: 8.76222
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 37
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 6.17977
New value of Value function: 6.17977
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 230
New value of Q matrix: 9.7541
New value of Value function: 9.7541
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 39
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 9.17867
New value of Value function: 9.17867
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 40
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 6.32353
New value of Value function: 6.32353
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 231
New value of Q matrix: 9.72161
New value of Value function: 9.72161
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 42
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 6.30527
New value of Value function: 6.30527
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 43
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 6.28779
New value of Value function: 6.28779
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 44
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.27098
New value of Value function: 6.27098
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 45
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.25479
New value of Value function: 6.25479
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 46
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 2.51236
New value of Value function: 6.25479
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 47
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.435484
New value of Value function: 0.435484
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 48
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 5.50337
New value of Value function: 5.50337
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 49
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 30
New value of Q matrix: 4.37411
New value of Value function: 4.37411
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 50
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 29
New value of Q matrix: 3.37038
New value of Value function: 3.37542
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 51
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 31
New value of Q matrix: 4.36828
New value of Value function: 4.36828
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 52
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 30
New value of Q matrix: 3.36203
New value of Value function: 3.37542
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 53
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 32
New value of Q matrix: 4.36358
New value of Value function: 4.36358
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 54
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.3667
New value of Value function: 3.3667
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 55
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.35829
New value of Value function: 3.36203
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 56
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.35104
New value of Value function: 3.36203
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 57
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 31
New value of Q matrix: 3.35447
New value of Value function: 3.35447
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 58
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 33
New value of Q matrix: 4.35615
New value of Value function: 4.35615
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 59
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 32
New value of Q matrix: 3.34706
New value of Value function: 3.35104
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 60
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 34
New value of Q matrix: 4.34953
New value of Value function: 4.34953
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 61
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 3.35104
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 62
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 63
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 64
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 65
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 66
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 67
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 68
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.299964
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 69
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 9.32986
New value of Value function: 9.32986
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 70
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 12.4361
New value of Value function: 12.4361
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 71
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.51218
New value of Value function: 9.34297
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 72
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 8.54513
New value of Value function: 8.54513
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 73
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 9.52918
New value of Value function: 9.52918
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 74
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 6.34719
New value of Value function: 6.34719
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 232
New value of Q matrix: 9.89968
New value of Value function: 9.89968
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 76
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 9.83008
New value of Value function: 9.83008
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 77
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 6.3318
New value of Value function: 6.3318
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 78
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 18
New value of Q matrix: 5.37108
New value of Value function: 5.37108
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 79
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 7.54307
New value of Value function: 7.54307
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 80
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.35875
New value of Value function: 5.35875
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 81
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.34677
New value of Value function: 5.34677
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 82
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 6.80068
New value of Value function: 6.80068
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 233
New value of Q matrix: 9.88874
New value of Value function: 9.88874
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 84
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.6492
New value of Value function: 6.80068
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 85
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 6.79302
New value of Value function: 6.79302
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 234
New value of Q matrix: 9.87804
New value of Value function: 9.87804
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 87
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.78508
New value of Value function: 6.78508
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 235
New value of Q matrix: 9.86755
New value of Value function: 9.86755
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 89
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.07258
New value of Value function: 6.78508
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 90
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 5.65784
New value of Value function: 5.65784
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 91
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 35
New value of Q matrix: 4.34412
New value of Value function: 4.34412
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 92
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 33
New value of Q matrix: 3.33899
New value of Value function: 3.35104
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 93
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 36
New value of Q matrix: 4.33969
New value of Value function: 4.33969
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 94
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.34314
New value of Value function: 3.34314
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 95
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.33547
New value of Value function: 3.33899
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 96
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 34
New value of Q matrix: 3.33167
New value of Value function: 3.33547
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 97
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 37
New value of Q matrix: 4.33351
New value of Value function: 4.33351
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 98
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.32801
New value of Value function: 3.33167
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 99
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 35
New value of Q matrix: 3.32465
New value of Value function: 3.32801
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 100
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 38
New value of Q matrix: 4.32722
New value of Value function: 4.32722
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 101
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.32075
New value of Value function: 3.32465
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 102
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 3.32465
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 103
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.90029
New value of Value function: 6.90029
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 104
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 36
New value of Q matrix: 3.31787
New value of Value function: 3.32075
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 105
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 39
New value of Q matrix: 4.32087
New value of Value function: 4.32087
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 106
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.31367
New value of Value function: 3.31787
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 107
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 37
New value of Q matrix: 3.31126
New value of Value function: 3.31367
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 108
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 40
New value of Q matrix: 4.31449
New value of Value function: 4.31449
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 109
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.30676
New value of Value function: 3.31126
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 110
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 38
New value of Q matrix: 3.30478
New value of Value function: 3.30676
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 111
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 41
New value of Q matrix: 4.30812
New value of Value function: 4.30812
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 112
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.85788
New value of Value function: 3.30676
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 113
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 47.0604
New value of Value function: 47.0604
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 114
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 2
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3981
	Distance: 9
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 236
New value of Q matrix: 9.42051
New value of Value function: 9.42051
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 2
----------
State: 3981
	Distance: 9
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 6.32631
New value of Value function: 6.32631
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 237
New value of Q matrix: 9.52111
New value of Value function: 9.52111
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 4
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 7.26742
New value of Value function: 8.04969
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 5
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.08766
New value of Value function: 6.08766
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 6
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.99989
New value of Value function: 8.04969
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 7
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 7.9324
New value of Value function: 8.04969
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 8
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.05722
New value of Value function: 6.05722
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 9
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 8.0092
New value of Value function: 8.0092
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 10
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.53489
New value of Value function: 8.50705
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 11
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 8.86779
New value of Value function: 8.86779
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 12
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 4.96464
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 13
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.00092
New value of Value function: 9.00092
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 14
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 4.76134
New value of Value function: 4.76134
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 15
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.68546
New value of Value function: 4.68546
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 238
New value of Q matrix: 9.40395
New value of Value function: 9.40395
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 17
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.6386
New value of Value function: 5.6386
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 18
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.6386
New value of Value function: 4.68546
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 19
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.62334
New value of Value function: 5.62334
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 239
New value of Q matrix: 9.3508
New value of Value function: 9.3508
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 21
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.91091
New value of Value function: 5.6386
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 22
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.79157
New value of Value function: 9.79157
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 23
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.17692
New value of Value function: 4.76134
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 24
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 25
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 26
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 27
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 28
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 6.25729
New value of Value function: 6.25729
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 157
New value of Q matrix: 8.27275
New value of Value function: 9.3508
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 30
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 5.32675
New value of Value function: 5.32675
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 240
New value of Q matrix: 9.28126
New value of Value function: 9.28126
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 32
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.30792
New value of Value function: 5.30792
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 33
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 7.24983
New value of Value function: 7.24983
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 34
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 4.67854
New value of Value function: 4.67854
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 35
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.07745
New value of Value function: 4.07745
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 241
New value of Q matrix: 9.37252
New value of Value function: 9.37252
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 37
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.88788
New value of Value function: 5.3036
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 38
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 39
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 8.81278
New value of Value function: 8.81278
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 40
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.32792
New value of Value function: 6.32792
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 41
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 5.38727
New value of Value function: 5.38727
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 242
New value of Q matrix: 9.30572
New value of Value function: 9.30572
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 43
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 5.64828
New value of Value function: 5.64828
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 243
New value of Q matrix: 9.20519
New value of Value function: 9.20519
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 45
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 5.58666
New value of Value function: 5.58666
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 46
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 3.88922
New value of Value function: 3.88922
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 47
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 3.99116
New value of Value function: 3.99116
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 244
New value of Q matrix: 9.16202
New value of Value function: 9.16202
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 49
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 6.06428
New value of Value function: 6.06428
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 50
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 4.89846
New value of Value function: 4.89846
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 51
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.91113
New value of Value function: 5.13206
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 52
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.12084
New value of Value function: 6.06428
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 245
New value of Q matrix: 9.1519
New value of Value function: 9.1519
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 54
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 6.69545
New value of Value function: 6.69545
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 55
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 5.55645
New value of Value function: 5.55645
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 56
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.1064
New value of Value function: 5.1064
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 57
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.88711
New value of Value function: 5.1064
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 58
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.07142
New value of Value function: 2.07142
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 59
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.08356
New value of Value function: 5.08356
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 60
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.06281
New value of Value function: 5.06281
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 61
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 3.96891
New value of Value function: 5.06281
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 62
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.03722
New value of Value function: 2.03722
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 63
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.04367
New value of Value function: 5.04367
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 64
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.02584
New value of Value function: 5.02584
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 65
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 5.00909
New value of Value function: 5.00909
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 66
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.99325
New value of Value function: 4.99325
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 67
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.97819
New value of Value function: 4.97819
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 68
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.96382
New value of Value function: 4.96382
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 69
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 4.97853
New value of Value function: 4.97853
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 70
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.02703
New value of Value function: 2.02703
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 71
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.01797
New value of Value function: 2.01797
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 72
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.00973
New value of Value function: 2.00973
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 73
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.98963
New value of Value function: 2.00973
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 74
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.00213
New value of Value function: 2.00213
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 75
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.99505
New value of Value function: 1.99505
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 76
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.205695
New value of Value function: 1.99505
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 77
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 5.96598
New value of Value function: 5.96598
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 78
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.01
New value of Value function: 1.99505
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 79
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.9751
New value of Value function: 4.9751
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 80
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.9884
New value of Value function: 1.98963
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 81
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.97556
New value of Value function: 1.9884
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 82
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.98212
New value of Value function: 1.98212
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 83
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.97614
New value of Value function: 1.97614
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 84
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.02467
New value of Value function: 1.97614
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 85
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 1
New value of Value function: 4.9751
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 86
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 1.95768
New value of Value function: 1.95768
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 87
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92535
New value of Value function: 4.9751
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 88
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.93992
New value of Value function: 4.93992
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 89
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.9114
New value of Value function: 4.92535
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 90
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.89053
New value of Value function: 4.9114
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 91
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.88685
New value of Value function: 4.89053
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 92
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.86229
New value of Value function: 4.88685
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 93
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.86499
New value of Value function: 4.86499
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 94
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.84513
New value of Value function: 4.86229
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 95
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.83798
New value of Value function: 4.84513
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 96
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 1.73253
New value of Value function: 4.84513
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 97
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.456814
New value of Value function: 1.95768
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 98
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 2.7801
New value of Value function: 2.7801
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 99
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.82682
New value of Value function: 4.83798
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 100
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.81634
New value of Value function: 4.82682
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 101
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.95638
New value of Value function: 4.95638
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 102
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 1.98303
New value of Value function: 1.98303
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 103
----------
State: 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0931853
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 104
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.9612
New value of Value function: 4.9612
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 105
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.97753
New value of Value function: 1.97753
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 106
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.97224
New value of Value function: 1.97556
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 107
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.96416
New value of Value function: 1.97224
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 108
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.96715
New value of Value function: 1.96715
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 109
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.96223
New value of Value function: 1.96416
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 110
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.95434
New value of Value function: 1.96223
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 111
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.95747
New value of Value function: 1.95747
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 112
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.95286
New value of Value function: 1.95434
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 113
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.9456
New value of Value function: 1.95286
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 114
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.94838
New value of Value function: 1.94838
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 115
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.94402
New value of Value function: 1.9456
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 116
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.93765
New value of Value function: 1.94402
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 117
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.93978
New value of Value function: 1.93978
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 118
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 1.93564
New value of Value function: 1.93765
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 119
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.93033
New value of Value function: 1.93564
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 120
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 1.93161
New value of Value function: 1.93161
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 121
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 1.92767
New value of Value function: 1.93033
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 122
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.9235
New value of Value function: 1.92767
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 123
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 1.92381
New value of Value function: 1.92381
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 124
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 1.92004
New value of Value function: 1.9235
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 125
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.91709
New value of Value function: 1.92004
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 126
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 1.91634
New value of Value function: 1.91709
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 127
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.762982
New value of Value function: 1.91709
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 128
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.92467
New value of Value function: 4.92467
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 129
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.91103
New value of Value function: 1.91634
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 130
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 1.91272
New value of Value function: 1.91272
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 131
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.45004
New value of Value function: 1.91272
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 132
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 4.41549
New value of Value function: 4.82682
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 133
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 6.22325
New value of Value function: 6.22325
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 134
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 1.90917
New value of Value function: 1.91103
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 135
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.90527
New value of Value function: 1.90917
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 136
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 1.90568
New value of Value function: 1.90568
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 137
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 1.90226
New value of Value function: 1.90527
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 138
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 1.32079
New value of Value function: 1.90527
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 139
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 6.40044
New value of Value function: 6.40044
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 140
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.89977
New value of Value function: 1.90226
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 141
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 1.8989
New value of Value function: 1.89977
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 142
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.8945
New value of Value function: 1.8989
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 143
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 1.89559
New value of Value function: 1.89559
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 144
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 1.89234
New value of Value function: 1.8945
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 145
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.88944
New value of Value function: 1.89234
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 146
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 1.88914
New value of Value function: 1.88944
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 147
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.88456
New value of Value function: 1.88914
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 148
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 1.88599
New value of Value function: 1.88599
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 149
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.92874
New value of Value function: 1.92874
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 150
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.96522
New value of Value function: 4.96522
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 151
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 4.95082
New value of Value function: 4.95082
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 152
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.89078
New value of Value function: 1.92874
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 153
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.90935
New value of Value function: 1.90935
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 154
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.93845
New value of Value function: 4.93845
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 155
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.92647
New value of Value function: 4.92647
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 156
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.91486
New value of Value function: 4.91486
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 157
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.90358
New value of Value function: 4.90358
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 158
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 2.44297
New value of Value function: 4.90358
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 159
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 6.51769
New value of Value function: 6.51769
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 160
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.89262
New value of Value function: 4.89262
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 161
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.88194
New value of Value function: 4.88194
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 162
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.87153
New value of Value function: 4.87153
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 163
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.86138
New value of Value function: 4.86138
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 164
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.9746
New value of Value function: 4.86138
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 246
New value of Q matrix: 9.06652
New value of Value function: 9.06652
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 166
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.85145
New value of Value function: 4.85145
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 167
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.84175
New value of Value function: 4.84175
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 168
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.83225
New value of Value function: 4.83225
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 169
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 3.26336
New value of Value function: 4.83225
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 170
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 6.58425
New value of Value function: 6.58425
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 171
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 4.38095
New value of Value function: 4.83225
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 172
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.83694
New value of Value function: 1.89078
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 173
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.82295
New value of Value function: 4.82295
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 174
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.81384
New value of Value function: 4.81384
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 175
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.8049
New value of Value function: 4.8049
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 176
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.79613
New value of Value function: 4.79613
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 177
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 4.58137
New value of Value function: 4.79613
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 178
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.8862
New value of Value function: 1.8862
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 179
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.88175
New value of Value function: 1.88599
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 180
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 1.88289
New value of Value function: 1.88289
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 181
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 1.87984
New value of Value function: 1.88175
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 182
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.87743
New value of Value function: 1.87984
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 183
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 1.87683
New value of Value function: 1.87743
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 184
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.87324
New value of Value function: 1.87683
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 185
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 1.87386
New value of Value function: 1.87386
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 186
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 1.87094
New value of Value function: 1.87324
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 187
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.86915
New value of Value function: 1.87094
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 188
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 1.86805
New value of Value function: 1.86915
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 189
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 1.86516
New value of Value function: 1.86805
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 190
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 1.8652
New value of Value function: 1.8652
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 191
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 1.86239
New value of Value function: 1.86516
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 192
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 1.40146
New value of Value function: 1.86516
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 193
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 6.64786
New value of Value function: 6.64786
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 194
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 1.86127
New value of Value function: 1.86239
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 195
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 1.85961
New value of Value function: 1.86127
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 196
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 1.85711
New value of Value function: 1.86127
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 197
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 1.46947
New value of Value function: 1.86127
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 198
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 6.69377
New value of Value function: 6.69377
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 199
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 1.85747
New value of Value function: 1.85747
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 200
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.34932
New value of Value function: 1.85747
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3981
	Distance: 9
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 247
New value of Q matrix: 9.07902
New value of Value function: 9.07902
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 2
----------
State: 3981
	Distance: 9
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 6.08725
New value of Value function: 6.08725
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 248
New value of Q matrix: 9.19905
New value of Value function: 9.19905
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 4
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 8.65009
New value of Value function: 8.65009
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 5
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.1819
New value of Value function: 6.1819
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 6
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 6.51248
New value of Value function: 6.51248
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 7
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 10.2808
New value of Value function: 10.2808
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 8
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.8585
New value of Value function: 10.8585
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 9
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 6.88845
New value of Value function: 6.88845
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 249
New value of Q matrix: 9.23837
New value of Value function: 9.23837
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 11
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 3.2941
New value of Value function: 6.88845
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 12
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 5.81957
New value of Value function: 5.81957
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 13
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 7.71559
New value of Value function: 7.71559
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 14
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 5.19736
New value of Value function: 5.19736
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 250
New value of Q matrix: 9.16925
New value of Value function: 9.16925
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 16
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.88176
New value of Value function: 6.88176
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 17
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.89772
New value of Value function: 5.3036
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 18
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.85087
New value of Value function: 5.85087
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 7.92517
New value of Value function: 9.16925
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 9.16346
New value of Value function: 9.16346
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 252
New value of Q matrix: 9.14008
New value of Value function: 9.14008
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 22
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 2.49404
New value of Value function: 4.89772
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 23
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 5.06307
New value of Value function: 5.06307
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 8.11107
New value of Value function: 9.14008
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 253
New value of Q matrix: 9.0589
New value of Value function: 9.0589
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 26
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.86945
New value of Value function: 4.86945
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 27
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.8451
New value of Value function: 4.8451
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 28
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.82343
New value of Value function: 4.82343
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 29
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.80374
New value of Value function: 4.80374
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 30
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.78558
New value of Value function: 4.78558
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 31
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.76866
New value of Value function: 4.76866
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 32
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.75277
New value of Value function: 4.75277
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 33
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.73774
New value of Value function: 4.73774
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 34
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.72345
New value of Value function: 4.72345
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 35
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.70982
New value of Value function: 4.70982
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 36
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.086
New value of Value function: 5.086
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 8.35935
New value of Value function: 9.0589
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 9.05321
New value of Value function: 9.05321
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 8.08339
New value of Value function: 9.05321
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 9.04754
New value of Value function: 9.04754
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 256
New value of Q matrix: 9.01906
New value of Value function: 9.01906
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 42
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 5.73288
New value of Value function: 5.73288
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 257
New value of Q matrix: 8.99763
New value of Value function: 8.99763
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 44
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 5.78333
New value of Value function: 5.78333
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 258
New value of Q matrix: 8.98069
New value of Value function: 8.98069
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 46
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 5.81316
New value of Value function: 5.81316
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 259
New value of Q matrix: 9.02094
New value of Value function: 9.02094
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 48
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 7.67258
New value of Value function: 7.67258
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 49
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 6.29401
New value of Value function: 6.29401
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 50
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 4.5291
New value of Value function: 4.5291
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 260
New value of Q matrix: 9.11861
New value of Value function: 9.11861
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 52
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 8.16542
New value of Value function: 8.16542
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 53
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.36559
New value of Value function: 6.29401
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 54
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 4.83109
New value of Value function: 4.83109
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 55
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 1.85376
New value of Value function: 1.85711
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 56
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 47
New value of Q matrix: 1.84122
New value of Value function: 1.85376
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 57
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.78752
New value of Value function: 4.78752
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 58
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 3.62912
New value of Value function: 4.78752
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 59
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 6.39365
New value of Value function: 6.39365
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 60
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 3.87682
New value of Value function: 4.78752
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 61
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 6.46915
New value of Value function: 6.46915
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 62
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.77905
New value of Value function: 4.77905
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 63
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.77073
New value of Value function: 4.77073
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 64
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 4.67732
New value of Value function: 4.77073
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 65
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 1.85012
New value of Value function: 1.85012
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 66
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.56605
New value of Value function: 1.85012
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 67
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 4.83127
New value of Value function: 4.83127
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 68
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.83983
New value of Value function: 1.85012
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 69
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.66305
New value of Value function: 1.85012
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 70
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 4.88462
New value of Value function: 4.88462
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 71
----------
State: 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -1.2477
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 72
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 3.21108
New value of Value function: 3.21108
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 73
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.82428
New value of Value function: 4.88462
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 74
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.8699
New value of Value function: 4.8699
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 75
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.85584
New value of Value function: 4.85584
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 76
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.84237
New value of Value function: 4.84237
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 77
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 4.60159
New value of Value function: 4.84237
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 78
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 1.84656
New value of Value function: 1.84656
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 79
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 1.84307
New value of Value function: 1.84307
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 80
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 1.83965
New value of Value function: 1.83983
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 81
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 1.83721
New value of Value function: 1.83965
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 82
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 1.83629
New value of Value function: 1.83721
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 83
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 50
New value of Q matrix: 1.77601
New value of Value function: 1.83694
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 84
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 6.54365
New value of Value function: 6.54365
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 85
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 51
New value of Q matrix: 1.80737
New value of Value function: 1.83694
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 86
----------
State: 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.172995
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 87
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 4.8845
New value of Value function: 4.8845
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 88
----------
State: 1453
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1854
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 1
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 261
New value of Q matrix: 9.02492
New value of Value function: 9.02492
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 2
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 4.96272
New value of Value function: 4.96272
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 262
New value of Q matrix: 9.21875
New value of Value function: 9.21875
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 4
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 10.3742
New value of Value function: 10.3742
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 5
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 9.569
New value of Value function: 9.569
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 6
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 6.18446
New value of Value function: 6.18446
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 263
New value of Q matrix: 9.3308
New value of Value function: 9.3308
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 8
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 9.36281
New value of Value function: 9.36281
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 9
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.50028
New value of Value function: 6.50028
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 10
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.0858
New value of Value function: 11.0858
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 11
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 10.028
New value of Value function: 10.028
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 12
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 8.16279
New value of Value function: 8.16279
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 13
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 12.1485
New value of Value function: 12.1485
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 14
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 10.7521
New value of Value function: 10.7521
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 15
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 9.6778
New value of Value function: 9.6778
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 16
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 10.0033
New value of Value function: 10.0033
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 17
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 35
New value of Q matrix: 9.22282
New value of Value function: 9.22282
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 8.51222
New value of Value function: 9.3308
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 8.24475
New value of Value function: 9.3308
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 9.32506
New value of Value function: 9.32506
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 265
New value of Q matrix: 9.4974
New value of Value function: 9.4974
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 22
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 36
New value of Q matrix: 8.75276
New value of Value function: 8.75276
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 8.38118
New value of Value function: 9.4974
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 266
New value of Q matrix: 9.63032
New value of Value function: 9.63032
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 25
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 37
New value of Q matrix: 8.70588
New value of Value function: 8.70588
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 26
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 6.53401
New value of Value function: 7.54307
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 267
New value of Q matrix: 9.75201
New value of Value function: 9.75201
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 28
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 9.19439
New value of Value function: 9.19439
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 29
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 6.71979
New value of Value function: 6.71979
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 8.70812
New value of Value function: 9.75201
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 268
New value of Q matrix: 9.74594
New value of Value function: 9.74594
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 32
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 5.26538
New value of Value function: 5.6492
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 33
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 8.31776
New value of Value function: 8.31776
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 34
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 5.86225
New value of Value function: 5.86225
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 269
New value of Q matrix: 9.88962
New value of Value function: 9.88962
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 36
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 5.91592
New value of Value function: 9.19439
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 37
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 5.77259
New value of Value function: 5.77259
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 38
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 42
New value of Q matrix: 4.30281
New value of Value function: 4.30281
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 39
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.30001
New value of Value function: 3.30478
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 40
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 39
New value of Q matrix: 3.29757
New value of Value function: 3.30001
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 41
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 43
New value of Q matrix: 4.29735
New value of Value function: 4.29735
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 42
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.29341
New value of Value function: 3.29757
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 43
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 40
New value of Q matrix: 3.29074
New value of Value function: 3.29341
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 44
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 44
New value of Q matrix: 4.29179
New value of Value function: 4.29179
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 45
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 41
New value of Q matrix: 3.2842
New value of Value function: 3.29341
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 46
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 45
New value of Q matrix: 4.28712
New value of Value function: 4.28712
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 47
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.28695
New value of Value function: 3.28695
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 48
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 49
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: -0.405081
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 50
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.797175
New value of Value function: 0.797175
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 51
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 46
New value of Q matrix: 4.38633
New value of Value function: 4.38633
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 52
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 53
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 1
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 270
New value of Q matrix: 9.76933
New value of Value function: 9.76933
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 2
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 5.36551
New value of Value function: 5.36551
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 271
New value of Q matrix: 9.98201
New value of Value function: 9.98201
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 4
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 11.1354
New value of Value function: 11.1354
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 5
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 9.00776
New value of Value function: 9.00776
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 6
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.12261
New value of Value function: 6.18446
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 7
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.58729
New value of Value function: 6.58729
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 272
New value of Q matrix: 10.0791
New value of Value function: 10.0791
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 9
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 10.5976
New value of Value function: 10.5976
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 10
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.86368
New value of Value function: 10.1646
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 11
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 7.64408
New value of Value function: 7.64408
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 12
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.13209
New value of Value function: 5.13209
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 273
New value of Q matrix: 10.2249
New value of Value function: 10.2249
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 14
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 11.9629
New value of Value function: 11.9629
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 15
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 7.95466
New value of Value function: 10.0033
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 16
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.84328
New value of Value function: 12.4361
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 17
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 11.8433
New value of Value function: 11.9629
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 18
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 13.1633
New value of Value function: 13.1633
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 19
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 9.34247
New value of Value function: 9.34247
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 274
New value of Q matrix: 10.3472
New value of Value function: 10.3472
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 21
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 8.77274
New value of Value function: 8.77274
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 22
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 7.14847
New value of Value function: 7.14847
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 23
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 8.43908
New value of Value function: 8.43908
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 8.40907
New value of Value function: 10.3472
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 10.341
New value of Value function: 10.341
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 276
New value of Q matrix: 10.402
New value of Value function: 10.402
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 27
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 9.64652
New value of Value function: 9.64652
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 28
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 39
New value of Q matrix: 8.89072
New value of Value function: 8.89072
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 8.69065
New value of Value function: 10.402
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 8.97685
New value of Value function: 10.402
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 10.3957
New value of Value function: 10.3957
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 278
New value of Q matrix: 10.296
New value of Value function: 10.296
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 33
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 6.32041
New value of Value function: 6.32041
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 279
New value of Q matrix: 10.3861
New value of Value function: 10.3861
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 35
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 40
New value of Q matrix: 8.6364
New value of Value function: 8.6364
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 280
New value of Q matrix: 10.4557
New value of Value function: 10.4557
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 37
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 8.97486
New value of Value function: 8.97486
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 38
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.36932
New value of Value function: 5.86225
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 39
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 3.05014
New value of Value function: 5.86225
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 40
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 5.87841
New value of Value function: 5.87841
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 41
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 47
New value of Q matrix: 4.47001
New value of Value function: 4.47001
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 42
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.8783
New value of Value function: 3.8783
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 43
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 0.806342
New value of Value function: 0.806342
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 44
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 5.97826
New value of Value function: 5.97826
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 45
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.195511
New value of Value function: 4.47001
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 46
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 8.36102
New value of Value function: 8.36102
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 47
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 31
New value of Q matrix: 5.85239
New value of Value function: 5.85239
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 48
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.42531
New value of Value function: 9.42531
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 49
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 48
New value of Q matrix: 4.52334
New value of Value function: 4.52334
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 50
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 51.4591
New value of Value function: 51.4591
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 51
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 2
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 10.4495
New value of Value function: 10.4495
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 282
New value of Q matrix: 10.6623
New value of Value function: 10.6623
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 3
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 4.75523
New value of Value function: 11.1354
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 4
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.5557
New value of Value function: 11.4486
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 8.63569
New value of Value function: 10.6623
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 283
New value of Q matrix: 10.8622
New value of Value function: 10.8622
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 7
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.4781
New value of Value function: 11.1354
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 8
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 30
New value of Q matrix: 10.2547
New value of Value function: 10.2547
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 9
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.33411
New value of Value function: 6.33411
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 10
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 13.3603
New value of Value function: 13.3603
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 11
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 9.44736
New value of Value function: 10.2547
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 12
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 6.75427
New value of Value function: 6.75427
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 13
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 10.9126
New value of Value function: 10.9126
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 14
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 10.4576
New value of Value function: 10.4576
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 15
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 11.8866
New value of Value function: 11.8866
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 16
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 10.1084
New value of Value function: 10.1084
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 17
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 12.0951
New value of Value function: 12.0951
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 18
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 10.0577
New value of Value function: 10.0577
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 19
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 13.3501
New value of Value function: 13.3501
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 20
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 10.4102
New value of Value function: 10.4102
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 21
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 9.48978
New value of Value function: 9.48978
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 22
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 9.25181
New value of Value function: 9.25181
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 284
New value of Q matrix: 10.9391
New value of Value function: 10.9391
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 24
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 8.96153
New value of Value function: 8.96153
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 285
New value of Q matrix: 10.9944
New value of Value function: 10.9944
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 26
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 8.74611
New value of Value function: 8.74611
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 286
New value of Q matrix: 10.7535
New value of Value function: 10.7535
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 28
----------
State: 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.64599
New value of Value function: 7.64599
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 287
New value of Q matrix: 10.8203
New value of Value function: 10.8203
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 30
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 42
New value of Q matrix: 8.78001
New value of Value function: 8.78001
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 288
New value of Q matrix: 10.8717
New value of Value function: 10.8717
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 32
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 7.00368
New value of Value function: 8.78001
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 33
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 32
New value of Q matrix: 5.93701
New value of Value function: 5.93701
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 34
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 8.41669
New value of Value function: 9.42531
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 35
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 10.8288
New value of Value function: 10.8288
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 36
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 33
New value of Q matrix: 6.0056
New value of Value function: 6.0056
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 37
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 7.83129
New value of Value function: 9.42531
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 38
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 7.92292
New value of Value function: 7.92292
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 39
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 6.08664
New value of Value function: 6.08664
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 40
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 49
New value of Q matrix: 11.2978
New value of Value function: 11.2978
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 41
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 30.1445
New value of Value function: 30.1445
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 42
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.80363
New value of Value function: 2.80363
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 43
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.85003
New value of Value function: 5.85003
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 44
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 5.83809
New value of Value function: 5.83809
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 45
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.82641
New value of Value function: 5.82641
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 46
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.81498
New value of Value function: 5.81498
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 47
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.80379
New value of Value function: 5.80379
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 48
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.79282
New value of Value function: 5.79282
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 49
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 5.78207
New value of Value function: 5.78207
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 50
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 4.1628
New value of Value function: 5.78207
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 51
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.7475
New value of Value function: 2.7475
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 52
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.77151
New value of Value function: 5.77151
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 53
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.76114
New value of Value function: 5.76114
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 54
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.62953
New value of Value function: 5.76114
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 55
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.75096
New value of Value function: 5.75096
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 56
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 4.75137
New value of Value function: 5.75096
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 57
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.71629
New value of Value function: 2.71629
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 58
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.74095
New value of Value function: 5.74095
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 59
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.7311
New value of Value function: 5.7311
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 60
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.72142
New value of Value function: 5.72142
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 61
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 5.08292
New value of Value function: 5.72142
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 62
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.69025
New value of Value function: 2.69025
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 63
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.71188
New value of Value function: 5.71188
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 64
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.70249
New value of Value function: 5.70249
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 65
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 3.49886
New value of Value function: 5.70249
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 66
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 7.28645
New value of Value function: 7.28645
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 67
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 50
New value of Q matrix: 14.0619
New value of Value function: 14.0619
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 68
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 23.1132
New value of Value function: 23.1132
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 69
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.52103
New value of Value function: 14.0619
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 70
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 51
New value of Q matrix: 26.1027
New value of Value function: 26.1027
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 71
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 3
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 10.8653
New value of Value function: 10.8653
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 9.27348
New value of Value function: 10.8653
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 290
New value of Q matrix: 11.0114
New value of Value function: 11.0114
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 4
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 9.81687
New value of Value function: 9.81687
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 5
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 8.7187
New value of Value function: 8.7187
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 6
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 9.77735
New value of Value function: 9.77735
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 7
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.89667
New value of Value function: 8.7187
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 8
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.24428
New value of Value function: 8.7187
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 158
New value of Q matrix: 8.62334
New value of Value function: 11.0114
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 10
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 9.74694
New value of Value function: 9.74694
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 11
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 8.66975
New value of Value function: 8.66975
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 12
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3973
	Distance: 9
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 24
New value of Q matrix: 6.94086
New value of Value function: 7.53489
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 13
----------
State: 3973
	Distance: 9
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 11.4595
New value of Value function: 11.4595
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 14
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.49139
New value of Value function: 7.49139
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 15
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 4.49811
New value of Value function: 7.49139
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 16
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 7.6955
New value of Value function: 7.6955
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 17
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.45393
New value of Value function: 7.45393
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 18
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.82589
New value of Value function: 7.45393
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 19
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 8.2568
New value of Value function: 8.2568
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 20
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.4206
New value of Value function: 7.4206
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 21
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.3903
New value of Value function: 7.3903
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 22
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 4.8147
New value of Value function: 7.3903
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 23
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 11.1608
New value of Value function: 11.1608
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 24
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.36237
New value of Value function: 7.36237
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 25
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.36677
New value of Value function: 7.36237
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 26
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 11.3571
New value of Value function: 11.3571
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 27
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.33634
New value of Value function: 7.33634
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 28
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 7.31188
New value of Value function: 7.31188
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 29
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 5.72472
New value of Value function: 7.31188
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 30
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 11.5083
New value of Value function: 11.5083
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 31
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 7.28876
New value of Value function: 7.28876
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 32
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 7.26679
New value of Value function: 7.26679
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 33
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 7.24581
New value of Value function: 7.24581
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 34
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 8.90624
New value of Value function: 8.90624
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 35
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.10776
New value of Value function: 11.8866
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 36
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 11.975
New value of Value function: 11.975
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 37
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 9.12522
New value of Value function: 9.12522
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 38
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.500175
New value of Value function: 5.83922
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 39
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 40
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 41
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 42
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 43
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 44
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 45
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 46
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 47
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 48
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 49
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 50
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 51
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 52
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 1.53553
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 53
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 54
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 55
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 56
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 57
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 58
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 59
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.98
New value of Value function: 4.98
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 60
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.10011
New value of Value function: 4.10011
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 61
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.41421
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 62
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 63
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 64
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 65
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 66
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 67
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 68
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 69
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 70
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 71
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 72
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 73
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 74
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 75
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 76
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 77
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 78
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 79
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 80
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 81
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 82
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 83
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 84
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 85
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 86
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 87
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 88
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 89
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 4.6286
New value of Value function: 4.6286
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 90
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.540818
New value of Value function: 9.32986
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 91
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 11.2144
New value of Value function: 11.2144
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 92
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 11.7223
New value of Value function: 11.7223
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 93
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 9.68028
New value of Value function: 9.68028
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 94
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 4.41412
New value of Value function: 8.78001
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 291
New value of Q matrix: 11.0513
New value of Value function: 11.0513
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 96
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 9.06449
New value of Value function: 9.06449
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 97
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 5.12648
New value of Value function: 5.70249
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 98
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 10.7123
New value of Value function: 10.7123
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 99
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 52
New value of Q matrix: 25.7947
New value of Value function: 25.7947
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 100
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 16.5178
New value of Value function: 16.5178
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 101
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.67022
New value of Value function: 2.67022
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 102
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.69324
New value of Value function: 5.69324
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 103
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.33904
New value of Value function: 5.69324
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 104
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.68412
New value of Value function: 5.68412
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 105
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 5.58351
New value of Value function: 5.68412
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 106
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.30259
New value of Value function: 10.7123
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 107
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 13.4782
New value of Value function: 13.4782
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 108
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 4.70604
New value of Value function: 25.7947
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 109
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.65269
New value of Value function: 2.65269
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 110
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.67513
New value of Value function: 5.67513
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 111
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 5.66627
New value of Value function: 5.66627
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 112
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.65753
New value of Value function: 5.65753
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 113
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 5.6489
New value of Value function: 5.6489
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 114
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 5.28449
New value of Value function: 5.6489
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 115
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 2.62991
New value of Value function: 2.62991
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 116
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.64038
New value of Value function: 5.64038
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 117
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.63198
New value of Value function: 5.63198
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 118
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.62367
New value of Value function: 5.62367
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 119
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.61547
New value of Value function: 5.61547
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 120
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.60736
New value of Value function: 5.60736
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 121
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.74312
New value of Value function: 5.60736
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 122
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 5.60683
New value of Value function: 5.60683
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 123
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 2.60192
New value of Value function: 2.60192
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 124
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.5989
New value of Value function: 5.5989
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 125
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.59106
New value of Value function: 5.59106
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 126
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.58331
New value of Value function: 5.58351
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 127
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 5.37236
New value of Value function: 5.58351
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 128
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 2.57717
New value of Value function: 2.57717
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 129
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 7.76056
New value of Value function: 7.76056
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 130
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 15.7588
New value of Value function: 15.7588
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 131
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 8.19867
New value of Value function: 25.7947
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 132
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 17.6448
New value of Value function: 17.6448
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 133
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 53
New value of Q matrix: 24.6351
New value of Value function: 24.6351
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 134
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 45.6938
New value of Value function: 45.6938
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 135
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 3
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 11.0448
New value of Value function: 11.0448
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 293
New value of Q matrix: 11.0751
New value of Value function: 11.0751
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 3
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 8.74603
New value of Value function: 8.74603
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 4
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 7.93387
New value of Value function: 7.93387
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 5
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 10.2484
New value of Value function: 10.2484
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 6
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.5852
New value of Value function: 11.5852
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 7
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 8.89839
New value of Value function: 8.89839
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 8
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 7.22412
New value of Value function: 7.22412
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 294
New value of Q matrix: 11.0213
New value of Value function: 11.0213
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 10
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 8.07167
New value of Value function: 8.07167
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 11
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 6.15378
New value of Value function: 6.15378
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 295
New value of Q matrix: 10.909
New value of Value function: 10.909
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 13
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 5.87375
New value of Value function: 5.87375
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 14
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.81501
New value of Value function: 4.81501
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 15
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 5.83812
New value of Value function: 5.83812
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 16
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 4.79007
New value of Value function: 4.79007
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 17
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 5.80778
New value of Value function: 5.80778
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 18
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 4.76676
New value of Value function: 4.76676
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 19
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 5.78104
New value of Value function: 5.78104
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 20
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.7191
New value of Value function: 4.76676
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 21
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.94611
New value of Value function: 4.94611
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 8.88727
New value of Value function: 10.909
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 296
New value of Q matrix: 10.7838
New value of Value function: 10.7838
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 24
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 6.31101
New value of Value function: 6.31101
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 297
New value of Q matrix: 10.6947
New value of Value function: 10.6947
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 26
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 6.64065
New value of Value function: 6.64065
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 298
New value of Q matrix: 10.6298
New value of Value function: 10.6298
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 28
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 6.86135
New value of Value function: 6.86135
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 299
New value of Q matrix: 10.656
New value of Value function: 10.656
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 30
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.18269
New value of Value function: 8.16542
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 31
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.99089
New value of Value function: 5.78104
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 32
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 7.88916
New value of Value function: 7.88916
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 33
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.08377
New value of Value function: 8.16542
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 34
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 6.60799
New value of Value function: 8.08377
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 35
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.79274
New value of Value function: 3.79274
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 36
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 7.02824
New value of Value function: 7.02824
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 300
New value of Q matrix: 10.676
New value of Value function: 10.676
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 38
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.0266
New value of Value function: 8.0266
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 39
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.98026
New value of Value function: 7.98026
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 40
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.94036
New value of Value function: 7.94036
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 41
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 7.43655
New value of Value function: 7.94036
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 42
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 6.58105
New value of Value function: 6.58105
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 43
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 4.62002
New value of Value function: 4.77073
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 44
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.86096
New value of Value function: 6.58105
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 45
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.68915
New value of Value function: 7.94036
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 301
New value of Q matrix: 10.6867
New value of Value function: 10.6867
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 47
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.96206
New value of Value function: 7.94036
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 48
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.77028
New value of Value function: 7.77028
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 49
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.90485
New value of Value function: 7.90485
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 50
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 7.24747
New value of Value function: 7.90485
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 51
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.52323
New value of Value function: 4.52323
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 52
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 7.30908
New value of Value function: 7.90485
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 53
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.69792
New value of Value function: 4.69792
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 54
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.87258
New value of Value function: 7.87258
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 55
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 4.32732
New value of Value function: 7.87258
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 56
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.75443
New value of Value function: 7.77028
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 57
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 9.24947
New value of Value function: 9.24947
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 58
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.84282
New value of Value function: 7.84282
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 59
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.8151
New value of Value function: 7.8151
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 60
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 7.78905
New value of Value function: 7.78905
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 61
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 7.76441
New value of Value function: 7.76441
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 62
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 7.39735
New value of Value function: 7.76441
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 63
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.69234
New value of Value function: 4.69234
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 64
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 7.741
New value of Value function: 7.741
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 65
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 7.71866
New value of Value function: 7.71866
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 66
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 7.69725
New value of Value function: 7.69725
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 67
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 6.63449
New value of Value function: 7.69725
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 159
New value of Q matrix: 8.90357
New value of Value function: 10.6867
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 69
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 5.03694
New value of Value function: 9.24947
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 302
New value of Q matrix: 10.7713
New value of Value function: 10.7713
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 71
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 9.97335
New value of Value function: 9.97335
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 72
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.87361
New value of Value function: 7.02824
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 73
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 10.4858
New value of Value function: 10.4858
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 74
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 7.17799
New value of Value function: 7.17799
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 303
New value of Q matrix: 10.7626
New value of Value function: 10.7626
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 76
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 7.67668
New value of Value function: 7.67668
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 77
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 7.65686
New value of Value function: 7.65686
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 78
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 7.09088
New value of Value function: 7.65686
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 9.5006
New value of Value function: 10.7626
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 304
New value of Q matrix: 10.5883
New value of Value function: 10.5883
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 81
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 34
New value of Q matrix: 5.23578
New value of Value function: 5.23578
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 305
New value of Q matrix: 10.5878
New value of Value function: 10.5878
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 83
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 7.63771
New value of Value function: 7.63771
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 84
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 7.61919
New value of Value function: 7.61919
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 85
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 4.93788
New value of Value function: 7.61919
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 86
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.18574
New value of Value function: 9.18574
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 87
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 6.70401
New value of Value function: 6.70401
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 88
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.22693
New value of Value function: 5.22693
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 89
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 4.62567
New value of Value function: 5.22693
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 90
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 6.79814
New value of Value function: 6.79814
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 91
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 4.65871
New value of Value function: 5.22693
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 92
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 6.80215
New value of Value function: 6.80215
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 93
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.0058
New value of Value function: 2.0058
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 94
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.21822
New value of Value function: 5.21822
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 95
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.20964
New value of Value function: 5.20964
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 96
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.20119
New value of Value function: 5.20119
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 97
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.19286
New value of Value function: 5.19286
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 98
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.18465
New value of Value function: 5.18465
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 99
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 5.17655
New value of Value function: 5.17655
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 100
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.16856
New value of Value function: 5.16856
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 101
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 5.16068
New value of Value function: 5.16068
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 102
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.1529
New value of Value function: 5.1529
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 103
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.14522
New value of Value function: 5.14522
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 104
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.13763
New value of Value function: 5.13763
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 105
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 4.75731
New value of Value function: 5.13763
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 106
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 52
New value of Q matrix: 1.84604
New value of Value function: 2.0058
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 107
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.13014
New value of Value function: 5.13014
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 108
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 4.82326
New value of Value function: 5.13014
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 109
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.03846
New value of Value function: 2.03846
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 110
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 4.16259
New value of Value function: 5.13014
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 111
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.85911
New value of Value function: 6.80215
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 112
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.63613
New value of Value function: 6.80215
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 113
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 7.60123
New value of Value function: 7.60123
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 114
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 7.58379
New value of Value function: 7.58379
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 115
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 7.56684
New value of Value function: 7.56684
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 116
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 7.55032
New value of Value function: 7.55032
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 117
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 7.53423
New value of Value function: 7.53423
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 118
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 7.51852
New value of Value function: 7.51852
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 119
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 7.98154
New value of Value function: 7.98154
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 120
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 6.8554
New value of Value function: 6.8554
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 121
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.12274
New value of Value function: 5.12274
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 122
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 5.11542
New value of Value function: 5.11542
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 123
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.10818
New value of Value function: 5.10818
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 124
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.10103
New value of Value function: 5.10103
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 125
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.09396
New value of Value function: 5.09396
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 126
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.59474
New value of Value function: 5.09396
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 127
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 5.08696
New value of Value function: 5.08696
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 128
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.08004
New value of Value function: 5.08004
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 129
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 5.07319
New value of Value function: 5.07319
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 130
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.06641
New value of Value function: 5.06641
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 131
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.0597
New value of Value function: 5.0597
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 132
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.05305
New value of Value function: 5.05305
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 133
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.04647
New value of Value function: 5.04647
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 134
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.03996
New value of Value function: 5.03996
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 135
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 4.35999
New value of Value function: 5.03996
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 136
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.29576
New value of Value function: 6.8554
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 137
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.09388
New value of Value function: 9.18574
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 138
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.34826
New value of Value function: 9.34826
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 139
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.78598
New value of Value function: 4.78598
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 140
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 8.41939
New value of Value function: 8.41939
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 141
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 6.88075
New value of Value function: 6.88075
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 142
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 4.05619
New value of Value function: 5.03996
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 306
New value of Q matrix: 10.4393
New value of Value function: 10.4393
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 144
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.03351
New value of Value function: 5.03351
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 145
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.02711
New value of Value function: 5.02711
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 146
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.02078
New value of Value function: 5.02078
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 147
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.0145
New value of Value function: 5.0145
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 148
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.00829
New value of Value function: 5.00829
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 149
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.00212
New value of Value function: 5.00212
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 150
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 4.99601
New value of Value function: 4.99601
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 151
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 4.98995
New value of Value function: 4.98995
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 152
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 4.98394
New value of Value function: 4.98394
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 153
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 4.97799
New value of Value function: 4.97799
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 154
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 4.97208
New value of Value function: 4.97208
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 155
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 4.96622
New value of Value function: 4.96622
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 156
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 5.21539
New value of Value function: 5.21539
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 307
New value of Q matrix: 10.3094
New value of Value function: 10.3094
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 158
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.67068
New value of Value function: 5.21539
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 159
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 5.87903
New value of Value function: 5.87903
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 308
New value of Q matrix: 10.2245
New value of Value function: 10.2245
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 161
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 6.27219
New value of Value function: 6.27219
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 309
New value of Q matrix: 10.1668
New value of Value function: 10.1668
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 163
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 6.51127
New value of Value function: 6.51127
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 310
New value of Q matrix: 10.1259
New value of Value function: 10.1259
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 165
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 6.65946
New value of Value function: 6.65946
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 160
New value of Q matrix: 9.09581
New value of Value function: 10.1259
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 167
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.02461
New value of Value function: 8.41939
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 8.88733
New value of Value function: 10.1259
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 10.1201
New value of Value function: 10.1201
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 312
New value of Q matrix: 10.0903
New value of Value function: 10.0903
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 171
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 4.49626
New value of Value function: 6.65946
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 172
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.40923
New value of Value function: 6.88075
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 173
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 5.47024
New value of Value function: 6.88075
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 174
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 4.91899
New value of Value function: 4.91899
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 175
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.67305
New value of Value function: 2.67305
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 176
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 5.05153
New value of Value function: 6.65946
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 177
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 1.98177
New value of Value function: 2.67305
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 178
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 3.0207
New value of Value function: 3.0207
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 179
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 13
New value of Q matrix: 4.94664
New value of Value function: 5.05153
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 180
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 7.3352
New value of Value function: 7.3352
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 181
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 8.74762
New value of Value function: 8.74762
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 182
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 6.90308
New value of Value function: 6.90308
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 183
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 5.30248
New value of Value function: 5.30248
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 184
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 2.74803
New value of Value function: 2.74803
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 185
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 4.59377
New value of Value function: 5.30248
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 186
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 6.96632
New value of Value function: 6.96632
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 187
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 5.41042
New value of Value function: 5.41042
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 188
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 1.96617
New value of Value function: 2.74803
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 189
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 2.61746
New value of Value function: 2.61746
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 190
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 5.49259
New value of Value function: 5.49259
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 313
New value of Q matrix: 9.99687
New value of Value function: 9.99687
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 192
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 5.85518
New value of Value function: 5.85518
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 9.00385
New value of Value function: 9.99687
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 314
New value of Q matrix: 9.92913
New value of Value function: 9.92913
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 195
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 6.09884
New value of Value function: 6.09884
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 161
New value of Q matrix: 9.29791
New value of Value function: 9.92913
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 197
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 5.88375
New value of Value function: 8.74762
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 198
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 9.78556
New value of Value function: 9.78556
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 199
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 6.56558
New value of Value function: 8.74762
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 200
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.26694
New value of Value function: 9.78556
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 9.92354
New value of Value function: 9.92354
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 316
New value of Q matrix: 10.201
New value of Value function: 10.201
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 3
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 12.5035
New value of Value function: 12.5035
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 4
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 10.1204
New value of Value function: 10.1204
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 5
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.29295
New value of Value function: 8.66975
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 6
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.39795
New value of Value function: 8.29295
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 7
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 13.21
New value of Value function: 13.21
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 8
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.25149
New value of Value function: 8.25149
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 9
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 6.90432
New value of Value function: 8.25149
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 10
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 11.3766
New value of Value function: 11.3766
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 11
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 9.91383
New value of Value function: 9.91383
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 12
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.15371
New value of Value function: 5.15371
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 317
New value of Q matrix: 10.3478
New value of Value function: 10.3478
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 14
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 10.25
New value of Value function: 10.25
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 15
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.6398
New value of Value function: 13.3501
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 16
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 3.61883
New value of Value function: 10.25
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 17
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 5.94388
New value of Value function: 5.94388
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 318
New value of Q matrix: 10.4941
New value of Value function: 10.4941
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 19
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 8.06987
New value of Value function: 8.06987
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 20
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 9.214
New value of Value function: 9.214
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 21
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 11.182
New value of Value function: 11.182
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 22
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 9.18071
New value of Value function: 9.18071
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 23
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.12186
New value of Value function: 13.3501
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 24
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 10.9385
New value of Value function: 10.9385
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 25
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 8.82914
New value of Value function: 11.182
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 26
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 11.8088
New value of Value function: 11.8088
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 27
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 3.35206
New value of Value function: 11.182
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 28
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 4
New value of Q matrix: 4.16743
New value of Value function: 4.16743
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 29
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 11.0858
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 30
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 8.51782
New value of Value function: 8.51782
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 31
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 13.578
New value of Value function: 13.578
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 32
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 12.2097
New value of Value function: 12.2097
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 33
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 9.82451
New value of Value function: 9.82451
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 34
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.61546
New value of Value function: 13.3501
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 35
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 10.2442
New value of Value function: 10.2442
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 36
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 5.93829
New value of Value function: 13.3501
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 37
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 12.6701
New value of Value function: 12.6701
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 38
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 12.0876
New value of Value function: 12.2097
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 39
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.1871
New value of Value function: 13.1871
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 40
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 10.5249
New value of Value function: 10.5249
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 41
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 11.0686
New value of Value function: 13.3501
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 42
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 14.0021
New value of Value function: 14.0021
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 43
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 9.5906
New value of Value function: 10.4102
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 44
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 10.5662
New value of Value function: 10.5662
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 45
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 8.47999
New value of Value function: 8.47999
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 319
New value of Q matrix: 10.5445
New value of Value function: 10.5445
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 47
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 9.26702
New value of Value function: 9.26702
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 48
----------
State: 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.4997
New value of Value function: 7.4997
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 320
New value of Q matrix: 10.6244
New value of Value function: 10.6244
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 50
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 44
New value of Q matrix: 8.83138
New value of Value function: 8.83138
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 9.17756
New value of Value function: 10.6244
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 321
New value of Q matrix: 10.6869
New value of Value function: 10.6869
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 53
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 8.64484
New value of Value function: 8.64484
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 322
New value of Q matrix: 10.7355
New value of Value function: 10.7355
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 55
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 46
New value of Q matrix: 8.49493
New value of Value function: 8.49493
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 323
New value of Q matrix: 10.773
New value of Value function: 10.773
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 57
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 47
New value of Q matrix: 8.37391
New value of Value function: 8.37391
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 162
New value of Q matrix: 9.5239
New value of Value function: 10.773
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 59
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 10.0273
New value of Value function: 10.0273
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 60
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 7.61066
New value of Value function: 8.37391
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 61
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 10.5178
New value of Value function: 10.5178
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 62
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 6.08109
New value of Value function: 8.37391
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 63
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 6.54171
New value of Value function: 8.37391
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 64
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 6.89862
New value of Value function: 8.37391
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 65
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 48
New value of Q matrix: 8.99586
New value of Value function: 8.99586
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 66
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 6.39774
New value of Value function: 6.39774
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 67
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 9.32985
New value of Value function: 9.32985
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 68
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 5.67734
New value of Value function: 5.67734
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 69
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 9.51238
New value of Value function: 9.51238
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 70
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 5.27887
New value of Value function: 5.58331
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 71
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 51
New value of Q matrix: 9.65453
New value of Value function: 9.65453
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 72
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 6.24512
New value of Value function: 6.24512
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 324
New value of Q matrix: 10.8721
New value of Value function: 10.8721
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 74
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 9.86644
New value of Value function: 9.86644
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 75
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 6.81899
New value of Value function: 6.81899
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 163
New value of Q matrix: 9.77798
New value of Value function: 10.8721
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 77
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 53
New value of Q matrix: 9.77965
New value of Value function: 9.77965
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 78
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 9.17797
New value of Value function: 9.17797
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 79
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.378
New value of Value function: 6.81899
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 80
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 8.28682
New value of Value function: 8.28682
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 81
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 40
New value of Q matrix: 19.0273
New value of Value function: 19.0273
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 82
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.06777
New value of Value function: 24.6351
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 83
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 23.5416
New value of Value function: 23.5416
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 84
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 54
New value of Q matrix: 27.5747
New value of Value function: 27.5747
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 85
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 42
New value of Q matrix: 6.83546
New value of Value function: 45.6938
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 86
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 14.1137
New value of Value function: 27.5747
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 87
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 55
New value of Q matrix: 30.0911
New value of Value function: 30.0911
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 88
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 32.313
New value of Value function: 32.313
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 89
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 10.6273
New value of Value function: 10.6273
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 90
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 56
New value of Q matrix: 30.4785
New value of Value function: 30.4785
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 91
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 53.4139
New value of Value function: 53.4139
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 92
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 4
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 9.16099
New value of Value function: 10.8721
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 10.8661
New value of Value function: 10.8661
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 9.39142
New value of Value function: 10.8661
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 10.8601
New value of Value function: 10.8601
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 10.8541
New value of Value function: 10.8541
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 164
New value of Q matrix: 10.2815
New value of Value function: 10.8541
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 7
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 15.1028
New value of Value function: 15.1028
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 8
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 13.1215
New value of Value function: 13.1215
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 9
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 29
New value of Q matrix: 10.7023
New value of Value function: 10.7023
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 328
New value of Q matrix: 11.0055
New value of Value function: 11.0055
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 11
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 11.5139
New value of Value function: 11.5139
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 12
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 8.42723
New value of Value function: 9.91383
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 13
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 9.13502
New value of Value function: 9.13502
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 14
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 14.8147
New value of Value function: 14.8147
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 15
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 10.7357
New value of Value function: 10.7357
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 16
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.98917
New value of Value function: 8.06987
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 17
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 9.33393
New value of Value function: 9.33393
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 18
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 12.6814
New value of Value function: 14.0021
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 19
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 14.4144
New value of Value function: 14.4144
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 20
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.64375
New value of Value function: 10.4102
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 21
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.56493
New value of Value function: 10.4102
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 22
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 11.009
New value of Value function: 11.009
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 23
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 14.6833
New value of Value function: 14.6833
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 24
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 5.86452
New value of Value function: 10.4102
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 25
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 12.3243
New value of Value function: 12.3243
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 26
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.1519
New value of Value function: 13.1519
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 27
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.48376
New value of Value function: 9.68028
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 28
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 10.8916
New value of Value function: 10.8916
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 29
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 54
New value of Q matrix: 9.52323
New value of Value function: 9.52323
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 329
New value of Q matrix: 11.0839
New value of Value function: 11.0839
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 31
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 55
New value of Q matrix: 9.31421
New value of Value function: 9.31421
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 330
New value of Q matrix: 11.1465
New value of Value function: 11.1465
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 33
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 56
New value of Q matrix: 9.14327
New value of Value function: 9.14327
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 9.38924
New value of Value function: 11.1465
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 331
New value of Q matrix: 11.1962
New value of Value function: 11.1962
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 36
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 57
New value of Q matrix: 9.003
New value of Value function: 9.003
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 332
New value of Q matrix: 11.2356
New value of Value function: 11.2356
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 38
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 58
New value of Q matrix: 9.14523
New value of Value function: 9.14523
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 39
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.08619
New value of Value function: 9.17797
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 40
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 8.80324
New value of Value function: 9.08619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 41
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 5.90576
New value of Value function: 9.14523
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 42
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.12322
New value of Value function: 9.08619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 165
New value of Q matrix: 10.5541
New value of Value function: 11.2356
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 44
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 11.469
New value of Value function: 11.469
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 45
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 59
New value of Q matrix: 9.2559
New value of Value function: 9.2559
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 46
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.02194
New value of Value function: 9.02194
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 47
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.96985
New value of Value function: 8.96985
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 48
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 8.60089
New value of Value function: 8.96985
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 49
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 60
New value of Q matrix: 9.76559
New value of Value function: 9.76559
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 50
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 7.2801
New value of Value function: 8.28682
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 333
New value of Q matrix: 11.3141
New value of Value function: 11.3141
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 52
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 61
New value of Q matrix: 10.2058
New value of Value function: 10.2058
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 53
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 10.6582
New value of Value function: 10.6582
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 54
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.28863
New value of Value function: 19.0273
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 55
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 13.1138
New value of Value function: 13.1138
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 56
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 41
New value of Q matrix: 19.2271
New value of Value function: 19.2271
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 57
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 22.6716
New value of Value function: 22.6716
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 58
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.92687
New value of Value function: 19.2271
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 59
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 62
New value of Q matrix: 10.8848
New value of Value function: 10.8848
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 60
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 12.3624
New value of Value function: 12.3624
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 61
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 42
New value of Q matrix: 21.2248
New value of Value function: 21.2248
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 62
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 12.6134
New value of Value function: 30.4785
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 63
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 22.8945
New value of Value function: 22.8945
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 64
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 57
New value of Q matrix: 33.5781
New value of Value function: 33.5781
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 65
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 43.5399
New value of Value function: 43.5399
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 66
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 24.756
New value of Value function: 24.756
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 67
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 58
New value of Q matrix: 34.9602
New value of Value function: 34.9602
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 68
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 59.5614
New value of Value function: 59.5614
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 69
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2206
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 5
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 11.3079
New value of Value function: 11.3079
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 335
New value of Q matrix: 11.327
New value of Value function: 11.327
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 3
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.60983
New value of Value function: 8.74603
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 4
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 9.16773
New value of Value function: 9.16773
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 5
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 8.94042
New value of Value function: 8.94042
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 6
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 9.65426
New value of Value function: 9.65426
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 7
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 12.4258
New value of Value function: 12.4258
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 8
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 10.0335
New value of Value function: 10.0335
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 9
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 7.47722
New value of Value function: 7.47722
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 10
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 4.52429
New value of Value function: 5.06307
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 11
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.40245
New value of Value function: 7.47722
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 12
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 7.07096
New value of Value function: 7.40245
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 13
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.21377
New value of Value function: 8.21377
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 336
New value of Q matrix: 11.2726
New value of Value function: 11.2726
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 15
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.35011
New value of Value function: 7.35011
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 16
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.30767
New value of Value function: 7.30767
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 17
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.27113
New value of Value function: 7.27113
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 18
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.23861
New value of Value function: 7.23861
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 19
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.99819
New value of Value function: 7.23861
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 20
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 10.6035
New value of Value function: 10.6035
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 21
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 5.28547
New value of Value function: 7.23861
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 22
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 8.17563
New value of Value function: 8.17563
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 337
New value of Q matrix: 11.2123
New value of Value function: 11.2123
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 24
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.86378
New value of Value function: 7.23861
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 25
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 5.03571
New value of Value function: 10.6035
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 26
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.40007
New value of Value function: 6.40007
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 27
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.53553
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 28
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 29
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 30
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.7329
New value of Value function: 7.7329
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 31
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.37175
New value of Value function: 4.37175
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 32
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 6.9349
New value of Value function: 6.9349
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 33
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 5.08706
New value of Value function: 5.08706
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 34
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.6205
New value of Value function: 2.61746
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 35
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 7.07857
New value of Value function: 7.07857
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 36
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 2.7504
New value of Value function: 2.7504
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 37
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 4.7086
New value of Value function: 6.09884
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 38
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 7.24815
New value of Value function: 7.24815
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 39
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.09164
New value of Value function: 6.09884
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 40
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 6.58424
New value of Value function: 6.58424
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 338
New value of Q matrix: 11.1202
New value of Value function: 11.1202
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 42
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 6.92005
New value of Value function: 6.92005
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 339
New value of Q matrix: 11.0512
New value of Value function: 11.0512
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 44
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.29615
New value of Value function: 6.92005
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 45
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 7.1542
New value of Value function: 7.1542
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 9.61275
New value of Value function: 11.0512
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 11.0452
New value of Value function: 11.0452
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 341
New value of Q matrix: 10.9931
New value of Value function: 10.9931
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 49
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 7.3172
New value of Value function: 7.3172
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 342
New value of Q matrix: 10.9526
New value of Value function: 10.9526
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 51
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 7.43196
New value of Value function: 7.43196
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 343
New value of Q matrix: 10.9205
New value of Value function: 10.9205
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 53
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 7.51283
New value of Value function: 7.51283
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 344
New value of Q matrix: 10.8944
New value of Value function: 10.8944
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 55
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 7.56968
New value of Value function: 7.56968
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 345
New value of Q matrix: 10.8729
New value of Value function: 10.8729
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 57
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 7.60938
New value of Value function: 7.60938
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 346
New value of Q matrix: 10.8546
New value of Value function: 10.8546
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 59
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 7.63672
New value of Value function: 7.63672
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 347
New value of Q matrix: 10.8388
New value of Value function: 10.8388
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 61
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 7.6551
New value of Value function: 7.6551
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 9.77081
New value of Value function: 10.8388
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 10.833
New value of Value function: 10.833
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 9.62409
New value of Value function: 10.833
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 65
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 7.56497
New value of Value function: 7.56497
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 66
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 7.75155
New value of Value function: 8.74762
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 67
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 7.93327
New value of Value function: 8.74762
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 68
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 9.07524
New value of Value function: 9.07524
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 69
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 7.65382
New value of Value function: 7.65382
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 70
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 27
New value of Q matrix: 7.66849
New value of Value function: 7.66849
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 349
New value of Q matrix: 10.8201
New value of Value function: 10.8201
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 72
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.56123
New value of Value function: 7.66849
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 73
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.79415
New value of Value function: 7.66849
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 74
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 28
New value of Q matrix: 7.6767
New value of Value function: 7.6767
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 9.90259
New value of Value function: 10.8201
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 10.8143
New value of Value function: 10.8143
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 351
New value of Q matrix: 10.8029
New value of Value function: 10.8029
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 78
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.99994
New value of Value function: 7.6767
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 79
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 29
New value of Q matrix: 7.68007
New value of Value function: 7.68007
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 352
New value of Q matrix: 10.7922
New value of Value function: 10.7922
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 81
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 30
New value of Q matrix: 7.68084
New value of Value function: 7.68084
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 9.53588
New value of Value function: 10.7922
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 353
New value of Q matrix: 10.7822
New value of Value function: 10.7822
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 84
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.09482
New value of Value function: 7.68084
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 85
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.0681
New value of Value function: 7.68084
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 86
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 31
New value of Q matrix: 7.67969
New value of Value function: 7.67969
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 9.76264
New value of Value function: 10.7822
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 88
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 7.80718
New value of Value function: 7.80718
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 89
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 9.4111
New value of Value function: 9.4111
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 90
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 7.98808
New value of Value function: 7.98808
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 91
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 32
New value of Q matrix: 7.67875
New value of Value function: 7.67875
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 9.9068
New value of Value function: 10.7822
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 354
New value of Q matrix: 10.7726
New value of Value function: 10.7726
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 94
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 33
New value of Q matrix: 7.67634
New value of Value function: 7.67634
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 355
New value of Q matrix: 10.7635
New value of Value function: 10.7635
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 96
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 34
New value of Q matrix: 7.67282
New value of Value function: 7.67282
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 356
New value of Q matrix: 10.7546
New value of Value function: 10.7546
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 98
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.74374
New value of Value function: 7.67282
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 99
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 5.53487
New value of Value function: 7.67282
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 100
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 7.94326
New value of Value function: 7.94326
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 101
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 3.3069
New value of Value function: 3.3069
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 102
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 35
New value of Q matrix: 7.66846
New value of Value function: 7.66846
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 357
New value of Q matrix: 10.746
New value of Value function: 10.746
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 104
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 36
New value of Q matrix: 7.66347
New value of Value function: 7.66347
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 358
New value of Q matrix: 10.7376
New value of Value function: 10.7376
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 106
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 37
New value of Q matrix: 7.658
New value of Value function: 7.658
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 359
New value of Q matrix: 10.7293
New value of Value function: 10.7293
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 108
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 38
New value of Q matrix: 7.65216
New value of Value function: 7.65216
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 360
New value of Q matrix: 10.7212
New value of Value function: 10.7212
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 110
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 39
New value of Q matrix: 7.64605
New value of Value function: 7.64605
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 361
New value of Q matrix: 10.7132
New value of Value function: 10.7132
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 112
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 40
New value of Q matrix: 7.63974
New value of Value function: 7.63974
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 166
New value of Q matrix: 10.6909
New value of Value function: 10.7132
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 114
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.43579
New value of Value function: 9.4111
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 362
New value of Q matrix: 10.7054
New value of Value function: 10.7054
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 116
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 41
New value of Q matrix: 7.63327
New value of Value function: 7.63327
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 9.99907
New value of Value function: 10.7054
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 10.6997
New value of Value function: 10.6997
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 364
New value of Q matrix: 10.6923
New value of Value function: 10.6923
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 120
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.2119
New value of Value function: 7.63327
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 121
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 42
New value of Q matrix: 7.62587
New value of Value function: 7.62587
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 10.0128
New value of Value function: 10.6923
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 365
New value of Q matrix: 10.6848
New value of Value function: 10.6909
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 124
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 43
New value of Q matrix: 7.03162
New value of Value function: 7.03162
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 125
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 8.06208
New value of Value function: 8.06208
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 126
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 6.96231
New value of Value function: 9.4111
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 127
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 9.57073
New value of Value function: 9.57073
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 128
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.54213
New value of Value function: 7.17799
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 167
New value of Q matrix: 10.8991
New value of Value function: 10.8991
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 130
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 10.8909
New value of Value function: 10.8909
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 131
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 4.69985
New value of Value function: 7.17799
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 132
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 9.6212
New value of Value function: 9.6212
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 133
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 4.50847
New value of Value function: 4.50847
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 134
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 7.31842
New value of Value function: 7.31842
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 168
New value of Q matrix: 10.8486
New value of Value function: 10.8486
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 136
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 7.69029
New value of Value function: 7.69029
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 137
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 8.17608
New value of Value function: 8.17608
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 138
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 9.72811
New value of Value function: 9.72811
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 139
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 8.11293
New value of Value function: 8.11293
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 140
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 44
New value of Q matrix: 7.13844
New value of Value function: 7.13844
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 169
New value of Q matrix: 10.8306
New value of Value function: 10.8306
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 142
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 7.99667
New value of Value function: 7.99667
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 143
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 8.36173
New value of Value function: 8.36173
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 144
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 10.0061
New value of Value function: 10.0061
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 145
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 6.10954
New value of Value function: 8.11293
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 146
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 2.59748
New value of Value function: 5.08706
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 147
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 3.52294
New value of Value function: 3.52294
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 148
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.07473
New value of Value function: 5.07473
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 149
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.06276
New value of Value function: 5.06276
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 150
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.05115
New value of Value function: 5.05115
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 151
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.03985
New value of Value function: 5.03985
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 152
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.02886
New value of Value function: 5.02886
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 153
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 5.01814
New value of Value function: 5.01814
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 154
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.00767
New value of Value function: 5.00767
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 155
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.99745
New value of Value function: 4.99745
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 156
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.98745
New value of Value function: 4.98745
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 157
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.8671
New value of Value function: 4.98745
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 158
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.97767
New value of Value function: 4.97767
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 159
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.96809
New value of Value function: 4.96809
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 160
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.95871
New value of Value function: 4.95871
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 161
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.9495
New value of Value function: 4.9495
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 162
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.94046
New value of Value function: 4.94046
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 163
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.93159
New value of Value function: 4.93159
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 164
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.92287
New value of Value function: 4.92287
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 165
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.9143
New value of Value function: 4.9143
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 166
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.86642
New value of Value function: 4.9143
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 167
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 5.28428
New value of Value function: 5.28428
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 168
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 3.52633
New value of Value function: 3.52633
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 169
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 7.22547
New value of Value function: 7.22547
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 170
New value of Q matrix: 10.9897
New value of Value function: 10.9897
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 171
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 7.14987
New value of Value function: 10.0061
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 172
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 10.2808
New value of Value function: 10.2808
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 173
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 10.2199
New value of Value function: 10.2199
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 174
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 8.28395
New value of Value function: 8.28395
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 175
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 46
New value of Q matrix: 7.32195
New value of Value function: 7.32195
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 171
New value of Q matrix: 11.1525
New value of Value function: 11.1525
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 177
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 6.04317
New value of Value function: 10.2199
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 178
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.04094
New value of Value function: 8.61063
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 172
New value of Q matrix: 11.1345
New value of Value function: 11.1345
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 180
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 8.00232
New value of Value function: 8.00232
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 173
New value of Q matrix: 11.1184
New value of Value function: 11.1184
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 182
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 8.00333
New value of Value function: 8.00333
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 366
New value of Q matrix: 10.812
New value of Value function: 11.1184
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 184
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 8.36168
New value of Value function: 10.2199
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 185
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 7.47498
New value of Value function: 10.2199
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 186
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 10.7903
New value of Value function: 10.7903
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 187
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 9.65726
New value of Value function: 9.65726
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 188
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 5.28414
New value of Value function: 5.28414
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 189
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 9.37207
New value of Value function: 9.37207
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 190
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 5.63564
New value of Value function: 5.63564
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 191
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 7.76568
New value of Value function: 9.37207
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 367
New value of Q matrix: 10.7826
New value of Value function: 11.1184
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 193
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 47
New value of Q matrix: 7.4219
New value of Value function: 7.4219
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 174
New value of Q matrix: 11.1036
New value of Value function: 11.1036
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 195
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 8.26354
New value of Value function: 8.26354
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 196
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 8.33022
New value of Value function: 8.33022
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 197
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 9.73077
New value of Value function: 9.73077
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 198
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 8.45651
New value of Value function: 8.45651
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 199
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 48
New value of Q matrix: 7.50426
New value of Value function: 7.50426
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 10.1355
New value of Value function: 11.1036
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 10.164
New value of Value function: 11.1036
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 11.0952
New value of Value function: 11.0952
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 11.0868
New value of Value function: 11.0868
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 368
New value of Q matrix: 10.9489
New value of Value function: 11.0868
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 5
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 12.4926
New value of Value function: 12.4926
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 6
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 9.69396
New value of Value function: 9.69396
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 7
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 10.4265
New value of Value function: 10.4265
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 8
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 12.5534
New value of Value function: 12.5534
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 9
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 13.5118
New value of Value function: 13.5118
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 10
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 9.61145
New value of Value function: 9.61145
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 11
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 6.79964
New value of Value function: 6.79964
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 10.2878
New value of Value function: 11.0868
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 9.6979
New value of Value function: 11.0868
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 9.84079
New value of Value function: 11.0868
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 10.3915
New value of Value function: 11.0868
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 10.9503
New value of Value function: 11.0868
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 11.0785
New value of Value function: 11.0785
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 178
New value of Q matrix: 11.0101
New value of Value function: 11.0101
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 19
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.20906
New value of Value function: 7.20906
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 20
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 2.48028
New value of Value function: 7.20906
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 21
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.98022
New value of Value function: 7.98022
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 22
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.78034
New value of Value function: 7.20906
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 23
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.13697
New value of Value function: 4.13697
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 24
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.18182
New value of Value function: 7.18182
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 25
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.15642
New value of Value function: 7.15642
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 26
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 4.68956
New value of Value function: 7.15642
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 27
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 10.2298
New value of Value function: 10.2298
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 28
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 4.88541
New value of Value function: 7.15642
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 29
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.4217
New value of Value function: 10.2298
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 30
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.53791
New value of Value function: 8.53791
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 31
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.10012
New value of Value function: 4.10012
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 32
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 7.13257
New value of Value function: 7.13257
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 33
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 7.11001
New value of Value function: 7.11001
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 34
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 7.08858
New value of Value function: 7.08858
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 35
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 7.06811
New value of Value function: 7.07096
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 36
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 9.39908
New value of Value function: 9.39908
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 37
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 10.1655
New value of Value function: 10.1655
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 179
New value of Q matrix: 11.1636
New value of Value function: 11.1636
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 39
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 9.66733
New value of Value function: 9.66733
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 10.49
New value of Value function: 11.1636
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 11.1553
New value of Value function: 11.1553
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 10.5716
New value of Value function: 11.1553
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 11.147
New value of Value function: 11.147
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 9.97353
New value of Value function: 11.147
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 182
New value of Q matrix: 11.2328
New value of Value function: 11.2328
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 46
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 9.32028
New value of Value function: 9.32028
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 47
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.14381
New value of Value function: 8.14381
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 183
New value of Q matrix: 11.3063
New value of Value function: 11.3063
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 49
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 3.81102
New value of Value function: 9.32028
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 50
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 7.42289
New value of Value function: 7.42289
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 184
New value of Q matrix: 11.2357
New value of Value function: 11.2357
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 52
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 7.70886
New value of Value function: 7.70886
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 185
New value of Q matrix: 11.3748
New value of Value function: 11.3748
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 54
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 9.75231
New value of Value function: 9.75231
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 186
New value of Q matrix: 11.4687
New value of Value function: 11.4687
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 56
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 9.42272
New value of Value function: 9.42272
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 187
New value of Q matrix: 11.5315
New value of Value function: 11.5315
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 58
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 9.19182
New value of Value function: 9.19182
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 188
New value of Q matrix: 11.8849
New value of Value function: 11.8849
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 60
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.7078
New value of Value function: 13.7078
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 61
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 9.09662
New value of Value function: 9.09662
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 189
New value of Q matrix: 11.8937
New value of Value function: 11.8937
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 63
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 7.30012
New value of Value function: 9.09662
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 64
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 10.2018
New value of Value function: 10.2018
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 65
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 10.2162
New value of Value function: 10.2162
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 66
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 10.6329
New value of Value function: 10.6329
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 67
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 9.46256
New value of Value function: 9.46256
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 190
New value of Q matrix: 12.0122
New value of Value function: 12.0122
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 69
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 17
New value of Q matrix: 10.252
New value of Value function: 10.252
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 70
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.06237
New value of Value function: 8.14381
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 71
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 8.51792
New value of Value function: 8.51792
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 191
New value of Q matrix: 12.0944
New value of Value function: 12.0944
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 73
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 11.2221
New value of Value function: 11.2221
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 74
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 6.79742
New value of Value function: 9.46256
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 10.7761
New value of Value function: 12.0944
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 12.0857
New value of Value function: 12.0857
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 10.3845
New value of Value function: 12.0857
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 12.077
New value of Value function: 12.077
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 194
New value of Q matrix: 12.1515
New value of Value function: 12.1515
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 80
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 9.87838
New value of Value function: 9.87838
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 81
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 7.91262
New value of Value function: 7.91262
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 82
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 11.1777
New value of Value function: 11.1777
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 83
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 10.8116
New value of Value function: 10.8116
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 84
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.74691
New value of Value function: 8.74691
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 195
New value of Q matrix: 12.2626
New value of Value function: 12.2626
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 86
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 10.4378
New value of Value function: 10.4378
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 196
New value of Q matrix: 12.3391
New value of Value function: 12.3391
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 88
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 5.36737
New value of Value function: 10.4378
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 89
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 12.026
New value of Value function: 12.026
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 90
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 10.1711
New value of Value function: 10.1711
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 197
New value of Q matrix: 12.522
New value of Value function: 12.522
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 92
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 12.6347
New value of Value function: 12.6347
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 93
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 10.062
New value of Value function: 10.062
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 94
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 7.08607
New value of Value function: 8.74691
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 95
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 9.97809
New value of Value function: 9.97809
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 96
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 9.01221
New value of Value function: 9.01221
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 370
New value of Q matrix: 11.024
New value of Value function: 12.522
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 98
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 8.6652
New value of Value function: 8.6652
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 99
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.17143
New value of Value function: 7.17143
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 198
New value of Q matrix: 12.4549
New value of Value function: 12.4549
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 101
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.87831
New value of Value function: 8.6652
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 102
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 7.84752
New value of Value function: 9.97809
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 103
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.91973
New value of Value function: 9.97809
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 104
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.70411
New value of Value function: 5.70411
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 105
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 10.713
New value of Value function: 10.713
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 106
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 8.81035
New value of Value function: 8.81035
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 199
New value of Q matrix: 12.403
New value of Value function: 12.403
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 108
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 8.91026
New value of Value function: 8.91026
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 10.2281
New value of Value function: 12.403
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 200
New value of Q matrix: 12.3618
New value of Value function: 12.3618
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 111
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 8.74125
New value of Value function: 8.74125
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 112
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.09573
New value of Value function: 8.09573
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 201
New value of Q matrix: 12.3119
New value of Value function: 12.3119
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 114
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 9.64749
New value of Value function: 9.64749
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 115
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 8.44859
New value of Value function: 8.44859
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 202
New value of Q matrix: 12.3287
New value of Value function: 12.3287
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 117
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 25
New value of Q matrix: 9.52095
New value of Value function: 9.52095
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 118
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 8.54877
New value of Value function: 8.54877
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 203
New value of Q matrix: 12.3355
New value of Value function: 12.3355
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 120
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 9.50964
New value of Value function: 9.50964
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 121
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 8.79951
New value of Value function: 8.79951
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 204
New value of Q matrix: 12.3411
New value of Value function: 12.3411
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 123
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 10.2514
New value of Value function: 10.2514
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 124
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 8.59942
New value of Value function: 8.59942
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 205
New value of Q matrix: 12.3975
New value of Value function: 12.3975
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 126
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 3.2274
New value of Value function: 10.2514
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 127
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.64707
New value of Value function: 5.70411
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 128
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 8.92651
New value of Value function: 8.92651
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 129
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 10.8679
New value of Value function: 10.8679
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 130
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 27
New value of Q matrix: 8.72915
New value of Value function: 8.72915
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 206
New value of Q matrix: 12.4924
New value of Value function: 12.4924
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 132
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 11.383
New value of Value function: 11.383
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 133
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 28
New value of Q matrix: 8.84977
New value of Value function: 8.84977
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 207
New value of Q matrix: 12.6159
New value of Value function: 12.6159
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 135
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 11.8172
New value of Value function: 11.8172
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 136
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 6.99915
New value of Value function: 8.84977
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 137
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 11.0156
New value of Value function: 11.0156
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 138
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 9.50917
New value of Value function: 9.50917
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 139
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.01
New value of Value function: 5.63564
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 140
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.99
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 141
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.06038
New value of Value function: 4.06038
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 142
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.06038
New value of Value function: 4.37175
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 143
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.01978
New value of Value function: 4.37175
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 144
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 4.79226
New value of Value function: 4.79226
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 145
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.38984
New value of Value function: 5.38984
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 146
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.62934
New value of Value function: 7.62934
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 147
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 3.77343
New value of Value function: 3.77343
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 148
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 5.69538
New value of Value function: 5.69538
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 149
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 8.61227
New value of Value function: 8.61227
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 150
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 49
New value of Q matrix: 7.7879
New value of Value function: 7.7879
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 208
New value of Q matrix: 12.5566
New value of Value function: 12.5566
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 152
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 29
New value of Q matrix: 8.92352
New value of Value function: 8.92352
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 153
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.24016
New value of Value function: 8.33022
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 154
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 8.35987
New value of Value function: 8.35987
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 155
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 7.90628
New value of Value function: 9.50917
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 156
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.3749
New value of Value function: 11.0156
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 157
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.72465
New value of Value function: 11.0156
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 158
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.47149
New value of Value function: 9.47149
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 159
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 5.5641
New value of Value function: 5.5641
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 160
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.20746
New value of Value function: 6.20746
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 161
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.76841
New value of Value function: 7.76841
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 162
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.535534
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 163
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 164
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 165
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 166
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 167
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 168
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 169
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 170
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 171
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 172
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 173
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 174
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.438167
New value of Value function: 0.438167
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 175
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.88601
New value of Value function: 6.88601
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 176
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.23432
New value of Value function: 1.23432
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 177
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.65124
New value of Value function: 6.65124
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 178
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.22198
New value of Value function: 1.23432
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 179
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -1.88284
New value of Value function: 1.22198
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 180
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 181
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 182
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 183
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 184
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.98
New value of Value function: 4.98
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 185
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.95064
New value of Value function: 1.95064
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 186
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.94545
New value of Value function: 4.94545
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 187
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.91909
New value of Value function: 1.91909
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 188
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.91915
New value of Value function: 4.91915
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 189
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.89453
New value of Value function: 1.89453
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 190
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.89737
New value of Value function: 4.89737
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 191
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.58473
New value of Value function: 3.58473
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 192
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 6.61712
New value of Value function: 6.61712
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 193
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.07003
New value of Value function: 3.58473
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 194
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.56084
New value of Value function: 3.56084
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 195
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 6.58806
New value of Value function: 6.58806
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 196
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 3.56084
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 197
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 198
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 199
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 200
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 12.5479
New value of Value function: 12.5479
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 11.0137
New value of Value function: 12.5479
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 11.215
New value of Value function: 12.5479
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 12.5393
New value of Value function: 12.5393
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 12.5306
New value of Value function: 12.5306
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 12.522
New value of Value function: 12.522
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 12.5134
New value of Value function: 12.5134
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 12.5049
New value of Value function: 12.5049
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 12.4964
New value of Value function: 12.4964
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 12.4879
New value of Value function: 12.4879
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 12.4794
New value of Value function: 12.4794
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 10.4615
New value of Value function: 12.4794
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 10.6501
New value of Value function: 12.4794
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 12.4709
New value of Value function: 12.4709
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 12.4625
New value of Value function: 12.4625
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 12.4541
New value of Value function: 12.4541
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 12.4457
New value of Value function: 12.4457
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 12.4374
New value of Value function: 12.4374
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 371
New value of Q matrix: 11.2818
New value of Value function: 12.4374
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 20
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 38
New value of Q matrix: 13.2767
New value of Value function: 13.2767
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 21
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 8.58411
New value of Value function: 13.21
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 22
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 13.9414
New value of Value function: 13.9414
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 23
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 32
New value of Q matrix: 11.0784
New value of Value function: 11.0784
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 24
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.7472
New value of Value function: 6.7472
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 11.3703
New value of Value function: 12.4374
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 12.429
New value of Value function: 12.429
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 10.8712
New value of Value function: 12.429
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 12.4207
New value of Value function: 12.4207
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 372
New value of Q matrix: 11.5305
New value of Value function: 12.4207
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 30
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 10.4428
New value of Value function: 10.4428
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 225
New value of Q matrix: 12.7128
New value of Value function: 12.7128
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 32
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 40
New value of Q matrix: 13.5298
New value of Value function: 13.5298
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 33
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.1569
New value of Value function: 11.1569
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 34
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 8.16645
New value of Value function: 8.16645
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 12.7044
New value of Value function: 12.7044
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 227
New value of Q matrix: 13.0526
New value of Value function: 13.0526
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 37
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 16.2487
New value of Value function: 16.2487
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 38
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 8.98612
New value of Value function: 13.5298
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 39
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 16.7611
New value of Value function: 16.7611
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 40
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 7.95519
New value of Value function: 13.5298
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 41
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 17.0197
New value of Value function: 17.0197
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 42
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 41
New value of Q matrix: 13.298
New value of Value function: 13.298
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 43
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 10.5395
New value of Value function: 10.5395
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 228
New value of Q matrix: 13.5028
New value of Value function: 13.5028
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 45
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 17.0746
New value of Value function: 17.0746
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 46
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 13.7099
New value of Value function: 13.7099
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 47
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 33
New value of Q matrix: 10.7314
New value of Value function: 10.7314
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 48
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 9.1509
New value of Value function: 9.1509
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 229
New value of Q matrix: 13.4982
New value of Value function: 13.4982
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 50
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.60179
New value of Value function: 10.5395
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 51
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 10.4607
New value of Value function: 10.4607
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 230
New value of Q matrix: 13.701
New value of Value function: 13.701
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 53
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 43
New value of Q matrix: 13.351
New value of Value function: 13.351
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 54
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 12.0713
New value of Value function: 12.0713
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 55
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 34
New value of Q matrix: 10.4634
New value of Value function: 10.4634
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 56
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.21459
New value of Value function: 8.21459
New value of Policy matrix: 4

=======================================
Simulation: 22
Iteration: 57
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 8.18105
New value of Value function: 8.18105
New value of Policy matrix: 4

=======================================
Simulation: 22
Iteration: 58
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 8.15013
New value of Value function: 8.15013
New value of Policy matrix: 4

=======================================
Simulation: 22
Iteration: 59
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.72889
New value of Value function: 8.72889
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 231
New value of Q matrix: 13.5655
New value of Value function: 13.5655
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 61
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.32389
New value of Value function: 8.72889
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 62
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 9.42329
New value of Value function: 9.42329
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 11.6587
New value of Value function: 13.5655
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 13.5566
New value of Value function: 13.5566
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 233
New value of Q matrix: 13.5436
New value of Value function: 13.5436
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 66
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 35
New value of Q matrix: 10.4407
New value of Value function: 10.4407
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 67
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 10.4082
New value of Value function: 10.4082
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 234
New value of Q matrix: 13.6356
New value of Value function: 13.6356
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 69
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 12.1444
New value of Value function: 12.1444
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 70
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 11.2832
New value of Value function: 13.351
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 71
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 10.1002
New value of Value function: 10.1002
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 72
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 11.3053
New value of Value function: 11.3053
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 73
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 11.6407
New value of Value function: 11.6407
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 74
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.1489
New value of Value function: 9.33393
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 75
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 12.2907
New value of Value function: 12.2907
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 76
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 10.3467
New value of Value function: 10.3467
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 77
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 13.9789
New value of Value function: 13.9789
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 78
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 10.7966
New value of Value function: 10.7966
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 79
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 14.8726
New value of Value function: 14.8726
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 80
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 12.3607
New value of Value function: 12.3607
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 81
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 12.0132
New value of Value function: 12.0132
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 82
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 31
New value of Q matrix: 10.7125
New value of Value function: 10.7125
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 83
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 7.79785
New value of Value function: 7.79785
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 235
New value of Q matrix: 13.6336
New value of Value function: 13.6336
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 85
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 32
New value of Q matrix: 10.6745
New value of Value function: 10.6745
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 373
New value of Q matrix: 11.6468
New value of Value function: 13.6336
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 87
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 63
New value of Q matrix: 10.8359
New value of Value function: 10.8359
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 236
New value of Q matrix: 13.6293
New value of Value function: 13.6293
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 89
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 33
New value of Q matrix: 10.2223
New value of Value function: 10.2223
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 90
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 8.28678
New value of Value function: 8.28678
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 91
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 5.51756
New value of Value function: 10.2223
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 92
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 8.70343
New value of Value function: 8.70343
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 93
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 11.1665
New value of Value function: 11.1665
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 94
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 64
New value of Q matrix: 10.7931
New value of Value function: 10.7931
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 237
New value of Q matrix: 13.657
New value of Value function: 13.657
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 96
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 11.3791
New value of Value function: 11.3791
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 97
----------
State: 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 9.2437
New value of Value function: 9.2437
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 238
New value of Q matrix: 13.6964
New value of Value function: 13.6964
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 99
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 12.0968
New value of Value function: 12.0968
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 100
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 65
New value of Q matrix: 10.7641
New value of Value function: 10.7641
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 10.7995
New value of Value function: 13.6964
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 239
New value of Q matrix: 13.7792
New value of Value function: 13.7792
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 103
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 12.4346
New value of Value function: 12.4346
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 104
----------
State: 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 9.94254
New value of Value function: 9.94254
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 11.1078
New value of Value function: 13.7792
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 240
New value of Q matrix: 13.878
New value of Value function: 13.878
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 107
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 6.71549
New value of Value function: 12.4346
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 11.9472
New value of Value function: 13.878
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 13.8691
New value of Value function: 13.8691
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 242
New value of Q matrix: 14.0081
New value of Value function: 14.0081
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 111
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 14.7307
New value of Value function: 14.7307
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 112
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 38
New value of Q matrix: 12.1804
New value of Value function: 12.1804
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 243
New value of Q matrix: 14.0755
New value of Value function: 14.0755
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 114
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 39
New value of Q matrix: 11.9809
New value of Value function: 11.9809
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 11.277
New value of Value function: 14.0755
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 14.0665
New value of Value function: 14.0665
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 374
New value of Q matrix: 11.813
New value of Value function: 14.0665
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 118
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 40
New value of Q matrix: 11.6071
New value of Value function: 11.6071
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 119
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 9.50286
New value of Value function: 9.50286
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 120
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 12.2395
New value of Value function: 12.2395
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 121
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 66
New value of Q matrix: 10.784
New value of Value function: 10.784
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 11.6248
New value of Value function: 14.0665
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 245
New value of Q matrix: 13.9605
New value of Value function: 13.9605
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 124
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 10.1619
New value of Value function: 10.1619
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 125
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 42
New value of Q matrix: 11.6964
New value of Value function: 11.6964
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 126
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 8.80553
New value of Value function: 8.80553
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 246
New value of Q matrix: 13.9999
New value of Value function: 13.9999
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 128
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 12.3033
New value of Value function: 12.3033
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 129
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 8.73466
New value of Value function: 10.784
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 130
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 16.9781
New value of Value function: 16.9781
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 131
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 23.9642
New value of Value function: 23.9642
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 132
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 24.6981
New value of Value function: 24.6981
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 133
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 46
New value of Q matrix: 25.8289
New value of Value function: 25.8289
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 134
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 59
New value of Q matrix: 30.9092
New value of Value function: 30.9092
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 135
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 19.8533
New value of Value function: 19.8533
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 136
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 60
New value of Q matrix: 34.6604
New value of Value function: 34.6604
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 137
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 43
New value of Q matrix: 10.8734
New value of Value function: 59.5614
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 138
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 61
New value of Q matrix: 37.9004
New value of Value function: 37.9004
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 139
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 46.7921
New value of Value function: 46.7921
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 140
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 14.1428
New value of Value function: 14.1428
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 141
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 47
New value of Q matrix: 27.8261
New value of Value function: 27.8261
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 142
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 62
New value of Q matrix: 39.0972
New value of Value function: 39.0972
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 143
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 60.7559
New value of Value function: 60.7559
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 144
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 6
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 11.9187
New value of Value function: 13.9999
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 11.9158
New value of Value function: 13.9999
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 13.991
New value of Value function: 13.991
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 376
New value of Q matrix: 12.3305
New value of Value function: 13.991
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 5
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 17.1251
New value of Value function: 17.1251
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 6
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 44
New value of Q matrix: 13.3015
New value of Value function: 13.3015
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 7
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 6.624
New value of Value function: 12.1444
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 248
New value of Q matrix: 14.3697
New value of Value function: 14.3697
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 9
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 17.1396
New value of Value function: 17.1396
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 10
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 12.274
New value of Value function: 13.3015
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 11
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 10.1199
New value of Value function: 10.1199
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 13.7324
New value of Value function: 13.7324
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 13
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 6.25843
New value of Value function: 11.3053
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 14
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 10.9721
New value of Value function: 10.9721
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 15
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 12.2691
New value of Value function: 12.2691
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 16
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 12.2609
New value of Value function: 12.2609
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 17
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 13.0688
New value of Value function: 13.0688
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 18
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 11.353
New value of Value function: 11.353
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 19
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 14.4361
New value of Value function: 14.4361
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 20
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 11.0561
New value of Value function: 11.353
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 21
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 13.2664
New value of Value function: 13.2664
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 22
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 7.72406
New value of Value function: 12.3033
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 249
New value of Q matrix: 14.4815
New value of Value function: 14.4815
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 24
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 12.8116
New value of Value function: 12.8116
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 250
New value of Q matrix: 14.5575
New value of Value function: 14.5575
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 26
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.23944
New value of Value function: 12.8116
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 27
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 12.4302
New value of Value function: 12.4302
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 28
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 12.9604
New value of Value function: 12.9604
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 29
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 13.8138
New value of Value function: 13.8138
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 30
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 44
New value of Q matrix: 12.1159
New value of Value function: 12.1159
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 31
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 11.4119
New value of Value function: 11.4119
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 251
New value of Q matrix: 14.5851
New value of Value function: 14.5851
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 33
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 9.11339
New value of Value function: 12.1159
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 34
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 13.4184
New value of Value function: 13.4184
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 35
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 8.53478
New value of Value function: 12.1159
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 11.467
New value of Value function: 14.5851
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 252
New value of Q matrix: 14.774
New value of Value function: 14.774
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 38
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 15.5312
New value of Value function: 15.5312
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 39
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 12.0429
New value of Value function: 12.0429
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 253
New value of Q matrix: 14.7833
New value of Value function: 14.7833
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 41
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 46
New value of Q matrix: 11.9828
New value of Value function: 11.9828
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 254
New value of Q matrix: 14.7883
New value of Value function: 14.7883
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 43
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 47
New value of Q matrix: 11.9329
New value of Value function: 11.9329
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 255
New value of Q matrix: 15.013
New value of Value function: 15.013
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 45
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 15.9586
New value of Value function: 15.9586
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 46
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 48
New value of Q matrix: 11.9856
New value of Value function: 11.9856
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 47
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 10.8657
New value of Value function: 11.4119
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 48
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 49
New value of Q matrix: 12.0302
New value of Value function: 12.0302
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 49
----------
State: 1969
	Distance: 4
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 11.7308
New value of Value function: 11.7308
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 12.2963
New value of Value function: 15.013
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 15.0036
New value of Value function: 15.0036
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 257
New value of Q matrix: 15.1079
New value of Value function: 15.1079
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 53
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 12.0846
New value of Value function: 12.0846
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 54
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 7.71159
New value of Value function: 7.71159
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 258
New value of Q matrix: 15.0989
New value of Value function: 15.0989
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 56
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 8.19813
New value of Value function: 12.0846
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 57
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 13.2113
New value of Value function: 13.2113
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 58
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 7.46552
New value of Value function: 12.0846
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 259
New value of Q matrix: 15.0905
New value of Value function: 15.0905
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 60
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 12.053
New value of Value function: 12.053
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 12.3582
New value of Value function: 15.0905
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 15.0812
New value of Value function: 15.0812
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 12.7082
New value of Value function: 15.0812
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 15.0718
New value of Value function: 15.0718
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 11.8373
New value of Value function: 15.0718
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 12.1661
New value of Value function: 15.0718
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 12.6323
New value of Value function: 15.0718
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 15.0625
New value of Value function: 15.0625
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 377
New value of Q matrix: 12.4837
New value of Value function: 15.0625
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 70
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 13.4055
New value of Value function: 13.4055
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 71
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 13.3862
New value of Value function: 13.3862
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 72
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 9.78409
New value of Value function: 12.053
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 73
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 14.1449
New value of Value function: 14.1449
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 74
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 12.6154
New value of Value function: 12.6154
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 75
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 50
New value of Q matrix: 11.7031
New value of Value function: 11.7031
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 76
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 9.78784
New value of Value function: 9.78784
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 378
New value of Q matrix: 12.5451
New value of Value function: 15.0625
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 78
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 15.6326
New value of Value function: 15.6326
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 79
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 48
New value of Q matrix: 26.906
New value of Value function: 26.906
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 80
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 17.415
New value of Value function: 17.415
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 81
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 21.0774
New value of Value function: 21.0774
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 82
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 49
New value of Q matrix: 25.0967
New value of Value function: 25.0967
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 83
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 21.6733
New value of Value function: 21.6733
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 84
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 14.0425
New value of Value function: 25.0967
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 85
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 50
New value of Q matrix: 27.3042
New value of Value function: 27.3042
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 86
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 63
New value of Q matrix: 36.1438
New value of Value function: 36.1438
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 87
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 27.9893
New value of Value function: 27.9893
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 88
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 64
New value of Q matrix: 39.2694
New value of Value function: 39.2694
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 89
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 49.4586
New value of Value function: 49.4586
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 90
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 4.68377
New value of Value function: 14.1428
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 91
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 6.48012
New value of Value function: 12.3624
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 92
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.925
New value of Value function: 8.925
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 93
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.88509
New value of Value function: 8.88509
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 94
----------
State: 1565
	Distance: 3
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 10.3367
New value of Value function: 10.3367
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 263
New value of Q matrix: 15.273
New value of Value function: 15.273
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 96
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 19.9739
New value of Value function: 19.9739
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 97
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 19.3451
New value of Value function: 27.3042
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 98
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 51
New value of Q matrix: 26.0653
New value of Value function: 26.0653
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 99
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 24.3687
New value of Value function: 24.3687
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 100
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 52
New value of Q matrix: 28.1193
New value of Value function: 28.1193
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 101
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 65
New value of Q matrix: 40.5959
New value of Value function: 40.5959
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 102
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 61.8539
New value of Value function: 61.8539
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 103
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 7
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 15.2636
New value of Value function: 15.2636
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 15.2542
New value of Value function: 15.2542
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 15.2449
New value of Value function: 15.2449
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 15.2356
New value of Value function: 15.2356
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 13.0285
New value of Value function: 15.2356
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 15.2262
New value of Value function: 15.2262
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 12.4743
New value of Value function: 15.2262
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 15.217
New value of Value function: 15.217
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 15.2077
New value of Value function: 15.2077
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 15.1985
New value of Value function: 15.1985
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 12.7454
New value of Value function: 15.1985
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 15.1893
New value of Value function: 15.1893
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 15.1801
New value of Value function: 15.1801
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 15.1709
New value of Value function: 15.1709
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 15.1617
New value of Value function: 15.1617
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 15.1526
New value of Value function: 15.1526
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 12.9332
New value of Value function: 15.1526
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 13.2921
New value of Value function: 15.1526
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 15.1435
New value of Value function: 15.1435
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 15.1344
New value of Value function: 15.1344
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 12.98
New value of Value function: 15.1344
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 15.1254
New value of Value function: 15.1254
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 15.1163
New value of Value function: 15.1163
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 15.1073
New value of Value function: 15.1073
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 15.0983
New value of Value function: 15.0983
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 15.0893
New value of Value function: 15.0893
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 15.0804
New value of Value function: 15.0804
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 15.0715
New value of Value function: 15.0715
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 15.0625
New value of Value function: 15.0625
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 15.0536
New value of Value function: 15.0536
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 15.0448
New value of Value function: 15.0448
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 13.1796
New value of Value function: 15.0448
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 379
New value of Q matrix: 12.5477
New value of Value function: 15.0448
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 34
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 4.40368
New value of Value function: 9.69396
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 35
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 12.3676
New value of Value function: 12.4926
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 36
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.19582
New value of Value function: 12.4926
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 289
New value of Q matrix: 15.0638
New value of Value function: 15.0638
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 38
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 10.0545
New value of Value function: 12.4926
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 290
New value of Q matrix: 15.0816
New value of Value function: 15.0816
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 40
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 10.8936
New value of Value function: 12.4926
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 291
New value of Q matrix: 15.0984
New value of Value function: 15.0984
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 42
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.50179
New value of Value function: 12.4926
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 15.0895
New value of Value function: 15.0895
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 15.0807
New value of Value function: 15.0807
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 13.509
New value of Value function: 15.0807
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 15.0719
New value of Value function: 15.0719
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 15.0632
New value of Value function: 15.0632
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 15.0544
New value of Value function: 15.0544
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 15.0457
New value of Value function: 15.0457
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 15.037
New value of Value function: 15.037
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 15.0283
New value of Value function: 15.0283
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 13.6888
New value of Value function: 15.0283
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 15.0196
New value of Value function: 15.0196
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 15.0109
New value of Value function: 15.0109
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 15.0023
New value of Value function: 15.0023
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 13.353
New value of Value function: 15.0023
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 14.9937
New value of Value function: 14.9937
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 14.9851
New value of Value function: 14.9851
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 13.838
New value of Value function: 14.9851
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 14.9765
New value of Value function: 14.9765
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 14.9679
New value of Value function: 14.9679
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 14.9594
New value of Value function: 14.9594
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 13.9635
New value of Value function: 14.9594
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 14.9509
New value of Value function: 14.9509
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 14.0708
New value of Value function: 14.9509
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 13.5024
New value of Value function: 14.9509
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 14.9424
New value of Value function: 14.9424
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 380
New value of Q matrix: 12.5503
New value of Value function: 14.9424
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 69
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 10.3922
New value of Value function: 10.3922
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 70
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.85931
New value of Value function: 10.4265
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 71
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 6.81366
New value of Value function: 6.81366
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 72
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 6.4257
New value of Value function: 10.4265
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 73
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 10.946
New value of Value function: 10.946
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 74
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 9.60749
New value of Value function: 9.60749
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 75
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 11.2367
New value of Value function: 11.2367
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 76
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.59727
New value of Value function: 9.60749
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 77
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 6.81366
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 78
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 5.74552
New value of Value function: 5.74552
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 79
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 7.21651
New value of Value function: 7.21651
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 80
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 11.1
New value of Value function: 11.1
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 81
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 12.0896
New value of Value function: 12.0896
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 82
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.0786
New value of Value function: 12.0786
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 83
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.88007
New value of Value function: 8.53791
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 84
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 10.3572
New value of Value function: 10.3572
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 85
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 11.9102
New value of Value function: 11.9102
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 86
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 31
New value of Q matrix: 11.439
New value of Value function: 11.439
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 87
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 7.5457
New value of Value function: 8.79951
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 88
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.68365
New value of Value function: 11.439
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 89
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 32
New value of Q matrix: 11.1336
New value of Value function: 11.1336
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 90
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 9.85785
New value of Value function: 9.85785
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 310
New value of Q matrix: 14.8901
New value of Value function: 14.8901
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 92
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 6.23088
New value of Value function: 11.1336
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 93
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 12.7167
New value of Value function: 12.7167
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 94
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 11.6038
New value of Value function: 11.6038
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 95
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 30
New value of Q matrix: 9.43796
New value of Value function: 9.43796
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 311
New value of Q matrix: 14.8673
New value of Value function: 14.8673
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 97
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 34
New value of Q matrix: 11.6235
New value of Value function: 11.6235
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 312
New value of Q matrix: 14.8469
New value of Value function: 14.8469
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 99
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 35
New value of Q matrix: 11.4774
New value of Value function: 11.4774
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 100
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 10.4714
New value of Value function: 10.4714
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 313
New value of Q matrix: 14.8195
New value of Value function: 14.8195
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 102
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 11.9551
New value of Value function: 11.9551
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 103
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.95578
New value of Value function: 9.43796
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 104
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 31
New value of Q matrix: 9.83908
New value of Value function: 9.83908
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 314
New value of Q matrix: 14.8204
New value of Value function: 14.8204
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 106
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 37
New value of Q matrix: 11.8583
New value of Value function: 11.8583
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 107
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 10.8511
New value of Value function: 10.8511
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 315
New value of Q matrix: 14.8159
New value of Value function: 14.8159
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 109
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 12.3259
New value of Value function: 12.3259
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 110
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.6475
New value of Value function: 9.83908
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 111
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 32
New value of Q matrix: 10.1623
New value of Value function: 10.1623
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 316
New value of Q matrix: 14.8376
New value of Value function: 14.8376
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 113
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 39
New value of Q matrix: 12.2325
New value of Value function: 12.2325
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 114
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 11.1038
New value of Value function: 11.1038
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 14.1493
New value of Value function: 14.8376
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 317
New value of Q matrix: 14.7902
New value of Value function: 14.7902
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 117
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 11.2593
New value of Value function: 11.2593
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 318
New value of Q matrix: 14.8081
New value of Value function: 14.8081
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 119
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 7.01528
New value of Value function: 12.2325
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 120
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 13.5622
New value of Value function: 13.5622
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 121
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 6.03182
New value of Value function: 12.2325
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 122
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 10.013
New value of Value function: 10.013
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 319
New value of Q matrix: 14.825
New value of Value function: 14.825
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 124
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 40
New value of Q matrix: 12.1446
New value of Value function: 12.1446
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 320
New value of Q matrix: 14.9146
New value of Value function: 14.9146
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 126
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 14.2163
New value of Value function: 14.2163
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 127
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 41
New value of Q matrix: 12.0854
New value of Value function: 12.0854
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 13.632
New value of Value function: 14.9146
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 13.7477
New value of Value function: 14.9146
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 321
New value of Q matrix: 15.0351
New value of Value function: 15.0351
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 131
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 14.7266
New value of Value function: 14.7266
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 132
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 4.70111
New value of Value function: 12.0854
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 133
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 10.1129
New value of Value function: 10.1129
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 134
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 15.1352
New value of Value function: 15.1352
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 135
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 12.5445
New value of Value function: 12.5445
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 136
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.7814
New value of Value function: 10.1623
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 13.8631
New value of Value function: 15.0351
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 322
New value of Q matrix: 15.0565
New value of Value function: 15.0565
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 139
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 43
New value of Q matrix: 12.4839
New value of Value function: 12.4839
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 140
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 11.4386
New value of Value function: 11.4386
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 323
New value of Q matrix: 15.0733
New value of Value function: 15.0733
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 142
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 8.41013
New value of Value function: 12.4839
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 143
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 11.568
New value of Value function: 11.568
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 324
New value of Q matrix: 15.0892
New value of Value function: 15.0892
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 145
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 8.49957
New value of Value function: 12.4839
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 146
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 15.5346
New value of Value function: 15.5346
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 147
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 12.8723
New value of Value function: 12.8723
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 148
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 33
New value of Q matrix: 10.4715
New value of Value function: 10.4715
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 325
New value of Q matrix: 15.1255
New value of Value function: 15.1255
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 150
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 12.7385
New value of Value function: 12.7385
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 326
New value of Q matrix: 15.1524
New value of Value function: 15.1524
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 152
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 46
New value of Q matrix: 12.6963
New value of Value function: 12.6963
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 153
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 11.6797
New value of Value function: 11.6797
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 327
New value of Q matrix: 15.1755
New value of Value function: 15.1755
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 155
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 8.20332
New value of Value function: 12.6963
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 156
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 47
New value of Q matrix: 12.6768
New value of Value function: 12.6768
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 157
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 11.7657
New value of Value function: 11.7657
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 328
New value of Q matrix: 15.1961
New value of Value function: 15.1961
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 159
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 48
New value of Q matrix: 12.5855
New value of Value function: 12.5855
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 329
New value of Q matrix: 15.2107
New value of Value function: 15.2107
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 161
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 49
New value of Q matrix: 12.5102
New value of Value function: 12.5102
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 330
New value of Q matrix: 15.2203
New value of Value function: 15.2203
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 163
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 50
New value of Q matrix: 12.5297
New value of Value function: 12.5297
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 164
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 9.27137
New value of Value function: 11.7657
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 165
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 51
New value of Q matrix: 12.5463
New value of Value function: 12.5463
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 166
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 10.1568
New value of Value function: 11.7657
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 167
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 34
New value of Q matrix: 10.7453
New value of Value function: 10.7453
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 331
New value of Q matrix: 15.2313
New value of Value function: 15.2313
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 169
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 12.975
New value of Value function: 12.975
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 170
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 35
New value of Q matrix: 10.9707
New value of Value function: 10.9707
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 332
New value of Q matrix: 15.265
New value of Value function: 15.265
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 172
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 13.3714
New value of Value function: 13.3714
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 173
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 36
New value of Q matrix: 11.161
New value of Value function: 11.161
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 333
New value of Q matrix: 15.3183
New value of Value function: 15.3183
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 175
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 13.7359
New value of Value function: 13.7359
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 176
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 7.78922
New value of Value function: 11.161
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 177
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 6.44023
New value of Value function: 6.44023
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 178
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 8.1148
New value of Value function: 11.161
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 179
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 37
New value of Q matrix: 10.8512
New value of Value function: 10.8512
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 180
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 8.37794
New value of Value function: 8.37794
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 181
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 8.56421
New value of Value function: 9.50917
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 182
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 9.48397
New value of Value function: 9.48397
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 183
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 6.85209
New value of Value function: 6.85209
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 184
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 6.65296
New value of Value function: 10.8512
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 185
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 11.9895
New value of Value function: 11.9895
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 186
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 9.5396
New value of Value function: 9.5396
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 187
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 5.90545
New value of Value function: 6.85209
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 188
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 11.2139
New value of Value function: 11.2139
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 189
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 7.1206
New value of Value function: 7.1206
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 190
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 38
New value of Q matrix: 10.5986
New value of Value function: 10.5986
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 191
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 8.39889
New value of Value function: 8.39889
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 192
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 8.35704
New value of Value function: 9.5396
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 334
New value of Q matrix: 15.3883
New value of Value function: 15.3883
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 194
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 9.76223
New value of Value function: 13.7359
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 335
New value of Q matrix: 15.4545
New value of Value function: 15.4545
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 196
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 55
New value of Q matrix: 13.5422
New value of Value function: 13.5422
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 336
New value of Q matrix: 15.614
New value of Value function: 15.614
New value of Policy matrix: 3

=======================================
Simulation: 24
Iteration: 198
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 16.0424
New value of Value function: 16.0424
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 199
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 10.6608
New value of Value function: 13.5422
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 337
New value of Q matrix: 15.792
New value of Value function: 15.792
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 14.042
New value of Value function: 15.792
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 13.2735
New value of Value function: 15.792
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 15.7834
New value of Value function: 15.7834
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 15.7749
New value of Value function: 15.7749
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 12.7074
New value of Value function: 15.7749
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 15.7663
New value of Value function: 15.7663
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 14.3332
New value of Value function: 15.7663
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 15.7578
New value of Value function: 15.7578
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 13.5643
New value of Value function: 15.7578
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 15.7493
New value of Value function: 15.7493
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 15.7408
New value of Value function: 15.7408
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 15.7323
New value of Value function: 15.7323
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 13.8137
New value of Value function: 15.7323
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 15.7238
New value of Value function: 15.7238
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 15.7153
New value of Value function: 15.7153
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 15.7069
New value of Value function: 15.7069
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 14.1936
New value of Value function: 15.7069
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 15.6985
New value of Value function: 15.6985
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 14.0264
New value of Value function: 15.6985
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 15.6901
New value of Value function: 15.6901
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 15.6817
New value of Value function: 15.6817
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 15.6733
New value of Value function: 15.6733
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 15.665
New value of Value function: 15.665
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 353
New value of Q matrix: 15.6492
New value of Value function: 15.6492
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 25
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 14.012
New value of Value function: 14.012
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 26
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 11.7392
New value of Value function: 11.7392
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 27
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 11.9795
New value of Value function: 11.9795
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 28
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 13.2914
New value of Value function: 13.2914
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 29
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 11.6482
New value of Value function: 11.6482
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 30
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 12.4927
New value of Value function: 12.4927
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 354
New value of Q matrix: 15.4584
New value of Value function: 15.4584
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 32
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 10.4381
New value of Value function: 10.4381
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 355
New value of Q matrix: 15.4352
New value of Value function: 15.4352
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 34
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 14.3867
New value of Value function: 14.3867
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 35
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 13.8102
New value of Value function: 13.8102
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 36
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 11.839
New value of Value function: 11.839
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 356
New value of Q matrix: 15.3974
New value of Value function: 15.3974
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 38
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 12.2803
New value of Value function: 12.2803
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 39
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 12.3164
New value of Value function: 12.3164
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 357
New value of Q matrix: 15.2881
New value of Value function: 15.2881
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 41
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 11.0795
New value of Value function: 11.0795
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 15.2801
New value of Value function: 15.2801
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 14.2869
New value of Value function: 15.2801
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 14.4324
New value of Value function: 15.2801
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 382
New value of Q matrix: 12.8327
New value of Value function: 15.2801
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 46
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 12.5335
New value of Value function: 12.5335
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 47
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 11.4082
New value of Value function: 12.3164
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 48
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 12.4082
New value of Value function: 12.5335
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 49
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 13.8631
New value of Value function: 13.8631
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 50
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 11.8892
New value of Value function: 11.8892
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 51
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 9.56252
New value of Value function: 9.56252
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 52
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 13.6199
New value of Value function: 13.6199
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 53
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 33
New value of Q matrix: 15.3608
New value of Value function: 15.3608
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 359
New value of Q matrix: 15.3436
New value of Value function: 15.3436
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 55
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 14.8648
New value of Value function: 14.8648
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 56
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 34
New value of Q matrix: 14.8171
New value of Value function: 14.8171
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 360
New value of Q matrix: 15.4661
New value of Value function: 15.4661
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 58
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 35
New value of Q matrix: 14.3935
New value of Value function: 14.3935
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 361
New value of Q matrix: 15.5846
New value of Value function: 15.5846
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 60
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 9.96259
New value of Value function: 14.8648
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 61
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 12.7627
New value of Value function: 12.7627
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 62
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 15.0624
New value of Value function: 15.0624
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 63
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 13.8029
New value of Value function: 13.8029
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 64
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 39
New value of Q matrix: 10.8916
New value of Value function: 10.8916
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 362
New value of Q matrix: 15.6413
New value of Value function: 15.6413
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 66
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 57
New value of Q matrix: 13.6499
New value of Value function: 13.6499
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 67
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 11.9402
New value of Value function: 11.9402
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 14.2046
New value of Value function: 15.6413
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 15.6331
New value of Value function: 15.6331
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 364
New value of Q matrix: 15.7526
New value of Value function: 15.7526
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 71
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 15.6298
New value of Value function: 15.6298
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 72
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 58
New value of Q matrix: 13.5114
New value of Value function: 13.5114
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 365
New value of Q matrix: 15.895
New value of Value function: 15.895
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 74
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 7.01104
New value of Value function: 15.6298
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 75
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 15.9063
New value of Value function: 15.9063
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 76
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 9.88564
New value of Value function: 15.6298
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 77
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 16.0753
New value of Value function: 16.0753
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 78
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 9.57958
New value of Value function: 13.5114
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 79
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 7.47573
New value of Value function: 16.0753
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 80
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 17.9146
New value of Value function: 17.9146
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 81
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 10.0956
New value of Value function: 16.0753
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 82
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 17.9146
New value of Value function: 17.9146
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 83
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 10.3128
New value of Value function: 16.0753
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 84
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 16.8207
New value of Value function: 16.8207
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 85
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 16.4438
New value of Value function: 16.4438
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 86
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 10.2735
New value of Value function: 13.5114
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 87
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 16.7493
New value of Value function: 16.7493
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 88
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 59
New value of Q matrix: 13.4105
New value of Value function: 13.4105
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 366
New value of Q matrix: 16.0877
New value of Value function: 16.0877
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 90
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 16.9878
New value of Value function: 16.9878
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 91
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 60
New value of Q matrix: 13.348
New value of Value function: 13.348
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 367
New value of Q matrix: 16.2824
New value of Value function: 16.2824
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 93
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 17.1771
New value of Value function: 17.1771
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 94
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 61
New value of Q matrix: 13.3188
New value of Value function: 13.3188
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 368
New value of Q matrix: 16.2774
New value of Value function: 16.2774
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 96
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 62
New value of Q matrix: 13.2928
New value of Value function: 13.2928
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 369
New value of Q matrix: 16.4714
New value of Value function: 16.4714
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 98
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 17.327
New value of Value function: 17.327
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 99
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 9.44247
New value of Value function: 13.2928
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 100
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 63
New value of Q matrix: 13.2334
New value of Value function: 13.2334
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 101
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 12.2623
New value of Value function: 12.2623
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 370
New value of Q matrix: 16.4522
New value of Value function: 16.4522
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 103
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 64
New value of Q matrix: 13.2402
New value of Value function: 13.2402
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 371
New value of Q matrix: 16.4343
New value of Value function: 16.4343
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 105
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 65
New value of Q matrix: 13.2438
New value of Value function: 13.2438
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 372
New value of Q matrix: 16.4176
New value of Value function: 16.4176
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 107
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 66
New value of Q matrix: 13.245
New value of Value function: 13.245
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 373
New value of Q matrix: 16.611
New value of Value function: 16.611
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 109
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 17.4454
New value of Value function: 17.4454
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 110
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 9.15936
New value of Value function: 13.245
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 111
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 11.2264
New value of Value function: 11.2264
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 14.4762
New value of Value function: 16.611
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 14.7132
New value of Value function: 16.611
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 16.6024
New value of Value function: 16.6024
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 13.0169
New value of Value function: 16.6024
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 14.9192
New value of Value function: 16.6024
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 16.5938
New value of Value function: 16.5938
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 376
New value of Q matrix: 16.7516
New value of Value function: 16.7516
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 119
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 31
New value of Q matrix: 15.6795
New value of Value function: 15.6795
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 120
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 15.4167
New value of Value function: 15.4167
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 121
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 16.8698
New value of Value function: 16.8698
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 377
New value of Q matrix: 16.9035
New value of Value function: 16.9035
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 123
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 46
New value of Q matrix: 16.4075
New value of Value function: 16.4075
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 14.5305
New value of Value function: 16.9035
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 15.1346
New value of Value function: 16.9035
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 16.8948
New value of Value function: 16.8948
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 379
New value of Q matrix: 16.9784
New value of Value function: 16.9784
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 128
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 32
New value of Q matrix: 15.3488
New value of Value function: 15.3488
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 384
New value of Q matrix: 13.2811
New value of Value function: 16.9784
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 130
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 9.96065
New value of Value function: 15.3488
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 131
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 17.407
New value of Value function: 17.407
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 132
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 14.6125
New value of Value function: 14.6125
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 133
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 16.3749
New value of Value function: 16.3749
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 134
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 16.3836
New value of Value function: 16.3836
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 135
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 48
New value of Q matrix: 16.6331
New value of Value function: 16.6331
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 136
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 67
New value of Q matrix: 13.2321
New value of Value function: 13.2321
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 137
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 12.617
New value of Value function: 12.617
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 380
New value of Q matrix: 16.9333
New value of Value function: 16.9333
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 139
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 68
New value of Q matrix: 13.2635
New value of Value function: 13.2635
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 140
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 12.8735
New value of Value function: 12.8735
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 381
New value of Q matrix: 16.8922
New value of Value function: 16.8922
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 142
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 69
New value of Q matrix: 13.3189
New value of Value function: 13.3189
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 382
New value of Q matrix: 16.8561
New value of Value function: 16.8561
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 144
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 70
New value of Q matrix: 13.3629
New value of Value function: 13.3629
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 383
New value of Q matrix: 16.8241
New value of Value function: 16.8241
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 146
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 71
New value of Q matrix: 13.4083
New value of Value function: 13.4083
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 147
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 13.0442
New value of Value function: 13.0442
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 384
New value of Q matrix: 16.796
New value of Value function: 16.796
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 149
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 72
New value of Q matrix: 13.4678
New value of Value function: 13.4678
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 150
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 10.5213
New value of Value function: 13.0442
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 151
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 73
New value of Q matrix: 13.52
New value of Value function: 13.52
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 152
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 11.2257
New value of Value function: 13.0442
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 153
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 74
New value of Q matrix: 13.7831
New value of Value function: 13.7831
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 154
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 40
New value of Q matrix: 11.3243
New value of Value function: 11.3243
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 385
New value of Q matrix: 16.7883
New value of Value function: 16.7883
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 156
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 5.95242
New value of Value function: 13.7831
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 157
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 12.3715
New value of Value function: 12.3715
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 158
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 75
New value of Q matrix: 14.0634
New value of Value function: 14.0634
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 159
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 41
New value of Q matrix: 11.6829
New value of Value function: 11.6829
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 386
New value of Q matrix: 16.7952
New value of Value function: 16.7952
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 161
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 76
New value of Q matrix: 14.3505
New value of Value function: 14.3505
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 162
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 42
New value of Q matrix: 11.9829
New value of Value function: 11.9829
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 387
New value of Q matrix: 16.8161
New value of Value function: 16.8161
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 164
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 10.598
New value of Value function: 14.3505
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 165
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 77
New value of Q matrix: 14.6368
New value of Value function: 14.6368
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 166
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 43
New value of Q matrix: 12.2368
New value of Value function: 12.2368
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 388
New value of Q matrix: 16.8503
New value of Value function: 16.8503
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 168
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 78
New value of Q matrix: 14.9174
New value of Value function: 14.9174
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 169
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 9.79636
New value of Value function: 12.2368
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 15.317
New value of Value function: 16.8503
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 389
New value of Q matrix: 16.7116
New value of Value function: 16.7116
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 172
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 18.7682
New value of Value function: 18.7682
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 173
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 79
New value of Q matrix: 14.8044
New value of Value function: 14.8044
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 174
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 13.1356
New value of Value function: 13.1356
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 175
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 44
New value of Q matrix: 12.434
New value of Value function: 12.434
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 390
New value of Q matrix: 16.7594
New value of Value function: 16.7594
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 177
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 80
New value of Q matrix: 15.0845
New value of Value function: 15.0845
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 178
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 12.6066
New value of Value function: 12.6066
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 391
New value of Q matrix: 16.8188
New value of Value function: 16.8188
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 180
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 81
New value of Q matrix: 15.3508
New value of Value function: 15.3508
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 181
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 46
New value of Q matrix: 12.7605
New value of Value function: 12.7605
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 392
New value of Q matrix: 16.7589
New value of Value function: 16.7589
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 183
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 47
New value of Q matrix: 12.8817
New value of Value function: 12.8817
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 393
New value of Q matrix: 16.8315
New value of Value function: 16.8315
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 185
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 10.2638
New value of Value function: 15.3508
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 186
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 14.1954
New value of Value function: 14.1954
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 187
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 8.10947
New value of Value function: 15.3508
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 188
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 15.2567
New value of Value function: 15.2567
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 189
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 10.6891
New value of Value function: 15.3508
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 190
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 11.5849
New value of Value function: 16.6331
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 191
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 17.1423
New value of Value function: 17.1423
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 192
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 82
New value of Q matrix: 15.2021
New value of Value function: 15.2021
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 193
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 13.5446
New value of Value function: 13.5446
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 194
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 83
New value of Q matrix: 15.482
New value of Value function: 15.482
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 195
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 48
New value of Q matrix: 12.9945
New value of Value function: 12.9945
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 394
New value of Q matrix: 16.9068
New value of Value function: 16.9068
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 197
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 11.4941
New value of Value function: 15.482
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 198
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 14.8281
New value of Value function: 14.8281
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 199
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 17.5927
New value of Value function: 17.5927
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 200
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 84
New value of Q matrix: 15.2917
New value of Value function: 15.2917
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 16.8983
New value of Value function: 16.8983
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 16.8898
New value of Value function: 16.8898
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 16.8814
New value of Value function: 16.8814
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 14.7465
New value of Value function: 16.8814
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 16.8729
New value of Value function: 16.8729
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 16.8644
New value of Value function: 16.8644
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 16.856
New value of Value function: 16.856
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 16.8476
New value of Value function: 16.8476
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 16.8392
New value of Value function: 16.8392
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 16.8308
New value of Value function: 16.8308
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 385
New value of Q matrix: 13.45
New value of Value function: 16.8308
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 10.8169
New value of Value function: 13.7324
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 13
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 46
New value of Q matrix: 13.9551
New value of Value function: 13.9551
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 14
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 10.318
New value of Value function: 14.3867
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 15
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 11.8739
New value of Value function: 17.1396
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 14.9353
New value of Value function: 16.8308
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 16.8224
New value of Value function: 16.8224
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 405
New value of Q matrix: 16.9787
New value of Value function: 16.9787
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 19
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 17.3534
New value of Value function: 17.3534
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 20
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 47
New value of Q matrix: 14.143
New value of Value function: 14.143
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 21
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 13.8212
New value of Value function: 13.8212
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 22
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 12.4092
New value of Value function: 14.143
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 23
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 48
New value of Q matrix: 14.7967
New value of Value function: 14.7967
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 24
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 40
New value of Q matrix: 13.5191
New value of Value function: 13.5191
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 25
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 12.3839
New value of Value function: 12.3839
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 26
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 14.2092
New value of Value function: 14.2092
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 27
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 11.65
New value of Value function: 11.65
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 28
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 17.2714
New value of Value function: 17.2714
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 29
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 13.1179
New value of Value function: 13.1179
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 30
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 14.5783
New value of Value function: 14.5783
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 31
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 12.9465
New value of Value function: 12.9465
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 32
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 15.6846
New value of Value function: 15.6846
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 33
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 14.0962
New value of Value function: 14.0962
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 34
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 13.0195
New value of Value function: 13.0195
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 35
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 51
New value of Q matrix: 11.998
New value of Value function: 11.998
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 406
New value of Q matrix: 16.8745
New value of Value function: 16.8745
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 37
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 52
New value of Q matrix: 12.2348
New value of Value function: 12.2348
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 15.1089
New value of Value function: 16.8745
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 407
New value of Q matrix: 16.7871
New value of Value function: 16.7871
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 40
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 53
New value of Q matrix: 12.425
New value of Value function: 12.425
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 408
New value of Q matrix: 16.7136
New value of Value function: 16.7136
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 42
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 9.60327
New value of Value function: 12.425
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 14.6946
New value of Value function: 16.7136
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 14.9226
New value of Value function: 16.7136
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 16.7053
New value of Value function: 16.7053
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 15.2484
New value of Value function: 16.7053
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 15.12
New value of Value function: 16.7053
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 16.697
New value of Value function: 16.697
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 16.6888
New value of Value function: 16.6888
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 412
New value of Q matrix: 16.6494
New value of Value function: 16.6494
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 51
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 12.9923
New value of Value function: 12.9923
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 52
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 13.0925
New value of Value function: 13.0925
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 413
New value of Q matrix: 16.6156
New value of Value function: 16.6156
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 54
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 13.1638
New value of Value function: 13.1638
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 414
New value of Q matrix: 16.5869
New value of Value function: 16.5869
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 56
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 12.2756
New value of Value function: 12.2756
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 57
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 9.73018
New value of Value function: 9.73018
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 415
New value of Q matrix: 16.5165
New value of Value function: 16.5165
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 59
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 27
New value of Q matrix: 12.4826
New value of Value function: 12.4826
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 416
New value of Q matrix: 16.4597
New value of Value function: 16.4597
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 61
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 8.64843
New value of Value function: 12.4826
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 62
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 13.9188
New value of Value function: 13.9188
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 63
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 8.42302
New value of Value function: 14.0962
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 64
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 14.8549
New value of Value function: 14.8549
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 65
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 13.2524
New value of Value function: 13.2524
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 66
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 14.1055
New value of Value function: 14.1055
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 67
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 18.4827
New value of Value function: 18.4827
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 68
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 17.7397
New value of Value function: 17.7397
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 69
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 21.9095
New value of Value function: 21.9095
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 70
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 53
New value of Q matrix: 27.1585
New value of Value function: 27.1585
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 71
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 26.3197
New value of Value function: 26.3197
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 72
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 54
New value of Q matrix: 29.204
New value of Value function: 29.204
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 73
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 66
New value of Q matrix: 38.5173
New value of Value function: 38.5173
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 74
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.417685
New value of Value function: 27.9893
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 75
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 6.43258
New value of Value function: 6.43258
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 76
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.23656
New value of Value function: 9.32986
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 77
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 17.2724
New value of Value function: 17.2724
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 78
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 21.3559
New value of Value function: 21.3559
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 79
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 55
New value of Q matrix: 28.3751
New value of Value function: 28.3751
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 80
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 27.9103
New value of Value function: 27.9103
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 81
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 56
New value of Q matrix: 29.9462
New value of Value function: 29.9462
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 82
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 67
New value of Q matrix: 36.7082
New value of Value function: 36.7082
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 83
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 32.6579
New value of Value function: 32.6579
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 84
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 68
New value of Q matrix: 35.6924
New value of Value function: 35.6924
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 85
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 35.0187
New value of Value function: 35.0187
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 86
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 69
New value of Q matrix: 38.8878
New value of Value function: 38.8878
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 87
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 44
New value of Q matrix: 14.8873
New value of Value function: 61.8539
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 88
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 70
New value of Q matrix: 41.6783
New value of Value function: 41.6783
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 89
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 50.9756
New value of Value function: 50.9756
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 90
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 17.6441
New value of Value function: 17.6441
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 91
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 57
New value of Q matrix: 31.7099
New value of Value function: 31.7099
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 92
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 18.9554
New value of Value function: 41.6783
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 93
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 58
New value of Q matrix: 33.2267
New value of Value function: 33.2267
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 94
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 71
New value of Q matrix: 42.8399
New value of Value function: 42.8399
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 95
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 62.3045
New value of Value function: 62.3045
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 96
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 32.6567
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 97
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 70.7345
New value of Value function: 70.7345
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 98
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 20.7918
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 99
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 29.8893
New value of Value function: 29.8893
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 100
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 54.2998
New value of Value function: 54.2998
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 101
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 4
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 15.4314
New value of Value function: 16.4597
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 16.4516
New value of Value function: 16.4516
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 16.4436
New value of Value function: 16.4436
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 16.4355
New value of Value function: 16.4355
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 16.4275
New value of Value function: 16.4275
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 16.4195
New value of Value function: 16.4195
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 15.2576
New value of Value function: 16.4195
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 16.4115
New value of Value function: 16.4115
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 16.4035
New value of Value function: 16.4035
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 16.3956
New value of Value function: 16.3956
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 16.3876
New value of Value function: 16.3876
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 16.3797
New value of Value function: 16.3797
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 16.3718
New value of Value function: 16.3718
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 16.3639
New value of Value function: 16.3639
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 16.3559
New value of Value function: 16.3559
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 16.3481
New value of Value function: 16.3481
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 15.519
New value of Value function: 16.3481
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 16.3402
New value of Value function: 16.3402
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 16.3323
New value of Value function: 16.3323
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 16.3245
New value of Value function: 16.3245
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 16.3166
New value of Value function: 16.3166
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 435
New value of Q matrix: 16.5019
New value of Value function: 16.5019
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 23
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 17.7439
New value of Value function: 17.7439
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 24
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 49
New value of Q matrix: 14.5882
New value of Value function: 14.5882
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 436
New value of Q matrix: 16.6965
New value of Value function: 16.6965
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 26
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 17.9455
New value of Value function: 17.9455
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 27
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 15.2216
New value of Value function: 15.2216
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 28
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 42
New value of Q matrix: 14.0628
New value of Value function: 14.0628
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 29
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 12.7645
New value of Value function: 12.7645
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 30
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 14.4395
New value of Value function: 14.4395
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 31
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 13.092
New value of Value function: 13.092
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 32
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 13.5164
New value of Value function: 13.5164
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 33
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 14.3331
New value of Value function: 14.3331
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 34
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 13.8266
New value of Value function: 13.8266
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 35
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 8.83534
New value of Value function: 15.6846
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 36
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 14.0446
New value of Value function: 14.0446
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 37
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 11.6821
New value of Value function: 11.6821
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 38
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 16.66
New value of Value function: 16.66
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 39
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 15.5674
New value of Value function: 15.5674
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 40
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 14.2112
New value of Value function: 14.2112
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 41
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 55
New value of Q matrix: 15.8024
New value of Value function: 15.8024
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 42
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 21.0962
New value of Value function: 21.0962
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 43
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 21.8859
New value of Value function: 21.8859
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 44
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 67
New value of Q matrix: 11.1194
New value of Value function: 21.0962
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 437
New value of Q matrix: 16.7897
New value of Value function: 16.7897
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 46
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 14.4269
New value of Value function: 15.8024
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 47
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 19.2801
New value of Value function: 19.2801
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 48
----------
State: 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 11.588
New value of Value function: 11.588
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 438
New value of Q matrix: 16.8783
New value of Value function: 16.8783
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 50
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 8.60288
New value of Value function: 15.8024
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 51
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 16.6352
New value of Value function: 16.6352
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 52
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 20.0487
New value of Value function: 20.0487
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 53
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 20.2576
New value of Value function: 20.2576
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 54
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 23.7698
New value of Value function: 23.7698
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 55
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 59
New value of Q matrix: 32.1076
New value of Value function: 32.1076
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 56
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 30.0847
New value of Value function: 30.0847
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 57
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 60
New value of Q matrix: 33.6961
New value of Value function: 33.6961
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 58
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 23.3408
New value of Value function: 42.8399
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 59
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 61
New value of Q matrix: 35.068
New value of Value function: 35.068
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 60
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 72
New value of Q matrix: 46.1618
New value of Value function: 46.1618
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 61
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 59.4945
New value of Value function: 59.4945
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 62
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 21.462
New value of Value function: 21.462
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 63
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 62
New value of Q matrix: 36.6723
New value of Value function: 36.6723
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 64
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 73
New value of Q matrix: 47.7697
New value of Value function: 47.7697
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 65
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 21
New value of Q matrix: 68.124
New value of Value function: 68.124
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 66
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 8
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 28
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 13.6159
New value of Value function: 16.8783
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 439
New value of Q matrix: 17.0639
New value of Value function: 17.0639
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 3
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 18.2572
New value of Value function: 18.2572
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 4
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 51
New value of Q matrix: 15.1462
New value of Value function: 15.1462
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 5
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 13.8868
New value of Value function: 13.8868
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 6
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 15.7215
New value of Value function: 15.7215
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 7
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 9.20094
New value of Value function: 14.4395
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 8
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 44
New value of Q matrix: 13.9669
New value of Value function: 13.9669
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 9
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 12.8725
New value of Value function: 12.8725
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 440
New value of Q matrix: 16.9958
New value of Value function: 16.9958
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 11
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 12.8007
New value of Value function: 12.8007
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 12
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 14.6761
New value of Value function: 14.6761
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 13
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 13.9969
New value of Value function: 13.9969
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 14
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 13.3278
New value of Value function: 13.3278
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 15
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 15.2617
New value of Value function: 15.2617
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 16
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 13.0734
New value of Value function: 13.0734
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 17
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 13.8135
New value of Value function: 13.8135
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 18
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 4.3761
New value of Value function: 14.0446
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 19
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.962775
New value of Value function: 4.16743
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 20
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.86881
New value of Value function: 8.86881
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 21
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 5
New value of Q matrix: 5.63195
New value of Value function: 5.63195
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 22
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 15.9599
New value of Value function: 15.9599
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 23
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 14.8047
New value of Value function: 14.8047
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 24
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 12.408
New value of Value function: 12.408
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 25
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 17.5443
New value of Value function: 17.5443
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 26
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 16.8256
New value of Value function: 16.8256
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 27
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 16.9265
New value of Value function: 16.9265
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 28
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 11.3552
New value of Value function: 15.8024
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 29
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 15.0666
New value of Value function: 16.9265
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 30
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 17.0389
New value of Value function: 17.0389
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 31
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 20.5762
New value of Value function: 20.5762
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 32
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 23.4841
New value of Value function: 23.4841
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 33
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 20.3557
New value of Value function: 20.3557
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 34
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 21.9946
New value of Value function: 21.9946
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 35
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 68
New value of Q matrix: 11.4476
New value of Value function: 20.3557
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 441
New value of Q matrix: 17.1326
New value of Value function: 17.1326
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 37
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 11.1281
New value of Value function: 17.0389
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 38
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 17.8275
New value of Value function: 17.8275
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 39
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 18.1135
New value of Value function: 18.1135
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 40
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 20.5663
New value of Value function: 20.5663
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 41
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 23.2594
New value of Value function: 23.2594
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 42
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 13.0342
New value of Value function: 20.5663
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 43
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 23.0832
New value of Value function: 23.0832
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 44
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 24.8654
New value of Value function: 24.8654
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 45
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 63
New value of Q matrix: 35.4265
New value of Value function: 35.4265
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 46
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 32.4931
New value of Value function: 32.4931
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 47
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 64
New value of Q matrix: 37.1597
New value of Value function: 37.1597
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 48
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 74
New value of Q matrix: 45.7817
New value of Value function: 45.7817
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 49
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 39.7871
New value of Value function: 39.7871
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 50
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 75
New value of Q matrix: 48.3984
New value of Value function: 48.3984
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 51
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 16.2242
New value of Value function: 68.124
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 52
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 36.3242
New value of Value function: 36.3242
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 53
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 24.8024
New value of Value function: 48.3984
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 54
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 76
New value of Q matrix: 50.6976
New value of Value function: 50.6976
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 55
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 74.7153
New value of Value function: 74.7153
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 56
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 20.0891
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 28
Iteration: 57
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 77
New value of Q matrix: 53.4635
New value of Value function: 53.4635
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 58
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 79.7895
New value of Value function: 79.7895
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 59
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 5
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 29
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 17.1245
New value of Value function: 17.1245
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 17.1164
New value of Value function: 17.1164
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 17.1082
New value of Value function: 17.1082
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 17.1001
New value of Value function: 17.1001
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 17.092
New value of Value function: 17.092
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 17.0839
New value of Value function: 17.0839
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 17.0759
New value of Value function: 17.0759
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 17.0678
New value of Value function: 17.0678
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 17.0598
New value of Value function: 17.0598
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 17.0517
New value of Value function: 17.0517
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 17.0437
New value of Value function: 17.0437
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 17.0357
New value of Value function: 17.0357
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 17.0277
New value of Value function: 17.0277
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 17.0197
New value of Value function: 17.0197
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 17.0118
New value of Value function: 17.0118
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 17.0038
New value of Value function: 17.0038
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 387
New value of Q matrix: 13.8675
New value of Value function: 17.0038
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 18
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 53
New value of Q matrix: 15.4622
New value of Value function: 15.4622
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 458
New value of Q matrix: 17.194
New value of Value function: 17.194
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 20
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 18.5379
New value of Value function: 18.5379
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 21
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 16.0157
New value of Value function: 16.0157
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 22
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 46
New value of Q matrix: 14.5797
New value of Value function: 14.5797
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 459
New value of Q matrix: 17.2052
New value of Value function: 17.2052
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 24
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 47
New value of Q matrix: 14.4474
New value of Value function: 14.4474
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 25
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 13.0518
New value of Value function: 13.0518
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 26
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 48
New value of Q matrix: 15.2645
New value of Value function: 15.2645
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 27
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.37402
New value of Value function: 15.2617
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 28
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 15.0055
New value of Value function: 15.0055
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 460
New value of Q matrix: 17.2355
New value of Value function: 17.2355
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 30
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 7.1753
New value of Value function: 15.0055
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 31
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 14.84
New value of Value function: 14.84
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 32
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 15.1352
New value of Value function: 15.1352
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 33
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 10.9839
New value of Value function: 13.0734
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 34
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 15.9435
New value of Value function: 15.9435
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 35
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 13.5867
New value of Value function: 13.5867
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 36
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 17.064
New value of Value function: 17.064
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 37
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 13.8718
New value of Value function: 13.8718
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 38
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 18.0911
New value of Value function: 18.0911
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 39
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 16.311
New value of Value function: 16.311
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 40
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 14.4574
New value of Value function: 14.4574
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 41
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 58
New value of Q matrix: 17.5817
New value of Value function: 17.5817
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 461
New value of Q matrix: 17.3832
New value of Value function: 17.3832
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 43
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 59
New value of Q matrix: 17.1426
New value of Value function: 17.1426
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 462
New value of Q matrix: 17.5036
New value of Value function: 17.5036
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 45
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 60
New value of Q matrix: 16.3096
New value of Value function: 16.3096
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 46
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 11.1569
New value of Value function: 11.1569
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 15.7279
New value of Value function: 17.5036
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 15.9115
New value of Value function: 17.5036
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 17.4955
New value of Value function: 17.4955
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 17.4873
New value of Value function: 17.4873
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 15.505
New value of Value function: 17.4873
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 15.4489
New value of Value function: 17.4873
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 16.0712
New value of Value function: 17.4873
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 17.4792
New value of Value function: 17.4792
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 17.4711
New value of Value function: 17.4711
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 467
New value of Q matrix: 17.437
New value of Value function: 17.437
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 57
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 14.3064
New value of Value function: 14.3064
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 58
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 17.6704
New value of Value function: 17.6704
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 59
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 15.3159
New value of Value function: 15.3159
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 60
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 16.874
New value of Value function: 16.874
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 61
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 11.7053
New value of Value function: 14.2112
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 62
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 17.313
New value of Value function: 17.313
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 63
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 15.523
New value of Value function: 15.523
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 64
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.80636
New value of Value function: 16.3096
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 65
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 61
New value of Q matrix: 15.7636
New value of Value function: 15.7636
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 66
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.32402
New value of Value function: 11.1569
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 67
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 12.0535
New value of Value function: 12.0535
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 468
New value of Q matrix: 17.491
New value of Value function: 17.491
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 69
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 62
New value of Q matrix: 15.8536
New value of Value function: 15.8536
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 70
----------
State: 1929
	Distance: 4
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 13.7131
New value of Value function: 13.7131
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 71
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 26.6829
New value of Value function: 26.6829
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 72
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 65
New value of Q matrix: 36.1684
New value of Value function: 36.1684
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 73
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 39.8357
New value of Value function: 39.8357
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 74
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 78
New value of Q matrix: 51.417
New value of Value function: 51.417
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 75
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 44.5671
New value of Value function: 44.5671
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 76
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 32.672
New value of Value function: 51.417
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 77
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 79
New value of Q matrix: 54.6319
New value of Value function: 54.6319
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 78
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 25.0507
New value of Value function: 79.7895
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 79
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -2
New value of Value function: 36.3242
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 80
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 81
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 14.3161
New value of Value function: 14.3161
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 14.0104
New value of Value function: 17.491
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 83
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 84
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 85
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 86
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 60.7568
New value of Value function: 60.7568
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 87
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 74.1749
New value of Value function: 74.1749
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 88
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 6
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 17.4829
New value of Value function: 17.4829
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 388
New value of Q matrix: 14.02
New value of Value function: 17.4829
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 3
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 14.8169
New value of Value function: 14.8169
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 4
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 12.2996
New value of Value function: 12.2996
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 5
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 13.4029
New value of Value function: 13.4029
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 6
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 15.7777
New value of Value function: 15.7777
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 7
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 15.8004
New value of Value function: 15.8004
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 8
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 11.9534
New value of Value function: 16.3749
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 9
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 17.2329
New value of Value function: 17.407
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 10
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 17.7666
New value of Value function: 17.7666
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 11
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 17.4111
New value of Value function: 17.4111
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 12
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 7.53679
New value of Value function: 17.5927
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 13
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 18.1
New value of Value function: 18.1
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 14
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 51
New value of Q matrix: 17.1328
New value of Value function: 17.1328
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 470
New value of Q matrix: 17.5973
New value of Value function: 17.5973
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 16
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 52
New value of Q matrix: 17.4722
New value of Value function: 17.4722
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 17
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 19.0303
New value of Value function: 19.0303
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 18
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 85
New value of Q matrix: 15.1973
New value of Value function: 15.1973
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 471
New value of Q matrix: 17.7217
New value of Value function: 17.7217
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 20
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 13.013
New value of Value function: 17.4722
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 21
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 17.8257
New value of Value function: 17.8257
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 22
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 86
New value of Q matrix: 15.1269
New value of Value function: 15.1269
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 472
New value of Q matrix: 17.7334
New value of Value function: 17.7334
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 24
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 87
New value of Q matrix: 15.0657
New value of Value function: 15.0657
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 389
New value of Q matrix: 14.2175
New value of Value function: 17.7334
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 26
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 11.8588
New value of Value function: 15.0657
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 27
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 18.11
New value of Value function: 18.11
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 28
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 88
New value of Q matrix: 15.0114
New value of Value function: 15.0114
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 473
New value of Q matrix: 17.7393
New value of Value function: 17.7393
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 30
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 89
New value of Q matrix: 14.9637
New value of Value function: 14.9637
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 15.6532
New value of Value function: 17.7393
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 474
New value of Q matrix: 17.7427
New value of Value function: 17.7427
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 33
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 90
New value of Q matrix: 14.9053
New value of Value function: 14.9053
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 34
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 13.631
New value of Value function: 13.631
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 35
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 91
New value of Q matrix: 14.8622
New value of Value function: 14.8622
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 36
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 14.8531
New value of Value function: 14.8531
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 37
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 49
New value of Q matrix: 13.2189
New value of Value function: 13.2189
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 475
New value of Q matrix: 17.7414
New value of Value function: 17.7414
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 39
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 92
New value of Q matrix: 15.1984
New value of Value function: 15.1984
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 40
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 50
New value of Q matrix: 13.4091
New value of Value function: 13.4091
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 476
New value of Q matrix: 17.7553
New value of Value function: 17.7553
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 42
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 93
New value of Q matrix: 15.5174
New value of Value function: 15.5174
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 43
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 11.7484
New value of Value function: 13.4091
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 477
New value of Q matrix: 17.7831
New value of Value function: 17.7831
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 45
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 94
New value of Q matrix: 15.4233
New value of Value function: 15.4233
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 478
New value of Q matrix: 17.8054
New value of Value function: 17.8054
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 47
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 95
New value of Q matrix: 15.4522
New value of Value function: 15.4522
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 48
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 13.3817
New value of Value function: 14.8531
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 479
New value of Q matrix: 17.8278
New value of Value function: 17.8278
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 50
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 96
New value of Q matrix: 15.478
New value of Value function: 15.478
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 51
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 11.7799
New value of Value function: 14.8531
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 52
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 13.4685
New value of Value function: 14.8531
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 53
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 14.6658
New value of Value function: 14.6658
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 54
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 97
New value of Q matrix: 15.762
New value of Value function: 15.762
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 55
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 51
New value of Q matrix: 13.5828
New value of Value function: 13.5828
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 480
New value of Q matrix: 17.8633
New value of Value function: 17.8633
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 57
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 98
New value of Q matrix: 16.0332
New value of Value function: 16.0332
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 58
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 52
New value of Q matrix: 13.7356
New value of Value function: 13.7356
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 481
New value of Q matrix: 17.9093
New value of Value function: 17.9093
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 60
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 10.839
New value of Value function: 16.0332
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 482
New value of Q matrix: 18.0469
New value of Value function: 18.0469
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 62
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 14.2053
New value of Value function: 18.11
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 63
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 11.6415
New value of Value function: 18.11
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 64
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 14.86
New value of Value function: 14.86
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 65
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 55
New value of Q matrix: 18.4825
New value of Value function: 18.4825
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 66
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 99
New value of Q matrix: 16.291
New value of Value function: 16.291
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 67
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 53
New value of Q matrix: 13.8909
New value of Value function: 13.8909
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 483
New value of Q matrix: 18.0961
New value of Value function: 18.0961
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 69
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 100
New value of Q matrix: 16.5371
New value of Value function: 16.5371
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 70
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 54
New value of Q matrix: 14.0303
New value of Value function: 14.0303
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 484
New value of Q matrix: 18.154
New value of Value function: 18.154
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 72
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 101
New value of Q matrix: 16.7712
New value of Value function: 16.7712
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 73
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 55
New value of Q matrix: 14.1573
New value of Value function: 14.1573
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 15.8763
New value of Value function: 18.154
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 485
New value of Q matrix: 18.2199
New value of Value function: 18.2199
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 76
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 102
New value of Q matrix: 16.9935
New value of Value function: 16.9935
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 77
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 12.9916
New value of Value function: 14.1573
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 486
New value of Q matrix: 18.2926
New value of Value function: 18.2926
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 79
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 103
New value of Q matrix: 16.8482
New value of Value function: 16.8482
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 80
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 15.0038
New value of Value function: 15.0038
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 81
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 104
New value of Q matrix: 16.7507
New value of Value function: 16.7507
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 82
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 15.9562
New value of Value function: 15.9562
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 83
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 56
New value of Q matrix: 14.2846
New value of Value function: 14.2846
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 487
New value of Q matrix: 18.3511
New value of Value function: 18.3511
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 85
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 105
New value of Q matrix: 16.984
New value of Value function: 16.984
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 86
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 57
New value of Q matrix: 14.4016
New value of Value function: 14.4016
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 488
New value of Q matrix: 18.4173
New value of Value function: 18.4173
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 88
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 106
New value of Q matrix: 17.2048
New value of Value function: 17.2048
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 89
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 58
New value of Q matrix: 14.5108
New value of Value function: 14.5108
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 489
New value of Q matrix: 18.4904
New value of Value function: 18.4904
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 91
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 12.1159
New value of Value function: 17.2048
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 92
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 5.91939
New value of Value function: 14.86
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 93
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.0702
New value of Value function: 10.0702
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 94
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 4.71058
New value of Value function: 4.71058
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 95
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.7031
New value of Value function: 9.7031
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 96
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.31873
New value of Value function: 6.31873
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 97
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 6.474
New value of Value function: 6.474
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 98
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.15681
New value of Value function: 2.15681
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 99
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 4.06176
New value of Value function: 4.06176
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 100
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 5.9767
New value of Value function: 5.9767
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 101
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 3.85463
New value of Value function: 3.85463
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 102
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 50
New value of Q matrix: 8.85104
New value of Value function: 8.85104
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 390
New value of Q matrix: 14.0932
New value of Value function: 18.4904
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 104
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 6.84956
New value of Value function: 8.85104
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 105
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 51
New value of Q matrix: 9.75484
New value of Value function: 9.75484
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 490
New value of Q matrix: 18.2172
New value of Value function: 18.2172
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 107
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 9.9023
New value of Value function: 9.9023
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 108
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.88733
New value of Value function: 8.61227
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 109
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 10.1939
New value of Value function: 10.1939
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 110
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 40
New value of Q matrix: 9.09373
New value of Value function: 9.09373
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 111
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 52
New value of Q matrix: 9.00046
New value of Value function: 9.00046
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 112
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 8.60788
New value of Value function: 8.60788
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 113
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 10.7181
New value of Value function: 10.7181
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 14.488
New value of Value function: 18.2172
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 14.2925
New value of Value function: 18.2172
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 491
New value of Q matrix: 18.0094
New value of Value function: 18.0094
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 117
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 12.0885
New value of Value function: 12.0885
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 492
New value of Q matrix: 18.1006
New value of Value function: 18.1006
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 119
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 107
New value of Q matrix: 17.4137
New value of Value function: 17.4137
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 120
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 59
New value of Q matrix: 14.564
New value of Value function: 14.564
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 493
New value of Q matrix: 18.0698
New value of Value function: 18.0698
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 122
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 60
New value of Q matrix: 14.606
New value of Value function: 14.606
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 14.8888
New value of Value function: 18.0698
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 494
New value of Q matrix: 18.0617
New value of Value function: 18.0617
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 16.0684
New value of Value function: 18.0617
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 495
New value of Q matrix: 18.0347
New value of Value function: 18.0347
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 127
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 61
New value of Q matrix: 14.6378
New value of Value function: 14.6378
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 392
New value of Q matrix: 14.3266
New value of Value function: 18.0347
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 129
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 10.7544
New value of Value function: 10.7544
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 130
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 13.5237
New value of Value function: 13.5237
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 131
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 11
New value of Q matrix: 10.3425
New value of Value function: 10.3425
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 132
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 13.8814
New value of Value function: 13.8814
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 133
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 12
New value of Q matrix: 10.1693
New value of Value function: 10.1939
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 134
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 13.9756
New value of Value function: 13.9756
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 135
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 9.1572
New value of Value function: 10.1939
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 136
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 108
New value of Q matrix: 17.6137
New value of Value function: 17.6137
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 137
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 62
New value of Q matrix: 14.6653
New value of Value function: 14.6653
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 496
New value of Q matrix: 17.8127
New value of Value function: 17.8127
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 139
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 10.1684
New value of Value function: 10.1693
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 140
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 8.3902
New value of Value function: 8.3902
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 141
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 63
New value of Q matrix: 14.5702
New value of Value function: 14.5702
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 142
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 53
New value of Q matrix: 9.77437
New value of Value function: 9.77437
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 497
New value of Q matrix: 17.7953
New value of Value function: 17.7953
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 144
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 64
New value of Q matrix: 14.5761
New value of Value function: 14.5761
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 498
New value of Q matrix: 17.779
New value of Value function: 17.779
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 146
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 10.2221
New value of Value function: 14.5761
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 147
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 109
New value of Q matrix: 17.7877
New value of Value function: 17.7877
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 148
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 65
New value of Q matrix: 14.5792
New value of Value function: 14.5792
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 499
New value of Q matrix: 17.7635
New value of Value function: 17.7635
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 150
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 66
New value of Q matrix: 14.58
New value of Value function: 14.58
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 500
New value of Q matrix: 17.7488
New value of Value function: 17.7488
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 152
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 11.6006
New value of Value function: 14.58
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 153
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 110
New value of Q matrix: 17.9447
New value of Value function: 17.9447
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 154
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 67
New value of Q matrix: 14.5789
New value of Value function: 14.5789
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 15.2028
New value of Value function: 17.7488
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 501
New value of Q matrix: 17.5396
New value of Value function: 17.5396
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 157
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 11.3328
New value of Value function: 11.3328
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 502
New value of Q matrix: 17.5349
New value of Value function: 17.5349
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 159
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 68
New value of Q matrix: 14.5523
New value of Value function: 14.5523
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 503
New value of Q matrix: 17.5292
New value of Value function: 17.5292
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 161
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 69
New value of Q matrix: 14.5284
New value of Value function: 14.5284
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 16.2164
New value of Value function: 17.5292
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 504
New value of Q matrix: 17.5856
New value of Value function: 17.5856
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 164
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 16.688
New value of Value function: 16.688
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 165
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 70
New value of Q matrix: 14.5143
New value of Value function: 14.5143
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 505
New value of Q matrix: 17.576
New value of Value function: 17.576
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 167
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 71
New value of Q matrix: 14.5007
New value of Value function: 14.5007
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 506
New value of Q matrix: 17.7178
New value of Value function: 17.7178
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 169
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 111
New value of Q matrix: 17.9044
New value of Value function: 17.9044
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 170
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 13.1701
New value of Value function: 16.688
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 171
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 12.457
New value of Value function: 17.9044
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 172
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 10.9938
New value of Value function: 18.4825
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 173
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 17.4551
New value of Value function: 17.4551
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 174
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 19.0495
New value of Value function: 19.0495
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 175
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 112
New value of Q matrix: 17.5866
New value of Value function: 17.5866
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 507
New value of Q matrix: 17.8374
New value of Value function: 17.8374
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 177
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 113
New value of Q matrix: 17.3112
New value of Value function: 17.3112
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 508
New value of Q matrix: 17.9394
New value of Value function: 17.9394
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 179
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 114
New value of Q matrix: 17.0723
New value of Value function: 17.0723
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 16.3901
New value of Value function: 17.9394
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 17.9315
New value of Value function: 17.9315
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 510
New value of Q matrix: 18.1054
New value of Value function: 18.1054
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 183
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 57
New value of Q matrix: 18.5031
New value of Value function: 18.5031
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 511
New value of Q matrix: 18.2475
New value of Value function: 18.2475
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 185
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 18.4788
New value of Value function: 18.4788
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 186
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 59
New value of Q matrix: 18.0344
New value of Value function: 18.0344
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 15.5355
New value of Value function: 18.2475
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 512
New value of Q matrix: 18.4063
New value of Value function: 18.4063
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 189
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 20.1106
New value of Value function: 20.1106
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 190
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 115
New value of Q matrix: 16.8997
New value of Value function: 16.8997
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 16.2737
New value of Value function: 18.4063
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 513
New value of Q matrix: 18.4648
New value of Value function: 18.4648
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 193
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 116
New value of Q matrix: 16.7494
New value of Value function: 16.7494
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 15.8525
New value of Value function: 18.4648
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 18.4566
New value of Value function: 18.4566
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 515
New value of Q matrix: 18.5062
New value of Value function: 18.5062
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 197
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 12.5672
New value of Value function: 16.7494
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 198
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 60
New value of Q matrix: 18.4924
New value of Value function: 18.4924
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 199
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 117
New value of Q matrix: 16.6173
New value of Value function: 16.6173
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 16.606
New value of Value function: 18.5062
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 14.5281
New value of Value function: 18.5062
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 516
New value of Q matrix: 18.6315
New value of Value function: 18.6315
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 3
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 7.79309
New value of Value function: 18.5379
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 517
New value of Q matrix: 18.6233
New value of Value function: 18.6233
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 18.6151
New value of Value function: 18.6151
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 519
New value of Q matrix: 18.607
New value of Value function: 18.607
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 18.5988
New value of Value function: 18.5988
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 394
New value of Q matrix: 14.7461
New value of Value function: 18.5988
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 9
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 55
New value of Q matrix: 15.9344
New value of Value function: 15.9344
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 521
New value of Q matrix: 18.7194
New value of Value function: 18.7194
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 11
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 18.8574
New value of Value function: 18.8574
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 56
New value of Q matrix: 15.7758
New value of Value function: 15.7758
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 13
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 14.1454
New value of Value function: 14.1454
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 14
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 16.4175
New value of Value function: 16.4175
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 15
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 50
New value of Q matrix: 15.4901
New value of Value function: 15.4901
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 16
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 14.4081
New value of Value function: 14.4081
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 522
New value of Q matrix: 18.597
New value of Value function: 18.597
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 18
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 13.6257
New value of Value function: 13.6257
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 19
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 51
New value of Q matrix: 15.4584
New value of Value function: 15.4584
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 20
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 14.9096
New value of Value function: 14.9096
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 16.4766
New value of Value function: 18.597
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 16.1459
New value of Value function: 18.597
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 18.5888
New value of Value function: 18.5888
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 524
New value of Q matrix: 18.5196
New value of Value function: 18.5196
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 25
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 15.8649
New value of Value function: 15.8649
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 26
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 16.0455
New value of Value function: 16.0455
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 27
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 14.9389
New value of Value function: 14.9389
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 16.798
New value of Value function: 18.5196
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 18.5115
New value of Value function: 18.5115
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 16.3944
New value of Value function: 18.5115
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 16.9668
New value of Value function: 18.5115
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 18.5035
New value of Value function: 18.5035
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 16.6506
New value of Value function: 18.5035
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 18.4954
New value of Value function: 18.4954
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 18.4873
New value of Value function: 18.4873
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 18.4793
New value of Value function: 18.4793
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 530
New value of Q matrix: 18.6178
New value of Value function: 18.6178
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 38
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 10.6997
New value of Value function: 18.8574
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 39
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 19.2063
New value of Value function: 19.2063
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 40
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 58
New value of Q matrix: 16.288
New value of Value function: 16.288
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 16.6251
New value of Value function: 18.6178
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 531
New value of Q matrix: 18.6217
New value of Value function: 18.6217
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 43
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 15.6309
New value of Value function: 15.6309
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 44
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 59
New value of Q matrix: 16.2193
New value of Value function: 16.2193
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 45
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 15.1447
New value of Value function: 15.1447
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 16.8288
New value of Value function: 18.6217
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 18.6136
New value of Value function: 18.6136
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 18.6055
New value of Value function: 18.6055
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 534
New value of Q matrix: 18.6251
New value of Value function: 18.6251
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 50
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 10.7837
New value of Value function: 16.2193
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 535
New value of Q matrix: 18.7716
New value of Value function: 18.7716
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 52
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 19.4127
New value of Value function: 19.4127
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 53
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 60
New value of Q matrix: 16.2523
New value of Value function: 16.2523
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 54
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 15.4678
New value of Value function: 15.4678
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 55
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 61
New value of Q matrix: 16.8455
New value of Value function: 16.8455
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 56
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 53
New value of Q matrix: 16.0383
New value of Value function: 16.0383
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 57
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 15.324
New value of Value function: 15.324
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 536
New value of Q matrix: 18.7518
New value of Value function: 18.7518
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 59
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 16.7409
New value of Value function: 16.7409
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 60
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 54
New value of Q matrix: 16.0563
New value of Value function: 16.0563
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 61
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 15.4148
New value of Value function: 15.4148
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 537
New value of Q matrix: 18.7873
New value of Value function: 18.7873
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 63
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 17.6159
New value of Value function: 17.6159
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 64
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 55
New value of Q matrix: 16.0839
New value of Value function: 16.0839
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 65
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 10.6362
New value of Value function: 15.4148
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 66
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 15.4801
New value of Value function: 15.4801
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 538
New value of Q matrix: 18.8585
New value of Value function: 18.8585
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 68
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 18.2325
New value of Value function: 18.2325
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 69
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 8.7634
New value of Value function: 16.0839
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 70
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 18.669
New value of Value function: 18.669
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 71
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 16.5791
New value of Value function: 16.5791
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 72
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 7.63586
New value of Value function: 14.9389
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 17.1538
New value of Value function: 18.8585
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 17.3192
New value of Value function: 18.8585
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 16.8406
New value of Value function: 18.8585
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 539
New value of Q matrix: 18.8504
New value of Value function: 18.8504
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 17.4648
New value of Value function: 18.8504
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 18.8423
New value of Value function: 18.8423
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 541
New value of Q matrix: 18.8342
New value of Value function: 18.8342
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 17.0319
New value of Value function: 18.8342
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 18.8261
New value of Value function: 18.8261
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 543
New value of Q matrix: 18.818
New value of Value function: 18.818
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 14.9415
New value of Value function: 18.818
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 544
New value of Q matrix: 18.8099
New value of Value function: 18.8099
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 17.2086
New value of Value function: 18.8099
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 545
New value of Q matrix: 18.8019
New value of Value function: 18.8019
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 546
New value of Q matrix: 18.8393
New value of Value function: 18.8393
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 88
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 62
New value of Q matrix: 16.6938
New value of Value function: 16.6938
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 547
New value of Q matrix: 18.9838
New value of Value function: 18.9838
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 90
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 13.2371
New value of Value function: 19.4127
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 91
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 63
New value of Q matrix: 17.2884
New value of Value function: 17.2884
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 92
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 57
New value of Q matrix: 16.5455
New value of Value function: 16.5455
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 93
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 15.5847
New value of Value function: 15.5847
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 548
New value of Q matrix: 19.0905
New value of Value function: 19.0905
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 95
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 16
New value of Q matrix: 18.0306
New value of Value function: 18.0306
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 96
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 64
New value of Q matrix: 17.7998
New value of Value function: 17.7998
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 97
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 58
New value of Q matrix: 16.5301
New value of Value function: 16.5301
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 98
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 9.8814
New value of Value function: 15.5847
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 99
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 59
New value of Q matrix: 16.517
New value of Value function: 16.517
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 100
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 15.6843
New value of Value function: 15.6843
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 396
New value of Q matrix: 15.0785
New value of Value function: 19.0905
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 102
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 12.5604
New value of Value function: 14.8147
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 103
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 15.7492
New value of Value function: 15.7492
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 549
New value of Q matrix: 19.1657
New value of Value function: 19.1657
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 105
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 18.5936
New value of Value function: 18.5936
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 106
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 60
New value of Q matrix: 16.5266
New value of Value function: 16.5266
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 107
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 15.8141
New value of Value function: 15.8141
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 17.4035
New value of Value function: 19.1657
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 550
New value of Q matrix: 19.1575
New value of Value function: 19.1575
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 551
New value of Q matrix: 19.0438
New value of Value function: 19.0438
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 111
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 14.3343
New value of Value function: 14.3343
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 112
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 8.33158
New value of Value function: 16.5266
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 113
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 65
New value of Q matrix: 18.2416
New value of Value function: 18.2416
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 114
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 61
New value of Q matrix: 16.5432
New value of Value function: 16.5432
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 115
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 15.825
New value of Value function: 15.825
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 552
New value of Q matrix: 19.1444
New value of Value function: 19.1444
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 117
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 19.0141
New value of Value function: 19.0141
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 118
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 62
New value of Q matrix: 16.9555
New value of Value function: 16.9555
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 119
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 15.1377
New value of Value function: 15.1377
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 17.0384
New value of Value function: 19.1444
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 553
New value of Q matrix: 19.0816
New value of Value function: 19.0816
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 122
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 16.1243
New value of Value function: 16.1243
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 123
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 15.8426
New value of Value function: 15.8426
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 554
New value of Q matrix: 19.0647
New value of Value function: 19.0647
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 125
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 15.8507
New value of Value function: 15.8507
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 555
New value of Q matrix: 19.0566
New value of Value function: 19.0566
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 556
New value of Q matrix: 19.1907
New value of Value function: 19.1907
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 128
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 14.2554
New value of Value function: 19.4127
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 557
New value of Q matrix: 19.319
New value of Value function: 19.319
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 130
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 20.0365
New value of Value function: 20.0365
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 131
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 66
New value of Q matrix: 18.4363
New value of Value function: 18.4363
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 132
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 19
New value of Q matrix: 18.6099
New value of Value function: 18.6099
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 133
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 67
New value of Q matrix: 18.8456
New value of Value function: 18.8456
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 134
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 10.2144
New value of Value function: 16.9555
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 135
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 68
New value of Q matrix: 19.2021
New value of Value function: 19.2021
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 136
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 63
New value of Q matrix: 16.9223
New value of Value function: 16.9223
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 137
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 15.9195
New value of Value function: 15.9195
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 558
New value of Q matrix: 19.4081
New value of Value function: 19.4081
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 139
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 20
New value of Q matrix: 18.4757
New value of Value function: 18.4757
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 140
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 13.7915
New value of Value function: 19.2021
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 141
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 21
New value of Q matrix: 18.3741
New value of Value function: 18.3741
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 142
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 69
New value of Q matrix: 19.5092
New value of Value function: 19.5092
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 143
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 64
New value of Q matrix: 16.902
New value of Value function: 16.902
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 144
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 13.6526
New value of Value function: 15.9195
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 145
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3973
	Distance: 9
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 70
New value of Q matrix: 18.6529
New value of Value function: 18.6529
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 146
----------
State: 3973
	Distance: 9
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 17.4664
New value of Value function: 17.4664
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 147
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 71
New value of Q matrix: 19.0185
New value of Value function: 19.0185
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 148
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 7.42293
New value of Value function: 16.902
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 149
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 7.8905
New value of Value function: 10.9721
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 150
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 6.26662
New value of Value function: 6.26662
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 151
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 12.2699
New value of Value function: 12.2699
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 152
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 72
New value of Q matrix: 19.3384
New value of Value function: 19.3384
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 153
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 13.3804
New value of Value function: 16.902
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 154
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 15.9909
New value of Value function: 15.9909
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 17.6023
New value of Value function: 19.4081
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 559
New value of Q matrix: 19.3999
New value of Value function: 19.3999
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 560
New value of Q matrix: 19.3917
New value of Value function: 19.3917
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 561
New value of Q matrix: 19.5371
New value of Value function: 19.5371
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 159
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 19
New value of Q matrix: 20.7496
New value of Value function: 20.7496
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 160
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 73
New value of Q matrix: 19.6187
New value of Value function: 19.6187
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 161
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 65
New value of Q matrix: 16.8932
New value of Value function: 16.8932
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 162
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 16.0736
New value of Value function: 16.0736
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 562
New value of Q matrix: 19.5289
New value of Value function: 19.5289
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 563
New value of Q matrix: 19.698
New value of Value function: 19.698
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 165
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 13.5041
New value of Value function: 20.7496
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 166
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 6.64373
New value of Value function: 18.3741
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 167
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 8.83257
New value of Value function: 18.3741
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 564
New value of Q matrix: 19.6897
New value of Value function: 19.6897
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 17.2673
New value of Value function: 19.6897
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 565
New value of Q matrix: 19.8518
New value of Value function: 19.8518
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 171
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 20
New value of Q matrix: 21.3473
New value of Value function: 21.3473
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 172
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 74
New value of Q matrix: 19.5689
New value of Value function: 19.5689
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 173
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 22
New value of Q matrix: 18.3739
New value of Value function: 18.3739
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 174
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 13.7106
New value of Value function: 19.5689
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 175
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 13.3294
New value of Value function: 13.3294
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 176
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 75
New value of Q matrix: 19.7299
New value of Value function: 19.7299
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 177
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 18.3541
New value of Value function: 18.3541
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 178
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 16.1048
New value of Value function: 16.1048
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 179
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 12.9218
New value of Value function: 15.3159
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 397
New value of Q matrix: 15.2333
New value of Value function: 19.8518
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 181
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 14.9428
New value of Value function: 15.3159
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 182
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 11.669
New value of Value function: 14.4574
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 183
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 17.1169
New value of Value function: 17.1169
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 184
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 15.6157
New value of Value function: 15.6157
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 185
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 63
New value of Q matrix: 15.9543
New value of Value function: 15.9543
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 566
New value of Q matrix: 19.8074
New value of Value function: 19.8074
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 187
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 64
New value of Q matrix: 15.5767
New value of Value function: 15.5767
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 188
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 14.4209
New value of Value function: 14.4209
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 189
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 65
New value of Q matrix: 15.5395
New value of Value function: 15.5395
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 190
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 14.3948
New value of Value function: 14.3948
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 191
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 19.4233
New value of Value function: 19.4233
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 192
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 26.6704
New value of Value function: 26.6704
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 193
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 27.9828
New value of Value function: 27.9828
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 194
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 66
New value of Q matrix: 36.2015
New value of Value function: 36.2015
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 195
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 39.5594
New value of Value function: 39.5594
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 196
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 67
New value of Q matrix: 38.6308
New value of Value function: 38.6308
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 197
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 38.8536
New value of Value function: 54.6319
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 198
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 2.74666
New value of Value function: 54.6319
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 199
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 24.9585
New value of Value function: 24.9585
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 200
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 68
New value of Q matrix: 40.7475
New value of Value function: 40.7475
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 567
New value of Q matrix: 19.799
New value of Value function: 19.799
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 17.484
New value of Value function: 19.799
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 568
New value of Q matrix: 19.7907
New value of Value function: 19.7907
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 569
New value of Q matrix: 19.7824
New value of Value function: 19.7824
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 570
New value of Q matrix: 19.7742
New value of Value function: 19.7742
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 17.6774
New value of Value function: 19.7742
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 571
New value of Q matrix: 19.7659
New value of Value function: 19.7659
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 572
New value of Q matrix: 19.7576
New value of Value function: 19.7576
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 573
New value of Q matrix: 19.7494
New value of Value function: 19.7494
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 17.815
New value of Value function: 19.7494
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 398
New value of Q matrix: 15.5991
New value of Value function: 19.7494
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 76
New value of Q matrix: 19.3653
New value of Value function: 19.3653
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 17.85
New value of Value function: 19.7494
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 17.6899
New value of Value function: 19.7494
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 574
New value of Q matrix: 19.7411
New value of Value function: 19.7411
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 575
New value of Q matrix: 19.7329
New value of Value function: 19.7329
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 17.8878
New value of Value function: 19.7329
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 576
New value of Q matrix: 19.7247
New value of Value function: 19.7247
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 18.0038
New value of Value function: 19.7247
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 577
New value of Q matrix: 19.7164
New value of Value function: 19.7164
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 578
New value of Q matrix: 19.7082
New value of Value function: 19.7082
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 579
New value of Q matrix: 19.7001
New value of Value function: 19.7001
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 580
New value of Q matrix: 19.6919
New value of Value function: 19.6919
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 581
New value of Q matrix: 19.6837
New value of Value function: 19.6837
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 582
New value of Q matrix: 19.6755
New value of Value function: 19.6755
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 583
New value of Q matrix: 19.6674
New value of Value function: 19.6674
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 18.0565
New value of Value function: 19.6674
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 584
New value of Q matrix: 19.6593
New value of Value function: 19.6593
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 585
New value of Q matrix: 19.6511
New value of Value function: 19.6511
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 586
New value of Q matrix: 19.643
New value of Value function: 19.643
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 587
New value of Q matrix: 19.6349
New value of Value function: 19.6349
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 588
New value of Q matrix: 19.6268
New value of Value function: 19.6268
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 589
New value of Q matrix: 19.6187
New value of Value function: 19.6187
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 590
New value of Q matrix: 19.6106
New value of Value function: 19.6106
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 591
New value of Q matrix: 19.6026
New value of Value function: 19.6026
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 592
New value of Q matrix: 19.5945
New value of Value function: 19.5945
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 18.1311
New value of Value function: 19.5945
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 593
New value of Q matrix: 19.5865
New value of Value function: 19.5865
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 594
New value of Q matrix: 19.5784
New value of Value function: 19.5784
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 595
New value of Q matrix: 19.5704
New value of Value function: 19.5704
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 596
New value of Q matrix: 19.5624
New value of Value function: 19.5624
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 597
New value of Q matrix: 19.5544
New value of Value function: 19.5544
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 598
New value of Q matrix: 19.5464
New value of Value function: 19.5464
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 17.9816
New value of Value function: 19.5464
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 599
New value of Q matrix: 19.5384
New value of Value function: 19.5384
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 18.2413
New value of Value function: 19.5384
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 600
New value of Q matrix: 19.5304
New value of Value function: 19.5304
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 601
New value of Q matrix: 19.5225
New value of Value function: 19.5225
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 18.1267
New value of Value function: 19.5225
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 602
New value of Q matrix: 19.5145
New value of Value function: 19.5145
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 399
New value of Q matrix: 15.9282
New value of Value function: 19.5145
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 52
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 77
New value of Q matrix: 19.3454
New value of Value function: 19.3454
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 53
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 12.8525
New value of Value function: 18.3739
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 603
New value of Q matrix: 19.5231
New value of Value function: 19.5231
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 55
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 66
New value of Q matrix: 16.6837
New value of Value function: 16.6837
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 56
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 14.7813
New value of Value function: 14.7813
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 57
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 67
New value of Q matrix: 16.7117
New value of Value function: 16.7117
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 58
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 16.1319
New value of Value function: 16.1319
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 18.3396
New value of Value function: 19.5231
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 604
New value of Q matrix: 19.5006
New value of Value function: 19.5006
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 61
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 16.1708
New value of Value function: 16.1708
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 605
New value of Q matrix: 19.5693
New value of Value function: 19.5693
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 63
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 23
New value of Q matrix: 18.3276
New value of Value function: 18.3276
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 64
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 78
New value of Q matrix: 19.5944
New value of Value function: 19.5944
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 65
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 68
New value of Q matrix: 16.5809
New value of Value function: 16.5809
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 66
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 16.0601
New value of Value function: 16.0601
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 67
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 79
New value of Q matrix: 19.9967
New value of Value function: 19.9967
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 68
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 19.6489
New value of Value function: 19.6489
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 69
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 28
New value of Q matrix: 16.2332
New value of Value function: 16.2332
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 70
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 17.2578
New value of Value function: 17.2578
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 71
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 12.3052
New value of Value function: 15.3159
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 72
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 10.2231
New value of Value function: 10.2231
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 400
New value of Q matrix: 16.0399
New value of Value function: 19.5693
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 74
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 15.3522
New value of Value function: 15.3522
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 75
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 15.0876
New value of Value function: 17.6704
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 76
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 18.5819
New value of Value function: 18.5819
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 77
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 17.1828
New value of Value function: 17.1828
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 78
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 17.1883
New value of Value function: 17.1883
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 79
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 11.4639
New value of Value function: 19.4233
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 80
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 18.4529
New value of Value function: 18.4529
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 81
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 17.9478
New value of Value function: 17.9478
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 82
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 17.7147
New value of Value function: 17.7147
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 83
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 17.2211
New value of Value function: 17.2211
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 84
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 21.3732
New value of Value function: 21.3732
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 85
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 27.2336
New value of Value function: 27.2336
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 86
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 27.3234
New value of Value function: 27.3234
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 87
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 27.5652
New value of Value function: 27.5652
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 88
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 30.7382
New value of Value function: 30.7382
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 89
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 69
New value of Q matrix: 40.1957
New value of Value function: 40.1957
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 90
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 40.4238
New value of Value function: 40.4238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 91
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 70
New value of Q matrix: 39.8161
New value of Value function: 39.8161
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 92
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 40.9387
New value of Value function: 40.9387
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 93
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 71
New value of Q matrix: 39.5447
New value of Value function: 39.5447
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 94
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 41.2413
New value of Value function: 41.2413
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 95
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 72
New value of Q matrix: 41.494
New value of Value function: 41.494
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 96
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 80
New value of Q matrix: 57.4672
New value of Value function: 57.4672
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 97
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 68.452
New value of Value function: 68.452
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 98
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 25.8692
New value of Value function: 25.8692
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 99
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 73
New value of Q matrix: 43.5304
New value of Value function: 43.5304
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 100
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 81
New value of Q matrix: 58.7228
New value of Value function: 58.7228
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 101
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 25
New value of Q matrix: 74.5696
New value of Value function: 74.5696
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 102
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 9
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 606
New value of Q matrix: 19.5613
New value of Value function: 19.5613
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 401
New value of Q matrix: 16.4441
New value of Value function: 19.5613
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 3
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 21
New value of Q matrix: 21.8818
New value of Value function: 21.8818
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 4
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 80
New value of Q matrix: 19.6504
New value of Value function: 19.6504
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 5
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 15.8451
New value of Value function: 15.8451
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 6
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 69
New value of Q matrix: 16.6325
New value of Value function: 16.6325
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 7
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 12.3352
New value of Value function: 16.1708
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 8
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 16.2133
New value of Value function: 16.2133
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 18.4322
New value of Value function: 19.5613
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 607
New value of Q matrix: 19.6256
New value of Value function: 19.6256
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 11
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 24
New value of Q matrix: 18.3534
New value of Value function: 18.3534
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 81
New value of Q matrix: 19.8522
New value of Value function: 19.8522
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 13
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 70
New value of Q matrix: 16.6825
New value of Value function: 16.6825
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 14
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 16.2594
New value of Value function: 16.2594
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 608
New value of Q matrix: 19.6882
New value of Value function: 19.6882
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 16
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 25
New value of Q matrix: 18.7859
New value of Value function: 18.7859
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 17
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 71
New value of Q matrix: 17.2033
New value of Value function: 17.2033
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 18
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 29
New value of Q matrix: 16.5771
New value of Value function: 16.5771
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 19
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 16.5599
New value of Value function: 16.5599
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 20
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 13.7217
New value of Value function: 16.5771
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 21
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 18.2935
New value of Value function: 18.2935
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 22
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 15.5039
New value of Value function: 15.5039
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 23
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 19.0523
New value of Value function: 19.0523
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 24
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 13.8618
New value of Value function: 17.1828
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 25
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 19.6441
New value of Value function: 19.6441
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 26
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 17.7659
New value of Value function: 17.7659
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 27
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 19.0886
New value of Value function: 19.0886
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 28
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 17.7807
New value of Value function: 17.7807
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 29
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 24.1918
New value of Value function: 24.1918
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 30
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 28.4391
New value of Value function: 28.4391
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 31
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 8.63894
New value of Value function: 30.7382
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 609
New value of Q matrix: 19.7253
New value of Value function: 19.7253
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 33
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 18.937
New value of Value function: 18.937
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 34
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 26.4326
New value of Value function: 26.4326
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 35
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 29.1447
New value of Value function: 29.1447
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 36
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 28.4521
New value of Value function: 28.4521
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 37
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 25.0837
New value of Value function: 25.0837
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 38
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 11.1524
New value of Value function: 28.4521
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 39
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 69
New value of Q matrix: 12.0592
New value of Value function: 28.4521
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 610
New value of Q matrix: 19.8071
New value of Value function: 19.8071
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 41
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 22.389
New value of Value function: 22.389
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 42
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 32.4436
New value of Value function: 32.4436
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 43
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 74
New value of Q matrix: 42.8676
New value of Value function: 42.8676
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 44
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.89256
New value of Value function: 41.2413
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 45
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 62.1356
New value of Value function: 62.1356
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 46
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 82
New value of Q matrix: 60.5008
New value of Value function: 60.5008
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 47
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 65.5563
New value of Value function: 65.5563
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 48
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 34.8258
New value of Value function: 34.8258
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 49
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 83
New value of Q matrix: 61.0936
New value of Value function: 61.0936
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 50
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 27
New value of Q matrix: 72.0002
New value of Value function: 72.0002
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 51
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 10
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 611
New value of Q matrix: 19.7991
New value of Value function: 19.7991
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 612
New value of Q matrix: 19.7911
New value of Value function: 19.7911
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 613
New value of Q matrix: 19.7831
New value of Value function: 19.7831
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 614
New value of Q matrix: 19.7752
New value of Value function: 19.7752
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 402
New value of Q matrix: 16.3809
New value of Value function: 19.7752
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 6
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 13.0013
New value of Value function: 13.0013
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 7
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 14.2717
New value of Value function: 14.2717
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 8
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 82
New value of Q matrix: 20.0928
New value of Value function: 20.0928
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 9
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 72
New value of Q matrix: 17.6086
New value of Value function: 17.6086
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 10
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 17
New value of Q matrix: 15.1681
New value of Value function: 15.1681
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 11
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 14.7765
New value of Value function: 14.7765
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 615
New value of Q matrix: 19.7313
New value of Value function: 19.7313
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 13
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 16.848
New value of Value function: 16.848
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 14
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 12.4325
New value of Value function: 15.1681
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 15
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 73
New value of Q matrix: 17.8904
New value of Value function: 17.8904
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 16
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 12.6298
New value of Value function: 15.1681
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 17
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 74
New value of Q matrix: 18.1376
New value of Value function: 18.1376
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 18
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 16.8342
New value of Value function: 16.8342
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 19
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 35
New value of Q matrix: 17.2628
New value of Value function: 17.2628
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 616
New value of Q matrix: 19.7457
New value of Value function: 19.7457
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 21
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 36
New value of Q matrix: 17.1437
New value of Value function: 17.1437
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 18.5324
New value of Value function: 19.7457
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 18.6232
New value of Value function: 19.7457
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 617
New value of Q matrix: 19.7425
New value of Value function: 19.7425
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 25
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 16.5577
New value of Value function: 16.5577
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 26
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.54217
New value of Value function: 14.7765
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 27
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 15.6608
New value of Value function: 15.6608
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 618
New value of Q matrix: 19.6927
New value of Value function: 19.6927
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 29
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 16.0342
New value of Value function: 16.0342
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 619
New value of Q matrix: 19.6922
New value of Value function: 19.6922
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 31
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 12.9943
New value of Value function: 16.848
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 620
New value of Q matrix: 19.7687
New value of Value function: 19.7687
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 33
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 19.4076
New value of Value function: 19.4076
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 34
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 75
New value of Q matrix: 18.0847
New value of Value function: 18.0847
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 35
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 16.8648
New value of Value function: 16.8648
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 36
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 11.5269
New value of Value function: 18.0847
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 37
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 76
New value of Q matrix: 18.4641
New value of Value function: 18.4641
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 38
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 16.6284
New value of Value function: 16.6284
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 39
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 16.2534
New value of Value function: 16.2534
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 621
New value of Q matrix: 19.7658
New value of Value function: 19.7658
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 41
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 16.5681
New value of Value function: 16.8648
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 622
New value of Q matrix: 19.7536
New value of Value function: 19.7536
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 43
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 15.2747
New value of Value function: 16.6284
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 44
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 15.9603
New value of Value function: 16.6284
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 45
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 16.6126
New value of Value function: 16.6126
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 623
New value of Q matrix: 19.8147
New value of Value function: 19.8147
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 47
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 14.9985
New value of Value function: 18.4641
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 403
New value of Q matrix: 16.6249
New value of Value function: 19.8147
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 49
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 10.5035
New value of Value function: 18.4641
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 50
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 14.6848
New value of Value function: 14.6848
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 51
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 17.0908
New value of Value function: 17.0908
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 52
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 16.3907
New value of Value function: 16.3907
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 624
New value of Q matrix: 19.81
New value of Value function: 19.81
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 54
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 16.6962
New value of Value function: 16.8648
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 55
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 18.0354
New value of Value function: 18.0354
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 56
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 14.8028
New value of Value function: 16.6126
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 57
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 18.7041
New value of Value function: 18.7041
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 58
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 16.7435
New value of Value function: 16.7435
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 59
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 16.4689
New value of Value function: 16.4689
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 625
New value of Q matrix: 19.8783
New value of Value function: 19.8783
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 61
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 19.2044
New value of Value function: 19.2044
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 62
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 16.247
New value of Value function: 16.7435
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 63
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 16.5391
New value of Value function: 16.5391
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 626
New value of Q matrix: 19.8703
New value of Value function: 19.8703
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 627
New value of Q matrix: 19.9639
New value of Value function: 19.9639
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 66
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 11.2148
New value of Value function: 19.4076
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 67
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 13.7198
New value of Value function: 13.7198
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 68
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 15.8229
New value of Value function: 15.8229
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 69
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 77
New value of Q matrix: 18.8187
New value of Value function: 18.8187
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 70
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 17.8338
New value of Value function: 17.8338
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 71
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 37
New value of Q matrix: 17.4356
New value of Value function: 17.4356
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 72
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 19.8177
New value of Value function: 19.8177
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 73
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 61
New value of Q matrix: 18.2711
New value of Value function: 18.2711
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 628
New value of Q matrix: 20.0088
New value of Value function: 20.0088
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 75
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 62
New value of Q matrix: 18.0854
New value of Value function: 18.0854
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 629
New value of Q matrix: 20.0189
New value of Value function: 20.0189
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 77
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 18.3228
New value of Value function: 18.3228
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 78
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 63
New value of Q matrix: 18.4412
New value of Value function: 18.4412
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 79
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 18.6837
New value of Value function: 18.6837
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 80
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 64
New value of Q matrix: 18.8174
New value of Value function: 18.8174
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 81
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 118
New value of Q matrix: 16.6359
New value of Value function: 16.6359
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 630
New value of Q matrix: 19.997
New value of Value function: 19.997
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 83
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 119
New value of Q matrix: 16.6506
New value of Value function: 16.6506
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 18.3058
New value of Value function: 19.997
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 631
New value of Q matrix: 19.989
New value of Value function: 19.989
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 18.7271
New value of Value function: 19.989
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 632
New value of Q matrix: 20.0543
New value of Value function: 20.0543
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 88
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 65
New value of Q matrix: 18.9017
New value of Value function: 18.9017
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 89
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 19.4889
New value of Value function: 19.4889
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 90
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 11.9854
New value of Value function: 16.6506
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 91
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 13.0175
New value of Value function: 16.6506
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 92
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 120
New value of Q matrix: 16.7301
New value of Value function: 16.7301
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 93
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 16.3632
New value of Value function: 16.3632
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 94
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 121
New value of Q matrix: 16.7728
New value of Value function: 16.7728
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 95
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 16.9158
New value of Value function: 16.9158
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 96
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 72
New value of Q matrix: 14.778
New value of Value function: 14.778
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 633
New value of Q matrix: 20.0364
New value of Value function: 20.0364
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 98
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 122
New value of Q matrix: 17.0315
New value of Value function: 17.0315
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 99
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 10.1752
New value of Value function: 14.778
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 100
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 73
New value of Q matrix: 15.0189
New value of Value function: 15.0189
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 18.8255
New value of Value function: 20.0364
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 634
New value of Q matrix: 20.0294
New value of Value function: 20.0294
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 103
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 123
New value of Q matrix: 17.2873
New value of Value function: 17.2873
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 104
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 74
New value of Q matrix: 15.2293
New value of Value function: 15.2293
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 635
New value of Q matrix: 20.0328
New value of Value function: 20.0328
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 106
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 12.5692
New value of Value function: 17.2873
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 18.9145
New value of Value function: 20.0328
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 18.2448
New value of Value function: 20.0328
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 636
New value of Q matrix: 20.0249
New value of Value function: 20.0249
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 637
New value of Q matrix: 20.0917
New value of Value function: 20.0917
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 111
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 66
New value of Q matrix: 18.6542
New value of Value function: 18.6542
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 638
New value of Q matrix: 20.1462
New value of Value function: 20.1462
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 113
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 67
New value of Q matrix: 18.4453
New value of Value function: 18.4453
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 18.4805
New value of Value function: 20.1462
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 639
New value of Q matrix: 20.1382
New value of Value function: 20.1382
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 18.6349
New value of Value function: 20.1382
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 640
New value of Q matrix: 20.1303
New value of Value function: 20.1303
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 641
New value of Q matrix: 20.1749
New value of Value function: 20.1749
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 119
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 68
New value of Q matrix: 18.2668
New value of Value function: 18.2668
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 642
New value of Q matrix: 20.2108
New value of Value function: 20.2108
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 121
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 69
New value of Q matrix: 18.1154
New value of Value function: 18.1154
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 643
New value of Q matrix: 20.2394
New value of Value function: 20.2394
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 123
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 70
New value of Q matrix: 17.9865
New value of Value function: 17.9865
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 644
New value of Q matrix: 20.2617
New value of Value function: 20.2617
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 125
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 71
New value of Q matrix: 18.2603
New value of Value function: 18.2603
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 126
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 20.1525
New value of Value function: 20.1525
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 127
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 124
New value of Q matrix: 17.2668
New value of Value function: 17.2668
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 645
New value of Q matrix: 20.2551
New value of Value function: 20.2551
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 129
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 125
New value of Q matrix: 17.2476
New value of Value function: 17.2476
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 646
New value of Q matrix: 20.2875
New value of Value function: 20.2875
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 131
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 72
New value of Q matrix: 18.7099
New value of Value function: 18.7099
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 132
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 126
New value of Q matrix: 17.2331
New value of Value function: 17.2331
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 647
New value of Q matrix: 20.336
New value of Value function: 20.336
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 134
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 13.9357
New value of Value function: 18.7099
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 135
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 15.0598
New value of Value function: 15.0598
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 136
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 73
New value of Q matrix: 19.1021
New value of Value function: 19.1021
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 137
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 127
New value of Q matrix: 17.4855
New value of Value function: 17.4855
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 138
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 75
New value of Q matrix: 15.4491
New value of Value function: 15.4491
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 19.0218
New value of Value function: 20.336
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 648
New value of Q matrix: 20.335
New value of Value function: 20.335
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 141
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 13.9775
New value of Value function: 17.4855
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 142
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 128
New value of Q matrix: 17.7338
New value of Value function: 17.7338
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 143
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 11.7187
New value of Value function: 15.4491
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 144
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 12.0785
New value of Value function: 15.4491
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 145
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 129
New value of Q matrix: 17.9592
New value of Value function: 17.9592
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 146
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 76
New value of Q matrix: 15.6421
New value of Value function: 15.6421
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 649
New value of Q matrix: 20.3525
New value of Value function: 20.3525
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 148
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 130
New value of Q matrix: 17.9406
New value of Value function: 17.9406
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 149
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 17.6026
New value of Value function: 17.6026
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 150
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 77
New value of Q matrix: 15.8138
New value of Value function: 15.8138
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 650
New value of Q matrix: 20.3685
New value of Value function: 20.3685
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 152
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 131
New value of Q matrix: 18.1778
New value of Value function: 18.1778
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 153
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 78
New value of Q matrix: 15.9668
New value of Value function: 15.9668
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 651
New value of Q matrix: 20.3931
New value of Value function: 20.3931
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 155
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 132
New value of Q matrix: 18.4067
New value of Value function: 18.4067
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 156
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 12.5902
New value of Value function: 15.9668
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 157
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 133
New value of Q matrix: 18.6148
New value of Value function: 18.6148
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 158
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 79
New value of Q matrix: 16.1043
New value of Value function: 16.1043
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 652
New value of Q matrix: 20.4337
New value of Value function: 20.4337
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 160
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 134
New value of Q matrix: 18.816
New value of Value function: 18.816
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 161
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 80
New value of Q matrix: 16.2301
New value of Value function: 16.2301
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 653
New value of Q matrix: 20.4804
New value of Value function: 20.4804
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 163
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 10.1069
New value of Value function: 18.816
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 164
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 9.90923
New value of Value function: 11.2139
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 165
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 16.6672
New value of Value function: 16.6672
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 166
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 11.4963
New value of Value function: 18.816
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 167
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 12.2806
New value of Value function: 16.6672
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 168
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 11.0803
New value of Value function: 17.4551
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 169
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 19.0007
New value of Value function: 19.0007
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 170
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 15.3145
New value of Value function: 19.1021
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 171
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 74
New value of Q matrix: 19.6282
New value of Value function: 19.6282
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 172
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 135
New value of Q matrix: 18.6834
New value of Value function: 18.6834
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 18.8078
New value of Value function: 20.4804
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 654
New value of Q matrix: 20.4724
New value of Value function: 20.4724
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 655
New value of Q matrix: 20.5124
New value of Value function: 20.5124
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 176
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 13.0655
New value of Value function: 18.6834
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 177
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 75
New value of Q matrix: 20.0749
New value of Value function: 20.0749
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 178
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 136
New value of Q matrix: 18.6614
New value of Value function: 18.6614
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 179
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 14.605
New value of Value function: 17.6026
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 180
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 137
New value of Q matrix: 18.6413
New value of Value function: 18.6413
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 181
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 15
New value of Q matrix: 17.5645
New value of Value function: 17.5645
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 182
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 138
New value of Q matrix: 18.6198
New value of Value function: 18.6198
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 183
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 18.1903
New value of Value function: 18.1903
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 184
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 81
New value of Q matrix: 16.3498
New value of Value function: 16.3498
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 656
New value of Q matrix: 20.5484
New value of Value function: 20.5484
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 186
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 139
New value of Q matrix: 18.8375
New value of Value function: 18.8375
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 187
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 82
New value of Q matrix: 16.4595
New value of Value function: 16.4595
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 18.4659
New value of Value function: 20.5484
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 657
New value of Q matrix: 20.5663
New value of Value function: 20.5663
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 190
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 15.5676
New value of Value function: 18.1903
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 191
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 140
New value of Q matrix: 19.0452
New value of Value function: 19.0452
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 192
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 83
New value of Q matrix: 16.5584
New value of Value function: 16.5584
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 658
New value of Q matrix: 20.6166
New value of Value function: 20.6166
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 194
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 141
New value of Q matrix: 19.2429
New value of Value function: 19.2429
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 195
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 84
New value of Q matrix: 16.6514
New value of Value function: 16.6514
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 659
New value of Q matrix: 20.6724
New value of Value function: 20.6724
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 197
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 142
New value of Q matrix: 19.431
New value of Value function: 19.431
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 198
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 85
New value of Q matrix: 16.7397
New value of Value function: 16.7397
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 660
New value of Q matrix: 20.7333
New value of Value function: 20.7333
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 200
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 143
New value of Q matrix: 19.6101
New value of Value function: 19.6101
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 661
New value of Q matrix: 20.7252
New value of Value function: 20.7252
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 662
New value of Q matrix: 20.7172
New value of Value function: 20.7172
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 663
New value of Q matrix: 20.7091
New value of Value function: 20.7091
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 18.6794
New value of Value function: 20.7091
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 18.8694
New value of Value function: 20.7091
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 664
New value of Q matrix: 20.7011
New value of Value function: 20.7011
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 665
New value of Q matrix: 20.6931
New value of Value function: 20.6931
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 666
New value of Q matrix: 20.6851
New value of Value function: 20.6851
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 667
New value of Q matrix: 20.677
New value of Value function: 20.677
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 668
New value of Q matrix: 20.669
New value of Value function: 20.669
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 669
New value of Q matrix: 20.6611
New value of Value function: 20.6611
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 670
New value of Q matrix: 20.6531
New value of Value function: 20.6531
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 671
New value of Q matrix: 20.6451
New value of Value function: 20.6451
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 672
New value of Q matrix: 20.6371
New value of Value function: 20.6371
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 673
New value of Q matrix: 20.6292
New value of Value function: 20.6292
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 18.9771
New value of Value function: 20.6292
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 674
New value of Q matrix: 20.6212
New value of Value function: 20.6212
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 675
New value of Q matrix: 20.6133
New value of Value function: 20.6133
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 19.0288
New value of Value function: 20.6133
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 16.8131
New value of Value function: 20.6133
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 19.1262
New value of Value function: 20.6133
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 676
New value of Q matrix: 20.6054
New value of Value function: 20.6054
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 677
New value of Q matrix: 20.5974
New value of Value function: 20.5974
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 678
New value of Q matrix: 20.5895
New value of Value function: 20.5895
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 679
New value of Q matrix: 20.5816
New value of Value function: 20.5816
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 680
New value of Q matrix: 20.5737
New value of Value function: 20.5737
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 681
New value of Q matrix: 20.5659
New value of Value function: 20.5659
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 682
New value of Q matrix: 20.558
New value of Value function: 20.558
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 683
New value of Q matrix: 20.5501
New value of Value function: 20.5501
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 684
New value of Q matrix: 20.5423
New value of Value function: 20.5423
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 685
New value of Q matrix: 20.5344
New value of Value function: 20.5344
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 686
New value of Q matrix: 20.5266
New value of Value function: 20.5266
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 687
New value of Q matrix: 20.5187
New value of Value function: 20.5187
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 688
New value of Q matrix: 20.5109
New value of Value function: 20.5109
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 689
New value of Q matrix: 20.5031
New value of Value function: 20.5031
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 19.1337
New value of Value function: 20.5031
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 19.2354
New value of Value function: 20.5031
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 690
New value of Q matrix: 20.4953
New value of Value function: 20.4953
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 691
New value of Q matrix: 20.4875
New value of Value function: 20.4875
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 692
New value of Q matrix: 20.4797
New value of Value function: 20.4797
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 693
New value of Q matrix: 20.4719
New value of Value function: 20.4719
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 694
New value of Q matrix: 20.4642
New value of Value function: 20.4642
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 695
New value of Q matrix: 20.4564
New value of Value function: 20.4564
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 696
New value of Q matrix: 20.4486
New value of Value function: 20.4486
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 697
New value of Q matrix: 20.4409
New value of Value function: 20.4409
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 698
New value of Q matrix: 20.4332
New value of Value function: 20.4332
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 19.1526
New value of Value function: 20.4332
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 699
New value of Q matrix: 20.4254
New value of Value function: 20.4254
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 700
New value of Q matrix: 20.4177
New value of Value function: 20.4177
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 701
New value of Q matrix: 20.41
New value of Value function: 20.41
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 19.2382
New value of Value function: 20.41
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 19.2607
New value of Value function: 20.41
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 702
New value of Q matrix: 20.4023
New value of Value function: 20.4023
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 703
New value of Q matrix: 20.3946
New value of Value function: 20.3946
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 19.3364
New value of Value function: 20.3946
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 704
New value of Q matrix: 20.3869
New value of Value function: 20.3869
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 705
New value of Q matrix: 20.3792
New value of Value function: 20.3792
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 706
New value of Q matrix: 20.3716
New value of Value function: 20.3716
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 405
New value of Q matrix: 17.1151
New value of Value function: 20.3716
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 60
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 15.7556
New value of Value function: 20.0928
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 61
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 83
New value of Q matrix: 20.1061
New value of Value function: 20.1061
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 62
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 17.0705
New value of Value function: 19.4076
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 63
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 15
New value of Q matrix: 18.7981
New value of Value function: 18.7981
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 64
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 78
New value of Q matrix: 19.1123
New value of Value function: 19.1123
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 65
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 30
New value of Q matrix: 16.7263
New value of Value function: 16.7263
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 66
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 16.206
New value of Value function: 16.206
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 67
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 9.59817
New value of Value function: 16.7263
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 68
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 31
New value of Q matrix: 16.7833
New value of Value function: 16.7833
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 69
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 17.2536
New value of Value function: 17.2536
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 70
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 13.1932
New value of Value function: 15.5039
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 71
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 26
New value of Q matrix: 15.8851
New value of Value function: 15.8851
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 72
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 20.2215
New value of Value function: 20.2215
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 73
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 18.3475
New value of Value function: 18.3475
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 74
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 20.4945
New value of Value function: 20.4945
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 75
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 11.883
New value of Value function: 22.389
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 76
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 20.6429
New value of Value function: 20.6429
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 77
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 22.8484
New value of Value function: 22.8484
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 78
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 19.0997
New value of Value function: 26.4326
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 79
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 21.2537
New value of Value function: 21.2537
New value of Policy matrix: 0

=======================================
Simulation: 35
Iteration: 80
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 29.0244
New value of Value function: 29.0244
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 81
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 17.9452
New value of Value function: 32.4436
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 82
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 30.9324
New value of Value function: 30.9324
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 83
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 35.0153
New value of Value function: 35.0153
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 84
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 75
New value of Q matrix: 42.2858
New value of Value function: 42.2858
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 85
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 42.1197
New value of Value function: 42.1197
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 86
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 76
New value of Q matrix: 41.8743
New value of Value function: 41.8743
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 87
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 42.6703
New value of Value function: 42.6703
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 88
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 77
New value of Q matrix: 44.2228
New value of Value function: 44.2228
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 89
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 84
New value of Q matrix: 58.8053
New value of Value function: 58.8053
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 90
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 49.8888
New value of Value function: 49.8888
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 91
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 85
New value of Q matrix: 57.3502
New value of Value function: 57.3502
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 92
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 53.0319
New value of Value function: 53.0319
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 93
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 86
New value of Q matrix: 58.9602
New value of Value function: 58.9602
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 94
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 65.4761
New value of Value function: 65.4761
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 95
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 35.9227
New value of Value function: 35.9227
New value of Policy matrix: 3

=======================================
Simulation: 35
Iteration: 96
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 78
New value of Q matrix: 46.0512
New value of Value function: 46.0512
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 97
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 87
New value of Q matrix: 59.6958
New value of Value function: 59.6958
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 98
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 27.4039
New value of Value function: 65.4761
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 99
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 57.6884
New value of Value function: 57.6884
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 100
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 29
New value of Q matrix: 71.7087
New value of Value function: 71.7087
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 101
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 11
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 36
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 707
New value of Q matrix: 20.3639
New value of Value function: 20.3639
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 708
New value of Q matrix: 20.3563
New value of Value function: 20.3563
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 709
New value of Q matrix: 20.3486
New value of Value function: 20.3486
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 19.4194
New value of Value function: 20.3486
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 710
New value of Q matrix: 20.341
New value of Value function: 20.341
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 711
New value of Q matrix: 20.3333
New value of Value function: 20.3333
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 712
New value of Q matrix: 20.3257
New value of Value function: 20.3257
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 713
New value of Q matrix: 20.3181
New value of Value function: 20.3181
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 714
New value of Q matrix: 20.3105
New value of Value function: 20.3105
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 715
New value of Q matrix: 20.3029
New value of Value function: 20.3029
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 716
New value of Q matrix: 20.2953
New value of Value function: 20.2953
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 717
New value of Q matrix: 20.2877
New value of Value function: 20.2877
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 718
New value of Q matrix: 20.2802
New value of Value function: 20.2802
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 719
New value of Q matrix: 20.2726
New value of Value function: 20.2726
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 19.4858
New value of Value function: 20.2726
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 720
New value of Q matrix: 20.2651
New value of Value function: 20.2651
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 721
New value of Q matrix: 20.2575
New value of Value function: 20.2575
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 722
New value of Q matrix: 20.25
New value of Value function: 20.25
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 723
New value of Q matrix: 20.2424
New value of Value function: 20.2424
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 724
New value of Q matrix: 20.2349
New value of Value function: 20.2349
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 19.3395
New value of Value function: 20.2349
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 725
New value of Q matrix: 20.2274
New value of Value function: 20.2274
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 406
New value of Q matrix: 17.1426
New value of Value function: 20.2274
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 24
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 16.0538
New value of Value function: 16.0538
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 25
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 14.5679
New value of Value function: 14.5679
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 26
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 17.0975
New value of Value function: 17.0975
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 27
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 13.4361
New value of Value function: 19.1123
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 28
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 15.0947
New value of Value function: 19.1123
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 29
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 27
New value of Q matrix: 20.0838
New value of Value function: 20.0838
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 30
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 79
New value of Q matrix: 19.1683
New value of Value function: 19.1683
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 31
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 16
New value of Q matrix: 18.5927
New value of Value function: 18.5927
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 32
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 80
New value of Q matrix: 19.5582
New value of Value function: 19.5582
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 33
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 17.7399
New value of Value function: 17.7399
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 34
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 16.6928
New value of Value function: 16.6928
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 19.3042
New value of Value function: 20.2274
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 726
New value of Q matrix: 20.2712
New value of Value function: 20.2712
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 37
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 19.313
New value of Value function: 19.313
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 38
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 18.8198
New value of Value function: 18.8198
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 39
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 10.7845
New value of Value function: 18.3228
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 40
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 15.6834
New value of Value function: 18.8198
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 41
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 20.0952
New value of Value function: 20.0952
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 42
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 19.667
New value of Value function: 19.667
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 43
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 12.9125
New value of Value function: 18.3228
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 44
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 19.2549
New value of Value function: 19.2549
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 45
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 16.8061
New value of Value function: 16.8061
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 727
New value of Q matrix: 20.3376
New value of Value function: 20.3376
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 47
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 28
New value of Q matrix: 18.9494
New value of Value function: 18.9494
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 48
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 15.8995
New value of Value function: 16.8061
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 49
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 19.7274
New value of Value function: 19.7274
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 50
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 39
New value of Q matrix: 18.1324
New value of Value function: 18.1324
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 728
New value of Q matrix: 20.3603
New value of Value function: 20.3603
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 52
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 40
New value of Q matrix: 18.5257
New value of Value function: 18.5257
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 53
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 18.8814
New value of Value function: 18.8814
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 54
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 19.5171
New value of Value function: 19.5171
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 55
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 76
New value of Q matrix: 19.7401
New value of Value function: 19.7401
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 19.3781
New value of Value function: 20.3603
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 729
New value of Q matrix: 20.4412
New value of Value function: 20.4412
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 58
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 11.9973
New value of Value function: 19.7401
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 59
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 20.2926
New value of Value function: 20.2926
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 60
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 77
New value of Q matrix: 19.8781
New value of Value function: 19.8781
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 61
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 19.5957
New value of Value function: 19.5957
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 62
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 15.9032
New value of Value function: 19.8781
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 63
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 16.6705
New value of Value function: 16.6705
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 64
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 78
New value of Q matrix: 20.3917
New value of Value function: 20.3917
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 65
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 144
New value of Q matrix: 19.4123
New value of Value function: 19.4123
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 730
New value of Q matrix: 20.5069
New value of Value function: 20.5069
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 67
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 145
New value of Q matrix: 19.2371
New value of Value function: 19.2371
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 731
New value of Q matrix: 20.6061
New value of Value function: 20.6061
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 69
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 79
New value of Q matrix: 20.8027
New value of Value function: 20.8027
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 70
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 12.4031
New value of Value function: 19.2371
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 71
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 8.94444
New value of Value function: 16.6705
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 72
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.8905
New value of Value function: 10.0702
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 73
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 8.40025
New value of Value function: 8.40025
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 74
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.0254
New value of Value function: 12.0254
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 75
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.80303
New value of Value function: 9.7031
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 76
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 10.4793
New value of Value function: 10.4793
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 77
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.3489
New value of Value function: 6.3489
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 78
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 7.2093
New value of Value function: 7.2093
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 79
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 4.33219
New value of Value function: 4.33219
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 80
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 6.31873
New value of Value function: 6.31873
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 81
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 9.49711
New value of Value function: 9.49711
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 82
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 5.98775
New value of Value function: 9.77437
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 83
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 42
New value of Q matrix: 9.83342
New value of Value function: 9.83342
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 84
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 54
New value of Q matrix: 10.8121
New value of Value function: 10.8121
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 732
New value of Q matrix: 20.5679
New value of Value function: 20.5679
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 86
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 86
New value of Q matrix: 15.9614
New value of Value function: 15.9614
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 87
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 9.0731
New value of Value function: 9.0731
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 88
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 9.06601
New value of Value function: 11.3328
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 89
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 8.87402
New value of Value function: 11.3328
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 90
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 9.39105
New value of Value function: 9.39105
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 91
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 12.9442
New value of Value function: 12.9442
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 733
New value of Q matrix: 20.6224
New value of Value function: 20.6224
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 93
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 13.4369
New value of Value function: 19.2371
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 94
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 16.9175
New value of Value function: 16.9175
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 95
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 80
New value of Q matrix: 21.1652
New value of Value function: 21.1652
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 96
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 146
New value of Q matrix: 19.0864
New value of Value function: 19.0864
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 19.4488
New value of Value function: 20.6224
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 734
New value of Q matrix: 20.6148
New value of Value function: 20.6148
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 735
New value of Q matrix: 20.738
New value of Value function: 20.738
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 100
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 12.89
New value of Value function: 21.1652
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 101
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 21.1559
New value of Value function: 21.1559
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 102
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 13.7371
New value of Value function: 21.1652
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 103
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 21.8792
New value of Value function: 21.8792
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 104
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 81
New value of Q matrix: 20.7613
New value of Value function: 20.7613
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 736
New value of Q matrix: 20.8418
New value of Value function: 20.8418
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 106
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 82
New value of Q matrix: 20.7214
New value of Value function: 20.7214
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 107
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 10.6847
New value of Value function: 19.5957
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 19.6023
New value of Value function: 20.8418
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 737
New value of Q matrix: 20.8341
New value of Value function: 20.8341
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 19.5677
New value of Value function: 20.8341
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 738
New value of Q matrix: 20.8264
New value of Value function: 20.8264
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 19.7049
New value of Value function: 20.8264
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 19.7967
New value of Value function: 20.8264
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 739
New value of Q matrix: 20.8188
New value of Value function: 20.8188
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 740
New value of Q matrix: 20.8111
New value of Value function: 20.8111
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 741
New value of Q matrix: 20.8035
New value of Value function: 20.8035
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 742
New value of Q matrix: 20.7607
New value of Value function: 20.7607
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 118
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 17.0217
New value of Value function: 17.0217
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 743
New value of Q matrix: 20.8389
New value of Value function: 20.8389
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 120
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 19
New value of Q matrix: 20.8832
New value of Value function: 20.8832
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 121
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 20.9932
New value of Value function: 20.9932
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 122
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 21.2458
New value of Value function: 21.2458
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 744
New value of Q matrix: 20.9561
New value of Value function: 20.9561
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 124
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 46
New value of Q matrix: 20.7299
New value of Value function: 20.7299
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 745
New value of Q matrix: 21.0596
New value of Value function: 21.0596
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 126
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 31
New value of Q matrix: 20.4289
New value of Value function: 20.4289
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 127
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 14.4539
New value of Value function: 17.0217
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 19.6965
New value of Value function: 21.0596
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 746
New value of Q matrix: 21.0519
New value of Value function: 21.0519
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 747
New value of Q matrix: 21.1479
New value of Value function: 21.1479
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 131
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 20
New value of Q matrix: 21.6304
New value of Value function: 21.6304
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 132
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 18.0925
New value of Value function: 20.4289
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 133
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 32
New value of Q matrix: 19.9733
New value of Value function: 19.9733
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 134
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 17.5588
New value of Value function: 17.5588
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 135
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 13.6302
New value of Value function: 19.9733
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 136
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 81
New value of Q matrix: 20.1377
New value of Value function: 20.1377
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 137
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 20.9393
New value of Value function: 20.9393
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 138
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 47
New value of Q matrix: 20.3224
New value of Value function: 20.3224
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 19.9107
New value of Value function: 21.1479
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 748
New value of Q matrix: 21.1401
New value of Value function: 21.1401
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 749
New value of Q matrix: 21.2125
New value of Value function: 21.2125
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 142
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 14.3212
New value of Value function: 20.3224
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 143
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 21.6562
New value of Value function: 21.6562
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 144
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 48
New value of Q matrix: 19.9872
New value of Value function: 19.9872
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 750
New value of Q matrix: 21.3303
New value of Value function: 21.3303
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 146
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 35
New value of Q matrix: 21.1029
New value of Value function: 21.1029
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 147
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 20.6731
New value of Value function: 20.6731
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 148
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 49
New value of Q matrix: 19.9451
New value of Value function: 19.9451
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 149
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 18.8334
New value of Value function: 18.8334
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 150
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 20.7327
New value of Value function: 20.7327
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 151
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 83
New value of Q matrix: 20.4355
New value of Value function: 20.4355
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 20.0307
New value of Value function: 21.3303
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 751
New value of Q matrix: 21.3225
New value of Value function: 21.3225
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 752
New value of Q matrix: 21.3921
New value of Value function: 21.3921
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 155
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 84
New value of Q matrix: 20.1892
New value of Value function: 20.1892
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 753
New value of Q matrix: 21.4699
New value of Value function: 21.4699
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 157
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 51
New value of Q matrix: 21.3285
New value of Value function: 21.3285
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 158
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 85
New value of Q matrix: 19.9795
New value of Value function: 19.9795
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 754
New value of Q matrix: 21.5662
New value of Value function: 21.5662
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 160
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 21.8071
New value of Value function: 21.8071
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 161
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 86
New value of Q matrix: 19.8038
New value of Value function: 19.8038
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 755
New value of Q matrix: 21.604
New value of Value function: 21.604
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 163
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 16.2057
New value of Value function: 19.8038
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 164
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 18.8326
New value of Value function: 18.8326
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 165
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 22.1915
New value of Value function: 22.1915
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 166
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 10.7157
New value of Value function: 19.8038
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 167
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 20.4242
New value of Value function: 20.4242
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 168
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 87
New value of Q matrix: 19.8677
New value of Value function: 19.8677
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 169
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 20.7624
New value of Value function: 20.7624
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 170
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 15.0507
New value of Value function: 19.0864
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 171
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 147
New value of Q matrix: 19.0288
New value of Value function: 19.0288
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 20.1651
New value of Value function: 21.604
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 756
New value of Q matrix: 21.5962
New value of Value function: 21.5962
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 757
New value of Q matrix: 21.6352
New value of Value function: 21.6352
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 175
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 88
New value of Q matrix: 20.291
New value of Value function: 20.291
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 176
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 148
New value of Q matrix: 18.9786
New value of Value function: 18.9786
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 758
New value of Q matrix: 21.6879
New value of Value function: 21.6879
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 178
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 12.9628
New value of Value function: 20.291
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 179
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 21.5828
New value of Value function: 21.5828
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 180
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 89
New value of Q matrix: 20.6618
New value of Value function: 20.6618
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 181
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 149
New value of Q matrix: 18.937
New value of Value function: 18.937
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 759
New value of Q matrix: 21.7521
New value of Value function: 21.7521
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 183
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 90
New value of Q matrix: 20.7559
New value of Value function: 20.7559
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 184
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 21.4241
New value of Value function: 21.4241
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 185
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 13.0801
New value of Value function: 18.937
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 186
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 17.0804
New value of Value function: 17.0804
New value of Policy matrix: 0

=======================================
Simulation: 36
Iteration: 187
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 17.2492
New value of Value function: 20.7559
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 188
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 15.8389
New value of Value function: 18.937
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 189
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 150
New value of Q matrix: 19.0893
New value of Value function: 19.0893
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 190
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 12.8974
New value of Value function: 15.9614
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 191
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 87
New value of Q matrix: 16.2372
New value of Value function: 16.2372
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 760
New value of Q matrix: 21.7574
New value of Value function: 21.7574
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 193
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 151
New value of Q matrix: 19.0446
New value of Value function: 19.0446
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 761
New value of Q matrix: 21.7609
New value of Value function: 21.7609
New value of Policy matrix: 3

=======================================
Simulation: 36
Iteration: 195
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 152
New value of Q matrix: 19.0416
New value of Value function: 19.0416
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 196
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 18.6474
New value of Value function: 18.6474
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 197
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 13.5111
New value of Value function: 16.2372
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 198
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 18.9838
New value of Value function: 18.9838
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 199
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 88
New value of Q matrix: 16.4831
New value of Value function: 16.4831
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 762
New value of Q matrix: 21.7642
New value of Value function: 21.7642
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 17.3609
New value of Value function: 21.7642
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 763
New value of Q matrix: 21.6602
New value of Value function: 21.6602
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 3
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 17.0207
New value of Value function: 17.0207
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 4
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 15.4737
New value of Value function: 15.4737
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 5
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 18.2711
New value of Value function: 18.2711
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 6
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 15.0611
New value of Value function: 20.1377
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 7
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 82
New value of Q matrix: 20.7731
New value of Value function: 20.7731
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 8
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 22.0807
New value of Value function: 22.0807
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 9
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 13.2388
New value of Value function: 22.1915
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 10
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 9.53792
New value of Value function: 17.7666
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 11
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 17.6723
New value of Value function: 17.6723
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 12
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 20.1662
New value of Value function: 20.1662
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 13
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 18.8844
New value of Value function: 18.8844
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 14
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 16.0577
New value of Value function: 22.1915
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 15
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 18.9145
New value of Value function: 18.9145
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 16
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 22.6483
New value of Value function: 22.6483
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 17
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 91
New value of Q matrix: 20.9083
New value of Value function: 20.9083
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 18
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 20.8787
New value of Value function: 20.8787
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 19
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 92
New value of Q matrix: 21.2151
New value of Value function: 21.2151
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 20
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 153
New value of Q matrix: 18.9933
New value of Value function: 18.9933
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 764
New value of Q matrix: 21.745
New value of Value function: 21.745
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 22
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 93
New value of Q matrix: 21.4835
New value of Value function: 21.4835
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 23
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 154
New value of Q matrix: 18.9558
New value of Value function: 18.9558
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 765
New value of Q matrix: 21.8362
New value of Value function: 21.8362
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 25
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 94
New value of Q matrix: 21.719
New value of Value function: 21.719
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 26
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 13.5875
New value of Value function: 18.9558
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 27
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 13.3022
New value of Value function: 17.0804
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 28
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 16.2199
New value of Value function: 18.9145
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 29
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 17.4357
New value of Value function: 17.4357
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 30
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 95
New value of Q matrix: 21.929
New value of Value function: 21.929
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 31
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 14.2468
New value of Value function: 18.9558
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 20.3082
New value of Value function: 21.8362
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 19.5716
New value of Value function: 21.8362
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 766
New value of Q matrix: 21.8283
New value of Value function: 21.8283
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 767
New value of Q matrix: 21.9324
New value of Value function: 21.9324
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 36
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 96
New value of Q matrix: 21.6008
New value of Value function: 21.6008
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 768
New value of Q matrix: 22.0209
New value of Value function: 22.0209
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 38
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 14.6274
New value of Value function: 21.6008
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 39
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 22.7291
New value of Value function: 22.7291
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 40
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 97
New value of Q matrix: 21.6078
New value of Value function: 21.6078
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 41
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 20.7318
New value of Value function: 20.7318
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 42
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 98
New value of Q matrix: 21.8258
New value of Value function: 21.8258
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 43
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 155
New value of Q matrix: 18.9433
New value of Value function: 18.9433
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 769
New value of Q matrix: 22.0112
New value of Value function: 22.0112
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 45
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 156
New value of Q matrix: 18.9311
New value of Value function: 18.9311
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 770
New value of Q matrix: 22.1048
New value of Value function: 22.1048
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 47
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 18.2237
New value of Value function: 21.8258
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 48
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 99
New value of Q matrix: 22.0184
New value of Value function: 22.0184
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 49
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 157
New value of Q matrix: 18.9273
New value of Value function: 18.9273
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 771
New value of Q matrix: 22.0916
New value of Value function: 22.0916
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 51
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 158
New value of Q matrix: 18.9228
New value of Value function: 18.9228
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 772
New value of Q matrix: 22.189
New value of Value function: 22.189
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 53
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 100
New value of Q matrix: 22.1899
New value of Value function: 22.1899
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 54
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 159
New value of Q matrix: 18.9264
New value of Value function: 18.9264
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 773
New value of Q matrix: 22.1728
New value of Value function: 22.1728
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 56
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 160
New value of Q matrix: 18.9949
New value of Value function: 18.9949
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 57
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 19
New value of Q matrix: 18.7134
New value of Value function: 18.7134
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 58
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 15.6578
New value of Value function: 18.9949
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 59
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 20
New value of Q matrix: 18.5103
New value of Value function: 18.5103
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 60
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 161
New value of Q matrix: 19.021
New value of Value function: 19.021
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 61
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 14.543
New value of Value function: 18.5103
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 774
New value of Q matrix: 22.1605
New value of Value function: 22.1605
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 63
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 162
New value of Q matrix: 19.0145
New value of Value function: 19.0145
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 19.9207
New value of Value function: 22.1605
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 775
New value of Q matrix: 22.1525
New value of Value function: 22.1525
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 776
New value of Q matrix: 22.2536
New value of Value function: 22.2536
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 67
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 101
New value of Q matrix: 22.1237
New value of Value function: 22.1237
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 68
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 21.3359
New value of Value function: 21.3359
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 69
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 163
New value of Q matrix: 19.0158
New value of Value function: 19.0158
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 20.1307
New value of Value function: 22.2536
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 20.3189
New value of Value function: 22.2536
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 777
New value of Q matrix: 22.2456
New value of Value function: 22.2456
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 778
New value of Q matrix: 22.2376
New value of Value function: 22.2376
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 779
New value of Q matrix: 22.3517
New value of Value function: 22.3517
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 75
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 55
New value of Q matrix: 22.7634
New value of Value function: 22.7634
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 76
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 22.3846
New value of Value function: 22.3846
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 77
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 15.4565
New value of Value function: 22.7634
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 78
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 22.9775
New value of Value function: 22.9775
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 79
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 23.3165
New value of Value function: 23.3165
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 80
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 102
New value of Q matrix: 22.1236
New value of Value function: 22.1236
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 81
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 21.2157
New value of Value function: 21.2157
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 82
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 103
New value of Q matrix: 22.2913
New value of Value function: 22.2913
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 83
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 164
New value of Q matrix: 19.0246
New value of Value function: 19.0246
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 408
New value of Q matrix: 17.5824
New value of Value function: 22.3517
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 85
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 165
New value of Q matrix: 19.2031
New value of Value function: 19.2031
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 86
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 89
New value of Q matrix: 16.7634
New value of Value function: 16.7634
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 780
New value of Q matrix: 22.3395
New value of Value function: 22.3395
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 88
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 15.037
New value of Value function: 19.2031
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 89
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 16.5507
New value of Value function: 19.2031
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 20.4855
New value of Value function: 22.3395
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 781
New value of Q matrix: 22.3315
New value of Value function: 22.3315
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 20.4952
New value of Value function: 22.3315
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 782
New value of Q matrix: 22.3235
New value of Value function: 22.3235
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 783
New value of Q matrix: 22.4579
New value of Value function: 22.4579
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 95
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 23.8135
New value of Value function: 23.8135
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 96
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 104
New value of Q matrix: 22.2631
New value of Value function: 22.2631
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 97
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 14
New value of Q matrix: 21.1688
New value of Value function: 21.1688
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 98
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 105
New value of Q matrix: 22.2332
New value of Value function: 22.2332
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 99
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 21.6445
New value of Value function: 21.6445
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 100
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 16.5003
New value of Value function: 19.2031
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 101
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 166
New value of Q matrix: 19.2126
New value of Value function: 19.2126
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 102
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 16.3072
New value of Value function: 18.5103
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 103
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 167
New value of Q matrix: 19.2213
New value of Value function: 19.2213
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 104
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 21
New value of Q matrix: 18.4053
New value of Value function: 18.4053
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 105
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 168
New value of Q matrix: 19.2213
New value of Value function: 19.2213
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 106
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 18.8723
New value of Value function: 18.8723
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 107
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 90
New value of Q matrix: 17.0238
New value of Value function: 17.0238
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 784
New value of Q matrix: 22.4426
New value of Value function: 22.4426
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 109
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 14.7955
New value of Value function: 19.2213
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 110
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 12.1141
New value of Value function: 12.1141
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 111
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 14.5641
New value of Value function: 14.5641
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 19.7994
New value of Value function: 22.4426
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 785
New value of Q matrix: 22.4278
New value of Value function: 22.4278
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 114
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 169
New value of Q matrix: 19.4238
New value of Value function: 19.4238
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 115
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 13.2595
New value of Value function: 17.0238
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 116
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 170
New value of Q matrix: 19.6102
New value of Value function: 19.6102
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 117
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 13.9019
New value of Value function: 17.0238
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 118
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 16.076
New value of Value function: 18.8723
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 119
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 23
New value of Q matrix: 19.2854
New value of Value function: 19.2854
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 120
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 91
New value of Q matrix: 17.2523
New value of Value function: 17.2523
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 20.6627
New value of Value function: 22.4278
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 786
New value of Q matrix: 22.4198
New value of Value function: 22.4198
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 787
New value of Q matrix: 22.5122
New value of Value function: 22.5122
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 124
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 106
New value of Q matrix: 22.445
New value of Value function: 22.445
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 125
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 17.0951
New value of Value function: 19.6102
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 126
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 16
New value of Q matrix: 16.7701
New value of Value function: 19.6102
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 127
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 22.0869
New value of Value function: 22.0869
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 128
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 14.3828
New value of Value function: 19.6102
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 129
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 107
New value of Q matrix: 22.6354
New value of Value function: 22.6354
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 130
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 171
New value of Q matrix: 19.647
New value of Value function: 19.647
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 131
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 24
New value of Q matrix: 19.115
New value of Value function: 19.115
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 132
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 172
New value of Q matrix: 19.8325
New value of Value function: 19.8325
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 133
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 92
New value of Q matrix: 17.4644
New value of Value function: 17.4644
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 788
New value of Q matrix: 22.5165
New value of Value function: 22.5165
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 135
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 173
New value of Q matrix: 20.0194
New value of Value function: 20.0194
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 136
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 93
New value of Q matrix: 17.6539
New value of Value function: 17.6539
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 789
New value of Q matrix: 22.5273
New value of Value function: 22.5273
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 138
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 174
New value of Q matrix: 20.2057
New value of Value function: 20.2057
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 139
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 94
New value of Q matrix: 17.8239
New value of Value function: 17.8239
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 790
New value of Q matrix: 22.5443
New value of Value function: 22.5443
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 141
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 175
New value of Q matrix: 20.3901
New value of Value function: 20.3901
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 142
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 95
New value of Q matrix: 17.9772
New value of Value function: 17.9772
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 20.6644
New value of Value function: 22.5443
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 791
New value of Q matrix: 22.4821
New value of Value function: 22.4821
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 145
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 8.77477
New value of Value function: 17.9772
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 146
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 13.9776
New value of Value function: 13.9776
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 147
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 14.2564
New value of Value function: 17.9772
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 148
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 9.80826
New value of Value function: 17.9772
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 149
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 10.1673
New value of Value function: 10.1673
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 150
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 96
New value of Q matrix: 17.7452
New value of Value function: 17.7452
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 151
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 78
New value of Q matrix: 7.50104
New value of Value function: 10.8121
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 792
New value of Q matrix: 22.5072
New value of Value function: 22.5072
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 153
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 176
New value of Q matrix: 20.3169
New value of Value function: 20.3169
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 154
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 15.7436
New value of Value function: 15.7436
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 409
New value of Q matrix: 17.632
New value of Value function: 22.5072
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 156
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 10.8092
New value of Value function: 15.7436
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 157
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 14.5959
New value of Value function: 20.3169
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 158
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 10.2973
New value of Value function: 17.4357
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 159
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 13.454
New value of Value function: 13.454
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 160
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 14.1561
New value of Value function: 14.1561
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 161
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 9.67827
New value of Value function: 9.67827
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 162
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 4.88341
New value of Value function: 4.88341
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 163
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 55
New value of Q matrix: 10.0685
New value of Value function: 10.0685
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 164
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 13.9678
New value of Value function: 13.9678
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 165
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 56
New value of Q matrix: 10.0363
New value of Value function: 10.0363
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 166
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 13.9453
New value of Value function: 13.9453
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 167
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 57
New value of Q matrix: 10.0058
New value of Value function: 10.0058
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 168
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 13.9225
New value of Value function: 13.9225
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 169
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 58
New value of Q matrix: 9.97658
New value of Value function: 9.97658
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 170
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 13.9113
New value of Value function: 13.9225
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 793
New value of Q matrix: 22.4383
New value of Value function: 22.4383
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 172
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 97
New value of Q matrix: 17.8944
New value of Value function: 17.8944
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 794
New value of Q matrix: 22.4623
New value of Value function: 22.4623
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 174
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 17.3685
New value of Value function: 20.3169
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 795
New value of Q matrix: 22.4854
New value of Value function: 22.4854
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 176
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 177
New value of Q matrix: 20.2375
New value of Value function: 20.2375
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 796
New value of Q matrix: 22.5049
New value of Value function: 22.5049
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 178
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 178
New value of Q matrix: 20.214
New value of Value function: 20.214
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 179
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 17.088
New value of Value function: 19.115
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 180
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 179
New value of Q matrix: 20.1923
New value of Value function: 20.1923
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 181
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 25
New value of Q matrix: 19.0901
New value of Value function: 19.0901
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 182
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 180
New value of Q matrix: 20.1705
New value of Value function: 20.1705
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 183
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 19.605
New value of Value function: 19.605
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 184
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 98
New value of Q matrix: 18.0343
New value of Value function: 18.0343
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 797
New value of Q matrix: 22.5213
New value of Value function: 22.5213
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 186
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 181
New value of Q matrix: 20.3699
New value of Value function: 20.3699
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 187
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 99
New value of Q matrix: 18.1611
New value of Value function: 18.1611
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 20.8221
New value of Value function: 22.5213
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 798
New value of Q matrix: 22.5173
New value of Value function: 22.5173
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 190
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 17.5665
New value of Value function: 19.605
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 191
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 27
New value of Q matrix: 20.0619
New value of Value function: 20.0619
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 192
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 10.6422
New value of Value function: 18.1611
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 193
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 15.4921
New value of Value function: 15.4921
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 194
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 100
New value of Q matrix: 17.8233
New value of Value function: 17.8233
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 195
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 13.8996
New value of Value function: 13.9113
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 196
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 7.58378
New value of Value function: 9.97658
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 197
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 59
New value of Q matrix: 9.94997
New value of Value function: 9.94997
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 198
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 17.0179
New value of Value function: 17.0179
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 799
New value of Q matrix: 22.4511
New value of Value function: 22.4511
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 200
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 101
New value of Q matrix: 17.963
New value of Value function: 17.963
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 20.8161
New value of Value function: 22.4511
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 20.9585
New value of Value function: 22.4511
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 800
New value of Q matrix: 22.4432
New value of Value function: 22.4432
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 801
New value of Q matrix: 22.4352
New value of Value function: 22.4352
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 802
New value of Q matrix: 22.4273
New value of Value function: 22.4273
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 17.8577
New value of Value function: 22.4273
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 21.0788
New value of Value function: 22.4273
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 803
New value of Q matrix: 22.4194
New value of Value function: 22.4194
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 804
New value of Q matrix: 22.4115
New value of Value function: 22.4115
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 805
New value of Q matrix: 22.4908
New value of Value function: 22.4908
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 11
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 22.3132
New value of Value function: 22.3132
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 15.2243
New value of Value function: 20.1061
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 13
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 23
New value of Q matrix: 22.6451
New value of Value function: 22.6451
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 14
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 84
New value of Q matrix: 20.0144
New value of Value function: 20.0144
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 411
New value of Q matrix: 18.1022
New value of Value function: 22.4908
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 16
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 14.8222
New value of Value function: 20.0144
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 17
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 14.2006
New value of Value function: 14.2006
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 18
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 15.7352
New value of Value function: 20.0144
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 19
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 14.8345
New value of Value function: 14.8345
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 20
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 85
New value of Q matrix: 20.6165
New value of Value function: 20.6165
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 21
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 83
New value of Q matrix: 20.8656
New value of Value function: 20.8656
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 22
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 32
New value of Q matrix: 17.0127
New value of Value function: 17.0127
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 23
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 16.8074
New value of Value function: 16.8074
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 24
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 17.6592
New value of Value function: 17.6592
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 25
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 12.1545
New value of Value function: 15.8851
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 26
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 16.7095
New value of Value function: 16.7095
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 27
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 7.62846
New value of Value function: 17.6592
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 28
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 20.9162
New value of Value function: 20.9162
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 29
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 18.1852
New value of Value function: 18.1852
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 30
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 16.2958
New value of Value function: 16.2958
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 31
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 20.7878
New value of Value function: 20.7878
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 32
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 19.0672
New value of Value function: 19.0672
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 33
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 7.31643
New value of Value function: 20.4945
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 34
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 21.7165
New value of Value function: 21.7165
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 35
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 24.2921
New value of Value function: 24.2921
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 36
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 29.8121
New value of Value function: 29.8121
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 37
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 17.0933
New value of Value function: 24.2921
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 38
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 28.9707
New value of Value function: 28.9707
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 39
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 11.6181
New value of Value function: 24.2921
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 21.1931
New value of Value function: 22.4908
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 806
New value of Q matrix: 22.4829
New value of Value function: 22.4829
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 807
New value of Q matrix: 22.365
New value of Value function: 22.365
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 43
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 17.3505
New value of Value function: 17.3505
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 44
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 19.3008
New value of Value function: 19.3008
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 45
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 13.4041
New value of Value function: 15.523
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 46
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 15.0767
New value of Value function: 19.3008
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 47
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 21.4152
New value of Value function: 21.4152
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 48
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 11.6446
New value of Value function: 19.3008
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 49
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 19.4894
New value of Value function: 19.4894
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 50
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 18.8517
New value of Value function: 18.8517
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 51
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 24.8715
New value of Value function: 24.8715
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 52
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 14.2945
New value of Value function: 28.9707
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 53
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 20.216
New value of Value function: 20.216
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 54
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 21.1947
New value of Value function: 21.1947
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 55
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 27.887
New value of Value function: 27.887
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 56
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 34.1959
New value of Value function: 34.1959
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 57
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 32.5629
New value of Value function: 32.5629
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 58
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 79
New value of Q matrix: 45.2853
New value of Value function: 45.2853
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 59
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 43.8546
New value of Value function: 43.8546
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 60
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 80
New value of Q matrix: 44.7409
New value of Value function: 44.7409
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 61
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 27.4547
New value of Value function: 43.8546
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 62
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 44.6235
New value of Value function: 44.6235
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 63
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 81
New value of Q matrix: 46.5584
New value of Value function: 46.5584
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 64
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 88
New value of Q matrix: 58.9939
New value of Value function: 58.9939
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 65
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 57.6884
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 66
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 67
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.84797
New value of Value function: 2.84797
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 68
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 12.5185
New value of Value function: 12.5185
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 69
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 29.0538
New value of Value function: 29.0538
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 70
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 37.012
New value of Value function: 37.012
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 71
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 82
New value of Q matrix: 45.9642
New value of Value function: 45.9642
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 72
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 45.4704
New value of Value function: 45.4704
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 73
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 83
New value of Q matrix: 47.5492
New value of Value function: 47.5492
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 74
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 44.2759
New value of Value function: 58.9939
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 75
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 9.67147
New value of Value function: 58.9939
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 76
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 42.1518
New value of Value function: 42.1518
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 77
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 89
New value of Q matrix: 58.3704
New value of Value function: 58.3704
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 78
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 57.6884
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 79
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 80
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 81
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 63.1492
New value of Value function: 63.1492
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 82
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 57.9495
New value of Value function: 57.9495
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 83
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 90
New value of Q matrix: 59.8062
New value of Value function: 59.8062
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 84
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 30
New value of Q matrix: 76.6987
New value of Value function: 76.6987
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 85
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 52.2942
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 86
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 80.7131
New value of Value function: 80.7131
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 87
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 7
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 39
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 808
New value of Q matrix: 22.3571
New value of Value function: 22.3571
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 809
New value of Q matrix: 22.3493
New value of Value function: 22.3493
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 810
New value of Q matrix: 22.3414
New value of Value function: 22.3414
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 19.9982
New value of Value function: 22.3414
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 811
New value of Q matrix: 22.3336
New value of Value function: 22.3336
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 812
New value of Q matrix: 22.3257
New value of Value function: 22.3257
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 21.2802
New value of Value function: 22.3257
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 813
New value of Q matrix: 22.3179
New value of Value function: 22.3179
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 20.9397
New value of Value function: 22.3179
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 18.2989
New value of Value function: 22.3179
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 20.1773
New value of Value function: 22.3179
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 814
New value of Q matrix: 22.2314
New value of Value function: 22.2314
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 13
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 17.8894
New value of Value function: 17.8894
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 14
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 16.4095
New value of Value function: 16.4095
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 15
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 17.0865
New value of Value function: 17.0865
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 16
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 12.1691
New value of Value function: 16.4095
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 17
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 17.0473
New value of Value function: 17.0473
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 18
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 18.2656
New value of Value function: 18.2656
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 19
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 20.1738
New value of Value function: 20.1738
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 20
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 23.8856
New value of Value function: 23.8856
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 21
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 58
New value of Q matrix: 24.2856
New value of Value function: 24.2856
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 22
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 16.1766
New value of Value function: 22.6354
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 815
New value of Q matrix: 22.4
New value of Value function: 22.4
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 24
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 59
New value of Q matrix: 24.1392
New value of Value function: 24.1392
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 25
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 22.5269
New value of Value function: 22.5269
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 26
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 60
New value of Q matrix: 24.5613
New value of Value function: 24.5613
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 27
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 15.228
New value of Value function: 22.6354
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 28
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 61
New value of Q matrix: 24.9259
New value of Value function: 24.9259
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 29
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 16.3767
New value of Value function: 22.6354
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 30
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 62
New value of Q matrix: 25.2413
New value of Value function: 25.2413
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 31
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 108
New value of Q matrix: 22.6576
New value of Value function: 22.6576
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 32
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 14.2585
New value of Value function: 22.0869
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 33
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 109
New value of Q matrix: 22.6776
New value of Value function: 22.6776
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 34
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 17
New value of Q matrix: 21.9326
New value of Value function: 21.9326
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 35
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 17.2797
New value of Value function: 22.6776
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 36
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 63
New value of Q matrix: 25.5197
New value of Value function: 25.5197
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 37
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 110
New value of Q matrix: 22.9148
New value of Value function: 22.9148
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 38
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 14.912
New value of Value function: 20.3699
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 39
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 12.3476
New value of Value function: 17.4357
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 40
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 11.7588
New value of Value function: 11.7588
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 41
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 5.76175
New value of Value function: 5.76175
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 42
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 12.5815
New value of Value function: 12.5815
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 43
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 10.0057
New value of Value function: 10.0057
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 44
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 60
New value of Q matrix: 11.141
New value of Value function: 11.141
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 816
New value of Q matrix: 22.4268
New value of Value function: 22.4268
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 46
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 182
New value of Q matrix: 20.5488
New value of Value function: 20.5488
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 47
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 102
New value of Q matrix: 18.0857
New value of Value function: 18.0857
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 413
New value of Q matrix: 18.3131
New value of Value function: 22.4268
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 49
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 16.5825
New value of Value function: 16.5825
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 817
New value of Q matrix: 22.4588
New value of Value function: 22.4588
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 51
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 15.7427
New value of Value function: 20.5488
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 52
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 11.5724
New value of Value function: 15.4921
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 53
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 20.3372
New value of Value function: 20.3372
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 54
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 16.1461
New value of Value function: 16.1461
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 55
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 18
New value of Q matrix: 14.9923
New value of Value function: 14.9923
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 56
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 15.9625
New value of Value function: 15.9625
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 57
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 11.6579
New value of Value function: 14.9923
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 58
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 16.9663
New value of Value function: 16.9663
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 59
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 103
New value of Q matrix: 18.0623
New value of Value function: 18.0623
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 60
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 14.405
New value of Value function: 17.0179
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 61
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 61
New value of Q matrix: 11.3596
New value of Value function: 11.3596
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 62
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 18.1261
New value of Value function: 18.1261
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 818
New value of Q matrix: 22.4898
New value of Value function: 22.4898
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 64
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 183
New value of Q matrix: 20.7212
New value of Value function: 20.7212
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 65
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 104
New value of Q matrix: 18.1802
New value of Value function: 18.1802
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 21.3741
New value of Value function: 22.4898
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 819
New value of Q matrix: 22.4377
New value of Value function: 22.4377
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 68
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 105
New value of Q matrix: 18.281
New value of Value function: 18.281
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 820
New value of Q matrix: 22.4752
New value of Value function: 22.4752
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 70
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 184
New value of Q matrix: 20.7316
New value of Value function: 20.7316
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 71
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 28
New value of Q matrix: 20.4467
New value of Value function: 20.4467
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 72
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 106
New value of Q matrix: 18.3752
New value of Value function: 18.3752
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 821
New value of Q matrix: 22.5119
New value of Value function: 22.5119
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 74
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 185
New value of Q matrix: 20.9124
New value of Value function: 20.9124
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 75
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 107
New value of Q matrix: 18.4633
New value of Value function: 18.4633
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 822
New value of Q matrix: 22.5534
New value of Value function: 22.5534
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 77
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 186
New value of Q matrix: 21.0859
New value of Value function: 21.0859
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 78
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 108
New value of Q matrix: 18.5465
New value of Value function: 18.5465
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 823
New value of Q matrix: 22.5995
New value of Value function: 22.5995
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 80
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 187
New value of Q matrix: 21.2523
New value of Value function: 21.2523
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 81
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 109
New value of Q matrix: 18.6257
New value of Value function: 18.6257
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 824
New value of Q matrix: 22.6497
New value of Value function: 22.6497
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 83
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 16.3063
New value of Value function: 21.2523
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 84
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 18.7949
New value of Value function: 20.3372
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 85
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 15.4298
New value of Value function: 21.2523
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 86
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 22.2482
New value of Value function: 22.2482
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 87
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 188
New value of Q matrix: 21.4118
New value of Value function: 21.4118
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 88
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 14.37
New value of Value function: 18.6257
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 89
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 189
New value of Q matrix: 21.5593
New value of Value function: 21.5593
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 90
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 12.111
New value of Value function: 18.6257
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 91
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 16.9399
New value of Value function: 16.9399
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 92
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 19
New value of Q matrix: 14.2606
New value of Value function: 14.2606
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 93
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 16.7772
New value of Value function: 16.7772
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 94
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 20
New value of Q matrix: 13.8914
New value of Value function: 13.8914
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 95
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 20.3437
New value of Value function: 20.3437
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 96
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 190
New value of Q matrix: 21.6957
New value of Value function: 21.6957
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 97
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 110
New value of Q matrix: 18.7017
New value of Value function: 18.7017
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 825
New value of Q matrix: 22.7133
New value of Value function: 22.7133
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 99
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 17.8676
New value of Value function: 21.6957
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 21.0885
New value of Value function: 22.7133
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 826
New value of Q matrix: 22.7054
New value of Value function: 22.7054
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 827
New value of Q matrix: 22.8091
New value of Value function: 22.8091
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 103
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 111
New value of Q matrix: 23.2531
New value of Value function: 23.2531
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 104
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 191
New value of Q matrix: 21.5427
New value of Value function: 21.5427
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 828
New value of Q matrix: 22.9207
New value of Value function: 22.9207
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 106
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 112
New value of Q matrix: 23.5436
New value of Value function: 23.5436
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 107
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 192
New value of Q matrix: 21.4091
New value of Value function: 21.4091
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 20.3914
New value of Value function: 22.9207
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 829
New value of Q matrix: 23.0383
New value of Value function: 23.0383
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 110
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 113
New value of Q matrix: 23.793
New value of Value function: 23.793
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 111
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 193
New value of Q matrix: 21.3971
New value of Value function: 21.3971
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 112
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 29
New value of Q matrix: 20.3978
New value of Value function: 20.3978
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 113
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 194
New value of Q matrix: 21.3825
New value of Value function: 21.3825
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 114
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 30
New value of Q matrix: 20.7843
New value of Value function: 20.7843
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 115
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 111
New value of Q matrix: 18.8067
New value of Value function: 18.8067
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 830
New value of Q matrix: 23.0776
New value of Value function: 23.0776
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 117
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 195
New value of Q matrix: 21.5426
New value of Value function: 21.5426
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 118
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 112
New value of Q matrix: 18.905
New value of Value function: 18.905
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 831
New value of Q matrix: 23.1209
New value of Value function: 23.1209
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 120
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 196
New value of Q matrix: 21.6979
New value of Value function: 21.6979
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 121
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 113
New value of Q matrix: 18.9976
New value of Value function: 18.9976
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 832
New value of Q matrix: 23.1681
New value of Value function: 23.1681
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 123
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 197
New value of Q matrix: 21.8482
New value of Value function: 21.8482
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 124
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 114
New value of Q matrix: 19.0856
New value of Value function: 19.0856
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 21.5223
New value of Value function: 23.1681
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 833
New value of Q matrix: 23.2187
New value of Value function: 23.2187
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 127
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 198
New value of Q matrix: 21.7159
New value of Value function: 21.7159
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 20.6115
New value of Value function: 23.2187
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 20.8122
New value of Value function: 23.2187
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 20.9953
New value of Value function: 23.2187
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 834
New value of Q matrix: 23.3342
New value of Value function: 23.3342
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 132
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 114
New value of Q matrix: 24.0464
New value of Value function: 24.0464
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 133
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 16.2043
New value of Value function: 21.7159
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 134
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 115
New value of Q matrix: 24.2751
New value of Value function: 24.2751
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 135
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 199
New value of Q matrix: 21.6014
New value of Value function: 21.6014
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 835
New value of Q matrix: 23.4622
New value of Value function: 23.4622
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 137
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 116
New value of Q matrix: 24.471
New value of Value function: 24.471
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 138
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 200
New value of Q matrix: 21.3265
New value of Value function: 21.3265
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 139
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 22.6823
New value of Value function: 22.6823
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 140
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 201
New value of Q matrix: 21.3441
New value of Value function: 21.3441
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 141
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 15.7034
New value of Value function: 20.7843
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 836
New value of Q matrix: 23.4853
New value of Value function: 23.4853
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 143
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 17.9022
New value of Value function: 21.3441
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 144
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 18.4143
New value of Value function: 21.3441
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 837
New value of Q matrix: 23.6146
New value of Value function: 23.6146
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 146
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 16.37
New value of Value function: 24.471
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 147
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 20.0312
New value of Value function: 20.0312
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 148
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 64
New value of Q matrix: 25.983
New value of Value function: 25.983
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 149
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 17.5772
New value of Value function: 24.471
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 838
New value of Q matrix: 23.7911
New value of Value function: 23.7911
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 151
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 16.7589
New value of Value function: 25.983
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 152
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 24.9805
New value of Value function: 24.9805
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 153
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 65
New value of Q matrix: 26.3853
New value of Value function: 26.3853
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 154
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 117
New value of Q matrix: 24.1088
New value of Value function: 24.1088
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 839
New value of Q matrix: 23.9751
New value of Value function: 23.9751
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 156
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 66
New value of Q matrix: 26.6908
New value of Value function: 26.6908
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 157
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 118
New value of Q matrix: 23.7983
New value of Value function: 23.7983
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 840
New value of Q matrix: 24.1631
New value of Value function: 24.1631
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 159
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 67
New value of Q matrix: 26.2768
New value of Value function: 26.2768
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 160
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 23.8722
New value of Value function: 23.8722
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 161
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 119
New value of Q matrix: 23.7669
New value of Value function: 23.7669
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 162
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 19
New value of Q matrix: 22.6472
New value of Value function: 22.6472
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 163
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 120
New value of Q matrix: 23.7353
New value of Value function: 23.7353
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 164
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 14.4581
New value of Value function: 22.6472
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 841
New value of Q matrix: 24.2436
New value of Value function: 24.2436
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 166
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 18.66
New value of Value function: 23.7353
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 842
New value of Q matrix: 24.408
New value of Value function: 24.408
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 168
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 26.2449
New value of Value function: 26.2449
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 169
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 69
New value of Q matrix: 25.6332
New value of Value function: 25.6332
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 843
New value of Q matrix: 24.5447
New value of Value function: 24.5447
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 171
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 70
New value of Q matrix: 25.5137
New value of Value function: 25.5137
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 172
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 15
New value of Q matrix: 23.9719
New value of Value function: 23.9719
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 173
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 71
New value of Q matrix: 25.8679
New value of Value function: 25.8679
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 174
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 121
New value of Q matrix: 23.5138
New value of Value function: 23.5138
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 844
New value of Q matrix: 24.6846
New value of Value function: 24.6846
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 176
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 72
New value of Q matrix: 26.152
New value of Value function: 26.152
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 177
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 16.8105
New value of Value function: 23.5138
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 178
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 20.9354
New value of Value function: 20.9354
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 179
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 17.2146
New value of Value function: 26.152
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 180
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 15.9517
New value of Value function: 20.1662
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 181
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 25.9149
New value of Value function: 25.9149
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 182
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 25.8905
New value of Value function: 26.152
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 183
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 73
New value of Q matrix: 26.4009
New value of Value function: 26.4009
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 184
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 122
New value of Q matrix: 23.5054
New value of Value function: 23.5054
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 185
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 20
New value of Q matrix: 22.5629
New value of Value function: 22.5629
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 186
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 123
New value of Q matrix: 23.4902
New value of Value function: 23.4902
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 187
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 15.0746
New value of Value function: 22.5629
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 845
New value of Q matrix: 24.7387
New value of Value function: 24.7387
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 189
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 11
New value of Q matrix: 18.9833
New value of Value function: 23.4902
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 190
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 24.7928
New value of Value function: 24.7928
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 191
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 124
New value of Q matrix: 23.3107
New value of Value function: 23.3107
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 846
New value of Q matrix: 24.8899
New value of Value function: 24.8899
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 193
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 74
New value of Q matrix: 26.5958
New value of Value function: 26.5958
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 194
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 17.3634
New value of Value function: 23.3107
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 195
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 10.3162
New value of Value function: 20.9354
New value of Policy matrix: 0

=======================================
Simulation: 39
Iteration: 196
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 1.24096
New value of Value function: 1.24096
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 197
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 16.9051
New value of Value function: 16.9051
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 198
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 11.9051
New value of Value function: 12.0254
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 199
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 11.9051
New value of Value function: 12.0254
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 200
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 13.7
New value of Value function: 13.7
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 847
New value of Q matrix: 24.8813
New value of Value function: 24.8813
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 21.8162
New value of Value function: 24.8813
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 22.0812
New value of Value function: 24.8813
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 848
New value of Q matrix: 24.8728
New value of Value function: 24.8728
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 849
New value of Q matrix: 24.8643
New value of Value function: 24.8643
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 850
New value of Q matrix: 24.8557
New value of Value function: 24.8557
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 414
New value of Q matrix: 18.5636
New value of Value function: 24.8557
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 8
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 86
New value of Q matrix: 20.6452
New value of Value function: 20.6452
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 9
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 15.3268
New value of Value function: 20.0838
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 10
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 87
New value of Q matrix: 20.6707
New value of Value function: 20.6707
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 11
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 28
New value of Q matrix: 19.9667
New value of Value function: 19.9667
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 88
New value of Q matrix: 21.2023
New value of Value function: 21.2023
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 13
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 84
New value of Q matrix: 21.0988
New value of Value function: 21.0988
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 14
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 35
New value of Q matrix: 18.7636
New value of Value function: 18.7636
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 851
New value of Q matrix: 24.8225
New value of Value function: 24.8225
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 16
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 85
New value of Q matrix: 21.3675
New value of Value function: 21.3675
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 17
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 36
New value of Q matrix: 18.56
New value of Value function: 18.56
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 18
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 21.5743
New value of Value function: 21.5743
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 852
New value of Q matrix: 24.7044
New value of Value function: 24.7044
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 20
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 13.3303
New value of Value function: 18.56
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 21
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 16.7954
New value of Value function: 16.7954
New value of Policy matrix: 0

=======================================
Simulation: 40
Iteration: 22
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 86
New value of Q matrix: 21.5839
New value of Value function: 21.5839
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 23
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 19.1547
New value of Value function: 19.1547
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 24
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 14.9472
New value of Value function: 17.3505
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 415
New value of Q matrix: 18.6428
New value of Value function: 24.7044
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 26
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 17.6941
New value of Value function: 17.6941
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 27
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 22.0835
New value of Value function: 22.0835
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 28
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 12.435
New value of Value function: 20.216
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 29
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 12.7986
New value of Value function: 17.6941
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 30
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 18.1175
New value of Value function: 22.0835
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 31
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 22.6185
New value of Value function: 22.6185
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 32
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 20.7791
New value of Value function: 20.7791
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 33
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 23.5575
New value of Value function: 23.5575
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 34
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 27.6103
New value of Value function: 27.6103
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 35
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 29.05
New value of Value function: 29.05
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 36
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 66
New value of Q matrix: 18.2103
New value of Value function: 27.6103
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 37
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 70
New value of Q matrix: 13.1825
New value of Value function: 32.5629
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 853
New value of Q matrix: 24.8972
New value of Value function: 24.8972
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 39
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 27.42
New value of Value function: 27.42
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 40
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 15.1973
New value of Value function: 29.05
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 41
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 21.6587
New value of Value function: 21.6587
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 42
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 27.0973
New value of Value function: 27.0973
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 43
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 36.5559
New value of Value function: 36.5559
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 44
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 30.6169
New value of Value function: 30.6169
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 45
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 27.6388
New value of Value function: 27.6388
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 46
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 34.4327
New value of Value function: 34.4327
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 47
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 84
New value of Q matrix: 46.9454
New value of Value function: 46.9454
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 48
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 46.3244
New value of Value function: 46.3244
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 49
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 85
New value of Q matrix: 46.5024
New value of Value function: 46.5024
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 50
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 46.8901
New value of Value function: 46.8901
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 51
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 86
New value of Q matrix: 48.0882
New value of Value function: 48.0882
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 52
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 91
New value of Q matrix: 59.1044
New value of Value function: 59.1044
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 53
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 58.9779
New value of Value function: 58.9779
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 54
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 92
New value of Q matrix: 61.3774
New value of Value function: 61.3774
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 55
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 73.262
New value of Value function: 73.262
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 56
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 37.7092
New value of Value function: 37.7092
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 57
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 87
New value of Q matrix: 49.6615
New value of Value function: 49.6615
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 58
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 93
New value of Q matrix: 62.6375
New value of Value function: 62.6375
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 59
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 33
New value of Q matrix: 77.7494
New value of Value function: 77.7494
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 60
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 12
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 41
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 854
New value of Q matrix: 24.8887
New value of Value function: 24.8887
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 855
New value of Q matrix: 24.8801
New value of Value function: 24.8801
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 856
New value of Q matrix: 24.8716
New value of Value function: 24.8716
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 22.3192
New value of Value function: 24.8716
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 21.2997
New value of Value function: 24.8716
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 857
New value of Q matrix: 24.8631
New value of Value function: 24.8631
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 858
New value of Q matrix: 24.8547
New value of Value function: 24.8547
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 859
New value of Q matrix: 24.8462
New value of Value function: 24.8462
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 860
New value of Q matrix: 24.8377
New value of Value function: 24.8377
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 861
New value of Q matrix: 24.8292
New value of Value function: 24.8292
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 416
New value of Q matrix: 18.905
New value of Value function: 24.8292
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 89
New value of Q matrix: 21.1561
New value of Value function: 21.1561
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 13
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 20.374
New value of Value function: 20.374
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 14
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 15.8565
New value of Value function: 21.6304
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 22.5301
New value of Value function: 24.8292
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 862
New value of Q matrix: 24.8208
New value of Value function: 24.8208
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 863
New value of Q matrix: 24.8123
New value of Value function: 24.8123
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 21.5727
New value of Value function: 24.8123
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 417
New value of Q matrix: 19.1518
New value of Value function: 24.8123
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 20
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 90
New value of Q matrix: 21.1576
New value of Value function: 21.1576
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 21
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 29
New value of Q matrix: 19.9628
New value of Value function: 20.374
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 22
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 91
New value of Q matrix: 21.7038
New value of Value function: 21.7038
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 23
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 87
New value of Q matrix: 21.839
New value of Value function: 21.839
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 24
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 14.9714
New value of Value function: 19.1547
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 25
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 22.58
New value of Value function: 22.58
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 26
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 22.0615
New value of Value function: 22.0615
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 27
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 30
New value of Q matrix: 18.0861
New value of Value function: 18.0861
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 28
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 22.6378
New value of Value function: 22.6378
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 29
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 24.9889
New value of Value function: 24.9889
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 30
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 17.93
New value of Value function: 27.42
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 31
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 14.0452
New value of Value function: 24.9889
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 32
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 22.5054
New value of Value function: 22.5054
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 33
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 26.1655
New value of Value function: 26.1655
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 34
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 27.2759
New value of Value function: 27.2759
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 35
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 27.3471
New value of Value function: 29.05
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 36
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 28.0278
New value of Value function: 28.0278
New value of Policy matrix: 0

=======================================
Simulation: 41
Iteration: 37
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 31.6383
New value of Value function: 31.6383
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 38
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 36.48
New value of Value function: 36.48
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 39
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 22.4619
New value of Value function: 34.4327
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 40
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 14.7435
New value of Value function: 36.48
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 41
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 10.9473
New value of Value function: 27.2759
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 42
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 14.7317
New value of Value function: 27.2759
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 43
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 29.8001
New value of Value function: 29.8001
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 44
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 36.4173
New value of Value function: 36.4173
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 45
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 15.6505
New value of Value function: 34.4327
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 46
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 37.8452
New value of Value function: 37.8452
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 47
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 88
New value of Q matrix: 48.9963
New value of Value function: 48.9963
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 48
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 12.2059
New value of Value function: 46.8901
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 49
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 36.2613
New value of Value function: 36.2613
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 50
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 89
New value of Q matrix: 48.4054
New value of Value function: 48.4054
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 51
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 47.713
New value of Value function: 47.713
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 52
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 90
New value of Q matrix: 50.0504
New value of Value function: 50.0504
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 53
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 94
New value of Q matrix: 61.7866
New value of Value function: 61.7866
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 54
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 60.5764
New value of Value function: 60.5764
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 55
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 95
New value of Q matrix: 63.4472
New value of Value function: 63.4472
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 56
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 45
New value of Q matrix: 21.8825
New value of Value function: 77.7494
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 57
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 96
New value of Q matrix: 64.9296
New value of Value function: 64.9296
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 58
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 29.5048
New value of Value function: 77.7494
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 59
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 45.8546
New value of Value function: 45.8546
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 60
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 97
New value of Q matrix: 66.2539
New value of Value function: 66.2539
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 61
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 34
New value of Q matrix: 75.4928
New value of Value function: 75.4928
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 62
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 98
New value of Q matrix: 67.2119
New value of Value function: 67.2119
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 63
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 79.4747
New value of Value function: 79.4747
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 64
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 94.04
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 41
Iteration: 65
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 13
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 42
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 418
New value of Q matrix: 19.228
New value of Value function: 24.8123
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 2
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 13.4348
New value of Value function: 17.8894
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 3
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 18.7223
New value of Value function: 18.7223
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 4
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 17.1778
New value of Value function: 17.1778
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 5
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 17.3361
New value of Value function: 17.3361
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 6
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 17.662
New value of Value function: 17.662
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 7
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 19.4719
New value of Value function: 19.4719
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 8
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 24.1851
New value of Value function: 24.1851
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 9
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 26.7606
New value of Value function: 26.7606
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 10
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 75
New value of Q matrix: 26.7669
New value of Value function: 26.7669
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 11
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 17.7413
New value of Value function: 23.3107
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 12
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 22.1843
New value of Value function: 22.1843
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 13
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 125
New value of Q matrix: 23.5629
New value of Value function: 23.5629
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 14
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 202
New value of Q matrix: 21.3596
New value of Value function: 21.3596
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 864
New value of Q matrix: 24.8639
New value of Value function: 24.8639
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 16
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 19.3374
New value of Value function: 23.5629
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 17
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 18.335
New value of Value function: 23.5629
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 18
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 23.0916
New value of Value function: 23.0916
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 19
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 126
New value of Q matrix: 23.793
New value of Value function: 23.793
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 20
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 17.1596
New value of Value function: 21.3596
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 21
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 21.9724
New value of Value function: 21.9724
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 22
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 17.9067
New value of Value function: 17.9067
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 23
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 31
New value of Q matrix: 21.1633
New value of Value function: 21.1633
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 24
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 115
New value of Q matrix: 19.3215
New value of Value function: 19.3215
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 865
New value of Q matrix: 24.8395
New value of Value function: 24.8395
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 26
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 203
New value of Q matrix: 21.4011
New value of Value function: 21.4011
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 27
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 32
New value of Q matrix: 21.5107
New value of Value function: 21.5107
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 28
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 116
New value of Q matrix: 19.5322
New value of Value function: 19.5322
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 866
New value of Q matrix: 24.8173
New value of Value function: 24.8173
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 30
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 204
New value of Q matrix: 21.4638
New value of Value function: 21.4638
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 31
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 33
New value of Q matrix: 21.8286
New value of Value function: 21.8286
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 32
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 15.0746
New value of Value function: 19.5322
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 33
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 34
New value of Q matrix: 22.0872
New value of Value function: 22.0872
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 34
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 117
New value of Q matrix: 19.7205
New value of Value function: 19.7205
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 867
New value of Q matrix: 24.798
New value of Value function: 24.798
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 36
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 17.9574
New value of Value function: 21.4638
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 37
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 18.6449
New value of Value function: 18.6449
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 38
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 15.0344
New value of Value function: 19.7205
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 39
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 205
New value of Q matrix: 21.6774
New value of Value function: 21.6774
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 40
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 118
New value of Q matrix: 19.6491
New value of Value function: 19.6491
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 41
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 19.6573
New value of Value function: 19.6573
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 868
New value of Q matrix: 24.7866
New value of Value function: 24.7866
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 43
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 18.6001
New value of Value function: 21.6774
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 44
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 16.9978
New value of Value function: 21.6774
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 45
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 22.7165
New value of Value function: 22.7165
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 46
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 206
New value of Q matrix: 21.8708
New value of Value function: 21.8708
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 47
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 17.0236
New value of Value function: 19.6491
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 21.8199
New value of Value function: 24.7866
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 869
New value of Q matrix: 24.8465
New value of Value function: 24.8465
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 50
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 127
New value of Q matrix: 24.0467
New value of Value function: 24.0467
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 51
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 19.1874
New value of Value function: 21.8708
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 52
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 207
New value of Q matrix: 21.94
New value of Value function: 21.94
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 53
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 35
New value of Q matrix: 21.8562
New value of Value function: 21.8562
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 54
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 208
New value of Q matrix: 22.1142
New value of Value function: 22.1142
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 55
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 119
New value of Q matrix: 19.8278
New value of Value function: 19.8278
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 22.7221
New value of Value function: 24.8465
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 22.8956
New value of Value function: 24.8465
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 870
New value of Q matrix: 24.8381
New value of Value function: 24.8381
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 22.0499
New value of Value function: 24.8381
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 23.0515
New value of Value function: 24.8381
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 23.1925
New value of Value function: 24.8381
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 19.4899
New value of Value function: 24.8381
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 23.3201
New value of Value function: 24.8381
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 871
New value of Q matrix: 24.8297
New value of Value function: 24.8297
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 23.4347
New value of Value function: 24.8297
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 872
New value of Q matrix: 24.8213
New value of Value function: 24.8213
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 23.5378
New value of Value function: 24.8213
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 873
New value of Q matrix: 24.8129
New value of Value function: 24.8129
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 874
New value of Q matrix: 24.8045
New value of Value function: 24.8045
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 875
New value of Q matrix: 24.7961
New value of Value function: 24.7961
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 876
New value of Q matrix: 24.6505
New value of Value function: 24.6505
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 72
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3981
	Distance: 9
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 5.60784
New value of Value function: 17.662
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 73
----------
State: 3981
	Distance: 9
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 14.9304
New value of Value function: 14.9304
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 22.2447
New value of Value function: 24.6505
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3941
	Distance: 9
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 877
New value of Q matrix: 24.0865
New value of Value function: 24.0865
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 76
----------
State: 3941
	Distance: 9
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 16.2046
New value of Value function: 16.2046
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 22.3768
New value of Value function: 24.0865
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 878
New value of Q matrix: 23.965
New value of Value function: 23.965
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 79
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 9.11275
New value of Value function: 17.662
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 80
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 81
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 82
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 83
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 84
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 85
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 86
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 87
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 88
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 89
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 90
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 91
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 92
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 93
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 94
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 95
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 20.7254
New value of Value function: 20.7254
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 19.6966
New value of Value function: 23.965
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 879
New value of Q matrix: 23.9569
New value of Value function: 23.9569
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 21.3403
New value of Value function: 23.9569
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 880
New value of Q matrix: 23.9488
New value of Value function: 23.9488
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 22.4863
New value of Value function: 23.9488
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 881
New value of Q matrix: 23.9408
New value of Value function: 23.9408
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 882
New value of Q matrix: 23.9327
New value of Value function: 23.9327
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 883
New value of Q matrix: 23.9247
New value of Value function: 23.9247
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 884
New value of Q matrix: 23.9166
New value of Value function: 23.9166
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 885
New value of Q matrix: 23.9086
New value of Value function: 23.9086
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 886
New value of Q matrix: 23.9005
New value of Value function: 23.9005
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 887
New value of Q matrix: 23.8925
New value of Value function: 23.8925
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 19.8894
New value of Value function: 23.8925
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 21.5609
New value of Value function: 23.8925
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 888
New value of Q matrix: 23.8845
New value of Value function: 23.8845
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 23.5475
New value of Value function: 23.8845
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 889
New value of Q matrix: 23.8765
New value of Value function: 23.8765
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 890
New value of Q matrix: 23.8685
New value of Value function: 23.8685
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 891
New value of Q matrix: 23.8605
New value of Value function: 23.8605
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 892
New value of Q matrix: 23.8525
New value of Value function: 23.8525
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 893
New value of Q matrix: 23.8445
New value of Value function: 23.8445
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 894
New value of Q matrix: 23.8365
New value of Value function: 23.8365
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 895
New value of Q matrix: 23.8286
New value of Value function: 23.8286
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 896
New value of Q matrix: 23.8206
New value of Value function: 23.8206
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 897
New value of Q matrix: 23.8127
New value of Value function: 23.8127
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 898
New value of Q matrix: 23.8047
New value of Value function: 23.8047
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 899
New value of Q matrix: 23.7968
New value of Value function: 23.7968
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 900
New value of Q matrix: 23.7888
New value of Value function: 23.7888
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 901
New value of Q matrix: 23.7809
New value of Value function: 23.7809
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 21.749
New value of Value function: 23.7809
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 902
New value of Q matrix: 23.773
New value of Value function: 23.773
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 903
New value of Q matrix: 23.7651
New value of Value function: 23.7651
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 904
New value of Q matrix: 23.7572
New value of Value function: 23.7572
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 905
New value of Q matrix: 23.7493
New value of Value function: 23.7493
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 21.9156
New value of Value function: 23.7493
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 22.5703
New value of Value function: 23.7493
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 22.6472
New value of Value function: 23.7493
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 906
New value of Q matrix: 23.7414
New value of Value function: 23.7414
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 907
New value of Q matrix: 23.7335
New value of Value function: 23.7335
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 908
New value of Q matrix: 23.7256
New value of Value function: 23.7256
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 909
New value of Q matrix: 23.7178
New value of Value function: 23.7178
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 910
New value of Q matrix: 23.7099
New value of Value function: 23.7099
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 911
New value of Q matrix: 23.7021
New value of Value function: 23.7021
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 912
New value of Q matrix: 23.6942
New value of Value function: 23.6942
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 913
New value of Q matrix: 23.6864
New value of Value function: 23.6864
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 22.7125
New value of Value function: 23.6864
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 22.7723
New value of Value function: 23.6864
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 124
New value of Q matrix: 21.7023
New value of Value function: 23.6864
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 144
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 16.5181
New value of Value function: 16.5181
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 145
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 20.5788
New value of Value function: 20.5788
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 146
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 20.3529
New value of Value function: 20.5788
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 147
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 19.298
New value of Value function: 19.298
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 914
New value of Q matrix: 23.6785
New value of Value function: 23.6785
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 20.0624
New value of Value function: 23.6785
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 915
New value of Q matrix: 23.6707
New value of Value function: 23.6707
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 916
New value of Q matrix: 23.6629
New value of Value function: 23.6629
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 917
New value of Q matrix: 23.6551
New value of Value function: 23.6551
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 918
New value of Q matrix: 23.6473
New value of Value function: 23.6473
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 20.2252
New value of Value function: 23.6473
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 919
New value of Q matrix: 23.6395
New value of Value function: 23.6395
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 920
New value of Q matrix: 23.6317
New value of Value function: 23.6317
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 921
New value of Q matrix: 23.6239
New value of Value function: 23.6239
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 922
New value of Q matrix: 23.6161
New value of Value function: 23.6161
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 22.0534
New value of Value function: 23.6161
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 923
New value of Q matrix: 23.6083
New value of Value function: 23.6083
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 924
New value of Q matrix: 23.6006
New value of Value function: 23.6006
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 22.1762
New value of Value function: 23.6006
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 125
New value of Q matrix: 21.7383
New value of Value function: 23.6006
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 164
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 19.1866
New value of Value function: 19.1866
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 165
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 19.7756
New value of Value function: 19.7756
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 925
New value of Q matrix: 23.5928
New value of Value function: 23.5928
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 926
New value of Q matrix: 23.585
New value of Value function: 23.585
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 927
New value of Q matrix: 23.5773
New value of Value function: 23.5773
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 928
New value of Q matrix: 23.5696
New value of Value function: 23.5696
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 929
New value of Q matrix: 23.5618
New value of Value function: 23.5618
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 930
New value of Q matrix: 23.5541
New value of Value function: 23.5541
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 931
New value of Q matrix: 23.5464
New value of Value function: 23.5464
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 932
New value of Q matrix: 23.5387
New value of Value function: 23.5387
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 933
New value of Q matrix: 23.531
New value of Value function: 23.531
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 934
New value of Q matrix: 23.5233
New value of Value function: 23.5233
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 935
New value of Q matrix: 23.5156
New value of Value function: 23.5156
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 936
New value of Q matrix: 23.5079
New value of Value function: 23.5079
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 937
New value of Q matrix: 23.5002
New value of Value function: 23.5002
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 20.3728
New value of Value function: 23.5002
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 20.5131
New value of Value function: 23.5002
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 938
New value of Q matrix: 23.4925
New value of Value function: 23.4925
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 939
New value of Q matrix: 23.4849
New value of Value function: 23.4849
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 940
New value of Q matrix: 23.4772
New value of Value function: 23.4772
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 941
New value of Q matrix: 23.4695
New value of Value function: 23.4695
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 942
New value of Q matrix: 23.4619
New value of Value function: 23.4619
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 943
New value of Q matrix: 23.459
New value of Value function: 23.459
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 187
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 22.6333
New value of Value function: 22.6333
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 188
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 19.1635
New value of Value function: 19.1635
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 189
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 22.8288
New value of Value function: 22.8288
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 190
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 18.9336
New value of Value function: 18.9336
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 191
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 22.7865
New value of Value function: 22.7865
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 192
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 18.5587
New value of Value function: 18.9336
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 193
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 22.7677
New value of Value function: 22.7677
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 194
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 18.7849
New value of Value function: 18.7849
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 195
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 22.698
New value of Value function: 22.698
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 196
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 18.4967
New value of Value function: 18.7849
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 197
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 22.6598
New value of Value function: 22.6598
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 198
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 18.6605
New value of Value function: 18.6605
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 199
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 22.5941
New value of Value function: 22.5941
New value of Policy matrix: 0

=======================================
Simulation: 42
Iteration: 200
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 19.1818
New value of Value function: 19.1818
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 944
New value of Q matrix: 23.4514
New value of Value function: 23.4514
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 945
New value of Q matrix: 23.4437
New value of Value function: 23.4437
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 946
New value of Q matrix: 23.4361
New value of Value function: 23.4361
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 947
New value of Q matrix: 23.4285
New value of Value function: 23.4285
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 22.2711
New value of Value function: 23.4285
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 948
New value of Q matrix: 23.4209
New value of Value function: 23.4209
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 949
New value of Q matrix: 23.4133
New value of Value function: 23.4133
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 22.8052
New value of Value function: 23.4133
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 21.8667
New value of Value function: 23.4133
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 22.3554
New value of Value function: 23.4133
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 950
New value of Q matrix: 23.4057
New value of Value function: 23.4057
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 22.8347
New value of Value function: 23.4057
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 22.8618
New value of Value function: 23.4057
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 951
New value of Q matrix: 23.3981
New value of Value function: 23.3981
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 952
New value of Q matrix: 23.3905
New value of Value function: 23.3905
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 953
New value of Q matrix: 23.3829
New value of Value function: 23.3829
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 954
New value of Q matrix: 23.3754
New value of Value function: 23.3754
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 955
New value of Q matrix: 23.3678
New value of Value function: 23.3678
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 956
New value of Q matrix: 23.3603
New value of Value function: 23.3603
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 957
New value of Q matrix: 23.3527
New value of Value function: 23.3527
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 21.9778
New value of Value function: 23.3527
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 958
New value of Q matrix: 23.3452
New value of Value function: 23.3452
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 22.8818
New value of Value function: 23.3452
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 426
New value of Q matrix: 20.5118
New value of Value function: 23.3452
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 25
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 18.401
New value of Value function: 18.401
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 26
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 18.5847
New value of Value function: 18.5847
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 27
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 9.20528
New value of Value function: 18.401
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 28
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 18.875
New value of Value function: 18.875
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 29
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 19.6127
New value of Value function: 19.6127
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 30
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 16.7171
New value of Value function: 21.839
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 31
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 18.6206
New value of Value function: 24.1851
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 32
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 88
New value of Q matrix: 22.8681
New value of Value function: 22.8681
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 33
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 27.4918
New value of Value function: 27.4918
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 34
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 76
New value of Q matrix: 27.0009
New value of Value function: 27.0009
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 35
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 18.3593
New value of Value function: 24.0467
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 36
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 77
New value of Q matrix: 26.8349
New value of Value function: 26.8349
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 37
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 25.5237
New value of Value function: 25.5237
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 38
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 128
New value of Q matrix: 23.984
New value of Value function: 23.984
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 39
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 18.0534
New value of Value function: 22.5629
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 40
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 129
New value of Q matrix: 23.9271
New value of Value function: 23.9271
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 41
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 21
New value of Q matrix: 22.5902
New value of Value function: 22.5902
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 42
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 130
New value of Q matrix: 24.1872
New value of Value function: 24.1872
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 43
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 209
New value of Q matrix: 21.9757
New value of Value function: 21.9757
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 959
New value of Q matrix: 23.4614
New value of Value function: 23.4614
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 45
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 19.1152
New value of Value function: 24.1872
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 46
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 78
New value of Q matrix: 27.0739
New value of Value function: 27.0739
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 47
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 131
New value of Q matrix: 24.4117
New value of Value function: 24.4117
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 48
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 210
New value of Q matrix: 21.855
New value of Value function: 21.855
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 960
New value of Q matrix: 23.581
New value of Value function: 23.581
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 50
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 132
New value of Q matrix: 24.6053
New value of Value function: 24.6053
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 51
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 211
New value of Q matrix: 21.7511
New value of Value function: 21.7511
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 961
New value of Q matrix: 23.7029
New value of Value function: 23.7029
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 53
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 133
New value of Q matrix: 24.7725
New value of Value function: 24.7725
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 54
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 212
New value of Q matrix: 21.6628
New value of Value function: 21.6628
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 427
New value of Q matrix: 20.7022
New value of Value function: 23.7029
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 56
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 213
New value of Q matrix: 21.7296
New value of Value function: 21.7296
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 57
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 36
New value of Q matrix: 22.1518
New value of Value function: 22.1518
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 58
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 120
New value of Q matrix: 19.886
New value of Value function: 19.886
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 22.9284
New value of Value function: 23.7029
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 428
New value of Q matrix: 20.7981
New value of Value function: 23.7029
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 61
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 121
New value of Q matrix: 19.9387
New value of Value function: 19.9387
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 962
New value of Q matrix: 23.729
New value of Value function: 23.729
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 63
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 18.5099
New value of Value function: 21.7296
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 64
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 23.0724
New value of Value function: 23.0724
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 65
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 214
New value of Q matrix: 21.9353
New value of Value function: 21.9353
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 66
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 122
New value of Q matrix: 19.9888
New value of Value function: 19.9888
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 963
New value of Q matrix: 23.7608
New value of Value function: 23.7608
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 68
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 215
New value of Q matrix: 22.13
New value of Value function: 22.13
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 69
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 13.5602
New value of Value function: 19.9888
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 70
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 17.9291
New value of Value function: 17.9291
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 71
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 11.937
New value of Value function: 11.937
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 72
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 123
New value of Q matrix: 20.0313
New value of Value function: 20.0313
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 73
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 20.0108
New value of Value function: 20.0108
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 964
New value of Q matrix: 23.7978
New value of Value function: 23.7978
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 75
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 216
New value of Q matrix: 22.3137
New value of Value function: 22.3137
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 76
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 14.2526
New value of Value function: 20.0313
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 77
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 17.5022
New value of Value function: 17.5022
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 78
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 15.3465
New value of Value function: 15.3465
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 22.4668
New value of Value function: 23.7978
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 965
New value of Q matrix: 23.8394
New value of Value function: 23.8394
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 81
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 217
New value of Q matrix: 22.4846
New value of Value function: 22.4846
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 82
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 14.5766
New value of Value function: 20.0313
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 83
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 17.0025
New value of Value function: 17.0025
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 84
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 6.92065
New value of Value function: 10.0057
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 85
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 6.82057
New value of Value function: 6.82057
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 86
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 45
New value of Q matrix: 10.4888
New value of Value function: 10.4888
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 87
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 62
New value of Q matrix: 12.5332
New value of Value function: 12.5332
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 966
New value of Q matrix: 23.7105
New value of Value function: 23.7105
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 89
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 17.0385
New value of Value function: 17.0385
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 90
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 22
New value of Q matrix: 15.5158
New value of Value function: 15.5158
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 91
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 20.9915
New value of Value function: 20.9915
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 92
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 218
New value of Q matrix: 22.6435
New value of Value function: 22.6435
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 93
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 124
New value of Q matrix: 20.071
New value of Value function: 20.071
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 967
New value of Q matrix: 23.7654
New value of Value function: 23.7654
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 95
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 219
New value of Q matrix: 22.794
New value of Value function: 22.794
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 96
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 125
New value of Q matrix: 20.1119
New value of Value function: 20.1119
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 968
New value of Q matrix: 23.8232
New value of Value function: 23.8232
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 98
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 220
New value of Q matrix: 22.9367
New value of Value function: 22.9367
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 99
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 126
New value of Q matrix: 20.154
New value of Value function: 20.154
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 969
New value of Q matrix: 23.8838
New value of Value function: 23.8838
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 101
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 221
New value of Q matrix: 23.0723
New value of Value function: 23.0723
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 102
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 15.9701
New value of Value function: 20.154
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 103
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 19.878
New value of Value function: 23.0723
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 104
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 222
New value of Q matrix: 23.1985
New value of Value function: 23.1985
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 105
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 15.7787
New value of Value function: 20.154
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 106
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 127
New value of Q matrix: 20.1976
New value of Value function: 20.1976
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 970
New value of Q matrix: 23.9506
New value of Value function: 23.9506
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 108
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 223
New value of Q matrix: 23.1805
New value of Value function: 23.1805
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 109
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 37
New value of Q matrix: 22.4549
New value of Value function: 22.4549
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 110
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 128
New value of Q matrix: 20.243
New value of Value function: 20.243
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 971
New value of Q matrix: 24.0148
New value of Value function: 24.0148
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 112
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 224
New value of Q matrix: 23.3048
New value of Value function: 23.3048
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 113
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 129
New value of Q matrix: 20.2898
New value of Value function: 20.2898
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 972
New value of Q matrix: 24.0807
New value of Value function: 24.0807
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 115
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 225
New value of Q matrix: 23.4236
New value of Value function: 23.4236
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 116
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 130
New value of Q matrix: 20.338
New value of Value function: 20.338
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 973
New value of Q matrix: 24.1483
New value of Value function: 24.1483
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 118
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 226
New value of Q matrix: 23.2199
New value of Value function: 23.2199
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 119
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 16.6399
New value of Value function: 16.6399
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 974
New value of Q matrix: 24.2073
New value of Value function: 24.2073
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 121
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 227
New value of Q matrix: 23.347
New value of Value function: 23.347
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 122
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 131
New value of Q matrix: 20.3928
New value of Value function: 20.3928
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 975
New value of Q matrix: 24.2683
New value of Value function: 24.2683
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 124
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 228
New value of Q matrix: 23.3392
New value of Value function: 23.3392
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 125
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 38
New value of Q matrix: 22.7362
New value of Value function: 22.7362
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 126
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 132
New value of Q matrix: 20.4479
New value of Value function: 20.4479
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 976
New value of Q matrix: 24.3271
New value of Value function: 24.3271
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 128
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 229
New value of Q matrix: 23.4651
New value of Value function: 23.4651
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 129
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 133
New value of Q matrix: 20.5031
New value of Value function: 20.5031
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 22.6156
New value of Value function: 24.3271
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 977
New value of Q matrix: 24.2942
New value of Value function: 24.2942
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 132
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 16.6849
New value of Value function: 20.5031
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 133
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 230
New value of Q matrix: 23.5859
New value of Value function: 23.5859
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 134
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 134
New value of Q matrix: 20.5504
New value of Value function: 20.5504
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 978
New value of Q matrix: 24.36
New value of Value function: 24.36
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 136
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 231
New value of Q matrix: 23.7017
New value of Value function: 23.7017
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 137
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 135
New value of Q matrix: 20.5991
New value of Value function: 20.5991
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 979
New value of Q matrix: 24.4272
New value of Value function: 24.4272
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 139
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 232
New value of Q matrix: 23.8127
New value of Value function: 23.8127
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 140
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 17.2547
New value of Value function: 20.5991
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 141
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 19.0334
New value of Value function: 23.8127
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 980
New value of Q matrix: 24.5262
New value of Value function: 24.5262
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 143
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 134
New value of Q matrix: 25.101
New value of Value function: 25.101
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 144
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 21
New value of Q matrix: 18.8874
New value of Value function: 23.8127
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 145
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 23.6528
New value of Value function: 23.6528
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 146
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 233
New value of Q matrix: 23.6469
New value of Value function: 23.6469
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 23.036
New value of Value function: 24.5262
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 981
New value of Q matrix: 24.6323
New value of Value function: 24.6323
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 149
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 135
New value of Q matrix: 25.3858
New value of Value function: 25.3858
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 150
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 234
New value of Q matrix: 23.4991
New value of Value function: 23.4991
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 982
New value of Q matrix: 24.744
New value of Value function: 24.744
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 152
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 136
New value of Q matrix: 25.6326
New value of Value function: 25.6326
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 153
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 235
New value of Q matrix: 23.3684
New value of Value function: 23.3684
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 23.1518
New value of Value function: 24.744
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 22.788
New value of Value function: 24.744
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 983
New value of Q matrix: 24.7361
New value of Value function: 24.7361
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 984
New value of Q matrix: 24.8521
New value of Value function: 24.8521
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 158
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 20.6249
New value of Value function: 25.6326
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 159
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 137
New value of Q matrix: 25.8464
New value of Value function: 25.8464
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 160
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 236
New value of Q matrix: 23.2535
New value of Value function: 23.2535
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 985
New value of Q matrix: 24.9712
New value of Value function: 24.9712
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 162
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 21.6597
New value of Value function: 25.8464
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 163
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 138
New value of Q matrix: 26.0315
New value of Value function: 26.0315
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 164
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 237
New value of Q matrix: 23.154
New value of Value function: 23.154
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 986
New value of Q matrix: 25.0922
New value of Value function: 25.0922
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 166
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 139
New value of Q matrix: 25.8945
New value of Value function: 25.8945
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 167
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 20.7406
New value of Value function: 23.6528
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 168
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 140
New value of Q matrix: 25.7696
New value of Value function: 25.7696
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 169
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 17.6322
New value of Value function: 23.6528
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 987
New value of Q matrix: 25.201
New value of Value function: 25.201
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 171
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 141
New value of Q matrix: 25.4478
New value of Value function: 25.4478
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 988
New value of Q matrix: 25.3474
New value of Value function: 25.3474
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 173
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 79
New value of Q matrix: 27.4249
New value of Value function: 27.4249
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 174
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 142
New value of Q matrix: 25.1664
New value of Value function: 25.1664
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 989
New value of Q matrix: 25.5002
New value of Value function: 25.5002
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 176
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 80
New value of Q matrix: 27.7032
New value of Value function: 27.7032
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 177
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 143
New value of Q matrix: 25.1036
New value of Value function: 25.1036
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 178
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 23
New value of Q matrix: 23.6945
New value of Value function: 23.6945
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 179
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 144
New value of Q matrix: 25.3385
New value of Value function: 25.3385
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 180
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 238
New value of Q matrix: 23.0951
New value of Value function: 23.0951
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 990
New value of Q matrix: 25.5823
New value of Value function: 25.5823
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 182
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 145
New value of Q matrix: 25.2654
New value of Value function: 25.2654
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 183
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 24
New value of Q matrix: 24.3415
New value of Value function: 24.3415
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 184
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 239
New value of Q matrix: 23.0454
New value of Value function: 23.0454
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 991
New value of Q matrix: 25.6595
New value of Value function: 25.6595
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 186
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 146
New value of Q matrix: 25.4764
New value of Value function: 25.4764
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 187
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 240
New value of Q matrix: 23.0039
New value of Value function: 23.0039
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 992
New value of Q matrix: 25.7409
New value of Value function: 25.7409
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 189
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 147
New value of Q matrix: 25.6659
New value of Value function: 25.6659
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 190
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 241
New value of Q matrix: 22.9704
New value of Value function: 22.9704
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 429
New value of Q matrix: 21.0367
New value of Value function: 25.7409
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 192
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 17.8366
New value of Value function: 22.9704
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 193
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 15.934
New value of Value function: 23.0724
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 194
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 24.2891
New value of Value function: 24.2891
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 195
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 148
New value of Q matrix: 25.8364
New value of Value function: 25.8364
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 196
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 242
New value of Q matrix: 23.005
New value of Value function: 23.005
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 197
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 17.0594
New value of Value function: 22.7362
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 993
New value of Q matrix: 25.8309
New value of Value function: 25.8309
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 199
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 149
New value of Q matrix: 25.9952
New value of Value function: 25.9952
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 200
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 18.7995
New value of Value function: 23.005
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 994
New value of Q matrix: 25.8227
New value of Value function: 25.8227
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 995
New value of Q matrix: 25.8145
New value of Value function: 25.8145
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 430
New value of Q matrix: 21.2031
New value of Value function: 25.8145
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 4
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 21.6812
New value of Value function: 21.6812
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 5
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 93
New value of Q matrix: 21.7572
New value of Value function: 21.7572
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 6
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 21
New value of Q matrix: 21.6324
New value of Value function: 21.6324
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 7
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 16.8991
New value of Value function: 22.8681
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 8
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 89
New value of Q matrix: 22.2564
New value of Value function: 22.2564
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 9
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 17.5724
New value of Value function: 17.5724
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 996
New value of Q matrix: 25.7898
New value of Value function: 25.7898
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 11
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 18.1309
New value of Value function: 22.2564
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 23.0385
New value of Value function: 25.7898
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 997
New value of Q matrix: 25.7816
New value of Value function: 25.7816
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 998
New value of Q matrix: 25.7701
New value of Value function: 25.7701
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 15
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.24146
New value of Value function: 22.6451
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 16
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 24
New value of Q matrix: 23.2359
New value of Value function: 23.2359
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 17
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 94
New value of Q matrix: 22.3014
New value of Value function: 22.3014
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 18
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 90
New value of Q matrix: 21.6148
New value of Value function: 21.6148
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 19
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 22.388
New value of Value function: 22.388
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 20
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 22
New value of Q matrix: 21.3693
New value of Value function: 21.3693
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 21
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 91
New value of Q matrix: 21.861
New value of Value function: 21.861
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 22
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 12.3402
New value of Value function: 19.1547
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 999
New value of Q matrix: 25.7345
New value of Value function: 25.7345
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 24
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 92
New value of Q matrix: 21.4998
New value of Value function: 21.4998
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 25
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 18.5736
New value of Value function: 18.5736
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1000
New value of Q matrix: 25.7164
New value of Value function: 25.7164
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 27
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 17.899
New value of Value function: 22.388
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 28
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 95
New value of Q matrix: 22.3899
New value of Value function: 22.3899
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 29
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 11.8062
New value of Value function: 22.388
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1001
New value of Q matrix: 25.7255
New value of Value function: 25.7255
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 31
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 15.6787
New value of Value function: 23.2359
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 32
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 25
New value of Q matrix: 23.822
New value of Value function: 23.822
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 33
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 17.2063
New value of Value function: 22.3899
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 34
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 17.3393
New value of Value function: 17.3393
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 35
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 96
New value of Q matrix: 22.7875
New value of Value function: 22.7875
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 36
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 93
New value of Q matrix: 21.2808
New value of Value function: 21.2808
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 37
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 19.3525
New value of Value function: 19.3525
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1002
New value of Q matrix: 25.7078
New value of Value function: 25.7078
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 39
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 22.4078
New value of Value function: 22.4078
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 23.2578
New value of Value function: 25.7078
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1003
New value of Q matrix: 25.6996
New value of Value function: 25.6996
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1004
New value of Q matrix: 25.6952
New value of Value function: 25.6952
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 43
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 97
New value of Q matrix: 22.8277
New value of Value function: 22.8277
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 44
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 19.4097
New value of Value function: 22.4078
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 45
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 98
New value of Q matrix: 22.8637
New value of Value function: 22.8637
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 46
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 30
New value of Q matrix: 20.2681
New value of Value function: 22.4078
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 47
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 99
New value of Q matrix: 23.1857
New value of Value function: 23.1857
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 48
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 18.1509
New value of Value function: 21.2808
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 49
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 22.417
New value of Value function: 22.417
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 23.4552
New value of Value function: 25.6952
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 431
New value of Q matrix: 21.2397
New value of Value function: 25.6952
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 52
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 19.7631
New value of Value function: 19.7631
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 53
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 31
New value of Q matrix: 18.5037
New value of Value function: 18.5037
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 54
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 22.2341
New value of Value function: 22.2341
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 55
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 19.7017
New value of Value function: 19.7017
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 56
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 23.3929
New value of Value function: 23.3929
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 57
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 27.5179
New value of Value function: 27.5179
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 58
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 18.1203
New value of Value function: 29.8001
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 59
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 29.7004
New value of Value function: 29.7004
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 60
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 33.6015
New value of Value function: 33.6015
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 61
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 40
New value of Q matrix: 36.8995
New value of Value function: 36.8995
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 62
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 28
New value of Q matrix: 37.2188
New value of Value function: 37.2188
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 63
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 37.2036
New value of Value function: 37.2036
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 64
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 16
New value of Q matrix: 9.04192
New value of Value function: 37.2188
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 65
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 22.4826
New value of Value function: 22.4826
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 66
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 31.7684
New value of Value function: 31.7684
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 67
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 42
New value of Q matrix: 37.4571
New value of Value function: 37.4571
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 68
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 36.6023
New value of Value function: 36.6023
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 69
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 29.2944
New value of Value function: 36.2613
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 70
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 12.291
New value of Value function: 36.6023
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1005
New value of Q matrix: 25.9714
New value of Value function: 25.9714
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 72
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 31.6678
New value of Value function: 31.6678
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 73
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 33.5504
New value of Value function: 33.5504
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 74
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 21.0788
New value of Value function: 31.6678
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 75
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 21.9355
New value of Value function: 31.6678
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 76
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 33.5105
New value of Value function: 33.5105
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 77
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 33.3181
New value of Value function: 33.3181
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 78
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 37.5759
New value of Value function: 37.5759
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 79
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 39.5139
New value of Value function: 39.5139
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 80
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 91
New value of Q matrix: 49.4408
New value of Value function: 49.4408
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 81
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 48.5597
New value of Value function: 48.5597
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 82
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 92
New value of Q matrix: 48.9856
New value of Value function: 48.9856
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 83
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 49.1355
New value of Value function: 49.1355
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 84
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 93
New value of Q matrix: 51.0132
New value of Value function: 51.0132
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 85
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 99
New value of Q matrix: 66.0821
New value of Value function: 66.0821
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 86
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 62.7876
New value of Value function: 62.7876
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 87
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 100
New value of Q matrix: 67.4419
New value of Value function: 67.4419
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 88
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 72.9509
New value of Value function: 72.9509
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 89
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 39.7216
New value of Value function: 39.7216
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 90
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 94
New value of Q matrix: 52.8444
New value of Value function: 52.8444
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 91
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 101
New value of Q matrix: 68.017
New value of Value function: 68.017
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 92
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 37
New value of Q matrix: 77.24
New value of Value function: 77.24
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 93
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 14
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 22.3079
New value of Value function: 25.9714
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1006
New value of Q matrix: 25.9632
New value of Value function: 25.9632
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 23.6579
New value of Value function: 25.9632
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 23.8417
New value of Value function: 25.9632
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1007
New value of Q matrix: 25.955
New value of Value function: 25.955
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1008
New value of Q matrix: 25.9469
New value of Value function: 25.9469
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1009
New value of Q matrix: 25.9387
New value of Value function: 25.9387
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1010
New value of Q matrix: 25.9305
New value of Value function: 25.9305
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1011
New value of Q matrix: 25.9224
New value of Value function: 25.9224
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1012
New value of Q matrix: 25.9142
New value of Value function: 25.9142
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 24.0038
New value of Value function: 25.9142
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1013
New value of Q matrix: 25.9061
New value of Value function: 25.9061
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 24.1502
New value of Value function: 25.9061
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1014
New value of Q matrix: 25.8979
New value of Value function: 25.8979
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1015
New value of Q matrix: 25.8898
New value of Value function: 25.8898
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1016
New value of Q matrix: 25.9116
New value of Value function: 25.9116
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 17
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 24.4362
New value of Value function: 24.4362
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 18
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 100
New value of Q matrix: 23.1864
New value of Value function: 23.1864
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 19
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 22.485
New value of Value function: 22.485
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 24.2835
New value of Value function: 25.9116
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1017
New value of Q matrix: 25.9035
New value of Value function: 25.9035
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1018
New value of Q matrix: 25.9438
New value of Value function: 25.9438
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 23
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 18.4699
New value of Value function: 24.4362
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1019
New value of Q matrix: 25.9829
New value of Value function: 25.9829
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 25
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 27
New value of Q matrix: 24.9208
New value of Value function: 24.9208
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 26
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 101
New value of Q matrix: 23.1403
New value of Value function: 23.1403
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 23.3551
New value of Value function: 25.9829
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1020
New value of Q matrix: 25.9806
New value of Value function: 25.9806
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 29
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 102
New value of Q matrix: 23.0988
New value of Value function: 23.0988
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1021
New value of Q matrix: 25.9771
New value of Value function: 25.9771
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 31
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 18.6591
New value of Value function: 23.0988
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 32
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 103
New value of Q matrix: 23.0612
New value of Value function: 23.0612
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1022
New value of Q matrix: 25.9725
New value of Value function: 25.9725
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 34
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 104
New value of Q matrix: 23.027
New value of Value function: 23.027
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1023
New value of Q matrix: 25.967
New value of Value function: 25.967
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 36
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 105
New value of Q matrix: 23.0498
New value of Value function: 23.0498
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 37
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 31
New value of Q matrix: 20.5467
New value of Value function: 22.485
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 38
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 18.2527
New value of Value function: 23.0498
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 39
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 17.8938
New value of Value function: 17.8938
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 40
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 106
New value of Q matrix: 23.3429
New value of Value function: 23.3429
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 41
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 94
New value of Q matrix: 21.6196
New value of Value function: 21.6196
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 42
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 39
New value of Q matrix: 20.1787
New value of Value function: 20.1787
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 43
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 11.8707
New value of Value function: 21.5743
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1024
New value of Q matrix: 25.9181
New value of Value function: 25.9181
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 45
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 95
New value of Q matrix: 21.4697
New value of Value function: 21.4697
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 46
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 20.001
New value of Value function: 20.001
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 24.4051
New value of Value function: 25.9181
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1025
New value of Q matrix: 25.91
New value of Value function: 25.91
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1026
New value of Q matrix: 25.8898
New value of Value function: 25.8898
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 50
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 22.5254
New value of Value function: 22.5254
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1027
New value of Q matrix: 25.8966
New value of Value function: 25.8966
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 52
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 107
New value of Q matrix: 23.3388
New value of Value function: 23.3388
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 53
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 22.5554
New value of Value function: 22.5554
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1028
New value of Q matrix: 25.9031
New value of Value function: 25.9031
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 55
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 108
New value of Q matrix: 23.3379
New value of Value function: 23.3379
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 56
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 23.485
New value of Value function: 23.485
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 57
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 23
New value of Q matrix: 21.137
New value of Value function: 21.137
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 58
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 96
New value of Q matrix: 21.4015
New value of Value function: 21.4015
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 59
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 27
New value of Q matrix: 20.5096
New value of Value function: 20.5096
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1029
New value of Q matrix: 25.8496
New value of Value function: 25.8496
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 61
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 97
New value of Q matrix: 21.4547
New value of Value function: 21.4547
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 62
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 24
New value of Q matrix: 20.9539
New value of Value function: 20.9539
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 63
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 98
New value of Q matrix: 21.8105
New value of Value function: 21.8105
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 64
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 40
New value of Q matrix: 20.5234
New value of Value function: 20.5234
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 65
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 15.9061
New value of Value function: 21.5743
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 66
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 22.2933
New value of Value function: 22.2933
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1030
New value of Q matrix: 25.7708
New value of Value function: 25.7708
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 68
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 12.2782
New value of Value function: 20.5234
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 69
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 41
New value of Q matrix: 20.8341
New value of Value function: 20.8341
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1031
New value of Q matrix: 25.7065
New value of Value function: 25.7065
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 71
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 22.8388
New value of Value function: 22.8388
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 72
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 42
New value of Q matrix: 21.1792
New value of Value function: 21.1792
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 73
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 22.3835
New value of Value function: 22.3835
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1032
New value of Q matrix: 25.6524
New value of Value function: 25.6524
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 75
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 43
New value of Q matrix: 21.4812
New value of Value function: 21.4812
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 76
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 22.3896
New value of Value function: 22.3896
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1033
New value of Q matrix: 25.6092
New value of Value function: 25.6092
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 78
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 13.8727
New value of Value function: 21.4812
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 79
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 13.4758
New value of Value function: 13.4758
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 80
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 16.1155
New value of Value function: 16.1155
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 81
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 13.3109
New value of Value function: 13.3109
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 82
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 17.4539
New value of Value function: 17.4539
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 83
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 15.5204
New value of Value function: 15.5204
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 84
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 14.3089
New value of Value function: 14.3089
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 85
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 7.23125
New value of Value function: 22.2341
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 86
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 14.5333
New value of Value function: 14.5333
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 87
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 11.3456
New value of Value function: 15.5204
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 88
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 14.0447
New value of Value function: 14.5333
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 89
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 21.937
New value of Value function: 21.937
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 90
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 19.7556
New value of Value function: 19.7556
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 91
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 23.2502
New value of Value function: 23.2502
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 92
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 24.3418
New value of Value function: 24.3418
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 93
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 29.1939
New value of Value function: 29.1939
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 94
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 32.9057
New value of Value function: 32.9057
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 95
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 28.733
New value of Value function: 33.5105
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 96
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 29.3128
New value of Value function: 29.3128
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 97
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 35.2147
New value of Value function: 35.2147
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 98
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 40.5518
New value of Value function: 40.5518
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 99
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 95
New value of Q matrix: 52.1057
New value of Value function: 52.1057
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 100
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 50.1842
New value of Value function: 50.1842
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 101
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 96
New value of Q matrix: 51.5522
New value of Value function: 51.5522
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 102
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 50.9122
New value of Value function: 50.9122
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 103
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 17.0692
New value of Value function: 51.5522
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 104
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 42.1223
New value of Value function: 42.1223
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 105
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 25.2452
New value of Value function: 51.5522
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 106
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 20.6639
New value of Value function: 42.1223
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 107
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 44.2285
New value of Value function: 44.2285
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 108
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 97
New value of Q matrix: 53.3579
New value of Value function: 53.3579
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 109
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 15.0946
New value of Value function: 68.017
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 110
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 34.5414
New value of Value function: 34.5414
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 111
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 24.8257
New value of Value function: 40.5518
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 112
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 26.3307
New value of Value function: 35.2147
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 113
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 23.5878
New value of Value function: 32.9057
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 114
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 34.841
New value of Value function: 34.841
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 115
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 45
New value of Q matrix: 41.3321
New value of Value function: 41.3321
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 116
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 42.4303
New value of Value function: 42.4303
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 117
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 43.0802
New value of Value function: 43.0802
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 118
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 98
New value of Q matrix: 52.7564
New value of Value function: 52.7564
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 119
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 51.7138
New value of Value function: 51.7138
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 120
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 99
New value of Q matrix: 54.4228
New value of Value function: 54.4228
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 121
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 102
New value of Q matrix: 67.041
New value of Value function: 67.041
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 122
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 50.1967
New value of Value function: 62.7876
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 123
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 55.3026
New value of Value function: 55.3026
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 124
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 103
New value of Q matrix: 68.0683
New value of Value function: 68.0683
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 125
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 42.2818
New value of Value function: 77.24
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 126
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 62.6353
New value of Value function: 62.6353
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 127
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 64.6983
New value of Value function: 64.6983
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 128
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 104
New value of Q matrix: 68.99
New value of Value function: 68.99
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 129
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 71.5759
New value of Value function: 71.5759
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 130
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 42.0108
New value of Value function: 42.0108
New value of Policy matrix: 3

=======================================
Simulation: 45
Iteration: 131
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 100
New value of Q matrix: 56.0105
New value of Value function: 56.0105
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 132
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 105
New value of Q matrix: 69.2701
New value of Value function: 69.2701
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 133
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 39
New value of Q matrix: 75.9737
New value of Value function: 75.9737
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 134
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 15
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1034
New value of Q matrix: 25.6013
New value of Value function: 25.6013
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1035
New value of Q matrix: 25.5933
New value of Value function: 25.5933
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1036
New value of Q matrix: 25.5854
New value of Value function: 25.5854
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1037
New value of Q matrix: 25.5774
New value of Value function: 25.5774
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1038
New value of Q matrix: 25.5695
New value of Value function: 25.5695
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 432
New value of Q matrix: 21.4738
New value of Value function: 25.5695
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 7
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 20.3394
New value of Value function: 23.3379
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 8
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 109
New value of Q matrix: 23.4253
New value of Value function: 23.4253
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 9
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 20.4609
New value of Value function: 23.485
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 10
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 110
New value of Q matrix: 23.504
New value of Value function: 23.504
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 11
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 24.0498
New value of Value function: 24.0498
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 12
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 25
New value of Q matrix: 20.8816
New value of Value function: 20.8816
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 13
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 19.3961
New value of Value function: 21.8105
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 14
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 26
New value of Q matrix: 20.8249
New value of Value function: 20.8249
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 15
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 99
New value of Q matrix: 22.3037
New value of Value function: 22.3037
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 16
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 21.9932
New value of Value function: 21.9932
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1039
New value of Q matrix: 25.5448
New value of Value function: 25.5448
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 18
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 14.5811
New value of Value function: 21.9932
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 19
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 16.4249
New value of Value function: 21.9932
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 20
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 24.0609
New value of Value function: 24.0609
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 21
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 46
New value of Q matrix: 22.3713
New value of Value function: 22.3713
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 22
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 20.2043
New value of Value function: 20.2043
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 23
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 40
New value of Q matrix: 28.1022
New value of Value function: 28.1022
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 23.5075
New value of Value function: 25.5448
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1040
New value of Q matrix: 25.4659
New value of Value function: 25.4659
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 26
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 23.5763
New value of Value function: 23.5763
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 27
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 41
New value of Q matrix: 27.1822
New value of Value function: 27.1822
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1041
New value of Q matrix: 25.493
New value of Value function: 25.493
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 29
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 25.7282
New value of Value function: 25.7282
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 30
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 42
New value of Q matrix: 24.6286
New value of Value function: 24.6286
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 31
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 13.8995
New value of Value function: 13.8995
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1042
New value of Q matrix: 25.5516
New value of Value function: 25.5516
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 33
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 11.2316
New value of Value function: 24.6286
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 34
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 43
New value of Q matrix: 23.1237
New value of Value function: 23.1237
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 35
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 22.2961
New value of Value function: 22.2961
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1043
New value of Q matrix: 25.5621
New value of Value function: 25.5621
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 37
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 44
New value of Q matrix: 23.0005
New value of Value function: 23.0005
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 24.4845
New value of Value function: 25.5621
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 433
New value of Q matrix: 21.6468
New value of Value function: 25.5621
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 40
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 22.3034
New value of Value function: 22.3034
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 24.5566
New value of Value function: 25.5621
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 23.6489
New value of Value function: 25.5621
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1044
New value of Q matrix: 25.5542
New value of Value function: 25.5542
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1045
New value of Q matrix: 25.1696
New value of Value function: 25.1696
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 45
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 21.9179
New value of Value function: 21.9179
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 434
New value of Q matrix: 21.9743
New value of Value function: 25.1696
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 47
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 20.2817
New value of Value function: 25.7282
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 48
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 26.2388
New value of Value function: 26.2388
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 49
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 25.459
New value of Value function: 25.459
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 50
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 34.4736
New value of Value function: 34.4736
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 51
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 32.4645
New value of Value function: 35.2147
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 52
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 33.9478
New value of Value function: 33.9478
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 53
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 37.2747
New value of Value function: 37.2747
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 54
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 46
New value of Q matrix: 41.7264
New value of Value function: 41.7264
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 55
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 45.1777
New value of Value function: 45.1777
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 56
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 101
New value of Q matrix: 55.5866
New value of Value function: 55.5866
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 57
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 18.7647
New value of Value function: 55.3026
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 58
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 34.2659
New value of Value function: 34.2659
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 59
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 38.982
New value of Value function: 38.982
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 60
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 22.0712
New value of Value function: 41.7264
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 61
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 36.2693
New value of Value function: 36.2693
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 62
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 47
New value of Q matrix: 42.4556
New value of Value function: 42.4556
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 63
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 47.3503
New value of Value function: 47.3503
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 64
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 31.8325
New value of Value function: 55.5866
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 65
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 36
New value of Q matrix: 46.2334
New value of Value function: 46.2334
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 66
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 44.4945
New value of Value function: 44.4945
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 67
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 48.1729
New value of Value function: 48.1729
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 68
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 102
New value of Q matrix: 55.2066
New value of Value function: 55.2066
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 69
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 55.725
New value of Value function: 55.725
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 70
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 103
New value of Q matrix: 56.7212
New value of Value function: 56.7212
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 71
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 106
New value of Q matrix: 68.3747
New value of Value function: 68.3747
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 72
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 31.2589
New value of Value function: 64.6983
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 73
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 61.184
New value of Value function: 61.184
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 74
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 57.5722
New value of Value function: 57.9495
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 75
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 60.37
New value of Value function: 61.184
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 76
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 62.9964
New value of Value function: 62.9964
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 77
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 107
New value of Q matrix: 69.1325
New value of Value function: 69.1325
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 78
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 40
New value of Q matrix: 79.6208
New value of Value function: 79.6208
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 79
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 37.7875
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 80
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 108
New value of Q matrix: 70.1614
New value of Value function: 70.1614
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 81
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 82.6551
New value of Value function: 82.6551
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 82
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 94.04
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 83
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 16
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1046
New value of Q matrix: 25.1618
New value of Value function: 25.1618
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 23.7477
New value of Value function: 25.1618
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1047
New value of Q matrix: 25.154
New value of Value function: 25.154
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1048
New value of Q matrix: 25.1463
New value of Value function: 25.1463
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1049
New value of Q matrix: 25.1385
New value of Value function: 25.1385
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1050
New value of Q matrix: 25.1307
New value of Value function: 25.1307
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 23.836
New value of Value function: 25.1307
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 435
New value of Q matrix: 22.1802
New value of Value function: 25.1307
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 9
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 111
New value of Q matrix: 23.8434
New value of Value function: 23.8434
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 10
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 100
New value of Q matrix: 22.2613
New value of Value function: 22.2613
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 436
New value of Q matrix: 22.3921
New value of Value function: 25.1307
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 112
New value of Q matrix: 24.1454
New value of Value function: 24.1454
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 13
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 101
New value of Q matrix: 22.7475
New value of Value function: 22.7475
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 14
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 47
New value of Q matrix: 23.6265
New value of Value function: 23.6265
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 15
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 27.2006
New value of Value function: 27.2006
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 16
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 46
New value of Q matrix: 24.3148
New value of Value function: 24.3148
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 17
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 21.8907
New value of Value function: 21.8907
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 22.5343
New value of Value function: 25.1307
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1051
New value of Q matrix: 25.123
New value of Value function: 25.123
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1052
New value of Q matrix: 25.1243
New value of Value function: 25.1243
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 21
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 22.1586
New value of Value function: 22.1586
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 24.5842
New value of Value function: 25.1243
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 24.6094
New value of Value function: 25.1243
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1053
New value of Q matrix: 25.1166
New value of Value function: 25.1166
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 22.7387
New value of Value function: 25.1166
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 22.5105
New value of Value function: 25.1166
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1054
New value of Q matrix: 25.1088
New value of Value function: 25.1088
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1055
New value of Q matrix: 25.1483
New value of Value function: 25.1483
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 29
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 48
New value of Q matrix: 23.527
New value of Value function: 23.527
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 30
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 22.0517
New value of Value function: 22.0517
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1056
New value of Q matrix: 25.1835
New value of Value function: 25.1835
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 32
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 49
New value of Q matrix: 23.4276
New value of Value function: 23.4276
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 33
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 22.0063
New value of Value function: 22.0063
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1057
New value of Q matrix: 25.2145
New value of Value function: 25.2145
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 35
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 50
New value of Q matrix: 23.3369
New value of Value function: 23.3369
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 36
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 21.9908
New value of Value function: 21.9908
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1058
New value of Q matrix: 25.2419
New value of Value function: 25.2419
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 38
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 51
New value of Q matrix: 24.54
New value of Value function: 24.54
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 39
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 25.9723
New value of Value function: 25.9723
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1059
New value of Q matrix: 25.3049
New value of Value function: 25.3049
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 41
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 16.8706
New value of Value function: 24.54
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 42
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 52
New value of Q matrix: 24.2946
New value of Value function: 24.2946
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 43
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 29.7126
New value of Value function: 29.7126
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 44
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 15.9251
New value of Value function: 25.9723
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 45
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 15.2077
New value of Value function: 24.2946
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 46
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 6.35107
New value of Value function: 14.5333
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 47
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 19.3398
New value of Value function: 19.3398
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 48
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 102
New value of Q matrix: 23.3717
New value of Value function: 23.3717
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 49
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 25.1762
New value of Value function: 25.1762
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 50
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 25.2151
New value of Value function: 25.2151
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 51
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 21.9838
New value of Value function: 21.9838
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1060
New value of Q matrix: 25.3866
New value of Value function: 25.3866
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 53
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 24.667
New value of Value function: 24.667
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 54
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 15.0852
New value of Value function: 21.9838
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1061
New value of Q matrix: 25.449
New value of Value function: 25.449
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 56
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 24.2517
New value of Value function: 24.2517
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 57
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 22.0891
New value of Value function: 22.0891
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1062
New value of Q matrix: 25.4969
New value of Value function: 25.4969
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 59
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 23.9568
New value of Value function: 23.9568
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 60
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 22.1575
New value of Value function: 22.1575
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 24.6642
New value of Value function: 25.4969
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1063
New value of Q matrix: 25.4891
New value of Value function: 25.4891
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 438
New value of Q matrix: 22.7115
New value of Value function: 25.4891
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 64
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 25.0233
New value of Value function: 25.0233
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 65
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 47
New value of Q matrix: 26.735
New value of Value function: 26.735
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 66
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 31
New value of Q matrix: 36.3273
New value of Value function: 36.3273
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 67
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 38.793
New value of Value function: 38.793
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 68
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 37.8659
New value of Value function: 37.8659
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 69
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 48
New value of Q matrix: 43.5
New value of Value function: 43.5
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 70
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 38
New value of Q matrix: 47.1796
New value of Value function: 47.1796
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 71
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 33.4051
New value of Value function: 44.4945
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 72
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 15.6788
New value of Value function: 38.793
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 73
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 40.4858
New value of Value function: 40.4858
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 74
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 49
New value of Q matrix: 44.244
New value of Value function: 44.244
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 75
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 49.097
New value of Value function: 49.097
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 76
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 104
New value of Q matrix: 56.2747
New value of Value function: 56.2747
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 77
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 18.7183
New value of Value function: 55.725
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 78
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 49.1761
New value of Value function: 49.1761
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 79
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 105
New value of Q matrix: 55.8739
New value of Value function: 55.8739
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 80
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 39.6252
New value of Value function: 55.725
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 81
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 63.2339
New value of Value function: 63.2339
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 82
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 106
New value of Q matrix: 57.3877
New value of Value function: 57.3877
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 83
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 33.8318
New value of Value function: 70.1614
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 84
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 107
New value of Q matrix: 58.7481
New value of Value function: 58.7481
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 85
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 109
New value of Q matrix: 69.0541
New value of Value function: 69.0541
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 86
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 20
New value of Q matrix: 65.2753
New value of Value function: 65.2753
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 87
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 40.8928
New value of Value function: 69.0541
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 88
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 108
New value of Q matrix: 59.8658
New value of Value function: 59.8658
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 89
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 110
New value of Q matrix: 70.3675
New value of Value function: 70.3675
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 90
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 50.0368
New value of Value function: 82.6551
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 91
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 69.9786
New value of Value function: 69.9786
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 92
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 76.7817
New value of Value function: 76.7817
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 93
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 44.9834
New value of Value function: 44.9834
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 94
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 109
New value of Q matrix: 60.9959
New value of Value function: 60.9959
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 95
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 111
New value of Q matrix: 70.9983
New value of Value function: 70.9983
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 96
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 43
New value of Q matrix: 80.176
New value of Value function: 80.176
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 97
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 62.6159
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 98
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 35.5111
New value of Value function: 80.176
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 99
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 18.5329
New value of Value function: 45.8546
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 100
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 63.5864
New value of Value function: 63.5864
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 101
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 8
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 48
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1064
New value of Q matrix: 25.4813
New value of Value function: 25.4813
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 24.7128
New value of Value function: 25.4813
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1065
New value of Q matrix: 25.4735
New value of Value function: 25.4735
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1066
New value of Q matrix: 25.4656
New value of Value function: 25.4656
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1067
New value of Q matrix: 25.4579
New value of Value function: 25.4579
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 23.9425
New value of Value function: 25.4579
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1068
New value of Q matrix: 25.4501
New value of Value function: 25.4501
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1069
New value of Q matrix: 25.4423
New value of Value function: 25.4423
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 439
New value of Q matrix: 22.9116
New value of Value function: 25.4423
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 10
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 113
New value of Q matrix: 24.2078
New value of Value function: 24.2078
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 11
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 23.5982
New value of Value function: 23.5982
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1070
New value of Q matrix: 25.4889
New value of Value function: 25.4889
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 13
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 114
New value of Q matrix: 24.5759
New value of Value function: 24.5759
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 14
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 16.8689
New value of Value function: 23.3717
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 15
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 19.7641
New value of Value function: 19.7641
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 16
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 115
New value of Q matrix: 24.9081
New value of Value function: 24.9081
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 17
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 103
New value of Q matrix: 24.0173
New value of Value function: 24.0173
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 18
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 25.8018
New value of Value function: 25.8018
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 19
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 24.5972
New value of Value function: 24.5972
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 20
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 22.1887
New value of Value function: 22.1887
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 24.7576
New value of Value function: 25.4889
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 24.0427
New value of Value function: 25.4889
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1071
New value of Q matrix: 25.4811
New value of Value function: 25.4811
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1072
New value of Q matrix: 25.5382
New value of Value function: 25.5382
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 25
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 19.8107
New value of Value function: 24.5972
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 26
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 26.0577
New value of Value function: 26.0577
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 27
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 55
New value of Q matrix: 25.936
New value of Value function: 25.936
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 28
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 25.2603
New value of Value function: 25.2603
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 29
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 18.8908
New value of Value function: 25.936
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 30
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 26.3924
New value of Value function: 26.3924
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 31
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 24.1343
New value of Value function: 24.1343
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1073
New value of Q matrix: 25.6478
New value of Value function: 25.6478
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 33
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 57
New value of Q matrix: 26.3414
New value of Value function: 26.3414
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 34
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 25.1692
New value of Value function: 25.1692
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 35
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 58
New value of Q matrix: 26.6764
New value of Value function: 26.6764
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 36
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 18.3779
New value of Value function: 24.1343
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 37
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 59
New value of Q matrix: 26.965
New value of Value function: 26.965
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 38
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 23.7925
New value of Value function: 23.7925
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 24.812
New value of Value function: 25.6478
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1074
New value of Q matrix: 25.64
New value of Value function: 25.64
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1075
New value of Q matrix: 25.7636
New value of Value function: 25.7636
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 42
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 60
New value of Q matrix: 27.1702
New value of Value function: 27.1702
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 43
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 23.6336
New value of Value function: 23.6336
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 44
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 22.3973
New value of Value function: 22.3973
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 45
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 28
New value of Q matrix: 23.5466
New value of Value function: 23.5466
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 46
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 22.3111
New value of Value function: 22.3973
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 47
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 19.8152
New value of Value function: 23.5466
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 48
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 61
New value of Q matrix: 27.3163
New value of Value function: 27.3163
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 49
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 34
New value of Q matrix: 19.9721
New value of Value function: 23.5466
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 50
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 24.2387
New value of Value function: 24.2387
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 51
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 25.0025
New value of Value function: 25.0025
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 52
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 17.9392
New value of Value function: 26.735
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 53
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 26.0814
New value of Value function: 26.0814
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 54
----------
State: 2693
	Distance: 6
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 30.5337
New value of Value function: 30.5337
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 55
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 37.9034
New value of Value function: 37.9034
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 56
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 40.3131
New value of Value function: 40.3131
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 57
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 39.4294
New value of Value function: 39.4294
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 58
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 27.772
New value of Value function: 44.244
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 59
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 24
New value of Q matrix: 12.9372
New value of Value function: 39.4294
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 60
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 22.4204
New value of Value function: 22.4204
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1076
New value of Q matrix: 25.8766
New value of Value function: 25.8766
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 62
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 48
New value of Q matrix: 29.232
New value of Value function: 29.232
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 63
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 14.8733
New value of Value function: 39.4294
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 24.8808
New value of Value function: 25.8766
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 24.9436
New value of Value function: 25.8766
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 25.0007
New value of Value function: 25.8766
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1077
New value of Q matrix: 25.8687
New value of Value function: 25.8687
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1078
New value of Q matrix: 25.8608
New value of Value function: 25.8608
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 24.1634
New value of Value function: 25.8608
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1079
New value of Q matrix: 25.8745
New value of Value function: 25.8745
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 71
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 35
New value of Q matrix: 20.3143
New value of Value function: 23.5466
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 72
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 25.3357
New value of Value function: 25.3357
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 73
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 26.8402
New value of Value function: 26.8402
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 74
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 12.8194
New value of Value function: 29.232
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 75
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 29.8519
New value of Value function: 29.8519
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 76
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 31.3468
New value of Value function: 31.3468
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 77
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 35
New value of Q matrix: 39.1726
New value of Value function: 39.1726
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 78
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 21.8836
New value of Value function: 40.3131
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 79
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 42.91
New value of Value function: 42.91
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 80
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 40.3958
New value of Value function: 40.3958
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 81
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 36
New value of Q matrix: 38.9758
New value of Value function: 38.9758
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 82
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 41.8591
New value of Value function: 41.8591
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 83
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 50
New value of Q matrix: 45.1437
New value of Value function: 45.1437
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 84
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 51.3563
New value of Value function: 51.3563
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 85
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 34.8571
New value of Value function: 60.9959
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 86
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 110
New value of Q matrix: 60.1541
New value of Value function: 60.1541
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 87
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 54.952
New value of Value function: 55.725
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 88
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 44.3682
New value of Value function: 69.9786
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 89
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 24.7047
New value of Value function: 60.37
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 90
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 91
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 92
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 67.3664
New value of Value function: 67.3664
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 93
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 63.9735
New value of Value function: 63.9735
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 94
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 74.801
New value of Value function: 74.801
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 95
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 9
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 49
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1080
New value of Q matrix: 25.8666
New value of Value function: 25.8666
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1081
New value of Q matrix: 25.8588
New value of Value function: 25.8588
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 25.0514
New value of Value function: 25.8588
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1082
New value of Q matrix: 25.8509
New value of Value function: 25.8509
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1083
New value of Q matrix: 25.8431
New value of Value function: 25.8431
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1084
New value of Q matrix: 25.8352
New value of Value function: 25.8352
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 440
New value of Q matrix: 23.1379
New value of Value function: 25.8352
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 8
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 116
New value of Q matrix: 24.8574
New value of Value function: 24.8574
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 9
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 21.5739
New value of Value function: 23.5982
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 10
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 117
New value of Q matrix: 25.2198
New value of Value function: 25.2198
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 11
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 104
New value of Q matrix: 23.8761
New value of Value function: 23.8761
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1085
New value of Q matrix: 25.8999
New value of Value function: 25.8999
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 13
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 118
New value of Q matrix: 25.5344
New value of Value function: 25.5344
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 14
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 105
New value of Q matrix: 23.6556
New value of Value function: 23.6556
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 15
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 18.3623
New value of Value function: 20.8249
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 16
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 24.074
New value of Value function: 24.074
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 17
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 27
New value of Q matrix: 21.1317
New value of Value function: 21.1317
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 18
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 106
New value of Q matrix: 24.4703
New value of Value function: 24.4703
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 19
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 62
New value of Q matrix: 27.1387
New value of Value function: 27.1387
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 20
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 20.7576
New value of Value function: 21.9908
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 21
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 28
New value of Q matrix: 20.9124
New value of Value function: 20.9124
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1086
New value of Q matrix: 25.9402
New value of Value function: 25.9402
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 23
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 107
New value of Q matrix: 24.2238
New value of Value function: 24.2238
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 24
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 28
New value of Q matrix: 21.4813
New value of Value function: 21.4813
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 25
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 108
New value of Q matrix: 24.9593
New value of Value function: 24.9593
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 26
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 12.5606
New value of Value function: 27.1387
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 27
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 109
New value of Q matrix: 25.6209
New value of Value function: 25.6209
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 28
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 14.3937
New value of Value function: 27.1387
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 29
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 11.2628
New value of Value function: 14.0447
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 30
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.20395
New value of Value function: 6.26662
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 31
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 26.8203
New value of Value function: 26.8203
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 32
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 21.1289
New value of Value function: 21.1289
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 33
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 12.9553
New value of Value function: 14.0447
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 34
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 16.5315
New value of Value function: 16.5315
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 35
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 16.4368
New value of Value function: 16.4368
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 36
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 26.3609
New value of Value function: 26.3609
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 37
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 16.373
New value of Value function: 26.8402
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 38
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 25.8653
New value of Value function: 25.8653
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 39
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 33.0777
New value of Value function: 33.0777
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 40
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 37
New value of Q matrix: 39.0522
New value of Value function: 39.0522
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 41
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 41.6537
New value of Value function: 41.6537
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 42
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 38
New value of Q matrix: 39.0822
New value of Value function: 39.0822
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 43
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 25.339
New value of Value function: 41.6537
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 44
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 30.9598
New value of Value function: 41.6537
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 45
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 43.0125
New value of Value function: 43.0125
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 46
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 51
New value of Q matrix: 46.2218
New value of Value function: 46.2218
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 47
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 41
New value of Q matrix: 50.6266
New value of Value function: 50.6266
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 48
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 49.9927
New value of Value function: 49.9927
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 49
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 42
New value of Q matrix: 50.1431
New value of Value function: 50.1431
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 50
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 50.4334
New value of Value function: 50.4334
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 51
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 52.0355
New value of Value function: 52.0355
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 52
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 43.5882
New value of Value function: 60.1541
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 53
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 111
New value of Q matrix: 59.3961
New value of Value function: 59.3961
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 54
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 56.7993
New value of Value function: 56.7993
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 55
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 112
New value of Q matrix: 60.6143
New value of Value function: 60.6143
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 56
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 7.72056
New value of Value function: 70.9983
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 57
----------
State: 1525
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 24.1481
New value of Value function: 24.1481
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 58
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 113
New value of Q matrix: 61.7125
New value of Value function: 61.7125
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 59
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 112
New value of Q matrix: 71.8843
New value of Value function: 71.8843
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 60
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 75.255
New value of Value function: 75.255
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 61
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 47.6025
New value of Value function: 47.6025
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 62
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 114
New value of Q matrix: 62.7852
New value of Value function: 62.7852
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 63
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 51.4624
New value of Value function: 71.8843
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 64
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 56.5497
New value of Value function: 71.8843
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 65
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 113
New value of Q matrix: 72.2246
New value of Value function: 72.2246
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 66
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 45
New value of Q matrix: 78.8007
New value of Value function: 78.8007
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 67
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 17
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 50
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1087
New value of Q matrix: 25.9323
New value of Value function: 25.9323
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1088
New value of Q matrix: 25.9244
New value of Value function: 25.9244
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 22.9944
New value of Value function: 25.9244
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1089
New value of Q matrix: 25.9166
New value of Value function: 25.9166
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1090
New value of Q matrix: 25.9087
New value of Value function: 25.9087
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1091
New value of Q matrix: 25.9009
New value of Value function: 25.9009
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1092
New value of Q matrix: 25.8931
New value of Value function: 25.8931
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1093
New value of Q matrix: 25.8852
New value of Value function: 25.8852
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1094
New value of Q matrix: 25.8774
New value of Value function: 25.8774
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1095
New value of Q matrix: 25.8696
New value of Value function: 25.8696
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1096
New value of Q matrix: 25.8618
New value of Value function: 25.8618
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1097
New value of Q matrix: 25.854
New value of Value function: 25.854
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 24.2739
New value of Value function: 25.854
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1098
New value of Q matrix: 25.8461
New value of Value function: 25.8461
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1099
New value of Q matrix: 25.8384
New value of Value function: 25.8384
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1100
New value of Q matrix: 25.8306
New value of Value function: 25.8306
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 25.0953
New value of Value function: 25.8306
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1101
New value of Q matrix: 25.8228
New value of Value function: 25.8228
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1102
New value of Q matrix: 25.815
New value of Value function: 25.815
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1103
New value of Q matrix: 25.8072
New value of Value function: 25.8072
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1104
New value of Q matrix: 25.7995
New value of Value function: 25.7995
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1105
New value of Q matrix: 25.7917
New value of Value function: 25.7917
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1106
New value of Q matrix: 25.7839
New value of Value function: 25.7839
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1107
New value of Q matrix: 25.7762
New value of Value function: 25.7762
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1108
New value of Q matrix: 25.7684
New value of Value function: 25.7684
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1109
New value of Q matrix: 25.7607
New value of Value function: 25.7607
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 23.2128
New value of Value function: 25.7607
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1110
New value of Q matrix: 25.753
New value of Value function: 25.753
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1111
New value of Q matrix: 25.7453
New value of Value function: 25.7453
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 25.1282
New value of Value function: 25.7453
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1112
New value of Q matrix: 25.7375
New value of Value function: 25.7375
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1113
New value of Q matrix: 25.7298
New value of Value function: 25.7298
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1114
New value of Q matrix: 25.7221
New value of Value function: 25.7221
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1115
New value of Q matrix: 25.7144
New value of Value function: 25.7144
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1116
New value of Q matrix: 25.7067
New value of Value function: 25.7067
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1117
New value of Q matrix: 25.699
New value of Value function: 25.699
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 441
New value of Q matrix: 23.3827
New value of Value function: 25.699
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 38
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 119
New value of Q matrix: 25.9772
New value of Value function: 25.9772
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 39
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 110
New value of Q matrix: 25.2474
New value of Value function: 25.2474
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 40
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 29
New value of Q matrix: 21.1965
New value of Value function: 21.1965
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 442
New value of Q matrix: 23.6021
New value of Value function: 25.699
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 42
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 111
New value of Q matrix: 25.8757
New value of Value function: 25.8757
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 43
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 63
New value of Q matrix: 27.5756
New value of Value function: 27.5756
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 44
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 30
New value of Q matrix: 26.7212
New value of Value function: 26.7212
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 45
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 18.3936
New value of Value function: 29.8519
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 46
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 26.1783
New value of Value function: 26.1783
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 47
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 27.3128
New value of Value function: 27.3128
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 48
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 28.7015
New value of Value function: 28.7015
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 49
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 51
New value of Q matrix: 31.5884
New value of Value function: 31.5884
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1118
New value of Q matrix: 25.87
New value of Value function: 25.87
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 51
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 24.3481
New value of Value function: 28.7015
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 52
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 36
New value of Q matrix: 20.9448
New value of Value function: 28.7015
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 53
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 13.0557
New value of Value function: 26.3609
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 54
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 18.2424
New value of Value function: 18.2424
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 55
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 27.2062
New value of Value function: 27.2062
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 56
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 30.0408
New value of Value function: 30.0408
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 57
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 29.7534
New value of Value function: 43.0125
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 58
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 27.2964
New value of Value function: 42.91
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 59
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 39
New value of Q matrix: 39.3224
New value of Value function: 39.3224
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 60
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 42.6653
New value of Value function: 42.6653
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 61
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 40.8145
New value of Value function: 40.8145
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 62
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 52
New value of Q matrix: 47.2332
New value of Value function: 47.2332
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 63
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 44
New value of Q matrix: 51.4164
New value of Value function: 51.4164
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 64
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 51.0709
New value of Value function: 51.0709
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 65
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 45
New value of Q matrix: 50.9906
New value of Value function: 50.9906
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 66
----------
State: 2285
	Distance: 5
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 51.4233
New value of Value function: 51.4233
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 67
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 26.2988
New value of Value function: 50.9906
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 68
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 53.0794
New value of Value function: 53.0794
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 69
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 49.7779
New value of Value function: 62.7852
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 70
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 115
New value of Q matrix: 61.8943
New value of Value function: 61.8943
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 71
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 58.1007
New value of Value function: 58.1007
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 72
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 116
New value of Q matrix: 62.9721
New value of Value function: 62.9721
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 73
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 114
New value of Q matrix: 71.5741
New value of Value function: 71.5741
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 74
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 71.019
New value of Value function: 71.019
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 75
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 115
New value of Q matrix: 71.0831
New value of Value function: 71.0831
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 76
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 23
New value of Q matrix: 71.7182
New value of Value function: 71.7182
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 77
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 28.3264
New value of Value function: 71.0831
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 78
----------
State: 2245
	Distance: 5
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 61.0628
New value of Value function: 61.0628
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 79
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 116
New value of Q matrix: 71.8194
New value of Value function: 71.8194
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 80
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 17.6679
New value of Value function: 78.8007
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 81
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 56.5542
New value of Value function: 78.8007
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 82
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 74.0237
New value of Value function: 74.0237
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 83
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 74.5729
New value of Value function: 74.5729
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 84
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 49.837
New value of Value function: 49.837
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 85
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 117
New value of Q matrix: 63.9085
New value of Value function: 63.9085
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 86
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 117
New value of Q matrix: 72.0974
New value of Value function: 72.0974
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 87
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 47
New value of Q matrix: 78.1418
New value of Value function: 78.1418
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 88
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 18
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 51
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1119
New value of Q matrix: 25.8622
New value of Value function: 25.8622
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1120
New value of Q matrix: 25.8545
New value of Value function: 25.8545
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1121
New value of Q matrix: 25.8468
New value of Value function: 25.8468
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1122
New value of Q matrix: 25.8391
New value of Value function: 25.8391
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 443
New value of Q matrix: 23.5111
New value of Value function: 25.8391
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 6
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 19.4281
New value of Value function: 19.4281
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 7
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 25
New value of Q matrix: 20.2336
New value of Value function: 20.2336
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 8
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 120
New value of Q matrix: 26.4007
New value of Value function: 26.4007
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 9
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 112
New value of Q matrix: 26.4749
New value of Value function: 26.4749
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 10
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 43
New value of Q matrix: 26.7429
New value of Value function: 26.7429
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1123
New value of Q matrix: 25.9476
New value of Value function: 25.9476
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 12
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 44
New value of Q matrix: 25.9474
New value of Value function: 25.9474
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 13
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 12.2267
New value of Value function: 20.6731
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 14
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 22.4686
New value of Value function: 22.4686
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 15
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 21.4893
New value of Value function: 25.9474
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 16
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 26.9132
New value of Value function: 26.9132
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 17
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 18.7806
New value of Value function: 27.7032
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 18
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 12.791
New value of Value function: 26.9132
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 19
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 22.1927
New value of Value function: 22.1927
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 20
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 14.7938
New value of Value function: 20.1662
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 21
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 9.55909
New value of Value function: 22.1927
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 22
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 26.9708
New value of Value function: 26.9708
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 23
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 22.9335
New value of Value function: 22.9335
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 24
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 20.09
New value of Value function: 20.09
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 25
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 23.2565
New value of Value function: 23.2565
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 26
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 18.0239
New value of Value function: 24.2891
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 27
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 25.1864
New value of Value function: 25.1864
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 28
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 24.3257
New value of Value function: 24.3257
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 29
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 81
New value of Q matrix: 28.0401
New value of Value function: 28.0401
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 30
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 150
New value of Q matrix: 25.922
New value of Value function: 25.922
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 31
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 19.4013
New value of Value function: 24.3415
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 32
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 19.4197
New value of Value function: 24.3415
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1124
New value of Q matrix: 26.0286
New value of Value function: 26.0286
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 34
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 151
New value of Q matrix: 25.6653
New value of Value function: 25.6653
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1125
New value of Q matrix: 26.1696
New value of Value function: 26.1696
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 36
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 82
New value of Q matrix: 28.3017
New value of Value function: 28.3017
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 37
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 22.425
New value of Value function: 25.6653
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 38
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 20.0108
New value of Value function: 25.6653
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 39
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 83
New value of Q matrix: 28.533
New value of Value function: 28.533
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 40
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 12
New value of Q matrix: 19.6429
New value of Value function: 25.6653
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 41
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 26.4394
New value of Value function: 26.4394
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 42
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 152
New value of Q matrix: 25.6193
New value of Value function: 25.6193
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 43
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 25
New value of Q matrix: 24.3458
New value of Value function: 24.3458
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 44
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 153
New value of Q matrix: 25.7936
New value of Value function: 25.7936
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 45
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 243
New value of Q matrix: 22.9988
New value of Value function: 22.9988
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1126
New value of Q matrix: 26.2401
New value of Value function: 26.2401
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 47
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 20.2732
New value of Value function: 25.7936
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 48
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 22.8533
New value of Value function: 22.8533
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 49
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 154
New value of Q matrix: 25.9528
New value of Value function: 25.9528
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 50
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 244
New value of Q matrix: 23.0314
New value of Value function: 23.0314
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 51
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 18.3952
New value of Value function: 22.7362
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 52
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 245
New value of Q matrix: 23.0619
New value of Value function: 23.0619
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 53
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 39
New value of Q matrix: 22.5913
New value of Value function: 22.5913
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 54
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 19.0223
New value of Value function: 23.0619
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 55
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 18.0328
New value of Value function: 18.0328
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 56
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 136
New value of Q matrix: 20.8031
New value of Value function: 20.8031
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1127
New value of Q matrix: 26.2279
New value of Value function: 26.2279
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 58
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 246
New value of Q matrix: 23.0813
New value of Value function: 23.0813
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 59
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 40
New value of Q matrix: 22.9081
New value of Value function: 22.9081
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 60
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 137
New value of Q matrix: 20.9878
New value of Value function: 20.9878
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1128
New value of Q matrix: 26.2167
New value of Value function: 26.2167
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 62
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 20.43
New value of Value function: 23.0813
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 63
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 18.4456
New value of Value function: 23.0813
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 64
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 155
New value of Q matrix: 26.1052
New value of Value function: 26.1052
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 65
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 247
New value of Q matrix: 23.2529
New value of Value function: 23.2529
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 66
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 17.4757
New value of Value function: 20.9878
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 67
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 19.909
New value of Value function: 23.2529
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 68
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 14
New value of Q matrix: 19.364
New value of Value function: 22.9081
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 69
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 19.3494
New value of Value function: 23.2529
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 70
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 23.6724
New value of Value function: 23.6724
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 71
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 248
New value of Q matrix: 23.4132
New value of Value function: 23.4132
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 72
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 138
New value of Q matrix: 21.1553
New value of Value function: 21.1553
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1129
New value of Q matrix: 26.2156
New value of Value function: 26.2156
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 74
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 20.9319
New value of Value function: 23.4132
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 75
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 19.65
New value of Value function: 23.4132
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 76
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 18.1133
New value of Value function: 18.1133
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 77
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 24
New value of Q matrix: 16.6688
New value of Value function: 16.6688
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 78
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 18.0941
New value of Value function: 20.9915
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 79
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 25
New value of Q matrix: 16.6914
New value of Value function: 16.6914
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 80
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 18.9042
New value of Value function: 20.9915
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 81
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 15.1705
New value of Value function: 16.6914
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 444
New value of Q matrix: 23.3219
New value of Value function: 26.2156
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 83
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 17.9194
New value of Value function: 17.9194
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 25.1972
New value of Value function: 26.2156
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1130
New value of Q matrix: 26.2145
New value of Value function: 26.2145
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 86
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 249
New value of Q matrix: 23.5736
New value of Value function: 23.5736
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 87
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 139
New value of Q matrix: 21.3077
New value of Value function: 21.3077
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1131
New value of Q matrix: 26.2182
New value of Value function: 26.2182
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 89
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 250
New value of Q matrix: 23.733
New value of Value function: 23.733
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 90
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 140
New value of Q matrix: 21.447
New value of Value function: 21.447
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1132
New value of Q matrix: 26.2264
New value of Value function: 26.2264
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 92
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 251
New value of Q matrix: 23.6704
New value of Value function: 23.6704
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 93
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 27
New value of Q matrix: 18.8903
New value of Value function: 18.8903
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1133
New value of Q matrix: 26.2326
New value of Value function: 26.2326
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 95
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 18.9457
New value of Value function: 23.6704
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 96
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 156
New value of Q matrix: 26.2916
New value of Value function: 26.2916
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 97
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 252
New value of Q matrix: 23.8318
New value of Value function: 23.8318
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 98
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 141
New value of Q matrix: 21.5753
New value of Value function: 21.5753
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1134
New value of Q matrix: 26.2433
New value of Value function: 26.2433
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 100
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 23
New value of Q matrix: 19.9493
New value of Value function: 23.8318
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 101
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 17.1532
New value of Value function: 24.3458
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 445
New value of Q matrix: 23.477
New value of Value function: 26.2433
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 103
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 253
New value of Q matrix: 23.9907
New value of Value function: 23.9907
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 104
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 17.2197
New value of Value function: 21.5753
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 105
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 18.2547
New value of Value function: 21.5753
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 106
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 19.0077
New value of Value function: 21.5753
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 107
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 142
New value of Q matrix: 21.6932
New value of Value function: 21.6932
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1135
New value of Q matrix: 26.2583
New value of Value function: 26.2583
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 109
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 24
New value of Q matrix: 19.9805
New value of Value function: 23.9907
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 110
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 25.0136
New value of Value function: 25.0136
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 111
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 254
New value of Q matrix: 23.9283
New value of Value function: 23.9283
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1136
New value of Q matrix: 26.3405
New value of Value function: 26.3405
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 113
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 20.474
New value of Value function: 26.2916
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 114
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 25.2818
New value of Value function: 25.2818
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 115
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 157
New value of Q matrix: 26.4829
New value of Value function: 26.4829
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 116
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 24
New value of Q matrix: 19.4096
New value of Value function: 23.9283
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 117
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 158
New value of Q matrix: 26.6585
New value of Value function: 26.6585
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 118
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 25
New value of Q matrix: 19.806
New value of Value function: 23.9283
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 119
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 159
New value of Q matrix: 26.8195
New value of Value function: 26.8195
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 120
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 255
New value of Q matrix: 23.875
New value of Value function: 23.875
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1137
New value of Q matrix: 26.4358
New value of Value function: 26.4358
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 122
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 160
New value of Q matrix: 26.736
New value of Value function: 26.736
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 123
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 18.9678
New value of Value function: 25.0136
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1138
New value of Q matrix: 26.5257
New value of Value function: 26.5257
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 125
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 161
New value of Q matrix: 26.6593
New value of Value function: 26.6593
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 126
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 27
New value of Q matrix: 25.5183
New value of Value function: 25.5183
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 127
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 26
New value of Q matrix: 20.0002
New value of Value function: 23.875
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 128
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 23.4107
New value of Value function: 23.4107
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 129
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 15.3853
New value of Value function: 18.1133
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 130
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 18.0423
New value of Value function: 23.4107
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 131
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 23.2512
New value of Value function: 23.2512
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 132
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 19.0765
New value of Value function: 19.0765
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 133
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 143
New value of Q matrix: 21.8243
New value of Value function: 21.8243
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1139
New value of Q matrix: 26.5289
New value of Value function: 26.5289
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 135
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 25
New value of Q matrix: 20.7202
New value of Value function: 23.875
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 136
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 41
New value of Q matrix: 22.8657
New value of Value function: 22.8657
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 137
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 256
New value of Q matrix: 24.0456
New value of Value function: 24.0456
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 138
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 144
New value of Q matrix: 21.9442
New value of Value function: 21.9442
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1140
New value of Q matrix: 26.5371
New value of Value function: 26.5371
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 140
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 257
New value of Q matrix: 24.2128
New value of Value function: 24.2128
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 141
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 145
New value of Q matrix: 22.0545
New value of Value function: 22.0545
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 23.478
New value of Value function: 26.5371
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1141
New value of Q matrix: 26.5882
New value of Value function: 26.5882
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 144
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 28
New value of Q matrix: 25.9818
New value of Value function: 25.9818
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 145
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 26
New value of Q matrix: 20.1172
New value of Value function: 24.2128
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 146
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 162
New value of Q matrix: 26.8409
New value of Value function: 26.8409
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 147
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 258
New value of Q matrix: 24.1769
New value of Value function: 24.1769
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 148
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 42
New value of Q matrix: 23.3237
New value of Value function: 23.3237
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 149
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 146
New value of Q matrix: 22.1594
New value of Value function: 22.1594
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1142
New value of Q matrix: 26.5985
New value of Value function: 26.5985
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 151
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 259
New value of Q matrix: 24.3485
New value of Value function: 24.3485
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 152
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 147
New value of Q matrix: 22.2562
New value of Value function: 22.2562
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1143
New value of Q matrix: 26.6135
New value of Value function: 26.6135
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 154
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 260
New value of Q matrix: 24.515
New value of Value function: 24.515
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 155
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 148
New value of Q matrix: 22.3459
New value of Value function: 22.3459
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1144
New value of Q matrix: 26.6329
New value of Value function: 26.6329
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 157
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 261
New value of Q matrix: 24.6764
New value of Value function: 24.6764
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 158
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 149
New value of Q matrix: 22.4295
New value of Value function: 22.4295
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1145
New value of Q matrix: 26.6564
New value of Value function: 26.6564
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 160
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 21.2438
New value of Value function: 24.6764
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1146
New value of Q matrix: 26.7426
New value of Value function: 26.7426
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 162
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 163
New value of Q matrix: 27.0437
New value of Value function: 27.0437
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 163
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 262
New value of Q matrix: 24.6022
New value of Value function: 24.6022
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1147
New value of Q matrix: 26.8321
New value of Value function: 26.8321
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 165
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 164
New value of Q matrix: 27.2243
New value of Value function: 27.2243
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 166
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 263
New value of Q matrix: 24.5381
New value of Value function: 24.5381
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1148
New value of Q matrix: 26.9241
New value of Value function: 26.9241
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 168
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 165
New value of Q matrix: 27.3853
New value of Value function: 27.3853
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 169
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 264
New value of Q matrix: 24.4838
New value of Value function: 24.4838
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 446
New value of Q matrix: 23.6551
New value of Value function: 26.9241
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 171
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 265
New value of Q matrix: 24.651
New value of Value function: 24.651
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 172
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 150
New value of Q matrix: 22.5295
New value of Value function: 22.5295
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1149
New value of Q matrix: 26.9383
New value of Value function: 26.9383
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 174
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 21.5556
New value of Value function: 24.651
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 175
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 20.3631
New value of Value function: 24.651
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 176
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 16.702
New value of Value function: 19.0765
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 177
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 12.8365
New value of Value function: 23.2512
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 178
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 11.6412
New value of Value function: 11.7588
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 179
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 15.8931
New value of Value function: 15.8931
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 180
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 18.4237
New value of Value function: 18.4237
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 181
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 46
New value of Q matrix: 10.3923
New value of Value function: 10.3923
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 182
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.51601
New value of Value function: 4.88341
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 183
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 7.26313
New value of Value function: 7.26313
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 184
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 47
New value of Q matrix: 10.311
New value of Value function: 10.311
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 185
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 6.05163
New value of Value function: 6.05163
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 186
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 63
New value of Q matrix: 13.9362
New value of Value function: 13.9362
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1150
New value of Q matrix: 26.7703
New value of Value function: 26.7703
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 188
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 18.8202
New value of Value function: 18.8202
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 189
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 28
New value of Q matrix: 18.4918
New value of Value function: 18.4918
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 190
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 22.3846
New value of Value function: 22.3846
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 191
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 20.6029
New value of Value function: 24.651
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 192
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 19.7607
New value of Value function: 19.7607
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 193
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 151
New value of Q matrix: 22.3897
New value of Value function: 22.3897
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 194
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 21.3306
New value of Value function: 21.3306
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1151
New value of Q matrix: 26.7889
New value of Value function: 26.7889
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 196
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 20.9669
New value of Value function: 24.651
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 197
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 20.5053
New value of Value function: 20.5053
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 198
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 152
New value of Q matrix: 22.0982
New value of Value function: 22.0982
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 199
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 64
New value of Q matrix: 15.1343
New value of Value function: 15.1343
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 447
New value of Q matrix: 23.3868
New value of Value function: 26.7889
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 24.4467
New value of Value function: 26.7889
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1152
New value of Q matrix: 26.7811
New value of Value function: 26.7811
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 25.3069
New value of Value function: 26.7811
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 24.6052
New value of Value function: 26.7811
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1153
New value of Q matrix: 26.7732
New value of Value function: 26.7732
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1154
New value of Q matrix: 26.7653
New value of Value function: 26.7653
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1155
New value of Q matrix: 26.7574
New value of Value function: 26.7574
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1156
New value of Q matrix: 26.7495
New value of Value function: 26.7495
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1157
New value of Q matrix: 26.7417
New value of Value function: 26.7417
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 24.7482
New value of Value function: 26.7417
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1158
New value of Q matrix: 26.7338
New value of Value function: 26.7338
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1159
New value of Q matrix: 26.726
New value of Value function: 26.726
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1160
New value of Q matrix: 26.7181
New value of Value function: 26.7181
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1161
New value of Q matrix: 26.7103
New value of Value function: 26.7103
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1162
New value of Q matrix: 26.7024
New value of Value function: 26.7024
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1163
New value of Q matrix: 26.6946
New value of Value function: 26.6946
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1164
New value of Q matrix: 26.6868
New value of Value function: 26.6868
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1165
New value of Q matrix: 26.679
New value of Value function: 26.679
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 24.875
New value of Value function: 26.679
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 25.3987
New value of Value function: 26.679
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 24.9919
New value of Value function: 26.679
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1166
New value of Q matrix: 26.6712
New value of Value function: 26.6712
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 25.4819
New value of Value function: 26.6712
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1167
New value of Q matrix: 26.6634
New value of Value function: 26.6634
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 23.7302
New value of Value function: 26.6634
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1168
New value of Q matrix: 26.6555
New value of Value function: 26.6555
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1169
New value of Q matrix: 26.6478
New value of Value function: 26.6478
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1170
New value of Q matrix: 26.64
New value of Value function: 26.64
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1171
New value of Q matrix: 26.6322
New value of Value function: 26.6322
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 25.5548
New value of Value function: 26.6322
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 23.957
New value of Value function: 26.6322
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1172
New value of Q matrix: 26.6244
New value of Value function: 26.6244
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1173
New value of Q matrix: 26.6166
New value of Value function: 26.6166
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1174
New value of Q matrix: 26.6089
New value of Value function: 26.6089
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1175
New value of Q matrix: 26.6011
New value of Value function: 26.6011
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1176
New value of Q matrix: 26.5933
New value of Value function: 26.5933
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1177
New value of Q matrix: 26.4459
New value of Value function: 26.4459
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 38
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 16.7287
New value of Value function: 18.7223
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 39
----------
State: 4381
	Distance: 10
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 20.2262
New value of Value function: 20.2262
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 40
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 19.9841
New value of Value function: 19.9841
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 41
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 20.803
New value of Value function: 20.803
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 42
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 121
New value of Q matrix: 26.838
New value of Value function: 26.838
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 43
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 113
New value of Q matrix: 26.9612
New value of Value function: 26.9612
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 44
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 46
New value of Q matrix: 26.3722
New value of Value function: 26.3722
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 45
----------
State: 3177
	Distance: 7
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 23.5463
New value of Value function: 23.5463
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 46
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 47
New value of Q matrix: 27.3751
New value of Value function: 27.3751
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 47
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 84
New value of Q matrix: 28.3848
New value of Value function: 28.3848
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 48
----------
State: 2777
	Distance: 6
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 19
New value of Q matrix: 27.5112
New value of Value function: 27.5112
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 49
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 166
New value of Q matrix: 27.3338
New value of Value function: 27.3338
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 50
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 29
New value of Q matrix: 25.9964
New value of Value function: 25.9964
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 51
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 23.3521
New value of Value function: 27.3338
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 52
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 167
New value of Q matrix: 27.494
New value of Value function: 27.494
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 53
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 266
New value of Q matrix: 24.5609
New value of Value function: 24.5609
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1178
New value of Q matrix: 26.5558
New value of Value function: 26.5558
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 55
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 168
New value of Q matrix: 27.6346
New value of Value function: 27.6346
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 56
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 267
New value of Q matrix: 24.4831
New value of Value function: 24.4831
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1179
New value of Q matrix: 26.6666
New value of Value function: 26.6666
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 58
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 21.0473
New value of Value function: 27.6346
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 59
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 20.1653
New value of Value function: 28.3848
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 60
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 24.1208
New value of Value function: 25.1864
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 61
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 85
New value of Q matrix: 28.8158
New value of Value function: 28.8158
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 62
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 169
New value of Q matrix: 27.3088
New value of Value function: 27.3088
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1180
New value of Q matrix: 26.8081
New value of Value function: 26.8081
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 64
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 86
New value of Q matrix: 29.163
New value of Value function: 29.163
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 65
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 170
New value of Q matrix: 27.2649
New value of Value function: 27.2649
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 66
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 30
New value of Q matrix: 25.9956
New value of Value function: 25.9956
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 67
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 21.7096
New value of Value function: 27.2649
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 68
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 24.1958
New value of Value function: 24.1958
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 69
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 268
New value of Q matrix: 24.6293
New value of Value function: 24.6293
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 70
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 15.6515
New value of Value function: 22.0982
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 71
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 21.0673
New value of Value function: 21.0673
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 72
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 153
New value of Q matrix: 22.2148
New value of Value function: 22.2148
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1181
New value of Q matrix: 26.8248
New value of Value function: 26.8248
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 74
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 27
New value of Q matrix: 21.6889
New value of Value function: 24.6293
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1182
New value of Q matrix: 26.9169
New value of Value function: 26.9169
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 76
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 24.066
New value of Value function: 27.2649
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 77
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 171
New value of Q matrix: 27.2244
New value of Value function: 27.2244
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 78
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 23.0585
New value of Value function: 25.9956
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 79
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 20.8291
New value of Value function: 25.9956
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1183
New value of Q matrix: 27.0052
New value of Value function: 27.0052
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 81
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 172
New value of Q matrix: 27.1872
New value of Value function: 27.1872
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 82
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 31
New value of Q matrix: 25.9812
New value of Value function: 25.9812
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 83
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 22.9815
New value of Value function: 27.1872
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 84
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 20.0018
New value of Value function: 24.1958
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 85
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 173
New value of Q matrix: 27.3541
New value of Value function: 27.3541
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 86
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 28
New value of Q matrix: 22.0756
New value of Value function: 24.6293
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1184
New value of Q matrix: 27.0946
New value of Value function: 27.0946
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 88
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 174
New value of Q matrix: 27.3062
New value of Value function: 27.3062
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 89
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 32
New value of Q matrix: 25.9904
New value of Value function: 25.9904
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 90
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 175
New value of Q matrix: 27.4632
New value of Value function: 27.4632
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 91
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 27
New value of Q matrix: 20.5158
New value of Value function: 24.6293
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 92
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 21.6494
New value of Value function: 27.4632
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 93
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 87
New value of Q matrix: 29.4874
New value of Value function: 29.4874
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 94
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 176
New value of Q matrix: 27.6079
New value of Value function: 27.6079
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 95
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 269
New value of Q matrix: 24.5802
New value of Value function: 24.5802
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 25.1308
New value of Value function: 27.0946
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1185
New value of Q matrix: 27.1886
New value of Value function: 27.1886
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 98
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 177
New value of Q matrix: 27.7376
New value of Value function: 27.7376
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 99
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 270
New value of Q matrix: 24.5398
New value of Value function: 24.5398
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 25.2658
New value of Value function: 27.1886
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1186
New value of Q matrix: 27.2836
New value of Value function: 27.2836
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 102
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 178
New value of Q matrix: 27.8543
New value of Value function: 27.8543
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 103
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 271
New value of Q matrix: 24.5077
New value of Value function: 24.5077
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1187
New value of Q matrix: 27.3792
New value of Value function: 27.3792
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 105
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 179
New value of Q matrix: 27.9596
New value of Value function: 27.9596
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 106
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 272
New value of Q matrix: 24.4824
New value of Value function: 24.4824
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 107
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 15
New value of Q matrix: 20.3642
New value of Value function: 23.3237
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 108
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 273
New value of Q matrix: 24.4587
New value of Value function: 24.4587
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 109
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 24.1054
New value of Value function: 24.1054
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1188
New value of Q matrix: 27.4749
New value of Value function: 27.4749
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 111
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 180
New value of Q matrix: 28.0531
New value of Value function: 28.0531
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 112
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 274
New value of Q matrix: 24.4431
New value of Value function: 24.4431
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1189
New value of Q matrix: 27.5706
New value of Value function: 27.5706
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 114
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 181
New value of Q matrix: 28.1382
New value of Value function: 28.1382
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 115
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 275
New value of Q matrix: 24.4341
New value of Value function: 24.4341
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1190
New value of Q matrix: 27.6658
New value of Value function: 27.6658
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 117
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 182
New value of Q matrix: 28.2162
New value of Value function: 28.2162
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 118
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 276
New value of Q matrix: 24.4314
New value of Value function: 24.4314
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1191
New value of Q matrix: 27.7605
New value of Value function: 27.7605
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 120
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 21.6087
New value of Value function: 28.2162
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 121
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 33
New value of Q matrix: 26.1546
New value of Value function: 26.1546
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 122
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 183
New value of Q matrix: 28.288
New value of Value function: 28.288
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 123
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 277
New value of Q matrix: 24.4345
New value of Value function: 24.4345
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1192
New value of Q matrix: 27.8545
New value of Value function: 27.8545
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 125
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 184
New value of Q matrix: 28.3545
New value of Value function: 28.3545
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 126
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 278
New value of Q matrix: 24.443
New value of Value function: 24.443
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1193
New value of Q matrix: 27.9476
New value of Value function: 27.9476
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 128
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 185
New value of Q matrix: 28.4165
New value of Value function: 28.4165
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 129
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 30
New value of Q matrix: 21.1471
New value of Value function: 24.443
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 130
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 24.7996
New value of Value function: 24.7996
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 131
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 279
New value of Q matrix: 24.375
New value of Value function: 24.375
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 132
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 29
New value of Q matrix: 19.6387
New value of Value function: 19.6387
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1194
New value of Q matrix: 27.924
New value of Value function: 27.924
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 134
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 280
New value of Q matrix: 24.5314
New value of Value function: 24.5314
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 135
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 154
New value of Q matrix: 22.4106
New value of Value function: 22.4106
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 448
New value of Q matrix: 23.4718
New value of Value function: 27.924
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 137
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 155
New value of Q matrix: 22.5901
New value of Value function: 22.5901
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 25.4451
New value of Value function: 27.924
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1195
New value of Q matrix: 27.9055
New value of Value function: 27.9055
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 140
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 281
New value of Q matrix: 24.7004
New value of Value function: 24.7004
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 141
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 156
New value of Q matrix: 22.7531
New value of Value function: 22.7531
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1196
New value of Q matrix: 27.8925
New value of Value function: 27.8925
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 143
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 22.0679
New value of Value function: 24.7004
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 144
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 282
New value of Q matrix: 24.8686
New value of Value function: 24.8686
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 145
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 157
New value of Q matrix: 22.7024
New value of Value function: 22.7024
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 146
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 22.4913
New value of Value function: 22.4913
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 449
New value of Q matrix: 23.4232
New value of Value function: 27.8925
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 148
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 30
New value of Q matrix: 20.547
New value of Value function: 20.547
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1197
New value of Q matrix: 27.8846
New value of Value function: 27.8846
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 150
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 283
New value of Q matrix: 25.0236
New value of Value function: 25.0236
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 151
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 158
New value of Q matrix: 22.8538
New value of Value function: 22.8538
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1198
New value of Q matrix: 27.8814
New value of Value function: 27.8814
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 153
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 21.6337
New value of Value function: 25.0236
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 154
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 21.2768
New value of Value function: 21.2768
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 155
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 31
New value of Q matrix: 20.1184
New value of Value function: 20.1184
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 156
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 23.079
New value of Value function: 23.079
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 157
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 22.0634
New value of Value function: 25.0236
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 158
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 21.3807
New value of Value function: 21.3807
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 159
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 17.1352
New value of Value function: 20.1184
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 160
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 65
New value of Q matrix: 16.3087
New value of Value function: 16.3087
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1199
New value of Q matrix: 27.8783
New value of Value function: 27.8783
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 162
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 284
New value of Q matrix: 25.178
New value of Value function: 25.178
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 163
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 159
New value of Q matrix: 22.9922
New value of Value function: 22.9922
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1200
New value of Q matrix: 27.8796
New value of Value function: 27.8796
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 165
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 285
New value of Q matrix: 25.3311
New value of Value function: 25.3311
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 166
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 160
New value of Q matrix: 23.1194
New value of Value function: 23.1194
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 24.2695
New value of Value function: 27.8796
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1201
New value of Q matrix: 27.8222
New value of Value function: 27.8222
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 169
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 161
New value of Q matrix: 23.2317
New value of Value function: 23.2317
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1202
New value of Q matrix: 27.9177
New value of Value function: 27.9177
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 171
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 186
New value of Q matrix: 28.5383
New value of Value function: 28.5383
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 172
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 286
New value of Q matrix: 25.4888
New value of Value function: 25.4888
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 173
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 162
New value of Q matrix: 23.3422
New value of Value function: 23.3422
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1203
New value of Q matrix: 27.9268
New value of Value function: 27.9268
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 175
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 287
New value of Q matrix: 25.6435
New value of Value function: 25.6435
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 176
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 163
New value of Q matrix: 23.4444
New value of Value function: 23.4444
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1204
New value of Q matrix: 27.94
New value of Value function: 27.94
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 178
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 288
New value of Q matrix: 25.7947
New value of Value function: 25.7947
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 179
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 164
New value of Q matrix: 23.5394
New value of Value function: 23.5394
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1205
New value of Q matrix: 27.9572
New value of Value function: 27.9572
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 181
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 289
New value of Q matrix: 25.74
New value of Value function: 25.74
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 182
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 24.51
New value of Value function: 24.51
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 25.7293
New value of Value function: 27.9572
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1206
New value of Q matrix: 27.9492
New value of Value function: 27.9492
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1207
New value of Q matrix: 28.0443
New value of Value function: 28.0443
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 186
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 187
New value of Q matrix: 28.6805
New value of Value function: 28.6805
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 187
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 29
New value of Q matrix: 22.0417
New value of Value function: 25.74
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 188
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 34
New value of Q matrix: 26.7254
New value of Value function: 26.7254
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 189
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 290
New value of Q matrix: 25.6827
New value of Value function: 25.6827
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1208
New value of Q matrix: 28.1406
New value of Value function: 28.1406
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 191
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 188
New value of Q matrix: 28.8078
New value of Value function: 28.8078
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 192
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 291
New value of Q matrix: 25.6344
New value of Value function: 25.6344
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1209
New value of Q matrix: 28.2378
New value of Value function: 28.2378
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 194
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 189
New value of Q matrix: 28.922
New value of Value function: 28.922
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 195
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 292
New value of Q matrix: 25.5947
New value of Value function: 25.5947
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1210
New value of Q matrix: 28.3354
New value of Value function: 28.3354
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 197
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 190
New value of Q matrix: 29.0248
New value of Value function: 29.0248
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 198
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 293
New value of Q matrix: 25.5754
New value of Value function: 25.5754
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 199
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 24.823
New value of Value function: 24.823
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1211
New value of Q matrix: 28.4331
New value of Value function: 28.4331
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 25.6483
New value of Value function: 28.4331
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1212
New value of Q matrix: 28.4249
New value of Value function: 28.4249
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1213
New value of Q matrix: 28.4168
New value of Value function: 28.4168
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1214
New value of Q matrix: 28.4086
New value of Value function: 28.4086
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1215
New value of Q matrix: 28.4005
New value of Value function: 28.4005
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1216
New value of Q matrix: 28.3923
New value of Value function: 28.3923
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1217
New value of Q matrix: 28.3842
New value of Value function: 28.3842
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1218
New value of Q matrix: 28.3761
New value of Value function: 28.3761
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1219
New value of Q matrix: 28.3679
New value of Value function: 28.3679
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1220
New value of Q matrix: 28.3598
New value of Value function: 28.3598
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1221
New value of Q matrix: 28.3517
New value of Value function: 28.3517
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1222
New value of Q matrix: 28.3436
New value of Value function: 28.3436
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1223
New value of Q matrix: 28.3355
New value of Value function: 28.3355
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1224
New value of Q matrix: 28.3274
New value of Value function: 28.3274
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1225
New value of Q matrix: 28.3193
New value of Value function: 28.3193
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1226
New value of Q matrix: 28.3112
New value of Value function: 28.3112
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1227
New value of Q matrix: 28.3031
New value of Value function: 28.3031
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 450
New value of Q matrix: 23.713
New value of Value function: 28.3031
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 19
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 18.322
New value of Value function: 26.838
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1228
New value of Q matrix: 28.295
New value of Value function: 28.295
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 451
New value of Q matrix: 23.9888
New value of Value function: 28.295
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 22
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 15.5287
New value of Value function: 26.838
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1229
New value of Q matrix: 28.287
New value of Value function: 28.287
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1230
New value of Q matrix: 28.2789
New value of Value function: 28.2789
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1231
New value of Q matrix: 28.2708
New value of Value function: 28.2708
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 452
New value of Q matrix: 24.2513
New value of Value function: 28.2708
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 27
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 19.104
New value of Value function: 26.838
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1232
New value of Q matrix: 28.2628
New value of Value function: 28.2628
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 25.9137
New value of Value function: 28.2628
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1233
New value of Q matrix: 28.2547
New value of Value function: 28.2547
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 453
New value of Q matrix: 24.5011
New value of Value function: 28.2547
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 32
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 122
New value of Q matrix: 27.2774
New value of Value function: 27.2774
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 33
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 114
New value of Q matrix: 26.7749
New value of Value function: 26.7749
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1234
New value of Q matrix: 28.3045
New value of Value function: 28.3045
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 35
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 123
New value of Q matrix: 27.057
New value of Value function: 27.057
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 36
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 24.577
New value of Value function: 24.577
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 37
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 29
New value of Q matrix: 22.2289
New value of Value function: 22.2289
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 38
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 115
New value of Q matrix: 27.2716
New value of Value function: 27.2716
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 39
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 19.6673
New value of Value function: 27.3751
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 40
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 28.4049
New value of Value function: 28.4049
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 41
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 116
New value of Q matrix: 27.7384
New value of Value function: 27.7384
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 42
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 64
New value of Q matrix: 28.3054
New value of Value function: 28.3054
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 43
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 32
New value of Q matrix: 28.5845
New value of Value function: 28.5845
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 44
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 31.2926
New value of Value function: 31.2926
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 45
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 52
New value of Q matrix: 30.4246
New value of Value function: 30.4246
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 46
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 23.721
New value of Value function: 23.721
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1235
New value of Q matrix: 28.3897
New value of Value function: 28.3897
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 48
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 29.7222
New value of Value function: 29.7222
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 49
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 53
New value of Q matrix: 29.694
New value of Value function: 29.694
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1236
New value of Q matrix: 28.5037
New value of Value function: 28.5037
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 51
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 54
New value of Q matrix: 29.085
New value of Value function: 29.085
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 25.841
New value of Value function: 28.5037
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1237
New value of Q matrix: 28.6152
New value of Value function: 28.6152
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 54
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 30.4206
New value of Value function: 30.4206
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 55
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 55
New value of Q matrix: 28.5785
New value of Value function: 28.5785
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 26.1109
New value of Value function: 28.6152
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 26.0269
New value of Value function: 28.6152
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 26.2914
New value of Value function: 28.6152
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1238
New value of Q matrix: 28.6071
New value of Value function: 28.6071
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 24.6156
New value of Value function: 28.6071
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1239
New value of Q matrix: 28.599
New value of Value function: 28.599
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 24.9303
New value of Value function: 28.599
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1240
New value of Q matrix: 28.5908
New value of Value function: 28.5908
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1241
New value of Q matrix: 28.5827
New value of Value function: 28.5827
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3973
	Distance: 9
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1242
New value of Q matrix: 28.3475
New value of Value function: 28.3475
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 66
----------
State: 3973
	Distance: 9
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 23.3496
New value of Value function: 23.3496
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 67
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 23.3526
New value of Value function: 27.057
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 68
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 28.5521
New value of Value function: 28.5521
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 69
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 26.4288
New value of Value function: 26.4288
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 70
----------
State: 4297
	Distance: 10
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 28.278
New value of Value function: 28.4049
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 71
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 11.254
New value of Value function: 26.4288
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 72
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 16.8276
New value of Value function: 16.8276
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 73
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 26.6879
New value of Value function: 26.6879
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 74
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 65
New value of Q matrix: 29.1502
New value of Value function: 29.1502
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 75
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 30.9061
New value of Value function: 30.9061
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 76
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 56
New value of Q matrix: 28.1089
New value of Value function: 28.1089
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1243
New value of Q matrix: 28.4964
New value of Value function: 28.4964
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 78
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 37
New value of Q matrix: 21.6006
New value of Value function: 30.9061
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 79
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 28.4127
New value of Value function: 28.4127
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 80
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 30.0083
New value of Value function: 30.0083
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 81
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 14.9426
New value of Value function: 28.1089
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 82
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 30.4
New value of Value function: 30.4
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 83
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 41
New value of Q matrix: 40.7246
New value of Value function: 40.7246
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 84
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 42.6081
New value of Value function: 42.6081
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 85
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 42.1189
New value of Value function: 42.1189
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 86
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 53
New value of Q matrix: 48.238
New value of Value function: 48.238
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 87
----------
State: 1925
	Distance: 4
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 55.0034
New value of Value function: 55.0034
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 88
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 118
New value of Q matrix: 61.5907
New value of Value function: 61.5907
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 89
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 56.124
New value of Value function: 56.124
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 90
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 21.1734
New value of Value function: 72.0974
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 91
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 51.2094
New value of Value function: 51.2094
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 92
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 119
New value of Q matrix: 62.6711
New value of Value function: 62.6711
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 93
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 118
New value of Q matrix: 72.674
New value of Value function: 72.674
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 94
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 48
New value of Q matrix: 81.1582
New value of Value function: 81.1582
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 95
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 19
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 54
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1244
New value of Q matrix: 28.4883
New value of Value function: 28.4883
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1245
New value of Q matrix: 28.4802
New value of Value function: 28.4802
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1246
New value of Q matrix: 28.4721
New value of Value function: 28.4721
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1247
New value of Q matrix: 28.4641
New value of Value function: 28.4641
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1248
New value of Q matrix: 28.456
New value of Value function: 28.456
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1249
New value of Q matrix: 28.448
New value of Value function: 28.448
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1250
New value of Q matrix: 28.4399
New value of Value function: 28.4399
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 26.1856
New value of Value function: 28.4399
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1251
New value of Q matrix: 28.4319
New value of Value function: 28.4319
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 26.442
New value of Value function: 28.4319
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 26.5799
New value of Value function: 28.4319
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1252
New value of Q matrix: 28.4238
New value of Value function: 28.4238
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1253
New value of Q matrix: 28.4158
New value of Value function: 28.4158
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1254
New value of Q matrix: 28.4078
New value of Value function: 28.4078
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1255
New value of Q matrix: 28.3998
New value of Value function: 28.3998
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1256
New value of Q matrix: 28.3918
New value of Value function: 28.3918
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 25.1999
New value of Value function: 28.3918
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1257
New value of Q matrix: 28.3838
New value of Value function: 28.3838
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1258
New value of Q matrix: 28.3758
New value of Value function: 28.3758
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1259
New value of Q matrix: 28.3678
New value of Value function: 28.3678
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1260
New value of Q matrix: 28.3598
New value of Value function: 28.3598
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 26.7005
New value of Value function: 28.3598
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1261
New value of Q matrix: 28.3518
New value of Value function: 28.3518
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1262
New value of Q matrix: 28.3438
New value of Value function: 28.3438
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1263
New value of Q matrix: 28.3358
New value of Value function: 28.3358
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1264
New value of Q matrix: 28.3279
New value of Value function: 28.3279
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1265
New value of Q matrix: 28.3199
New value of Value function: 28.3199
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1266
New value of Q matrix: 28.3119
New value of Value function: 28.3119
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 26.3226
New value of Value function: 28.3119
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 26.8071
New value of Value function: 28.3119
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1267
New value of Q matrix: 28.304
New value of Value function: 28.304
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1268
New value of Q matrix: 28.296
New value of Value function: 28.296
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1269
New value of Q matrix: 28.2881
New value of Value function: 28.2881
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1270
New value of Q matrix: 28.2801
New value of Value function: 28.2801
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 26.4467
New value of Value function: 28.2801
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1271
New value of Q matrix: 28.2722
New value of Value function: 28.2722
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 454
New value of Q matrix: 24.4206
New value of Value function: 28.2722
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 38
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 12.6961
New value of Value function: 19.9841
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 39
----------
State: 4341
	Distance: 10
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 20.5348
New value of Value function: 20.5348
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 40
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.63711
New value of Value function: 20.803
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 41
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 12.9057
New value of Value function: 12.9057
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 42
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 20.5949
New value of Value function: 20.803
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 43
----------
State: 4301
	Distance: 10
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 22.1311
New value of Value function: 22.1311
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 44
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 24.7412
New value of Value function: 24.7412
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 45
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 27.0857
New value of Value function: 27.0857
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 46
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 88
New value of Q matrix: 29.9401
New value of Value function: 29.9401
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 47
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 191
New value of Q matrix: 29.1185
New value of Value function: 29.1185
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 48
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 22.1484
New value of Value function: 25.5754
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 49
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 21.3382
New value of Value function: 24.7996
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 50
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 24.0587
New value of Value function: 29.1185
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 51
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 7.67184
New value of Value function: 24.7996
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 52
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 23.029
New value of Value function: 23.029
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 53
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 26.6682
New value of Value function: 26.6682
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 54
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 192
New value of Q matrix: 29.2052
New value of Value function: 29.2052
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 55
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 28
New value of Q matrix: 21.1579
New value of Value function: 25.5754
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 56
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 193
New value of Q matrix: 29.2854
New value of Value function: 29.2854
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 57
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 294
New value of Q matrix: 25.5412
New value of Value function: 25.5412
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1272
New value of Q matrix: 28.3765
New value of Value function: 28.3765
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 59
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 24.86
New value of Value function: 29.2854
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 60
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 25.5173
New value of Value function: 25.5173
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 61
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 21.5486
New value of Value function: 25.5412
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 62
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 26.0078
New value of Value function: 26.0078
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 63
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 295
New value of Q matrix: 25.7021
New value of Value function: 25.7021
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 64
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 165
New value of Q matrix: 23.6603
New value of Value function: 23.6603
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 25.4444
New value of Value function: 28.3765
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 24.5927
New value of Value function: 28.3765
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1273
New value of Q matrix: 28.3784
New value of Value function: 28.3784
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 68
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 296
New value of Q matrix: 25.6668
New value of Value function: 25.6668
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1274
New value of Q matrix: 28.4797
New value of Value function: 28.4797
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 70
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 22.5671
New value of Value function: 29.2854
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1275
New value of Q matrix: 28.5962
New value of Value function: 28.5962
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 72
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 89
New value of Q matrix: 30.3697
New value of Value function: 30.3697
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 73
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 194
New value of Q matrix: 29
New value of Value function: 29
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1276
New value of Q matrix: 28.7214
New value of Value function: 28.7214
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 75
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 90
New value of Q matrix: 30.7218
New value of Value function: 30.7218
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 76
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 195
New value of Q matrix: 28.8896
New value of Value function: 28.8896
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 77
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 35
New value of Q matrix: 27.1792
New value of Value function: 27.1792
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 78
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 30
New value of Q matrix: 21.9233
New value of Value function: 25.6668
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 79
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 196
New value of Q matrix: 28.9982
New value of Value function: 28.9982
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 80
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 297
New value of Q matrix: 25.6533
New value of Value function: 25.6533
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1277
New value of Q matrix: 28.8049
New value of Value function: 28.8049
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 82
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 197
New value of Q matrix: 29.0978
New value of Value function: 29.0978
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 83
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 34
New value of Q matrix: 22.4226
New value of Value function: 25.6533
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 84
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 22.491
New value of Value function: 26.0078
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 85
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 26.379
New value of Value function: 26.379
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 86
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 298
New value of Q matrix: 25.8138
New value of Value function: 25.8138
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 87
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 166
New value of Q matrix: 23.8044
New value of Value function: 23.8044
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1278
New value of Q matrix: 28.798
New value of Value function: 28.798
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 89
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 31
New value of Q matrix: 22.2616
New value of Value function: 25.8138
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 90
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 198
New value of Q matrix: 29.2014
New value of Value function: 29.2014
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 91
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 32
New value of Q matrix: 22.5893
New value of Value function: 25.8138
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 92
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 22.7285
New value of Value function: 26.379
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 93
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 35
New value of Q matrix: 22.7087
New value of Value function: 25.8138
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 94
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 26.6828
New value of Value function: 26.6828
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 95
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 299
New value of Q matrix: 25.973
New value of Value function: 25.973
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 96
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 16.6265
New value of Value function: 23.8044
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 97
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 21.4666
New value of Value function: 21.4666
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 98
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 32
New value of Q matrix: 19.8939
New value of Value function: 19.8939
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 99
----------
State: 1973
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 23.8098
New value of Value function: 23.8098
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 100
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 300
New value of Q matrix: 26.1227
New value of Value function: 26.1227
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 101
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 167
New value of Q matrix: 23.9364
New value of Value function: 23.9364
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 26.5993
New value of Value function: 28.798
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1279
New value of Q matrix: 28.7997
New value of Value function: 28.7997
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 104
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 22.7282
New value of Value function: 26.1227
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 105
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 301
New value of Q matrix: 26.0404
New value of Value function: 26.0404
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 106
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 33
New value of Q matrix: 20.8718
New value of Value function: 20.8718
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1280
New value of Q matrix: 28.7992
New value of Value function: 28.7992
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 108
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 302
New value of Q matrix: 26.1933
New value of Value function: 26.1933
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 109
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 17.3282
New value of Value function: 23.9364
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 110
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 20.7315
New value of Value function: 20.7315
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 111
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 14.1988
New value of Value function: 14.1988
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 112
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 168
New value of Q matrix: 23.7211
New value of Value function: 23.7211
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 113
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 66
New value of Q matrix: 17.4414
New value of Value function: 17.4414
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1281
New value of Q matrix: 28.8029
New value of Value function: 28.8029
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 115
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 22.9073
New value of Value function: 26.1933
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 116
----------
State: 2697
	Distance: 6
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 26.995
New value of Value function: 26.995
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 117
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 303
New value of Q matrix: 26.3249
New value of Value function: 26.3249
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 118
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 169
New value of Q matrix: 23.8591
New value of Value function: 23.8591
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1282
New value of Q matrix: 28.8101
New value of Value function: 28.8101
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 120
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 304
New value of Q matrix: 26.4565
New value of Value function: 26.4565
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 121
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 170
New value of Q matrix: 23.9866
New value of Value function: 23.9866
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1283
New value of Q matrix: 28.8208
New value of Value function: 28.8208
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 123
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 305
New value of Q matrix: 26.5877
New value of Value function: 26.5877
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 124
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 171
New value of Q matrix: 24.1048
New value of Value function: 24.1048
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1284
New value of Q matrix: 28.8348
New value of Value function: 28.8348
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 126
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 306
New value of Q matrix: 26.7178
New value of Value function: 26.7178
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 127
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 172
New value of Q matrix: 24.2148
New value of Value function: 24.2148
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1285
New value of Q matrix: 28.8519
New value of Value function: 28.8519
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 129
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 307
New value of Q matrix: 26.8465
New value of Value function: 26.8465
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 130
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 173
New value of Q matrix: 24.3173
New value of Value function: 24.3173
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 26.9478
New value of Value function: 28.8519
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1286
New value of Q matrix: 28.8722
New value of Value function: 28.8722
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 133
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 22.8447
New value of Value function: 26.8465
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 134
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 21.5659
New value of Value function: 21.5659
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 135
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 174
New value of Q matrix: 24.1619
New value of Value function: 24.1619
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 136
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 67
New value of Q matrix: 18.4361
New value of Value function: 18.4361
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1287
New value of Q matrix: 28.8919
New value of Value function: 28.8919
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 138
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 308
New value of Q matrix: 26.9646
New value of Value function: 26.9646
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 139
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 20.1656
New value of Value function: 24.1619
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 140
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 175
New value of Q matrix: 24.2708
New value of Value function: 24.2708
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 26.747
New value of Value function: 28.8919
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1288
New value of Q matrix: 28.9142
New value of Value function: 28.9142
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 143
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 309
New value of Q matrix: 27.082
New value of Value function: 27.082
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 144
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 176
New value of Q matrix: 24.3729
New value of Value function: 24.3729
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1289
New value of Q matrix: 28.9392
New value of Value function: 28.9392
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 146
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 310
New value of Q matrix: 27.1983
New value of Value function: 27.1983
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 147
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 177
New value of Q matrix: 24.4689
New value of Value function: 24.4689
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1290
New value of Q matrix: 28.9667
New value of Value function: 28.9667
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 149
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 311
New value of Q matrix: 27.3132
New value of Value function: 27.3132
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 150
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 178
New value of Q matrix: 24.5594
New value of Value function: 24.5594
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 456
New value of Q matrix: 24.5492
New value of Value function: 28.9667
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 152
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 34
New value of Q matrix: 21.2825
New value of Value function: 21.2825
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 153
----------
State: 1573
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 23.5532
New value of Value function: 23.5532
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1291
New value of Q matrix: 28.9966
New value of Value function: 28.9966
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 155
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 312
New value of Q matrix: 27.4264
New value of Value function: 27.4264
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 156
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 179
New value of Q matrix: 24.6452
New value of Value function: 24.6452
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1292
New value of Q matrix: 29.0287
New value of Value function: 29.0287
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 158
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 313
New value of Q matrix: 27.5379
New value of Value function: 27.5379
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 159
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 180
New value of Q matrix: 24.7267
New value of Value function: 24.7267
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 457
New value of Q matrix: 24.3949
New value of Value function: 29.0287
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 161
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 68
New value of Q matrix: 19.3217
New value of Value function: 19.3217
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1293
New value of Q matrix: 29.063
New value of Value function: 29.063
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 163
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 314
New value of Q matrix: 27.6475
New value of Value function: 27.6475
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 164
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 17.2581
New value of Value function: 24.7267
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 165
----------
State: 1897
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 16.019
New value of Value function: 16.019
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 166
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 181
New value of Q matrix: 24.8044
New value of Value function: 24.8044
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1294
New value of Q matrix: 29.0994
New value of Value function: 29.0994
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 168
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 315
New value of Q matrix: 27.755
New value of Value function: 27.755
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 169
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 182
New value of Q matrix: 24.8788
New value of Value function: 24.8788
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 458
New value of Q matrix: 24.3797
New value of Value function: 29.0994
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 171
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 35
New value of Q matrix: 22.0475
New value of Value function: 22.0475
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1295
New value of Q matrix: 29.1377
New value of Value function: 29.1377
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 173
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 316
New value of Q matrix: 27.8605
New value of Value function: 27.8605
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 174
----------
State: 1937
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 19.5705
New value of Value function: 24.8788
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1296
New value of Q matrix: 29.1778
New value of Value function: 29.1778
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 176
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 30
New value of Q matrix: 22.1998
New value of Value function: 27.8605
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 177
----------
State: 2377
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 36
New value of Q matrix: 27.913
New value of Value function: 27.913
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 178
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 317
New value of Q matrix: 27.7496
New value of Value function: 27.7496
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1297
New value of Q matrix: 29.2537
New value of Value function: 29.2537
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 180
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 199
New value of Q matrix: 29.4333
New value of Value function: 29.4333
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 181
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 318
New value of Q matrix: 27.6276
New value of Value function: 27.6276
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 182
----------
State: 1977
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 25.3921
New value of Value function: 25.3921
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1298
New value of Q matrix: 29.3337
New value of Value function: 29.3337
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 184
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 200
New value of Q matrix: 29.6396
New value of Value function: 29.6396
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 185
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 319
New value of Q matrix: 27.5388
New value of Value function: 27.5388
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1299
New value of Q matrix: 29.4172
New value of Value function: 29.4172
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 187
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 24.7575
New value of Value function: 29.6396
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 188
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 26.8492
New value of Value function: 26.8492
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 189
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 91
New value of Q matrix: 31.1014
New value of Value function: 31.1014
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 190
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 201
New value of Q matrix: 29.8247
New value of Value function: 29.8247
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 191
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 31
New value of Q matrix: 22.9044
New value of Value function: 27.5388
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1300
New value of Q matrix: 29.5035
New value of Value function: 29.5035
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 193
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 202
New value of Q matrix: 29.9963
New value of Value function: 29.9963
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 194
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 320
New value of Q matrix: 27.4644
New value of Value function: 27.4644
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1301
New value of Q matrix: 29.592
New value of Value function: 29.592
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 196
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 24.7189
New value of Value function: 29.9963
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 197
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 18.0123
New value of Value function: 26.8492
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 198
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 27.9917
New value of Value function: 27.9917
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 199
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 203
New value of Q matrix: 30.1502
New value of Value function: 30.1502
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 200
----------
State: 2337
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 321
New value of Q matrix: 27.3992
New value of Value function: 27.3992
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 459
New value of Q matrix: 24.5175
New value of Value function: 29.592
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 2
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 24.9614
New value of Value function: 24.9614
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1302
New value of Q matrix: 29.5974
New value of Value function: 29.5974
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 4
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 124
New value of Q matrix: 26.9362
New value of Value function: 26.9362
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 5
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 25.2538
New value of Value function: 25.2538
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1303
New value of Q matrix: 29.5993
New value of Value function: 29.5993
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 7
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 20.7285
New value of Value function: 26.9362
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1304
New value of Q matrix: 29.5459
New value of Value function: 29.5459
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 9
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 19.2044
New value of Value function: 24.9208
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1305
New value of Q matrix: 29.494
New value of Value function: 29.494
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 11
----------
State: 4377
	Distance: 10
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 28
New value of Q matrix: 26.0067
New value of Value function: 26.0067
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 12
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 125
New value of Q matrix: 26.8526
New value of Value function: 26.8526
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 13
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 25.4553
New value of Value function: 25.4553
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1306
New value of Q matrix: 29.4965
New value of Value function: 29.4965
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 15
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 22.3084
New value of Value function: 26.8526
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1307
New value of Q matrix: 29.499
New value of Value function: 29.499
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 17
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 126
New value of Q matrix: 26.7948
New value of Value function: 26.7948
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1308
New value of Q matrix: 29.4997
New value of Value function: 29.4997
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 19
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 127
New value of Q matrix: 26.7424
New value of Value function: 26.7424
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 27.1279
New value of Value function: 29.4997
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1309
New value of Q matrix: 29.4916
New value of Value function: 29.4916
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 27.2925
New value of Value function: 29.4916
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 25.7604
New value of Value function: 29.4916
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1310
New value of Q matrix: 29.4834
New value of Value function: 29.4834
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1311
New value of Q matrix: 29.4753
New value of Value function: 29.4753
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1312
New value of Q matrix: 29.4671
New value of Value function: 29.4671
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1313
New value of Q matrix: 29.459
New value of Value function: 29.459
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1314
New value of Q matrix: 29.4509
New value of Value function: 29.4509
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1315
New value of Q matrix: 29.4428
New value of Value function: 29.4428
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1316
New value of Q matrix: 29.4346
New value of Value function: 29.4346
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1317
New value of Q matrix: 29.4265
New value of Value function: 29.4265
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1318
New value of Q matrix: 29.4184
New value of Value function: 29.4184
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1319
New value of Q matrix: 29.4103
New value of Value function: 29.4103
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1320
New value of Q matrix: 29.4022
New value of Value function: 29.4022
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1321
New value of Q matrix: 29.3941
New value of Value function: 29.3941
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1322
New value of Q matrix: 29.3861
New value of Value function: 29.3861
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1323
New value of Q matrix: 29.378
New value of Value function: 29.378
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1324
New value of Q matrix: 29.3699
New value of Value function: 29.3699
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1325
New value of Q matrix: 29.3618
New value of Value function: 29.3618
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1326
New value of Q matrix: 29.3538
New value of Value function: 29.3538
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 27.4327
New value of Value function: 29.3538
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1327
New value of Q matrix: 29.3457
New value of Value function: 29.3457
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1328
New value of Q matrix: 29.3377
New value of Value function: 29.3377
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 460
New value of Q matrix: 24.7486
New value of Value function: 29.3377
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 45
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 128
New value of Q matrix: 27.2479
New value of Value function: 27.2479
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 46
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 117
New value of Q matrix: 27.301
New value of Value function: 27.301
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 47
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 30
New value of Q matrix: 22.9225
New value of Value function: 22.9225
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 48
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 118
New value of Q matrix: 27.9047
New value of Value function: 27.9047
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 49
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 66
New value of Q matrix: 28.8753
New value of Value function: 28.8753
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 50
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 23.5455
New value of Value function: 26.1783
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 51
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 15.9095
New value of Value function: 28.8753
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 52
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 29.1269
New value of Value function: 29.1269
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 53
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 21.0588
New value of Value function: 28.8753
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 54
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 22.7015
New value of Value function: 28.8753
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 55
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 67
New value of Q matrix: 29.6965
New value of Value function: 29.6965
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 56
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 21.5479
New value of Value function: 30.9061
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 57
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 68
New value of Q matrix: 29.3594
New value of Value function: 29.3594
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 58
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 26.1359
New value of Value function: 26.1359
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1329
New value of Q matrix: 29.4125
New value of Value function: 29.4125
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 60
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 69
New value of Q matrix: 30.1103
New value of Value function: 30.1103
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 61
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 36
New value of Q matrix: 30.1081
New value of Value function: 30.1081
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1330
New value of Q matrix: 29.5056
New value of Value function: 29.5056
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 63
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 18.7118
New value of Value function: 30.1103
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 64
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 31.021
New value of Value function: 31.021
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 65
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 70
New value of Q matrix: 30.6717
New value of Value function: 30.6717
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 66
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 37
New value of Q matrix: 30.4158
New value of Value function: 30.4158
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 67
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 24.5817
New value of Value function: 31.2926
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 68
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 38
New value of Q matrix: 30.6695
New value of Value function: 30.6695
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 69
----------
State: 2773
	Distance: 6
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 30.4296
New value of Value function: 30.4296
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 70
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 31.3783
New value of Value function: 31.3783
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 71
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 58
New value of Q matrix: 29.8499
New value of Value function: 29.8499
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1331
New value of Q matrix: 29.6306
New value of Value function: 29.6306
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 73
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 31.88
New value of Value function: 31.88
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 74
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 59
New value of Q matrix: 29.3922
New value of Value function: 29.3922
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1332
New value of Q matrix: 29.7657
New value of Value function: 29.7657
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 76
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 32.2265
New value of Value function: 32.2265
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 77
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 60
New value of Q matrix: 29.0147
New value of Value function: 29.0147
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1333
New value of Q matrix: 29.9064
New value of Value function: 29.9064
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 79
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 32.4576
New value of Value function: 32.4576
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 80
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 61
New value of Q matrix: 28.7065
New value of Value function: 28.7065
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1334
New value of Q matrix: 30.0495
New value of Value function: 30.0495
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 82
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 32.6043
New value of Value function: 32.6043
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 83
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 18.842
New value of Value function: 28.7065
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 84
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 19.7254
New value of Value function: 30.0083
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 85
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 29.4081
New value of Value function: 29.4081
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 86
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 30.0703
New value of Value function: 30.0703
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 87
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 62
New value of Q matrix: 30.9914
New value of Value function: 30.9914
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 88
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 43
New value of Q matrix: 41.8235
New value of Value function: 41.8235
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 89
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 34.7005
New value of Value function: 42.6081
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 90
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 35.3267
New value of Value function: 42.6081
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 91
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 44
New value of Q matrix: 41.5761
New value of Value function: 41.5761
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 92
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 44.2542
New value of Value function: 44.2542
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 93
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 54
New value of Q matrix: 44.8387
New value of Value function: 44.8387
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 94
----------
State: 1965
	Distance: 4
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 14.7178
New value of Value function: 22.4826
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 26.0951
New value of Value function: 30.0495
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1335
New value of Q matrix: 30.0413
New value of Value function: 30.0413
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1336
New value of Q matrix: 30.1409
New value of Value function: 30.1409
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 98
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 18.3771
New value of Value function: 30.9914
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 99
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 63
New value of Q matrix: 32.9025
New value of Value function: 32.9025
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 100
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 45
New value of Q matrix: 41.6112
New value of Value function: 41.6112
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 101
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 44.0846
New value of Value function: 44.0846
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 102
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 42.4633
New value of Value function: 42.4633
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 103
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 22.4518
New value of Value function: 44.8387
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 104
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 9.76341
New value of Value function: 34.2659
New value of Policy matrix: 0

=======================================
Simulation: 55
Iteration: 105
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 66.5142
New value of Value function: 66.5142
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 106
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 78.5483
New value of Value function: 78.5483
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 107
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 77.2352
New value of Value function: 77.2352
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 108
----------
State: 1485
	Distance: 3
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 52.4827
New value of Value function: 52.4827
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 109
----------
State: 1885
	Distance: 4
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 120
New value of Q matrix: 63.7004
New value of Value function: 63.7004
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 110
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 119
New value of Q matrix: 73.113
New value of Value function: 73.113
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 111
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 50
New value of Q matrix: 80.3189
New value of Value function: 80.3189
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 112
----------
State: 1445
	Distance: 3
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 20
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Simulation: 56
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1337
New value of Q matrix: 30.1327
New value of Value function: 30.1327
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1338
New value of Q matrix: 30.1244
New value of Value function: 30.1244
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1339
New value of Q matrix: 30.1162
New value of Value function: 30.1162
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1340
New value of Q matrix: 30.108
New value of Value function: 30.108
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 27.6204
New value of Value function: 30.108
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1341
New value of Q matrix: 30.0997
New value of Value function: 30.0997
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1342
New value of Q matrix: 30.0915
New value of Value function: 30.0915
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1343
New value of Q matrix: 30.0833
New value of Value function: 30.0833
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1344
New value of Q matrix: 30.0751
New value of Value function: 30.0751
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1345
New value of Q matrix: 30.0669
New value of Value function: 30.0669
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1346
New value of Q matrix: 30.0587
New value of Value function: 30.0587
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 26.9684
New value of Value function: 30.0587
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 27.1729
New value of Value function: 30.0587
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1347
New value of Q matrix: 30.0505
New value of Value function: 30.0505
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 461
New value of Q matrix: 24.9921
New value of Value function: 30.0505
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 16
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 23.5403
New value of Value function: 27.2479
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1348
New value of Q matrix: 30.0423
New value of Value function: 30.0423
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1349
New value of Q matrix: 30.0342
New value of Value function: 30.0342
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 462
New value of Q matrix: 25.2239
New value of Value function: 30.0342
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 20
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 129
New value of Q matrix: 27.7214
New value of Value function: 27.7214
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 21
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 119
New value of Q matrix: 27.5186
New value of Value function: 27.5186
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 22
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 31
New value of Q matrix: 23.5189
New value of Value function: 23.5189
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 23
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 21.0253
New value of Value function: 27.5186
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 24
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 32
New value of Q matrix: 24.0006
New value of Value function: 24.0006
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 25
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 120
New value of Q matrix: 27.0134
New value of Value function: 27.0134
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 26
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 20.2083
New value of Value function: 21.1965
New value of Policy matrix: 0

=======================================
Simulation: 56
Iteration: 27
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 28.1634
New value of Value function: 28.1634
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 28
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 30
New value of Q matrix: 22.2074
New value of Value function: 22.2074
New value of Policy matrix: 0

=======================================
Simulation: 56
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 27.7869
New value of Value function: 30.0342
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1350
New value of Q matrix: 30.026
New value of Value function: 30.026
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1351
New value of Q matrix: 30.0183
New value of Value function: 30.0183
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 32
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 121
New value of Q matrix: 26.8086
New value of Value function: 26.8086
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 33
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 33
New value of Q matrix: 24.2686
New value of Value function: 24.2686
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 34
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 122
New value of Q matrix: 27.5833
New value of Value function: 27.5833
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 35
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 71
New value of Q matrix: 30.221
New value of Value function: 30.221
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 36
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 26.3115
New value of Value function: 26.3115
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1352
New value of Q matrix: 30.0972
New value of Value function: 30.0972
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 38
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 72
New value of Q matrix: 29.8471
New value of Value function: 29.8471
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 39
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 26.4514
New value of Value function: 26.4514
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1353
New value of Q matrix: 30.1638
New value of Value function: 30.1638
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 41
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 73
New value of Q matrix: 29.5358
New value of Value function: 29.5358
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 42
----------
State: 3173
	Distance: 7
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 26.5653
New value of Value function: 26.5653
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1354
New value of Q matrix: 30.2203
New value of Value function: 30.2203
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 44
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 24.0956
New value of Value function: 29.5358
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 45
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 20.1018
New value of Value function: 29.5358
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 46
----------
State: 3933
	Distance: 9
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 18.5793
New value of Value function: 28.1634
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 47
----------
State: 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 31
New value of Q matrix: 23.0535
New value of Value function: 23.0535
New value of Policy matrix: 0

=======================================
Simulation: 56
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1355
New value of Q matrix: 30.1654
New value of Value function: 30.1654
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 49
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 23.1973
New value of Value function: 25.4553
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 50
----------
State: 4337
	Distance: 10
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 130
New value of Q matrix: 27.588
New value of Value function: 27.588
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 51
----------
State: 3977
	Distance: 9
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 26.1999
New value of Value function: 26.1999
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 52
----------
State: 3577
	Distance: 8
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 34
New value of Q matrix: 24.6183
New value of Value function: 24.6183
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 53
----------
State: 3937
	Distance: 9
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 8
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 123
New value of Q matrix: 27.2442
New value of Value function: 27.2442
New value of Policy matrix: 2

