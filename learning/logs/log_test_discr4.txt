=======================================
Simulation: 1
Iteration: 1
----------
State: 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5593
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 5593
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 5545
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 14
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 17
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.05988
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 18
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0597602
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 19
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 21
----------
State: 5497
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 23
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 24
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 26
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 27
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.03992
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00071856
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0791216
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 46
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 49
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 51
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 52
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06108
New value of Value function: 0.06108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 53
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 54
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 55
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 56
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06108
New value of Value function: 0.06108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 57
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 58
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 59
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 60
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 61
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109944
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 62
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0609384
New value of Value function: 0.0609384
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 63
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.11988
New value of Value function: 0.11988
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 64
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0610584
New value of Value function: 0.0610584
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 65
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 66
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 67
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00142419
New value of Value function: 0.00142419
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00212979
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00351138
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00212979
New value of Value function: 0.0791216
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0789634
New value of Value function: 0.0789634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00486249
New value of Value function: 0.0789634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00618659
New value of Value function: 0.0789634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00748419
New value of Value function: 0.0789634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00350853
New value of Value function: 0.0789634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0048597
New value of Value function: 0.0789634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0788054
New value of Value function: 0.0788054
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0021241
New value of Value function: 0.0788054
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00875301
New value of Value function: 0.0788054
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0786478
New value of Value function: 0.0786478
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0784905
New value of Value function: 0.0784905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00999078
New value of Value function: 0.0784905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00617534
New value of Value function: 0.0784905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00746466
New value of Value function: 0.0784905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0112038
New value of Value function: 0.0784905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0087282
New value of Value function: 0.0784905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0123925
New value of Value function: 0.0784905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00211702
New value of Value function: 0.0784905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0783335
New value of Value function: 0.0783335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00349162
New value of Value function: 0.0783335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00996364
New value of Value function: 0.0783335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0781769
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00482897
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0135519
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.014688
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00613958
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00742397
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0111715
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0123553
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00868267
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0158014
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0135154
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0099162
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0168926
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0179619
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00348186
New value of Value function: 0.0781769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0780205
New value of Value function: 0.0780205
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0111222
New value of Value function: 0.0780205
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0190071
New value of Value function: 0.0780205
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0778645
New value of Value function: 0.0778645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0200285
New value of Value function: 0.0778645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0123014
New value of Value function: 0.0778645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0210295
New value of Value function: 0.0778645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0220104
New value of Value function: 0.0778645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00481379
New value of Value function: 0.0778645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00611907
New value of Value function: 0.0778645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0229718
New value of Value function: 0.0778645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0777088
New value of Value function: 0.0777088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00739545
New value of Value function: 0.0777088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0146438
New value of Value function: 0.0777088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00864629
New value of Value function: 0.0777088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00987213
New value of Value function: 0.0777088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0134541
New value of Value function: 0.0777088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0145838
New value of Value function: 0.0777088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0157497
New value of Value function: 0.0777088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0775533
New value of Value function: 0.0775533
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0110706
New value of Value function: 0.0775533
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0239083
New value of Value function: 0.0775533
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0156881
New value of Value function: 0.0775533
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0167703
New value of Value function: 0.0775533
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0773982
New value of Value function: 0.0773982
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.017828
New value of Value function: 0.0773982
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0188646
New value of Value function: 0.0773982
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0772434
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0248205
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0168251
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0257145
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.017879
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0189118
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0198777
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0122396
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0133852
New value of Value function: 0.0772434
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0770889
New value of Value function: 0.0770889
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0265878
New value of Value function: 0.0770889
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0769348
New value of Value function: 0.0769348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0145023
New value of Value function: 0.0769348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0199184
New value of Value function: 0.0769348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.020865
New value of Value function: 0.0769348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0155971
New value of Value function: 0.0769348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0274409
New value of Value function: 0.0769348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0209048
New value of Value function: 0.0769348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0218716
New value of Value function: 0.0769348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0767809
New value of Value function: 0.0767809
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0766273
New value of Value function: 0.0766273
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.021827
New value of Value function: 0.0766273
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0764741
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0228107
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.022767
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0236882
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.023731
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0246329
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0166617
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0255168
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0245909
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0282686
New value of Value function: 0.0764741
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0763211
New value of Value function: 0.0763211
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0254729
New value of Value function: 0.0763211
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0263802
New value of Value function: 0.0763211
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.029077
New value of Value function: 0.0763211
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0298693
New value of Value function: 0.0763211
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0177022
New value of Value function: 0.0763211
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0761685
New value of Value function: 0.0761685
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0306429
New value of Value function: 0.0761685
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0272236
New value of Value function: 0.0761685
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0280502
New value of Value function: 0.0761685
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0760162
New value of Value function: 0.0760162
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0758641
New value of Value function: 0.0758641
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0757124
New value of Value function: 0.0757124
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.028852
New value of Value function: 0.0757124
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0313929
New value of Value function: 0.0757124
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.075561
New value of Value function: 0.075561
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0187083
New value of Value function: 0.075561
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0754098
New value of Value function: 0.0754098
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.075259
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0321197
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0196888
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0263181
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0271464
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0328319
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.03353
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.034214
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0348844
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0206497
New value of Value function: 0.075259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0751085
New value of Value function: 0.0751085
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0749583
New value of Value function: 0.0749583
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0748084
New value of Value function: 0.0748084
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0746588
New value of Value function: 0.0746588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0355306
New value of Value function: 0.0746588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0215805
New value of Value function: 0.0746588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0224928
New value of Value function: 0.0746588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0745094
New value of Value function: 0.0745094
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0361611
New value of Value function: 0.0745094
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0296162
New value of Value function: 0.0745094
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0743604
New value of Value function: 0.0743604
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0233814
New value of Value function: 0.0743604
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.027942
New value of Value function: 0.0743604
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0287216
New value of Value function: 0.0743604
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0294857
New value of Value function: 0.0743604
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0367764
New value of Value function: 0.0743604
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0303623
New value of Value function: 0.0743604
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0742117
New value of Value function: 0.0742117
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0740633
New value of Value function: 0.0740633
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0739152
New value of Value function: 0.0739152
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0302264
New value of Value function: 0.0739152
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0310855
New value of Value function: 0.0739152
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0242443
New value of Value function: 0.0739152
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0737673
New value of Value function: 0.0737673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0373687
New value of Value function: 0.0737673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0317916
New value of Value function: 0.0737673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0250872
New value of Value function: 0.0737673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0324836
New value of Value function: 0.0737673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0331618
New value of Value function: 0.0737673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0338263
New value of Value function: 0.0737673
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0736198
New value of Value function: 0.0736198
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0259106
New value of Value function: 0.0736198
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 0.112147
New value of Value function: 0.112147
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 228
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00201865
New value of Value function: 0.00201865
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0316405
New value of Value function: 0.112147
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0351685
New value of Value function: 0.112147
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.03864
New value of Value function: 0.112147
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.027411
New value of Value function: 0.112147
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0364837
New value of Value function: 0.112147
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0330264
New value of Value function: 0.112147
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0377727
New value of Value function: 0.112147
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.111923
New value of Value function: 0.111923
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0398818
New value of Value function: 0.111923
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0410988
New value of Value function: 0.111923
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.111699
New value of Value function: 0.111699
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0288734
New value of Value function: 0.111699
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.111476
New value of Value function: 0.111476
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 45
New value of Q matrix: 0.149283
New value of Value function: 0.149283
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 243
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00201865
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 244
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 245
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 246
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 247
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00268709
New value of Value function: 0.00268709
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.035053
New value of Value function: 0.149283
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0429639
New value of Value function: 0.149283
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0447917
New value of Value function: 0.149283
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.148984
New value of Value function: 0.148984
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.148686
New value of Value function: 0.148686
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0396936
New value of Value function: 0.148686
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 48
New value of Q matrix: 0.185761
New value of Value function: 0.185761
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 255
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.83676e-05
New value of Value function: 0.00268709
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 256
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00597704
New value of Value function: 0.00597704
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0422434
New value of Value function: 0.185761
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0472395
New value of Value function: 0.185761
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0447423
New value of Value function: 0.185761
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.185389
New value of Value function: 0.185389
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0376889
New value of Value function: 0.185389
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0402721
New value of Value function: 0.185389
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 50
New value of Q matrix: 0.221681
New value of Value function: 0.221681
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 264
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00399027
New value of Value function: 0.00399027
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.050285
New value of Value function: 0.221681
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.221238
New value of Value function: 0.221238
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 0.0794667
New value of Value function: 0.221238
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 268
----------
State: 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5833
	Distance: 10
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 269
----------
State: 5833
	Distance: 10
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0601076
New value of Value function: 0.0601076
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 270
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.18248e-05
New value of Value function: 0.00597704
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 271
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.064018
New value of Value function: 0.064018
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 272
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000154987
New value of Value function: 0.00597704
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 273
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00983979
New value of Value function: 0.00983979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 52
New value of Q matrix: 0.25699
New value of Value function: 0.25699
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 275
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00122271
New value of Value function: 0.00983979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 276
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5881
	Distance: 10
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.064018
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 277
----------
State: 5881
	Distance: 10
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0601771
New value of Value function: 0.0601771
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 278
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000329003
New value of Value function: 0.00983979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 279
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000177116
New value of Value function: 0.00983979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 280
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000177116
New value of Value function: 0.00983979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 281
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0142688
New value of Value function: 0.0142688
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0825032
New value of Value function: 0.25699
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 53
New value of Q matrix: 0.292107
New value of Value function: 0.292107
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 284
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0192414
New value of Value function: 0.0192414
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0545373
New value of Value function: 0.292107
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.291523
New value of Value function: 0.291523
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 55
New value of Q matrix: 0.326039
New value of Value function: 0.326039
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 288
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000173574
New value of Value function: 0.0192414
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 289
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 290
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 291
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0611523
New value of Value function: 0.0611523
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 292
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0686064
New value of Value function: 0.0686064
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0497161
New value of Value function: 0.326039
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0341646
New value of Value function: 0.326039
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0393501
New value of Value function: 0.326039
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0867218
New value of Value function: 0.326039
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 56
New value of Q matrix: 0.360753
New value of Value function: 0.360753
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 298
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00123492
New value of Value function: 0.0686064
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 299
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0623097
New value of Value function: 0.0686064
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 300
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 301
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 302
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 303
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 304
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06108
New value of Value function: 0.06108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 305
----------
State: 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109944
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 306
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0588
New value of Value function: 0.06108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 307
----------
State: 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0410994
New value of Value function: 0.0410994
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 308
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00110074
New value of Value function: 0.06108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 309
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00110074
New value of Value function: 0.0611523
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 310
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00109944
New value of Value function: 0.0611523
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 311
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0598584
New value of Value function: 0.0598584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 312
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 313
----------
State: 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 314
----------
State: 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 315
----------
State: 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 316
----------
State: 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 317
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 318
----------
State: 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0410775
New value of Value function: 0.0410775
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 319
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0583638
New value of Value function: 0.0598584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 320
----------
State: 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0410775
New value of Value function: 0.0410994
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 321
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00217947
New value of Value function: 0.0598584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 322
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5881
	Distance: 10
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0610125
New value of Value function: 0.0610125
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 323
----------
State: 5881
	Distance: 10
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0610994
New value of Value function: 0.0610994
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 324
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00123492
New value of Value function: 0.06108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 325
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.0686064
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 326
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109822
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 327
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0021549
New value of Value function: 0.0610125
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 328
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0579359
New value of Value function: 0.0598584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 329
----------
State: 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 313
	Distance: 0
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0410775
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 330
----------
State: 313
	Distance: 0
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 313
	Distance: 0
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 331
----------
State: 313
	Distance: 0
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 332
----------
State: 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 333
----------
State: 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 334
----------
State: 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 335
----------
State: 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 336
----------
State: 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000739394
New value of Value function: 0.000739394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 337
----------
State: 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.0410775
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 338
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.33091e-05
New value of Value function: 1.33091e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 339
----------
State: 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.000739394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 340
----------
State: 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 361
	Distance: 0
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 341
----------
State: 361
	Distance: 0
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 342
----------
State: 6121
	Distance: 10
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 361
	Distance: 0
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 343
----------
State: 361
	Distance: 0
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 313
	Distance: 0
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 344
----------
State: 313
	Distance: 0
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000739394
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 345
----------
State: 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0400002
New value of Value function: 0.0410775
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 346
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107745
New value of Value function: 0.00107745
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 347
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0632159
New value of Value function: 0.0632159
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 348
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00215626
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 349
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00321136
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 350
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5881
	Distance: 10
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00217852
New value of Value function: 0.0610125
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 351
----------
State: 5881
	Distance: 10
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.120977
New value of Value function: 0.120977
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 352
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000346345
New value of Value function: 0.06108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 353
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000668768
New value of Value function: 0.0192414
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 354
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0253501
New value of Value function: 0.0253501
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0450566
New value of Value function: 0.360753
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.050649
New value of Value function: 0.360753
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 57
New value of Q matrix: 0.393538
New value of Value function: 0.393538
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 358
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00708369
New value of Value function: 0.00708369
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 58
New value of Q matrix: 0.426767
New value of Value function: 0.426767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 360
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00802122
New value of Value function: 0.06108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0564036
New value of Value function: 0.426767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 0.125444
New value of Value function: 0.426767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 363
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0325249
New value of Value function: 0.0325249
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 59
New value of Q matrix: 0.458817
New value of Value function: 0.458817
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 365
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0401331
New value of Value function: 0.0401331
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0578948
New value of Value function: 0.458817
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.0617052
New value of Value function: 0.458817
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.457899
New value of Value function: 0.457899
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.456984
New value of Value function: 0.456984
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 40
New value of Q matrix: 0.163657
New value of Value function: 0.456984
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 371
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0475562
New value of Value function: 0.0475562
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0649626
New value of Value function: 0.456984
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.45607
New value of Value function: 0.45607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 63
New value of Q matrix: 0.488048
New value of Value function: 0.488048
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 375
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0166457
New value of Value function: 0.06108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 0.20124
New value of Value function: 0.488048
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 377
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0553899
New value of Value function: 0.0553899
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 64
New value of Q matrix: 0.519284
New value of Value function: 0.519284
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 379
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00952068
New value of Value function: 0.0553899
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 42
New value of Q matrix: 0.237343
New value of Value function: 0.519284
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 381
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109944
New value of Value function: 0.00708369
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 382
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0764402
New value of Value function: 0.0764402
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 383
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00934711
New value of Value function: 0.00934711
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 65
New value of Q matrix: 0.549066
New value of Value function: 0.549066
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 385
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0168252
New value of Value function: 0.0168252
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.0703543
New value of Value function: 0.549066
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.547968
New value of Value function: 0.547968
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0735268
New value of Value function: 0.547968
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0819196
New value of Value function: 0.547968
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 67
New value of Q matrix: 0.578006
New value of Value function: 0.578006
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 391
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0609582
New value of Value function: 0.0609582
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 392
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000302854
New value of Value function: 0.0168252
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 393
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0195643
New value of Value function: 0.0195643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.0793513
New value of Value function: 0.578006
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0656796
New value of Value function: 0.578006
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.57685
New value of Value function: 0.57685
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.242979
New value of Value function: 0.57685
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0747493
New value of Value function: 0.57685
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0906645
New value of Value function: 0.57685
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 69
New value of Q matrix: 0.605665
New value of Value function: 0.605665
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 401
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.030075
New value of Value function: 0.030075
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.249022
New value of Value function: 0.605665
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 70
New value of Q matrix: 0.634928
New value of Value function: 0.634928
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 404
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0863401
New value of Value function: 0.0863401
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 45
New value of Q matrix: 0.285138
New value of Value function: 0.634928
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 406
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00275238
New value of Value function: 0.0609582
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 407
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0857106
New value of Value function: 0.0857106
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 408
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0657108
New value of Value function: 0.0657108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 71
New value of Q matrix: 0.663412
New value of Value function: 0.663412
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 410
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.076338
New value of Value function: 0.076338
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 72
New value of Q matrix: 0.691518
New value of Value function: 0.691518
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 412
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00154419
New value of Value function: 0.076338
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 413
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0872585
New value of Value function: 0.0872585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 73
New value of Q matrix: 0.719258
New value of Value function: 0.719258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 415
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0109009
New value of Value function: 0.0872585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 416
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00308396
New value of Value function: 0.0872585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 417
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00302228
New value of Value function: 0.0872585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 418
----------
State: 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0615707
New value of Value function: 0.0615707
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 419
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0613097
New value of Value function: 0.0872585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 420
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0616542
New value of Value function: 0.0872585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 421
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00393225
New value of Value function: 0.0872585
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 422
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.128805
New value of Value function: 0.128805
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 423
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.09846
New value of Value function: 0.09846
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.086201
New value of Value function: 0.719258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 74
New value of Q matrix: 0.746645
New value of Value function: 0.746645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 426
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00473411
New value of Value function: 0.09846
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 427
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.10993
New value of Value function: 0.10993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.0912039
New value of Value function: 0.746645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.102819
New value of Value function: 0.746645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.745152
New value of Value function: 0.745152
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.743662
New value of Value function: 0.743662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.114149
New value of Value function: 0.743662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.102237
New value of Value function: 0.743662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.292822
New value of Value function: 0.743662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.300351
New value of Value function: 0.743662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0978629
New value of Value function: 0.743662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.113578
New value of Value function: 0.743662
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.742174
New value of Value function: 0.742174
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.124666
New value of Value function: 0.742174
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.307703
New value of Value function: 0.742174
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 78
New value of Q matrix: 0.768439
New value of Value function: 0.768439
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 442
----------
State: 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0138319
New value of Value function: 0.0615707
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.109738
New value of Value function: 0.768439
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.315381
New value of Value function: 0.768439
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 79
New value of Q matrix: 0.795049
New value of Value function: 0.795049
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 446
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00695792
New value of Value function: 0.10993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 447
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.14054
New value of Value function: 0.14054
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.121854
New value of Value function: 0.795049
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.126177
New value of Value function: 0.795049
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.133727
New value of Value function: 0.795049
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.145364
New value of Value function: 0.795049
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.793459
New value of Value function: 0.793459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.156739
New value of Value function: 0.793459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.167886
New value of Value function: 0.793459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.178811
New value of Value function: 0.793459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.323356
New value of Value function: 0.793459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.189517
New value of Value function: 0.793459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 81
New value of Q matrix: 0.820119
New value of Value function: 0.820119
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 459
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.152491
New value of Value function: 0.152491
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.200489
New value of Value function: 0.820119
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.211241
New value of Value function: 0.820119
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.136935
New value of Value function: 0.820119
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 82
New value of Q matrix: 0.846462
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 464
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.164678
New value of Value function: 0.164678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.13889
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.222253
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.149432
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.16168
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.151348
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.332125
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.233044
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.340719
New value of Value function: 0.846462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.844769
New value of Value function: 0.844769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.34911
New value of Value function: 0.844769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.163527
New value of Value function: 0.844769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.175462
New value of Value function: 0.844769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.173652
New value of Value function: 0.844769
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.843079
New value of Value function: 0.843079
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.841393
New value of Value function: 0.841393
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.243528
New value of Value function: 0.841393
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.253803
New value of Value function: 0.841393
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.83971
New value of Value function: 0.83971
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 87
New value of Q matrix: 0.86588
New value of Value function: 0.86588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 484
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.17697
New value of Value function: 0.17697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.264312
New value of Value function: 0.86588
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 88
New value of Q matrix: 0.891748
New value of Value function: 0.891748
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 487
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0642489
New value of Value function: 0.17697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 488
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021384
New value of Value function: 0.17697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 489
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00073979
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 490
----------
State: 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04108
New value of Value function: 0.0410994
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 491
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0619855
New value of Value function: 0.0619855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 492
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00318546
New value of Value function: 0.17697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 493
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00321137
New value of Value function: 0.17697
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 494
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00186288
New value of Value function: 0.0619855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 495
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.124109
New value of Value function: 0.124109
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 496
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109822
New value of Value function: 0.11988
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 497
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0621312
New value of Value function: 0.0621312
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 498
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00073979
New value of Value function: 0.00108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 499
----------
State: 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.042234
New value of Value function: 0.042234
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 500
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0590112
New value of Value function: 0.124109
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 501
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.182743
New value of Value function: 0.182743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 502
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0639312
New value of Value function: 0.0639312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 503
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.189482
New value of Value function: 0.189482
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 89
New value of Q matrix: 0.917324
New value of Value function: 0.917324
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 505
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0042979
New value of Value function: 0.189482
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 506
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00115076
New value of Value function: 0.0639312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 507
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0660633
New value of Value function: 0.0660633
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 508
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.202204
New value of Value function: 0.202204
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 90
New value of Q matrix: 0.940086
New value of Value function: 0.940086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 510
----------
State: 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00110827
New value of Value function: 0.0615707
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 511
----------
State: 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00118914
New value of Value function: 0.0615707
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 512
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00118914
New value of Value function: 0.0660633
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 513
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0683817
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 514
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00423002
New value of Value function: 0.202204
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 515
----------
State: 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.122318
New value of Value function: 0.122318
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 516
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00601144
New value of Value function: 0.10993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 517
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.119461
New value of Value function: 0.119461
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 518
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0623999
New value of Value function: 0.10993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 519
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0128846
New value of Value function: 0.10993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 520
----------
State: 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.179908
New value of Value function: 0.179908
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 521
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00197875
New value of Value function: 0.00201865
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 522
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.124653
New value of Value function: 0.124653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.188875
New value of Value function: 0.940086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.202019
New value of Value function: 0.940086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.187101
New value of Value function: 0.940086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.359049
New value of Value function: 0.940086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.20028
New value of Value function: 0.940086
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.938206
New value of Value function: 0.938206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.936329
New value of Value function: 0.936329
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.27588
New value of Value function: 0.936329
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 93
New value of Q matrix: 0.959846
New value of Value function: 0.959846
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 532
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.139438
New value of Value function: 0.139438
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.213552
New value of Value function: 0.959846
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.226558
New value of Value function: 0.959846
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.940649
New value of Value function: 0.940649
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 536
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 537
----------
State: 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0169317
New value of Value function: 0.0169317
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 95
New value of Q matrix: 0.963379
New value of Value function: 0.963379
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 539
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00154279
New value of Value function: 0.0857106
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 540
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00275301
New value of Value function: 0.0857106
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 541
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0865063
New value of Value function: 0.0865063
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 542
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00744833
New value of Value function: 0.139438
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 543
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00633762
New value of Value function: 0.0865063
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 544
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.26067
New value of Value function: 0.26067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 545
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.121693
New value of Value function: 0.139438
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 546
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0468143
New value of Value function: 0.0468143
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 96
New value of Q matrix: 0.984954
New value of Value function: 0.984954
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 548
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0164887
New value of Value function: 0.0468143
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 549
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0415571
New value of Value function: 0.0415571
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 550
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0855242
New value of Value function: 0.0855242
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 551
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0177292
New value of Value function: 0.0415571
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.288092
New value of Value function: 0.984954
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.966003
New value of Value function: 0.966003
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 554
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000748028
New value of Value function: 0.0415571
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 555
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0347627
New value of Value function: 0.0415571
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.299718
New value of Value function: 0.966003
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.947431
New value of Value function: 0.947431
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 558
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0014811
New value of Value function: 0.0415571
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 559
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0408427
New value of Value function: 0.0415571
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 560
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00250988
New value of Value function: 0.0468143
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 561
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.153703
New value of Value function: 0.153703
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.310777
New value of Value function: 0.947431
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 99
New value of Q matrix: 0.969325
New value of Value function: 0.969325
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 564
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0633258
New value of Value function: 0.0633258
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 100
New value of Q matrix: 0.991079
New value of Value function: 0.991079
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 566
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00522632
New value of Value function: 0.0633258
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 567
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00958541
New value of Value function: 0.153703
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 568
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0121603
New value of Value function: 0.153703
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 569
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.168468
New value of Value function: 0.168468
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.215818
New value of Value function: 0.991079
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.322401
New value of Value function: 0.991079
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.989096
New value of Value function: 0.989096
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.369672
New value of Value function: 0.989096
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.239831
New value of Value function: 0.989096
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.333757
New value of Value function: 0.989096
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.252838
New value of Value function: 0.989096
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 102
New value of Q matrix: 1.01235
New value of Value function: 1.01235
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 578
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.183321
New value of Value function: 0.183321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.380501
New value of Value function: 1.01235
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.229724
New value of Value function: 1.01235
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 1.01032
New value of Value function: 1.01032
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 104
New value of Q matrix: 1.03335
New value of Value function: 1.03335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 583
----------
State: 5257
	Distance: 9
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00585741
New value of Value function: 0.179908
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 584
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00750132
New value of Value function: 0.26067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 585
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0611203
New value of Value function: 0.182743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 586
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600194
New value of Value function: 0.182743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 587
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00434777
New value of Value function: 0.00434777
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 588
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0586806
New value of Value function: 0.182743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 589
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.6352e-05
New value of Value function: 0.00107745
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 590
----------
State: 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.33091e-05
New value of Value function: 0.000739394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 591
----------
State: 6073
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000744
New value of Value function: 0.000744
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 592
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.93941e-05
New value of Value function: 0.00107745
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 593
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000739394
New value of Value function: 0.00107745
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 594
----------
State: 265
	Distance: 0
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0400194
New value of Value function: 0.0410775
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 595
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00181611
New value of Value function: 0.00181611
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 596
----------
State: 217
	Distance: 0
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0846787
New value of Value function: 0.0846787
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 597
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118897
New value of Value function: 0.182743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 598
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00328937
New value of Value function: 0.00434777
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 599
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5881
	Distance: 10
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.181266
New value of Value function: 0.181266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 600
----------
State: 5881
	Distance: 10
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.183249
New value of Value function: 0.183249
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 601
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0656849
New value of Value function: 0.26067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 602
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00305137
New value of Value function: 0.0855242
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 603
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.144954
New value of Value function: 0.144954
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 604
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0194587
New value of Value function: 0.0633258
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 605
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.013375
New value of Value function: 0.183321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 606
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0526678
New value of Value function: 0.0526678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.24373
New value of Value function: 1.03335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 1.03129
New value of Value function: 1.03129
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.257418
New value of Value function: 1.03129
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 1.02922
New value of Value function: 1.02922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.391417
New value of Value function: 1.02922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.270796
New value of Value function: 1.02922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.345608
New value of Value function: 1.02922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 1.02717
New value of Value function: 1.02717
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.283869
New value of Value function: 1.02717
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.29668
New value of Value function: 1.02717
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 1.02511
New value of Value function: 1.02511
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.266233
New value of Value function: 1.02511
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 619
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 1.02306
New value of Value function: 1.02306
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.279324
New value of Value function: 1.02306
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 1.02102
New value of Value function: 1.02102
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 111
New value of Q matrix: 1.0432
New value of Value function: 1.0432
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 623
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.160832
New value of Value function: 0.160832
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.357473
New value of Value function: 1.0432
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.384537
New value of Value function: 1.0432
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 626
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0703921
New value of Value function: 0.0703921
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 627
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 1.02361
New value of Value function: 1.02361
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 628
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0874092
New value of Value function: 0.0874092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 1.00471
New value of Value function: 1.00471
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 630
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.103746
New value of Value function: 0.103746
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.986482
New value of Value function: 0.986482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 632
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0811657
New value of Value function: 0.103746
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 633
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.020937
New value of Value function: 0.0633258
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 634
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0033189
New value of Value function: 0.103746
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 635
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00511994
New value of Value function: 0.103746
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 636
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0836209
New value of Value function: 0.103746
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 637
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.159483
New value of Value function: 0.159483
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 638
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.119428
New value of Value function: 0.119428
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.968902
New value of Value function: 0.968902
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 640
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.134479
New value of Value function: 0.134479
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.291177
New value of Value function: 0.968902
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.394286
New value of Value function: 0.968902
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.951945
New value of Value function: 0.951945
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 644
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.120682
New value of Value function: 0.134479
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 645
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0791943
New value of Value function: 0.0791943
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.367459
New value of Value function: 0.951945
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 117
New value of Q matrix: 0.976206
New value of Value function: 0.976206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 648
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0155281
New value of Value function: 0.183321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 649
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.149361
New value of Value function: 0.149361
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.95937
New value of Value function: 0.95937
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 651
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00770605
New value of Value function: 0.149361
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 652
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.163643
New value of Value function: 0.163643
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5833
	Distance: 10
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 119
New value of Q matrix: 0.981264
New value of Value function: 0.981264
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 654
----------
State: 5833
	Distance: 10
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0176628
New value of Value function: 0.0601076
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.389346
New value of Value function: 0.981264
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 656
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.178033
New value of Value function: 0.178033
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.30841
New value of Value function: 0.981264
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.979302
New value of Value function: 0.979302
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.96292
New value of Value function: 0.96292
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 660
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.191805
New value of Value function: 0.191805
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.398892
New value of Value function: 0.96292
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.408246
New value of Value function: 0.96292
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.319574
New value of Value function: 0.96292
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.960995
New value of Value function: 0.960995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.33048
New value of Value function: 0.960995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.377407
New value of Value function: 0.960995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.387157
New value of Value function: 0.960995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.959073
New value of Value function: 0.959073
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.341134
New value of Value function: 0.959073
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.302617
New value of Value function: 0.959073
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.957155
New value of Value function: 0.957155
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 125
New value of Q matrix: 0.981311
New value of Value function: 0.981311
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 673
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0152169
New value of Value function: 0.183321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 674
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0119914
New value of Value function: 0.183321
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 675
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00846966
New value of Value function: 0.26067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 676
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0609213
New value of Value function: 0.0610125
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 677
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00287802
New value of Value function: 0.00287802
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 678
----------
State: 5929
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0612309
New value of Value function: 0.0612309
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 679
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00187743
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 680
----------
State: 6025
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0640513
New value of Value function: 0.0640513
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 681
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00235862
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 682
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00354231
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 683
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00510266
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 684
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0631607
New value of Value function: 0.181266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 685
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.238871
New value of Value function: 0.238871
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 686
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00470234
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 687
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0667586
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 688
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00230713
New value of Value function: 0.119461
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 689
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00239623
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 690
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00930029
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 691
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.118587
New value of Value function: 0.238871
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 692
----------
State: 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00537713
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 693
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.295325
New value of Value function: 0.295325
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 694
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0666543
New value of Value function: 0.0683817
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 695
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.127472
New value of Value function: 0.127472
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 696
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021503
New value of Value function: 0.119461
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 697
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.119943
New value of Value function: 0.119943
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 698
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0627291
New value of Value function: 0.159483
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 699
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.173957
New value of Value function: 0.173957
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.397078
New value of Value function: 0.981311
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.314228
New value of Value function: 0.981311
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.351975
New value of Value function: 0.981311
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 703
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.362599
New value of Value function: 0.981311
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.373011
New value of Value function: 0.981311
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.325607
New value of Value function: 0.981311
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.979349
New value of Value function: 0.979349
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.97739
New value of Value function: 0.97739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.406729
New value of Value function: 0.97739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.383144
New value of Value function: 0.97739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.416188
New value of Value function: 0.97739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.975435
New value of Value function: 0.975435
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 712
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.973484
New value of Value function: 0.973484
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.417604
New value of Value function: 0.973484
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.393003
New value of Value function: 0.973484
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 715
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.971537
New value of Value function: 0.971537
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 716
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.336583
New value of Value function: 0.971537
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 131
New value of Q matrix: 0.993532
New value of Value function: 0.993532
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 718
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00172229
New value of Value function: 0.0791943
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 719
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021765
New value of Value function: 0.0791943
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 720
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0629685
New value of Value function: 0.0629685
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 721
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.230514
New value of Value function: 0.230514
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 722
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0198619
New value of Value function: 0.0198619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 132
New value of Q matrix: 1.01402
New value of Value function: 1.01402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 724
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00113343
New value of Value function: 0.0198619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 725
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00219183
New value of Value function: 0.0629685
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 726
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0628425
New value of Value function: 0.0628425
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 727
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.062148
New value of Value function: 0.0628425
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 728
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000357513
New value of Value function: 0.000357513
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 729
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000357513
New value of Value function: 0.0198619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 730
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00224193
New value of Value function: 0.0198619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 731
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0627168
New value of Value function: 0.0627168
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 732
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.121482
New value of Value function: 0.121482
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 733
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.43524e-06
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 734
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00218667
New value of Value function: 0.00218667
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 735
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.179072
New value of Value function: 0.179072
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 736
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.56667e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 737
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4677
	Distance: 8
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000350363
New value of Value function: 0.00218667
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 738
----------
State: 4677
	Distance: 8
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0182523
New value of Value function: 0.0182523
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.427504
New value of Value function: 1.01402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.426116
New value of Value function: 1.01402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.435846
New value of Value function: 1.01402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 133
New value of Q matrix: 1.03376
New value of Value function: 1.03376
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 743
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0200035
New value of Value function: 0.0200035
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 134
New value of Q matrix: 1.05345
New value of Value function: 1.05345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 745
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0385655
New value of Value function: 0.0385655
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.446091
New value of Value function: 1.05345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.437916
New value of Value function: 1.05345
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 135
New value of Q matrix: 1.07274
New value of Value function: 1.07274
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 749
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000357513
New value of Value function: 0.0198619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 750
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00104454
New value of Value function: 0.0198619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 751
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000694178
New value of Value function: 0.0385655
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 752
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00137447
New value of Value function: 0.0385655
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 753
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000357513
New value of Value function: 0.0385655
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 754
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0387739
New value of Value function: 0.0387739
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 136
New value of Q matrix: 1.09198
New value of Value function: 1.09198
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 756
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00104454
New value of Value function: 0.0387739
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 757
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00104829
New value of Value function: 0.0385655
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 758
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0576541
New value of Value function: 0.0576541
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.456825
New value of Value function: 1.09198
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 760
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 137
New value of Q matrix: 1.11157
New value of Value function: 1.11157
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 761
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0976186
New value of Value function: 0.0976186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 138
New value of Q matrix: 1.13109
New value of Value function: 1.13109
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 763
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0661596
New value of Value function: 0.0976186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 764
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0768606
New value of Value function: 0.0768606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.405503
New value of Value function: 1.13109
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 1.12883
New value of Value function: 1.12883
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 140
New value of Q matrix: 1.14764
New value of Value function: 1.14764
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 768
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00542038
New value of Value function: 0.0768606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 769
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.178714
New value of Value function: 0.178714
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 770
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.235179
New value of Value function: 0.235179
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 771
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021823
New value of Value function: 0.0021823
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 772
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00423322
New value of Value function: 0.00423322
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 773
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.119494
New value of Value function: 0.235179
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 774
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000694178
New value of Value function: 0.0385655
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 775
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0584516
New value of Value function: 0.0584516
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 141
New value of Q matrix: 1.16574
New value of Value function: 1.16574
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 777
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00207946
New value of Value function: 0.0584516
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 778
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00239911
New value of Value function: 0.0584516
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 779
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0782659
New value of Value function: 0.0782659
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.468672
New value of Value function: 1.16574
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.480282
New value of Value function: 1.16574
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 142
New value of Q matrix: 1.18383
New value of Value function: 1.18383
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 783
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00423322
New value of Value function: 0.0782659
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 784
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00529162
New value of Value function: 0.235179
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 785
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.290551
New value of Value function: 0.290551
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 786
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00736858
New value of Value function: 0.00736858
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 787
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00321737
New value of Value function: 0.290551
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 788
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00426626
New value of Value function: 0.119943
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 789
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.182774
New value of Value function: 0.182774
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 790
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00933504
New value of Value function: 0.290551
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 791
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.287287
New value of Value function: 0.287287
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 792
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00240714
New value of Value function: 0.0768606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 793
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00369631
New value of Value function: 0.0768606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 794
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.116975
New value of Value function: 0.116975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.491985
New value of Value function: 1.18383
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.418702
New value of Value function: 1.18383
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 1.18146
New value of Value function: 1.18146
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 144
New value of Q matrix: 1.19994
New value of Value function: 1.19994
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 799
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0054229
New value of Value function: 0.116975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 800
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.241224
New value of Value function: 0.241224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 801
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.136235
New value of Value function: 0.136235
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.35145
New value of Value function: 1.19994
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 145
New value of Q matrix: 1.21839
New value of Value function: 1.21839
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 804
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.155441
New value of Value function: 0.155441
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 146
New value of Q matrix: 1.23541
New value of Value function: 1.23541
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 806
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0975608
New value of Value function: 0.0975608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.366658
New value of Value function: 1.23541
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 147
New value of Q matrix: 1.2535
New value of Value function: 1.2535
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 809
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00448579
New value of Value function: 0.155441
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 810
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.0822743
New value of Value function: 0.155441
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 811
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00132842
New value of Value function: 0.0975608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 812
----------
State: 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0452299
New value of Value function: 0.0452299
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 813
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00423302
New value of Value function: 0.290551
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 814
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118933
New value of Value function: 0.118933
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 815
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00115749
New value of Value function: 0.00736858
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 816
----------
State: 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.022563
New value of Value function: 0.0452299
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 1.22924
New value of Value function: 1.22924
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 818
----------
State: 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0442381
New value of Value function: 0.0452299
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 1.20547
New value of Value function: 1.20547
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 820
----------
State: 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0417561
New value of Value function: 0.0452299
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 821
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00642032
New value of Value function: 0.0975608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 822
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.142385
New value of Value function: 0.155441
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 823
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0105419
New value of Value function: 0.0975608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 824
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.28997
New value of Value function: 0.28997
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 825
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.34419
New value of Value function: 0.34419
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 826
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000132634
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 827
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00214079
New value of Value function: 0.00736858
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 828
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.116554
New value of Value function: 0.116554
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 829
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0601326
New value of Value function: 0.0601326
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 830
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00428119
New value of Value function: 0.00736858
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 831
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0134166
New value of Value function: 0.0134166
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 832
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00849039
New value of Value function: 0.34419
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 833
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.302595
New value of Value function: 0.302595
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 834
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0671005
New value of Value function: 0.34419
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 835
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.397326
New value of Value function: 0.397326
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 836
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00719662
New value of Value function: 0.00719662
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 837
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.449621
New value of Value function: 0.449621
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 838
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0133898
New value of Value function: 0.0133898
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 839
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00443658
New value of Value function: 0.0133898
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 840
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.012441
New value of Value function: 0.0133898
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 841
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.448722
New value of Value function: 0.448722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 842
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0172253
New value of Value function: 0.448722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 843
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0738354
New value of Value function: 0.448722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 844
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.17886
New value of Value function: 0.448722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 845
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00411509
New value of Value function: 0.0975608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 846
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00578889
New value of Value function: 0.0975608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 847
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0074292
New value of Value function: 0.0975608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 848
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0155022
New value of Value function: 0.0975608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 849
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.343298
New value of Value function: 0.343298
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 850
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.117308
New value of Value function: 0.117308
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.503844
New value of Value function: 1.20547
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.432026
New value of Value function: 1.20547
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.445084
New value of Value function: 1.20547
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.381024
New value of Value function: 1.20547
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 1.20306
New value of Value function: 1.20306
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 1.20065
New value of Value function: 1.20065
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 1.19825
New value of Value function: 1.19825
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 153
New value of Q matrix: 1.21453
New value of Value function: 1.21453
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 859
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0229959
New value of Value function: 0.0229959
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 154
New value of Q matrix: 1.23065
New value of Value function: 1.23065
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 861
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0135359
New value of Value function: 0.0229959
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 862
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0446877
New value of Value function: 0.0446877
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 155
New value of Q matrix: 1.24684
New value of Value function: 1.24684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 864
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0662371
New value of Value function: 0.0662371
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.458626
New value of Value function: 1.24684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.395846
New value of Value function: 1.24684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.51621
New value of Value function: 1.24684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.471896
New value of Value function: 1.24684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 1.24435
New value of Value function: 1.24435
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.528284
New value of Value function: 1.24435
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.451556
New value of Value function: 1.24435
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.484857
New value of Value function: 1.24435
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 1.24186
New value of Value function: 1.24186
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 1.23938
New value of Value function: 1.23938
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 159
New value of Q matrix: 1.25578
New value of Value function: 1.25578
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 876
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0875165
New value of Value function: 0.0875165
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.497764
New value of Value function: 1.25578
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 1.25327
New value of Value function: 1.25327
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 161
New value of Q matrix: 1.26978
New value of Value function: 1.26978
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 880
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0148405
New value of Value function: 0.0875165
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 881
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.108622
New value of Value function: 0.108622
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 162
New value of Q matrix: 1.28634
New value of Value function: 1.28634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 883
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0183716
New value of Value function: 0.108622
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 884
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.337246
New value of Value function: 0.337246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 885
----------
State: 69
	Distance: 0
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0924023
New value of Value function: 0.0924023
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 886
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.178736
New value of Value function: 0.448722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 887
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.211123
New value of Value function: 0.211123
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.411084
New value of Value function: 1.28634
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 1.28377
New value of Value function: 1.28377
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.465633
New value of Value function: 1.28377
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 164
New value of Q matrix: 1.30617
New value of Value function: 1.30617
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 892
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0229512
New value of Value function: 0.448722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 893
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00906077
New value of Value function: 0.337246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 894
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0769565
New value of Value function: 0.337246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 895
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.447824
New value of Value function: 0.447824
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 896
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.500823
New value of Value function: 0.500823
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 897
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.129961
New value of Value function: 0.129961
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 165
New value of Q matrix: 1.32239
New value of Value function: 1.32239
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 899
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.151165
New value of Value function: 0.151165
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 900
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.511611
New value of Value function: 1.32239
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 901
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 1.31974
New value of Value function: 1.31974
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 902
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.426617
New value of Value function: 1.31974
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 903
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.480076
New value of Value function: 1.31974
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 904
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.49423
New value of Value function: 1.31974
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 905
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 167
New value of Q matrix: 1.34236
New value of Value function: 1.34236
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 906
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.553527
New value of Value function: 0.553527
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 907
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.172304
New value of Value function: 0.172304
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 908
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.525542
New value of Value function: 1.34236
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 909
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.541881
New value of Value function: 1.34236
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 910
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 1.33968
New value of Value function: 1.33968
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 911
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 169
New value of Q matrix: 1.35598
New value of Value function: 1.35598
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 912
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0279676
New value of Value function: 0.172304
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 913
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0324557
New value of Value function: 0.553527
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 914
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0823222
New value of Value function: 0.553527
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 915
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.037877
New value of Value function: 0.553527
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 916
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0065051
New value of Value function: 0.337246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 917
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00455547
New value of Value function: 0.302595
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 918
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00919254
New value of Value function: 0.127472
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 919
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000803254
New value of Value function: 0.00434777
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 920
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00229449
New value of Value function: 0.00434777
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 921
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.190369
New value of Value function: 0.190369
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 922
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.302613
New value of Value function: 0.302613
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 923
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.393299
New value of Value function: 0.393299
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 924
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.17674
New value of Value function: 0.17674
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 925
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.539439
New value of Value function: 1.35598
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 926
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.508753
New value of Value function: 1.35598
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 1.35327
New value of Value function: 1.35327
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 171
New value of Q matrix: 1.36939
New value of Value function: 1.36939
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 929
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.197854
New value of Value function: 0.197854
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 930
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 172
New value of Q matrix: 1.38556
New value of Value function: 1.38556
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 931
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.126948
New value of Value function: 0.197854
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 932
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.139902
New value of Value function: 0.139902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 933
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 173
New value of Q matrix: 1.40037
New value of Value function: 1.40037
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 934
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.162311
New value of Value function: 0.162311
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 174
New value of Q matrix: 1.41528
New value of Value function: 1.41528
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 936
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0198842
New value of Value function: 0.162311
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 937
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.318378
New value of Value function: 0.318378
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 938
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.184539
New value of Value function: 0.184539
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 175
New value of Q matrix: 1.4303
New value of Value function: 1.4303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 940
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.206594
New value of Value function: 0.206594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 176
New value of Q matrix: 1.44525
New value of Value function: 1.44525
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 942
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.12797
New value of Value function: 0.197854
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 943
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.219912
New value of Value function: 0.219912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 944
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 177
New value of Q matrix: 1.46031
New value of Value function: 1.46031
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 945
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.241799
New value of Value function: 0.241799
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 178
New value of Q matrix: 1.47545
New value of Value function: 1.47545
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 947
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.129763
New value of Value function: 0.241799
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 948
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.263521
New value of Value function: 0.263521
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 179
New value of Q matrix: 1.49069
New value of Value function: 1.49069
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 950
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.285083
New value of Value function: 0.285083
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.557876
New value of Value function: 1.49069
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.52541
New value of Value function: 1.49069
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 180
New value of Q matrix: 1.50417
New value of Value function: 1.50417
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 954
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.20673
New value of Value function: 0.20673
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.44516
New value of Value function: 1.50417
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.541977
New value of Value function: 1.50417
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.558213
New value of Value function: 1.50417
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 181
New value of Q matrix: 1.51781
New value of Value function: 1.51781
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 959
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.229916
New value of Value function: 0.229916
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 960
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 182
New value of Q matrix: 1.53159
New value of Value function: 1.53159
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 961
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.252886
New value of Value function: 0.252886
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 183
New value of Q matrix: 1.54551
New value of Value function: 1.54551
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 963
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0151782
New value of Value function: 0.252886
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 964
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.252008
New value of Value function: 0.252008
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 965
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00871709
New value of Value function: 0.302613
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 966
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.251504
New value of Value function: 0.251504
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 967
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.313554
New value of Value function: 0.313554
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 968
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.389985
New value of Value function: 0.389985
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 969
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.275647
New value of Value function: 0.275647
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 184
New value of Q matrix: 1.55957
New value of Value function: 1.55957
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 971
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.298207
New value of Value function: 0.298207
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 185
New value of Q matrix: 1.57374
New value of Value function: 1.57374
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 973
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.32057
New value of Value function: 0.32057
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 186
New value of Q matrix: 1.58804
New value of Value function: 1.58804
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 975
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.342743
New value of Value function: 0.342743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 187
New value of Q matrix: 1.60245
New value of Value function: 1.60245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 977
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.125429
New value of Value function: 0.342743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 978
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0218944
New value of Value function: 0.342743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 979
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.388354
New value of Value function: 0.388354
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 980
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.364732
New value of Value function: 0.364732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.575892
New value of Value function: 1.60245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.557494
New value of Value function: 1.60245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 1.59924
New value of Value function: 1.59924
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.593161
New value of Value function: 1.59924
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 189
New value of Q matrix: 1.61425
New value of Value function: 1.61425
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 986
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0824078
New value of Value function: 0.388354
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 987
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.409644
New value of Value function: 0.409644
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.5754
New value of Value function: 1.61425
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 1.61102
New value of Value function: 1.61102
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 191
New value of Q matrix: 1.62617
New value of Value function: 1.62617
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 991
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.430722
New value of Value function: 0.430722
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 192
New value of Q matrix: 1.6414
New value of Value function: 1.6414
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 993
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.451653
New value of Value function: 0.451653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.576264
New value of Value function: 1.6414
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 193
New value of Q matrix: 1.6543
New value of Value function: 1.6543
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 996
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.341788
New value of Value function: 0.341788
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.466034
New value of Value function: 1.6543
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.486491
New value of Value function: 1.6543
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 194
New value of Q matrix: 1.66778
New value of Value function: 1.66778
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1000
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0295863
New value of Value function: 0.364732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1001
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0118548
New value of Value function: 0.451653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1002
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00799227
New value of Value function: 0.313554
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1003
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0087911
New value of Value function: 0.313554
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1004
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.312927
New value of Value function: 0.312927
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1005
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.133579
New value of Value function: 0.312927
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1006
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.387458
New value of Value function: 0.387458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1007
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.594758
New value of Value function: 1.66778
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1008
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.593912
New value of Value function: 1.66778
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1009
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 1.66445
New value of Value function: 1.66445
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1010
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 196
New value of Q matrix: 1.67813
New value of Value function: 1.67813
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1011
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0346272
New value of Value function: 0.387458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1012
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.374798
New value of Value function: 0.374798
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1013
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0696043
New value of Value function: 0.451653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1014
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0888894
New value of Value function: 0.451653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1015
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0177699
New value of Value function: 0.451653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1016
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.400084
New value of Value function: 0.400084
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1017
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.309588
New value of Value function: 0.309588
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1018
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.611504
New value of Value function: 1.67813
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1019
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 197
New value of Q matrix: 1.69154
New value of Value function: 1.69154
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1020
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0218868
New value of Value function: 0.387458
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1021
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.410156
New value of Value function: 0.410156
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1022
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 198
New value of Q matrix: 1.7051
New value of Value function: 1.7051
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1023
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.040681
New value of Value function: 0.410156
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1024
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.374048
New value of Value function: 0.374048
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1025
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00908695
New value of Value function: 0.374048
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1026
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0653577
New value of Value function: 0.0653577
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1027
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00531584
New value of Value function: 0.0609384
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1028
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.354865
New value of Value function: 0.354865
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1029
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00720151
New value of Value function: 0.302613
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1030
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.0693972
New value of Value function: 0.400084
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1031
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0115971
New value of Value function: 0.0609384
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1032
----------
State: 5977
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.414969
New value of Value function: 0.414969
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1033
----------
State: 5305
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.459465
New value of Value function: 0.459465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1034
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.0807901
New value of Value function: 0.410156
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1035
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0134442
New value of Value function: 0.309588
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1036
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0131079
New value of Value function: 0.451653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1037
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.3733
New value of Value function: 0.3733
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1038
----------
State: 5353
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0732795
New value of Value function: 0.3733
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1039
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.304691
New value of Value function: 0.304691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1040
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.450003
New value of Value function: 0.450003
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1041
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.0870217
New value of Value function: 0.410156
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1042
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.334088
New value of Value function: 0.334088
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1043
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 199
New value of Q matrix: 1.71838
New value of Value function: 1.71838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1044
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.432884
New value of Value function: 0.432884
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1045
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.630205
New value of Value function: 1.71838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1046
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 200
New value of Q matrix: 1.7318
New value of Value function: 1.7318
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1047
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.455399
New value of Value function: 0.455399
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1048
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 201
New value of Q matrix: 1.74536
New value of Value function: 1.74536
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1049
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.477707
New value of Value function: 0.477707
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1050
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 202
New value of Q matrix: 1.75905
New value of Value function: 1.75905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1051
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.499816
New value of Value function: 0.499816
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1052
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.508424
New value of Value function: 1.75905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1053
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 203
New value of Q matrix: 1.77287
New value of Value function: 1.77287
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1054
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.521731
New value of Value function: 0.521731
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1055
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 204
New value of Q matrix: 1.7868
New value of Value function: 1.7868
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1056
----------
State: 4681
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.145188
New value of Value function: 0.521731
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1057
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.359568
New value of Value function: 0.359568
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1058
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 205
New value of Q matrix: 1.79754
New value of Value function: 1.79754
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1059
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.384733
New value of Value function: 0.384733
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1060
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.530612
New value of Value function: 1.79754
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1061
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.552355
New value of Value function: 1.79754
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1062
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 1.76539
New value of Value function: 1.76539
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1063
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.165194
New value of Value function: 0.211123
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1064
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.408815
New value of Value function: 0.408815
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1065
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 207
New value of Q matrix: 1.77744
New value of Value function: 1.77744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1066
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.432633
New value of Value function: 0.432633
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1067
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.614857
New value of Value function: 1.77744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1068
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.614028
New value of Value function: 1.77744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1069
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 1.77388
New value of Value function: 1.77388
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1070
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 209
New value of Q matrix: 1.78619
New value of Value function: 1.78619
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1071
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.456132
New value of Value function: 0.456132
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1072
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 210
New value of Q matrix: 1.79868
New value of Value function: 1.79868
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1073
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.143337
New value of Value function: 0.456132
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1074
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.239276
New value of Value function: 0.239276
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1075
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 1.76701
New value of Value function: 1.76701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1076
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.266297
New value of Value function: 0.266297
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1077
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.573114
New value of Value function: 1.76701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1078
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.649407
New value of Value function: 1.76701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1079
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.633554
New value of Value function: 1.76701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1080
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.593458
New value of Value function: 1.76701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1081
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.613395
New value of Value function: 1.76701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1082
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.668225
New value of Value function: 1.76701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1083
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 1.76348
New value of Value function: 1.76348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1084
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.686603
New value of Value function: 1.76348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1085
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 1.733
New value of Value function: 1.733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1086
----------
State: 73
	Distance: 0
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0311941
New value of Value function: 0.266297
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1087
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5833
	Distance: 10
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 81
New value of Q matrix: 0.713953
New value of Value function: 1.733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1088
----------
State: 5833
	Distance: 10
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0311941
New value of Value function: 0.0601076
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1089
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.652077
New value of Value function: 1.733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1090
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.632321
New value of Value function: 1.733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1091
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.650869
New value of Value function: 1.733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1092
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.670229
New value of Value function: 1.733
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1093
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 1.72954
New value of Value function: 1.72954
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1094
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 1.72608
New value of Value function: 1.72608
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1095
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 1.72263
New value of Value function: 1.72263
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1096
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.668859
New value of Value function: 1.72263
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1097
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 217
New value of Q matrix: 1.73189
New value of Value function: 1.73189
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1098
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0294501
New value of Value function: 0.206594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1099
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.605558
New value of Value function: 0.605558
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1100
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.170266
New value of Value function: 0.170266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1101
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.107875
New value of Value function: 0.107875
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.687999
New value of Value function: 1.73189
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 1.72843
New value of Value function: 1.72843
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 219
New value of Q matrix: 1.7358
New value of Value function: 1.7358
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1105
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00429287
New value of Value function: 0.107875
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1106
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.136962
New value of Value function: 0.136962
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 220
New value of Q matrix: 1.74355
New value of Value function: 1.74355
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1108
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.165606
New value of Value function: 0.165606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.633944
New value of Value function: 1.74355
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.731058
New value of Value function: 1.74355
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 221
New value of Q matrix: 1.7524
New value of Value function: 1.7524
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1112
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0369611
New value of Value function: 0.206594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1113
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.504721
New value of Value function: 0.504721
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1114
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.234005
New value of Value function: 0.234005
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 222
New value of Q matrix: 1.76156
New value of Value function: 1.76156
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1116
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0453069
New value of Value function: 0.234005
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1117
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.558839
New value of Value function: 0.558839
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1118
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.261033
New value of Value function: 0.261033
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 223
New value of Q matrix: 1.77103
New value of Value function: 1.77103
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1120
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.287691
New value of Value function: 0.287691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 224
New value of Q matrix: 1.78079
New value of Value function: 1.78079
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1122
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0124591
New value of Value function: 0.287691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1123
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.313992
New value of Value function: 0.313992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 225
New value of Q matrix: 1.79082
New value of Value function: 1.79082
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1125
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.339947
New value of Value function: 0.339947
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 226
New value of Q matrix: 1.80113
New value of Value function: 1.80113
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1127
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0183289
New value of Value function: 0.339947
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1128
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0240814
New value of Value function: 0.339947
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1129
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.365568
New value of Value function: 0.365568
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.653685
New value of Value function: 1.80113
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 227
New value of Q matrix: 1.81168
New value of Value function: 1.81168
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1132
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.390867
New value of Value function: 0.390867
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.706849
New value of Value function: 1.81168
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 1.80806
New value of Value function: 1.80806
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.688027
New value of Value function: 1.80806
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.748982
New value of Value function: 1.80806
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 229
New value of Q matrix: 1.82011
New value of Value function: 1.82011
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1138
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0240754
New value of Value function: 0.456132
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1139
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.604347
New value of Value function: 0.604347
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1140
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.65239
New value of Value function: 0.65239
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1141
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0187957
New value of Value function: 0.0187957
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1142
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0488625
New value of Value function: 0.65239
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1143
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.702407
New value of Value function: 0.702407
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1144
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.169842
New value of Value function: 0.169842
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1145
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5253
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000680295
New value of Value function: 0.165606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1146
----------
State: 5253
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.032762
New value of Value function: 0.032762
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 230
New value of Q matrix: 1.82405
New value of Value function: 1.82405
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1148
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000468304
New value of Value function: 0.0187957
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1149
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0010584
New value of Value function: 0.0187957
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1150
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00209797
New value of Value function: 0.00209797
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1151
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.174561
New value of Value function: 0.174561
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1152
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000797261
New value of Value function: 0.0187957
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1153
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00417933
New value of Value function: 0.0187957
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1154
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.231408
New value of Value function: 0.231408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1155
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0214769
New value of Value function: 0.0214769
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1156
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 7
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.166445
New value of Value function: 0.166445
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1157
----------
State: 4101
	Distance: 7
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 7
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1158
----------
State: 4101
	Distance: 7
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.062996
New value of Value function: 0.062996
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1159
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 7
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.16425
New value of Value function: 0.16425
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1160
----------
State: 4101
	Distance: 7
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0328328
New value of Value function: 0.062996
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 231
New value of Q matrix: 1.82795
New value of Value function: 1.82795
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1162
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0082611
New value of Value function: 0.0214769
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1163
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.287167
New value of Value function: 0.287167
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1164
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0336907
New value of Value function: 0.0336907
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1165
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.748965
New value of Value function: 0.748965
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1166
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0329031
New value of Value function: 0.0336907
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 232
New value of Q matrix: 1.832
New value of Value function: 1.832
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1168
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00298091
New value of Value function: 0.0336907
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1169
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00718793
New value of Value function: 0.165606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1170
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.19527
New value of Value function: 0.19527
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 233
New value of Q matrix: 1.83887
New value of Value function: 1.83887
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1172
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.224464
New value of Value function: 0.224464
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 234
New value of Q matrix: 1.84614
New value of Value function: 1.84614
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1174
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.253206
New value of Value function: 0.253206
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.725943
New value of Value function: 1.84614
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 1.84245
New value of Value function: 1.84245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.673776
New value of Value function: 1.84245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.70743
New value of Value function: 1.84245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.744588
New value of Value function: 1.84245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.76286
New value of Value function: 1.84245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.767166
New value of Value function: 1.84245
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 1.83876
New value of Value function: 1.83876
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.693398
New value of Value function: 1.83876
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 1.83508
New value of Value function: 1.83508
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.712561
New value of Value function: 1.83508
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 238
New value of Q matrix: 1.84294
New value of Value function: 1.84294
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1187
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0026443
New value of Value function: 0.253206
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1188
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0359734
New value of Value function: 0.0359734
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1189
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5829
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.160965
New value of Value function: 0.160965
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1190
----------
State: 5829
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0331729
New value of Value function: 0.0331729
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.726455
New value of Value function: 1.84294
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.745098
New value of Value function: 1.84294
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 1.83925
New value of Value function: 1.83925
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.763303
New value of Value function: 1.83925
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.784929
New value of Value function: 1.83925
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 240
New value of Q matrix: 1.84703
New value of Value function: 1.84703
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1197
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.281388
New value of Value function: 0.281388
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.780849
New value of Value function: 1.84703
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 1.84333
New value of Value function: 1.84333
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 242
New value of Q matrix: 1.85153
New value of Value function: 1.85153
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1201
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.309088
New value of Value function: 0.309088
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 243
New value of Q matrix: 1.86006
New value of Value function: 1.86006
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1203
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00815499
New value of Value function: 0.309088
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1204
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.336387
New value of Value function: 0.336387
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 244
New value of Q matrix: 1.86892
New value of Value function: 1.86892
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1206
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.3633
New value of Value function: 0.3633
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 245
New value of Q matrix: 1.87808
New value of Value function: 1.87808
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1208
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.389839
New value of Value function: 0.389839
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 246
New value of Q matrix: 1.88753
New value of Value function: 1.88753
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1210
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.416018
New value of Value function: 0.416018
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 247
New value of Q matrix: 1.89727
New value of Value function: 1.89727
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1212
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.441849
New value of Value function: 0.441849
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.799383
New value of Value function: 1.89727
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.732461
New value of Value function: 1.89727
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.817546
New value of Value function: 1.89727
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.751963
New value of Value function: 1.89727
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 1.89348
New value of Value function: 1.89348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.835278
New value of Value function: 1.89348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.771006
New value of Value function: 1.89348
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 1.88969
New value of Value function: 1.88969
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.852587
New value of Value function: 1.88969
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 1.88591
New value of Value function: 1.88591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.781983
New value of Value function: 1.88591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.80029
New value of Value function: 1.88591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.818231
New value of Value function: 1.88591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 1.88214
New value of Value function: 1.88214
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.803109
New value of Value function: 1.88214
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 252
New value of Q matrix: 1.88451
New value of Value function: 1.88451
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1229
----------
State: 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00795328
New value of Value function: 0.00795328
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1230
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0149974
New value of Value function: 0.441849
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1231
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0608098
New value of Value function: 0.441849
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1232
----------
State: 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0339211
New value of Value function: 0.0339211
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 253
New value of Q matrix: 1.88747
New value of Value function: 1.88747
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1234
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0359015
New value of Value function: 0.0359015
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1235
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0358297
New value of Value function: 0.0358297
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1236
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0485944
New value of Value function: 0.0485944
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1237
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.79486
New value of Value function: 0.79486
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1238
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0505199
New value of Value function: 0.0505199
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1239
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.165699
New value of Value function: 0.165699
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1240
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.466986
New value of Value function: 0.466986
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 254
New value of Q matrix: 1.89812
New value of Value function: 1.89812
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1242
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.491813
New value of Value function: 0.491813
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.836032
New value of Value function: 1.89812
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.853478
New value of Value function: 1.89812
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 1.89433
New value of Value function: 1.89433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 256
New value of Q matrix: 1.89735
New value of Value function: 1.89735
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1247
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0504189
New value of Value function: 0.0504189
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1248
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.063718
New value of Value function: 0.063718
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1249
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.013805
New value of Value function: 0.79486
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1250
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0099488
New value of Value function: 0.304691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1251
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.372904
New value of Value function: 0.372904
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1252
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0202412
New value of Value function: 0.79486
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1253
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.439754
New value of Value function: 0.439754
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1254
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0277519
New value of Value function: 0.79486
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1255
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.505266
New value of Value function: 0.505266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1256
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.84011
New value of Value function: 0.84011
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1257
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0654262
New value of Value function: 0.0654262
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1258
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5829
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.162982
New value of Value function: 0.162982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1259
----------
State: 5829
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0341523
New value of Value function: 0.0341523
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.87056
New value of Value function: 1.89735
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 257
New value of Q matrix: 1.90825
New value of Value function: 1.90825
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1262
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.516325
New value of Value function: 0.516325
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 258
New value of Q matrix: 1.91938
New value of Value function: 1.91938
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1264
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.540547
New value of Value function: 0.540547
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.887698
New value of Value function: 1.91938
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 259
New value of Q matrix: 1.93073
New value of Value function: 1.93073
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1267
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.564489
New value of Value function: 0.564489
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 260
New value of Q matrix: 1.94227
New value of Value function: 1.94227
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1269
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.58816
New value of Value function: 0.58816
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 261
New value of Q matrix: 1.95401
New value of Value function: 1.95401
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1271
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.611569
New value of Value function: 0.611569
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.905116
New value of Value function: 1.95401
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 262
New value of Q matrix: 1.95554
New value of Value function: 1.95554
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1274
----------
State: 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00117767
New value of Value function: 0.0339211
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1275
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0652954
New value of Value function: 0.0652954
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1276
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0651648
New value of Value function: 0.0651648
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1277
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0789835
New value of Value function: 0.0789835
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1278
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.83843
New value of Value function: 0.83843
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1279
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.883083
New value of Value function: 0.883083
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1280
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0432533
New value of Value function: 0.0789835
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1281
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0257057
New value of Value function: 0.611569
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1282
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.634538
New value of Value function: 0.634538
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 263
New value of Q matrix: 1.96785
New value of Value function: 1.96785
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1284
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0194136
New value of Value function: 0.634538
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1285
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00523094
New value of Value function: 0.634538
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1286
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0158955
New value of Value function: 0.0601326
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1287
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0530542
New value of Value function: 0.883083
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1288
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0062274
New value of Value function: 0.287167
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1289
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0100591
New value of Value function: 0.287167
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1290
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.614698
New value of Value function: 0.614698
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1291
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0554653
New value of Value function: 0.390867
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1292
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0265093
New value of Value function: 0.614698
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1293
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0176375
New value of Value function: 0.505266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1294
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00225389
New value of Value function: 0.505266
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1295
----------
State: 5401
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.125147
New value of Value function: 0.125147
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1296
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.11972
New value of Value function: 0.11972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1297
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00293368
New value of Value function: 0.00293368
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1298
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.166758
New value of Value function: 0.166758
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1299
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0145023
New value of Value function: 0.390867
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1300
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.48243
New value of Value function: 0.48243
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.791007
New value of Value function: 1.96785
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 264
New value of Q matrix: 1.97553
New value of Value function: 1.97553
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1303
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.418609
New value of Value function: 0.418609
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.871095
New value of Value function: 1.97553
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 1.97158
New value of Value function: 1.97158
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.922503
New value of Value function: 1.97158
New value of Policy matrix: 0

