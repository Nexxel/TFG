=======================================
Simulation: 1
Iteration: 1
----------
State: 34025
	Distance: 14
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 42953
	Distance: 18
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38633
	Distance: 16
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 8
----------
State: 38633
	Distance: 16
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 34309
	Distance: 14
	Angle: 21
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 22
----------
State: 34309
	Distance: 14
	Angle: 21
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34309
	Distance: 14
	Angle: 21
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 34309
	Distance: 14
	Angle: 21
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 25
----------
State: 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 28
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 29
----------
State: 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118819
New value of Value function: 0.118819
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 31
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0014256
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.03992
New value of Value function: 0.03992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 36
----------
State: 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 37
----------
State: 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00071856
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00071856
New value of Value function: 0.03992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0398402
New value of Value function: 0.0398402
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142131
New value of Value function: 0.0398402
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00211421
New value of Value function: 0.0398402
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00278905
New value of Value function: 0.0398402
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00142272
New value of Value function: 0.0398402
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00211001
New value of Value function: 0.0398402
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0397605
New value of Value function: 0.0397605
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.039681
New value of Value function: 0.039681
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00278207
New value of Value function: 0.039681
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0396016
New value of Value function: 0.0396016
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0021071
New value of Value function: 0.0396016
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0395224
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00344467
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00277636
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000711403
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00140858
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00408718
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00471684
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00343783
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00533391
New value of Value function: 0.0395224
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0394433
New value of Value function: 0.0394433
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 32101
	Distance: 13
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 0.0786545
New value of Value function: 0.0786545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 61
----------
State: 32101
	Distance: 13
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 63
----------
State: 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 43717
	Distance: 18
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 43717
	Distance: 18
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00141578
New value of Value function: 0.00141578
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00664301
New value of Value function: 0.0786545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0784972
New value of Value function: 0.0784972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00344083
New value of Value function: 0.0784972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 68
----------
State: 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00211714
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00478496
New value of Value function: 0.0784972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00610221
New value of Value function: 0.0784972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 0.116947
New value of Value function: 0.116947
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 72
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 73
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 74
----------
State: 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00210504
New value of Value function: 0.00210504
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 0.154646
New value of Value function: 0.154646
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.78907e-05
New value of Value function: 0.00210504
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.50236e-05
New value of Value function: 0.00210504
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00484656
New value of Value function: 0.00484656
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 29893
	Distance: 12
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 0.191553
New value of Value function: 0.191553
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 80
----------
State: 29893
	Distance: 12
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.72381e-05
New value of Value function: 8.72381e-05
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 81
----------
State: 32197
	Distance: 13
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34213
	Distance: 14
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00484656
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 34213
	Distance: 14
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34213
	Distance: 14
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 34213
	Distance: 14
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213875
New value of Value function: 0.00213875
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 84
----------
State: 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213875
New value of Value function: 0.118819
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34405
	Distance: 14
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.176443
New value of Value function: 0.176443
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 34405
	Distance: 14
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 39013
	Distance: 16
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 39013
	Distance: 16
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34409
	Distance: 14
	Angle: 22
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 88
----------
State: 34409
	Distance: 14
	Angle: 22
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 34405
	Distance: 14
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 34405
	Distance: 14
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00344795
New value of Value function: 0.00344795
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00681702
New value of Value function: 0.191553
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.19117
New value of Value function: 0.19117
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00942122
New value of Value function: 0.19117
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 34405
	Distance: 14
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 0.227408
New value of Value function: 0.227408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 94
----------
State: 34405
	Distance: 14
	Angle: 22
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 38729
	Distance: 16
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00344795
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 95
----------
State: 38729
	Distance: 16
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43337
	Distance: 18
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 96
----------
State: 43337
	Distance: 18
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43049
	Distance: 18
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 43049
	Distance: 18
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 98
----------
State: 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43049
	Distance: 18
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 99
----------
State: 43049
	Distance: 18
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43049
	Distance: 18
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 100
----------
State: 43049
	Distance: 18
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 101
----------
State: 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 102
----------
State: 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 103
----------
State: 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 104
----------
State: 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 105
----------
State: 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 106
----------
State: 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 42857
	Distance: 18
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 107
----------
State: 42857
	Distance: 18
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 108
----------
State: 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 42569
	Distance: 18
	Angle: 11
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 109
----------
State: 42569
	Distance: 18
	Angle: 11
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 110
----------
State: 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 111
----------
State: 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021384
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 112
----------
State: 47657
	Distance: 20
	Angle: 16
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 1289
	Distance: 0
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 113
----------
State: 1289
	Distance: 0
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 114
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 1385
	Distance: 0
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 115
----------
State: 1385
	Distance: 0
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47177
	Distance: 20
	Angle: 11
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 116
----------
State: 47177
	Distance: 20
	Angle: 11
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47177
	Distance: 20
	Angle: 11
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 117
----------
State: 47177
	Distance: 20
	Angle: 11
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 118
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 119
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 1289
	Distance: 0
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 121
----------
State: 1289
	Distance: 0
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.040013
New value of Value function: 0.040013
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 122
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47177
	Distance: 20
	Angle: 11
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 123
----------
State: 47177
	Distance: 20
	Angle: 11
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47273
	Distance: 20
	Angle: 12
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 124
----------
State: 47273
	Distance: 20
	Angle: 12
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 1385
	Distance: 0
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 125
----------
State: 1385
	Distance: 0
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04108
New value of Value function: 0.04108
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 126
----------
State: 47465
	Distance: 20
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 42857
	Distance: 18
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600194
New value of Value function: 0.0600194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 127
----------
State: 42857
	Distance: 18
	Angle: 14
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00108
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 128
----------
State: 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06108
New value of Value function: 0.06108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 129
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109944
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 130
----------
State: 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109944
New value of Value function: 0.06108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 131
----------
State: 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0609578
New value of Value function: 0.0609578
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 132
----------
State: 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0608359
New value of Value function: 0.0608359
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 133
----------
State: 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0621575
New value of Value function: 0.0621575
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 134
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0599188
New value of Value function: 0.0599188
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 135
----------
State: 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.121993
New value of Value function: 0.121993
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 136
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06108
New value of Value function: 0.06108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 137
----------
State: 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 138
----------
State: 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021384
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 139
----------
State: 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00209563
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 140
----------
State: 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43337
	Distance: 18
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 141
----------
State: 43337
	Distance: 18
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43337
	Distance: 18
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 142
----------
State: 43337
	Distance: 18
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00219587
New value of Value function: 0.00219587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.180652
New value of Value function: 0.180652
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 144
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00217689
New value of Value function: 0.06108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 145
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0053851
New value of Value function: 0.06108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 47753
	Distance: 20
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43337
	Distance: 18
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600395
New value of Value function: 0.180652
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 147
----------
State: 43337
	Distance: 18
	Angle: 19
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 34409
	Distance: 14
	Angle: 22
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 34409
	Distance: 14
	Angle: 22
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00409335
New value of Value function: 0.00409335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.010774
New value of Value function: 0.227408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0106035
New value of Value function: 0.227408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0146519
New value of Value function: 0.227408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0184522
New value of Value function: 0.227408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00547376
New value of Value function: 0.227408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0133261
New value of Value function: 0.227408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.017153
New value of Value function: 0.227408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.226953
New value of Value function: 0.226953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0208951
New value of Value function: 0.226953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0144766
New value of Value function: 0.226953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0182722
New value of Value function: 0.226953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0219919
New value of Value function: 0.226953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.2265
New value of Value function: 0.2265
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0256291
New value of Value function: 0.2265
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.226047
New value of Value function: 0.226047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0291853
New value of Value function: 0.226047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0326705
New value of Value function: 0.226047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0360859
New value of Value function: 0.226047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.022152
New value of Value function: 0.226047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.225594
New value of Value function: 0.225594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0257697
New value of Value function: 0.225594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0245379
New value of Value function: 0.225594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0281078
New value of Value function: 0.225594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00942498
New value of Value function: 0.225594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0316064
New value of Value function: 0.225594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0350349
New value of Value function: 0.225594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0394249
New value of Value function: 0.225594
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.225143
New value of Value function: 0.225143
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.22136
New value of Value function: 0.22136
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 178
----------
State: 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.08028
New value of Value function: 0.08028
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 179
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.060245
New value of Value function: 0.060245
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 180
----------
State: 2245
	Distance: 0
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00398449
New value of Value function: 0.08028
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0292388
New value of Value function: 0.22136
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0426209
New value of Value function: 0.22136
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0326385
New value of Value function: 0.22136
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0359702
New value of Value function: 0.22136
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.220918
New value of Value function: 0.220918
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.220476
New value of Value function: 0.220476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.013205
New value of Value function: 0.220476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0392193
New value of Value function: 0.220476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0383028
New value of Value function: 0.220476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0169095
New value of Value function: 0.220476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0205399
New value of Value function: 0.220476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.220035
New value of Value function: 0.220035
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0414974
New value of Value function: 0.220035
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0446281
New value of Value function: 0.220035
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0240897
New value of Value function: 0.220035
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 0.256719
New value of Value function: 0.256719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 197
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00110346
New value of Value function: 0.060245
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 198
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0021658
New value of Value function: 0.060245
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 199
----------
State: 34501
	Distance: 14
	Angle: 23
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 34505
	Distance: 14
	Angle: 23
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.90512e-05
New value of Value function: 0.060245
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 200
----------
State: 34505
	Distance: 14
	Angle: 23
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 201
----------
State: 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47849
	Distance: 20
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 202
----------
State: 47849
	Distance: 20
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43241
	Distance: 18
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 203
----------
State: 43241
	Distance: 18
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38633
	Distance: 16
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 204
----------
State: 38633
	Distance: 16
	Angle: 18
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 205
----------
State: 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 34217
	Distance: 14
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0620537
New value of Value function: 0.0620537
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 206
----------
State: 34217
	Distance: 14
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00317597
New value of Value function: 0.00317597
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 207
----------
State: 38821
	Distance: 16
	Angle: 20
	Height: 9
	Object picked: 0
	Arm folded: 1
State': 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00321294
New value of Value function: 0.176443
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 208
----------
State: 38825
	Distance: 16
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 34217
	Distance: 14
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.12087
New value of Value function: 0.12087
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 209
----------
State: 34217
	Distance: 14
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00317597
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 210
----------
State: 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109944
New value of Value function: 0.00109944
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 211
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0598782
New value of Value function: 0.0599188
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 212
----------
State: 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.97899e-05
New value of Value function: 0.00109944
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 213
----------
State: 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.9184e-05
New value of Value function: 0.00109944
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 214
----------
State: 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 39017
	Distance: 16
	Angle: 22
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 215
----------
State: 39017
	Distance: 16
	Angle: 22
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 39113
	Distance: 16
	Angle: 23
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 216
----------
State: 39113
	Distance: 16
	Angle: 23
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 217
----------
State: 43433
	Distance: 18
	Angle: 20
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00215599
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 218
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00635593
New value of Value function: 0.0599188
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 219
----------
State: 43145
	Distance: 18
	Angle: 17
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47561
	Distance: 20
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0599188
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 220
----------
State: 47561
	Distance: 20
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47561
	Distance: 20
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 221
----------
State: 47561
	Distance: 20
	Angle: 15
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 1.296e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 222
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 223
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 224
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.56608e-05
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 225
----------
State: 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
State': 47369
	Distance: 20
	Angle: 13
	Height: 10
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.81076e-05
New value of Value function: 0.00072
New value of Policy matrix: 3

